{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RoBERTASUMEXT_eval2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlEffL_vvt0q",
        "outputId": "07b8dfff-912b-4938-b0bd-4bf0656902c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp9RhWPtdXBw",
        "outputId": "e96893da-2f14-4fa9-a11d-ae1238ebb6f4"
      },
      "source": [
        "# GPU Settings\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May  2 10:39:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF-eIXqnmFd2",
        "outputId": "0f26ff55-7e0b-4e79-9b94-494eb45aab78"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqWYHEVEwMDV",
        "outputId": "eb475de8-d9dc-4223-911e-5bf2e5c34e58"
      },
      "source": [
        "cd /content/drive/MyDrive/nn4nlp_project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u536tcr0yqdC",
        "outputId": "63170371-81e6-4e64-c5e4-bba71519231c"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/   \u001b[01;34mlogs\u001b[0m/    \u001b[01;34mpyrouge\u001b[0m/  \u001b[01;34mresults\u001b[0m/  \u001b[01;34mxsum_abs_baseline\u001b[0m/\n",
            "\u001b[01;34mfiles\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34mrefs\u001b[0m/     \u001b[01;34mtemp\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGdCcpqQwZ4K",
        "outputId": "db758a08-b186-41e9-b4ff-856a2b7d3a80"
      },
      "source": [
        "cd files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ8Gi0QZFWej",
        "outputId": "e818a988-db5e-460f-a7cf-d2c6c30b0554"
      },
      "source": [
        "!unzip bertext_cnndm_transformer.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  bertext_cnndm_transformer.zip\n",
            "replace bertext_cnndm_transformer.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB_v6Lh8RHs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4bbf8cb-1b30-493e-cd27-0c0f573317cf"
      },
      "source": [
        "!pip install pyrouge --upgrade\n",
        "!pip install https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
        "!pip install pyrouge\n",
        "!pip show pyrouge\n",
        "!git clone https://github.com/andersjo/pyrouge.git\n",
        "from pyrouge import Rouge155\n",
        "!pyrouge_set_rouge_path 'pyrouge/tools/ROUGE-1.5.5'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyrouge\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/85/e522dd6b36880ca19dcf7f262b22365748f56edc6f455e7b6a37d0382c32/pyrouge-0.1.3.tar.gz (60kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 20kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-cp37-none-any.whl size=191613 sha256=b1b9b3bbb78bdea56e5cff114dd5a2b0474ff0219f541c64ba9c1dc0c807d8e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/d3/0c/e5b04e15b6b87c42e980de3931d2686e14d36e045058983599\n",
            "Successfully built pyrouge\n",
            "Installing collected packages: pyrouge\n",
            "Successfully installed pyrouge-0.1.3\n",
            "Collecting https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "\u001b[?25l  Downloading https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "\u001b[K     - 337kB 447kB/s\n",
            "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): pyrouge==0.1.3 from https://github.com/bheinzerling/pyrouge/archive/master.zip in /usr/local/lib/python3.7/dist-packages\n",
            "Building wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-cp37-none-any.whl size=191913 sha256=8db1d22531ff08162d3cbf06d2c4ebf50d62a7c9fa9b0fcc9da0d26da3b464d4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qf8_wtub/wheels/70/02/b4/a23b5feb5980a5eb940441cb04ec1e17d5f18344138efbecf8\n",
            "Successfully built pyrouge\n",
            "Requirement already satisfied: pyrouge in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Name: pyrouge\n",
            "Version: 0.1.3\n",
            "Summary: A Python wrapper for the ROUGE summarization evaluation package.\n",
            "Home-page: https://github.com/noutenki/pyrouge\n",
            "Author: Benjamin Heinzerling, Anders Johannsen\n",
            "Author-email: benjamin.heinzerling@h-its.org\n",
            "License: LICENSE.txt\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: \n",
            "Required-by: \n",
            "fatal: destination path 'pyrouge' already exists and is not an empty directory.\n",
            "2021-05-02 10:39:28,521 [MainThread  ] [INFO ]  Set ROUGE home directory to pyrouge/tools/ROUGE-1.5.5.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWpax6fMKQFF"
      },
      "source": [
        "!chmod 777 '/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1eBg0X0LBzZ"
      },
      "source": [
        "!chmod 777 'pyrouge/tools/ROUGE-1.5.5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyJTYO4JXn7C"
      },
      "source": [
        "!chmod 777 'pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UVuNBqSc7vr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0927646a-0a37-4c08-dfb6-b698358e3378"
      },
      "source": [
        "!pyrouge_set_rouge_path '/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-02 10:39:29,883 [MainThread  ] [INFO ]  Set ROUGE home directory to /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCfbL52EaVxr",
        "outputId": "8b6711ad-6fa5-4773-e858-1b423ee6c77e"
      },
      "source": [
        "!python3 -m pyrouge.test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-01 14:25:52,721 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp2st3glh3/rouge_conf.xml\n",
            "F2021-05-01 14:25:52,810 [MainThread  ] [INFO ]  Processing files in data/SL2003_models_plain_text.\n",
            "2021-05-01 14:25:52,810 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-06.html.\n",
            "2021-05-01 14:25:52,810 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-09.html.\n",
            "2021-05-01 14:25:52,810 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-13.html.\n",
            "2021-05-01 14:25:52,810 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-18.html.\n",
            "2021-05-01 14:25:52,811 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-21.html.\n",
            "2021-05-01 14:25:52,811 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-17.html.\n",
            "2021-05-01 14:25:52,811 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-01.html.\n",
            "2021-05-01 14:25:52,811 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-07.html.\n",
            "2021-05-01 14:25:52,811 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-08.html.\n",
            "2021-05-01 14:25:52,811 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-20.html.\n",
            "2021-05-01 14:25:52,812 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-15.html.\n",
            "2021-05-01 14:25:52,812 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-22.html.\n",
            "2021-05-01 14:25:52,812 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-12.html.\n",
            "2021-05-01 14:25:52,812 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-02.html.\n",
            "2021-05-01 14:25:52,812 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-14.html.\n",
            "2021-05-01 14:25:52,813 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-19.html.\n",
            "2021-05-01 14:25:52,813 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-16.html.\n",
            "2021-05-01 14:25:52,813 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-25.html.\n",
            "2021-05-01 14:25:52,813 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-23.html.\n",
            "2021-05-01 14:25:52,813 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-11.html.\n",
            "2021-05-01 14:25:52,813 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-03.html.\n",
            "2021-05-01 14:25:52,814 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-05.html.\n",
            "2021-05-01 14:25:52,814 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-24.html.\n",
            "2021-05-01 14:25:52,814 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-04.html.\n",
            "2021-05-01 14:25:52,814 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-10.html.\n",
            "2021-05-01 14:25:52,814 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp0jzxkk7_.\n",
            ".2021-05-01 14:25:52,828 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp9o4isq32/rouge_conf.xml\n",
            "2021-05-01 14:25:52,828 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp9o4isq32/rouge_conf.xml\n",
            "Can't locate XML/Parser.pm in @INC (you may need to install the XML::Parser module) (@INC contains: /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5 /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.26.1 /usr/local/share/perl/5.26.1 /usr/lib/x86_64-linux-gnu/perl5/5.26 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.26 /usr/share/perl/5.26 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base) at /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/XML/DOM.pm line 41.\n",
            "BEGIN failed--compilation aborted at /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/XML/DOM.pm line 70.\n",
            "Compilation failed in require at /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl line 177.\n",
            "BEGIN failed--compilation aborted at /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl line 177.\n",
            "E2021-05-01 14:25:54,227 [MainThread  ] [INFO ]  Processing files in data/SL2003_models_rouge_format.\n",
            "2021-05-01 14:25:54,228 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-06.html.\n",
            "/usr/local/bin/pyrouge_convert_rouge_format_to_plain_text:14: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 14 of the file /usr/local/bin/pyrouge_convert_rouge_format_to_plain_text. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  soup = BeautifulSoup(html)\n",
            "2021-05-01 14:25:54,231 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-09.html.\n",
            "2021-05-01 14:25:54,232 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-13.html.\n",
            "2021-05-01 14:25:54,233 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-18.html.\n",
            "2021-05-01 14:25:54,234 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-21.html.\n",
            "2021-05-01 14:25:54,235 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-17.html.\n",
            "2021-05-01 14:25:54,236 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-01.html.\n",
            "2021-05-01 14:25:54,236 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-07.html.\n",
            "2021-05-01 14:25:54,237 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-08.html.\n",
            "2021-05-01 14:25:54,238 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-20.html.\n",
            "2021-05-01 14:25:54,239 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-15.html.\n",
            "2021-05-01 14:25:54,239 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-22.html.\n",
            "2021-05-01 14:25:54,240 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-12.html.\n",
            "2021-05-01 14:25:54,240 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-02.html.\n",
            "2021-05-01 14:25:54,241 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-14.html.\n",
            "2021-05-01 14:25:54,242 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-19.html.\n",
            "2021-05-01 14:25:54,242 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-16.html.\n",
            "2021-05-01 14:25:54,243 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-25.html.\n",
            "2021-05-01 14:25:54,244 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-23.html.\n",
            "2021-05-01 14:25:54,244 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-11.html.\n",
            "2021-05-01 14:25:54,245 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-03.html.\n",
            "2021-05-01 14:25:54,246 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-05.html.\n",
            "2021-05-01 14:25:54,246 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-24.html.\n",
            "2021-05-01 14:25:54,247 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-04.html.\n",
            "2021-05-01 14:25:54,248 [MainThread  ] [INFO ]  Processing SL.P.10.R.A.SL062003-10.html.\n",
            "2021-05-01 14:25:54,248 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpsev0v7fm.\n",
            ".E.2021-05-01 14:25:54,355 [MainThread  ] [INFO ]  Writing summaries.\n",
            "2021-05-01 14:25:54,355 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpepczjldc/system and model files to /tmp/tmpepczjldc/model.\n",
            "2021-05-01 14:25:54,355 [MainThread  ] [INFO ]  Processing files in data/systems_plain.\n",
            "2021-05-01 14:25:54,356 [MainThread  ] [INFO ]  Processing D30001.M.100.T.A.\n",
            "2021-05-01 14:25:54,356 [MainThread  ] [INFO ]  Processing D30003.M.100.T.A.\n",
            "2021-05-01 14:25:54,356 [MainThread  ] [INFO ]  Processing D30002.M.100.T.A.\n",
            "2021-05-01 14:25:54,357 [MainThread  ] [INFO ]  Processing D30005.M.100.T.A.\n",
            "2021-05-01 14:25:54,357 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpepczjldc/system.\n",
            "2021-05-01 14:25:54,357 [MainThread  ] [INFO ]  Processing files in data/models_plain.\n",
            "2021-05-01 14:25:54,357 [MainThread  ] [INFO ]  Processing D30005.M.100.T.G.\n",
            "2021-05-01 14:25:54,357 [MainThread  ] [INFO ]  Processing D30003.M.100.T.B.\n",
            "2021-05-01 14:25:54,358 [MainThread  ] [INFO ]  Processing D30001.M.100.T.C.\n",
            "2021-05-01 14:25:54,358 [MainThread  ] [INFO ]  Processing D30003.M.100.T.F.\n",
            "2021-05-01 14:25:54,358 [MainThread  ] [INFO ]  Processing D30003.M.100.T.C.\n",
            "2021-05-01 14:25:54,358 [MainThread  ] [INFO ]  Processing D30002.M.100.T.E.\n",
            "2021-05-01 14:25:54,359 [MainThread  ] [INFO ]  Processing D30001.M.100.T.D.\n",
            "2021-05-01 14:25:54,359 [MainThread  ] [INFO ]  Processing D30002.M.100.T.B.\n",
            "2021-05-01 14:25:54,359 [MainThread  ] [INFO ]  Processing D30005.M.100.T.B.\n",
            "2021-05-01 14:25:54,359 [MainThread  ] [INFO ]  Processing D30005.M.100.T.C.\n",
            "2021-05-01 14:25:54,360 [MainThread  ] [INFO ]  Processing D30001.M.100.T.B.\n",
            "2021-05-01 14:25:54,360 [MainThread  ] [INFO ]  Processing D30002.M.100.T.C.\n",
            "2021-05-01 14:25:54,360 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpepczjldc/model.\n",
            "2021-05-01 14:25:54,361 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp1lerkl1l/rouge_conf.xml\n",
            "2021-05-01 14:25:54,361 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp1lerkl1l/rouge_conf.xml\n",
            "Can't locate XML/Parser.pm in @INC (you may need to install the XML::Parser module) (@INC contains: /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5 /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.26.1 /usr/local/share/perl/5.26.1 /usr/lib/x86_64-linux-gnu/perl5/5.26 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.26 /usr/share/perl/5.26 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base) at /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/XML/DOM.pm line 41.\n",
            "BEGIN failed--compilation aborted at /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/XML/DOM.pm line 70.\n",
            "Compilation failed in require at /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl line 177.\n",
            "BEGIN failed--compilation aborted at /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl line 177.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pyrouge_evaluate_plain_text_files\", line 25, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/bin/pyrouge_evaluate_plain_text_files\", line 21, in main\n",
            "    output = rouge.convert_and_evaluate(args.system_id, args.split_sents)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyrouge/Rouge155.py\", line 361, in convert_and_evaluate\n",
            "    rouge_output = self.evaluate(system_id, rouge_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyrouge/Rouge155.py\", line 336, in evaluate\n",
            "    rouge_output = check_output(command).decode(\"UTF-8\")\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 411, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 512, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl', '-e', '/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data', '-c', '95', '-2', '-1', '-U', '-r', '1000', '-n', '4', '-w', '1.2', '-a', '-m', '/tmp/tmp1lerkl1l/rouge_conf.xml']' returned non-zero exit status 2.\n",
            "E.E..\n",
            "======================================================================\n",
            "ERROR: test_evaluation (pyrouge.tests.Rouge155_test.PyrougeTest)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyrouge/tests/Rouge155_test.py\", line 156, in test_evaluation\n",
            "    pyrouge_output = rouge.evaluate(system_id=11).strip()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyrouge/Rouge155.py\", line 336, in evaluate\n",
            "    rouge_output = check_output(command).decode(\"UTF-8\")\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 411, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 512, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl', '-e', '/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data', '-c', '95', '-2', '-1', '-U', '-r', '1000', '-n', '4', '-w', '1.2', '-a', '-m', '/tmp/tmp9o4isq32/rouge_conf.xml']' returned non-zero exit status 2.\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_options (pyrouge.tests.Rouge155_test.PyrougeTest)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyrouge/tests/Rouge155_test.py\", line 218, in test_options\n",
            "    pyrouge_output = check_output_clean(pyrouge_command)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyrouge/tests/Rouge155_test.py\", line 17, in <lambda>\n",
            "    check_output_clean = lambda c: check_output(c).decode(\"UTF-8\").strip()\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 411, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 488, in run\n",
            "    with Popen(*popenargs, **kwargs) as process:\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 800, in __init__\n",
            "    restore_signals, start_new_session)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1551, in _execute_child\n",
            "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'pyrouge_evaluate_plain_text_files.py': 'pyrouge_evaluate_plain_text_files.py'\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_rouge_for_plain_text (pyrouge.tests.Rouge155_test.PyrougeTest)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyrouge/tests/Rouge155_test.py\", line 173, in test_rouge_for_plain_text\n",
            "    pyrouge_output = check_output_clean(pyrouge_command.split())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyrouge/tests/Rouge155_test.py\", line 17, in <lambda>\n",
            "    check_output_clean = lambda c: check_output(c).decode(\"UTF-8\").strip()\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 411, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 512, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['pyrouge_evaluate_plain_text_files', '-m', 'data/models_plain', '-s', 'data/systems_plain', '-sfp', 'D(\\\\d+).M.100.T.A', '-mfp', 'D#ID#.M.100.T.[A-Z]', '-id', '1']' returned non-zero exit status 1.\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_write_config (pyrouge.tests.Rouge155_test.PyrougeTest)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyrouge/tests/Rouge155_test.py\", line 197, in test_write_config\n",
            "    check_output(command.split())\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 411, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 488, in run\n",
            "    with Popen(*popenargs, **kwargs) as process:\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 800, in __init__\n",
            "    restore_signals, start_new_session)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1551, in _execute_child\n",
            "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'pyrouge_write_config_file.py': 'pyrouge_write_config_file.py'\n",
            "\n",
            "======================================================================\n",
            "FAIL: test_config_file (pyrouge.tests.Rouge155_test.PyrougeTest)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyrouge/tests/Rouge155_test.py\", line 147, in test_config_file\n",
            "    add_data_path(\"ROUGE-test_11.xml\")))\n",
            "AssertionError: False is not true\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 11 tests in 1.699s\n",
            "\n",
            "FAILED (failures=1, errors=4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ-h1h45Lgj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317190c4-75a3-4a80-b3c8-2396c0427c56"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 16.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.41.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/8f/42959300c543b4d34bc9f9b54954471a33384c181084ed84f070763d7f37/boto3-1.17.62-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 21.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 19.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.15.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.0MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.62\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/60/ba830f93176fdc23166043298173ee2aecd5cf150f1ede51d6506f021deb/botocore-1.20.62-py2.py3-none-any.whl (7.5MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5MB 23.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.62->boto3->pytorch-transformers) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.62 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, sentencepiece, pytorch-transformers\n",
            "Successfully installed boto3-1.17.62 botocore-1.20.62 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVmZnEYgQnyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597d9db5-7bf3-4f96-bb2c-ac564aa57225"
      },
      "source": [
        "!sudo apt-get install libxml-parser-perl\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libauthen-sasl-perl libdata-dump-perl libencode-locale-perl\n",
            "  libfile-listing-perl libfont-afm-perl libhtml-form-perl libhtml-format-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhtml-tree-perl\n",
            "  libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl\n",
            "  libhttp-message-perl libhttp-negotiate-perl libio-html-perl\n",
            "  libio-socket-ssl-perl liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libtimedate-perl libtry-tiny-perl liburi-perl libwww-perl\n",
            "  libwww-robotrules-perl netbase perl-openssl-defaults\n",
            "Suggested packages:\n",
            "  libdigest-hmac-perl libgssapi-perl libcrypt-ssleay-perl libauthen-ntlm-perl\n",
            "The following NEW packages will be installed:\n",
            "  libauthen-sasl-perl libdata-dump-perl libencode-locale-perl\n",
            "  libfile-listing-perl libfont-afm-perl libhtml-form-perl libhtml-format-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhtml-tree-perl\n",
            "  libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl\n",
            "  libhttp-message-perl libhttp-negotiate-perl libio-html-perl\n",
            "  libio-socket-ssl-perl liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libtimedate-perl libtry-tiny-perl liburi-perl libwww-perl\n",
            "  libwww-robotrules-perl libxml-parser-perl netbase perl-openssl-defaults\n",
            "0 upgraded, 31 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 1,713 kB of archives.\n",
            "After this operation, 5,581 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 netbase all 5.4 [12.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdata-dump-perl all 1.23-1 [27.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfile-listing-perl all 6.04-1 [9,774 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfont-afm-perl all 1.20-2 [13.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-form-perl all 6.03-1 [23.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tree-perl all 5.07-1 [200 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-format-perl all 2.12-1 [41.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-cookies-perl all 6.04-1 [17.2 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-daemon-perl all 6.01-1 [17.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-negotiate-perl all 6.00-2 [13.4 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 perl-openssl-defaults amd64 3build1 [7,012 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnet-ssleay-perl amd64 1.84-1ubuntu0.2 [283 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libio-socket-ssl-perl all 2.060-3~ubuntu18.04.1 [173 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnet-http-perl all 6.17-1 [22.7 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtry-tiny-perl all 0.30-1 [20.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwww-robotrules-perl all 6.01-1 [14.1 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libwww-perl all 6.31-1ubuntu0.1 [137 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-protocol-https-perl all 6.07-2 [8,284 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnet-smtp-ssl-perl all 1.04-1 [5,948 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmailtools-perl all 2.18-1 [74.0 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxml-parser-perl amd64 2.44-2build3 [199 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 libauthen-sasl-perl all 2.1600-1 [48.7 kB]\n",
            "Fetched 1,713 kB in 3s (661 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 31.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package netbase.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../00-netbase_5.4_all.deb ...\n",
            "Unpacking netbase (5.4) ...\n",
            "Selecting previously unselected package libdata-dump-perl.\n",
            "Preparing to unpack .../01-libdata-dump-perl_1.23-1_all.deb ...\n",
            "Unpacking libdata-dump-perl (1.23-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../02-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../03-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../04-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libfile-listing-perl.\n",
            "Preparing to unpack .../05-libfile-listing-perl_6.04-1_all.deb ...\n",
            "Unpacking libfile-listing-perl (6.04-1) ...\n",
            "Selecting previously unselected package libfont-afm-perl.\n",
            "Preparing to unpack .../06-libfont-afm-perl_1.20-2_all.deb ...\n",
            "Unpacking libfont-afm-perl (1.20-2) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../07-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../08-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../09-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../10-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../11-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../12-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package libhtml-form-perl.\n",
            "Preparing to unpack .../13-libhtml-form-perl_6.03-1_all.deb ...\n",
            "Unpacking libhtml-form-perl (6.03-1) ...\n",
            "Selecting previously unselected package libhtml-tree-perl.\n",
            "Preparing to unpack .../14-libhtml-tree-perl_5.07-1_all.deb ...\n",
            "Unpacking libhtml-tree-perl (5.07-1) ...\n",
            "Selecting previously unselected package libhtml-format-perl.\n",
            "Preparing to unpack .../15-libhtml-format-perl_2.12-1_all.deb ...\n",
            "Unpacking libhtml-format-perl (2.12-1) ...\n",
            "Selecting previously unselected package libhttp-cookies-perl.\n",
            "Preparing to unpack .../16-libhttp-cookies-perl_6.04-1_all.deb ...\n",
            "Unpacking libhttp-cookies-perl (6.04-1) ...\n",
            "Selecting previously unselected package libhttp-daemon-perl.\n",
            "Preparing to unpack .../17-libhttp-daemon-perl_6.01-1_all.deb ...\n",
            "Unpacking libhttp-daemon-perl (6.01-1) ...\n",
            "Selecting previously unselected package libhttp-negotiate-perl.\n",
            "Preparing to unpack .../18-libhttp-negotiate-perl_6.00-2_all.deb ...\n",
            "Unpacking libhttp-negotiate-perl (6.00-2) ...\n",
            "Selecting previously unselected package perl-openssl-defaults:amd64.\n",
            "Preparing to unpack .../19-perl-openssl-defaults_3build1_amd64.deb ...\n",
            "Unpacking perl-openssl-defaults:amd64 (3build1) ...\n",
            "Selecting previously unselected package libnet-ssleay-perl.\n",
            "Preparing to unpack .../20-libnet-ssleay-perl_1.84-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libnet-ssleay-perl (1.84-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libio-socket-ssl-perl.\n",
            "Preparing to unpack .../21-libio-socket-ssl-perl_2.060-3~ubuntu18.04.1_all.deb ...\n",
            "Unpacking libio-socket-ssl-perl (2.060-3~ubuntu18.04.1) ...\n",
            "Selecting previously unselected package libnet-http-perl.\n",
            "Preparing to unpack .../22-libnet-http-perl_6.17-1_all.deb ...\n",
            "Unpacking libnet-http-perl (6.17-1) ...\n",
            "Selecting previously unselected package libtry-tiny-perl.\n",
            "Preparing to unpack .../23-libtry-tiny-perl_0.30-1_all.deb ...\n",
            "Unpacking libtry-tiny-perl (0.30-1) ...\n",
            "Selecting previously unselected package libwww-robotrules-perl.\n",
            "Preparing to unpack .../24-libwww-robotrules-perl_6.01-1_all.deb ...\n",
            "Unpacking libwww-robotrules-perl (6.01-1) ...\n",
            "Selecting previously unselected package libwww-perl.\n",
            "Preparing to unpack .../25-libwww-perl_6.31-1ubuntu0.1_all.deb ...\n",
            "Unpacking libwww-perl (6.31-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblwp-protocol-https-perl.\n",
            "Preparing to unpack .../26-liblwp-protocol-https-perl_6.07-2_all.deb ...\n",
            "Unpacking liblwp-protocol-https-perl (6.07-2) ...\n",
            "Selecting previously unselected package libnet-smtp-ssl-perl.\n",
            "Preparing to unpack .../27-libnet-smtp-ssl-perl_1.04-1_all.deb ...\n",
            "Unpacking libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Selecting previously unselected package libmailtools-perl.\n",
            "Preparing to unpack .../28-libmailtools-perl_2.18-1_all.deb ...\n",
            "Unpacking libmailtools-perl (2.18-1) ...\n",
            "Selecting previously unselected package libxml-parser-perl.\n",
            "Preparing to unpack .../29-libxml-parser-perl_2.44-2build3_amd64.deb ...\n",
            "Unpacking libxml-parser-perl (2.44-2build3) ...\n",
            "Selecting previously unselected package libauthen-sasl-perl.\n",
            "Preparing to unpack .../30-libauthen-sasl-perl_2.1600-1_all.deb ...\n",
            "Unpacking libauthen-sasl-perl (2.1600-1) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libtry-tiny-perl (0.30-1) ...\n",
            "Setting up libfont-afm-perl (1.20-2) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up perl-openssl-defaults:amd64 (3build1) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libdata-dump-perl (1.23-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libnet-http-perl (6.17-1) ...\n",
            "Setting up libwww-robotrules-perl (6.01-1) ...\n",
            "Setting up libauthen-sasl-perl (2.1600-1) ...\n",
            "Setting up netbase (5.4) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libnet-ssleay-perl (1.84-1ubuntu0.2) ...\n",
            "Setting up libio-socket-ssl-perl (2.060-3~ubuntu18.04.1) ...\n",
            "Setting up libhtml-tree-perl (5.07-1) ...\n",
            "Setting up libfile-listing-perl (6.04-1) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up libhttp-negotiate-perl (6.00-2) ...\n",
            "Setting up libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Setting up libhtml-format-perl (2.12-1) ...\n",
            "Setting up libhttp-cookies-perl (6.04-1) ...\n",
            "Setting up libhttp-daemon-perl (6.01-1) ...\n",
            "Setting up libhtml-form-perl (6.03-1) ...\n",
            "Setting up libmailtools-perl (2.18-1) ...\n",
            "Setting up liblwp-protocol-https-perl (6.07-2) ...\n",
            "Setting up libwww-perl (6.31-1ubuntu0.1) ...\n",
            "Setting up libxml-parser-perl (2.44-2build3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (56.0.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8YN8N3BLVuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927e16a0-bfaa-488c-9a7b-78abf8ae6e4b"
      },
      "source": [
        "cd pyrouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7QOzsTKLbGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0f4c07-a7c0-469c-c3d1-885eb9f02907"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbuild\u001b[0m/  \u001b[01;34mdist\u001b[0m/    \u001b[01;34mpyrouge\u001b[0m/           README.md  \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/   LICENSE  \u001b[01;34mpyrouge.egg-info\u001b[0m/  setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGLhuq24LaZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c6b9ea8-cb56-463e-c295-c5657ddaadf0"
      },
      "source": [
        "!sudo python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing pyrouge.egg-info/PKG-INFO\n",
            "writing dependency_links to pyrouge.egg-info/dependency_links.txt\n",
            "writing requirements to pyrouge.egg-info/requires.txt\n",
            "writing top-level names to pyrouge.egg-info/top_level.txt\n",
            "adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
            "writing manifest file 'pyrouge.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pyrouge\n",
            "copying build/lib/pyrouge/__init__.py -> build/bdist.linux-x86_64/egg/pyrouge\n",
            "copying build/lib/pyrouge/base.py -> build/bdist.linux-x86_64/egg/pyrouge\n",
            "copying build/lib/pyrouge/rouge.py -> build/bdist.linux-x86_64/egg/pyrouge\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pyrouge/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pyrouge/base.py to base.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pyrouge/rouge.py to rouge.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pyrouge.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pyrouge.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pyrouge.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pyrouge.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pyrouge.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pyrouge.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "creating 'dist/pyrouge-0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing pyrouge-0.1-py3.7.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/pyrouge-0.1-py3.7.egg\n",
            "Extracting pyrouge-0.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding pyrouge 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pyrouge-0.1-py3.7.egg\n",
            "Processing dependencies for pyrouge==0.1\n",
            "Searching for pandas==1.1.5\n",
            "Best match: pandas 1.1.5\n",
            "Adding pandas 1.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for beautifulsoup4==4.6.3\n",
            "Best match: beautifulsoup4 4.6.3\n",
            "Adding beautifulsoup4 4.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for pyrouge==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR5q5BLjLqyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7936b815-577d-431f-959a-4783b55d3b5c"
      },
      "source": [
        "cd tools/ROUGE-1.5.5/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edGMEAVzLxbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd876e2-e798-4140-f0cf-c42f3b6fca1a"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  README.txt  RELEASE-NOTE.txt  \u001b[01;32mROUGE-1.5.5.pl\u001b[0m*  runROUGE-test.pl  \u001b[01;34mXML\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iqeome7L7KA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9477a774-8fb3-4cd7-e809-03ec489cd0d0"
      },
      "source": [
        "cd data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95fr8koOMEk3"
      },
      "source": [
        "!ln -sf WordNet-2.0-Exceptions/WordNet-2.0.exc.db WordNet-2.0.exc.db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2be3kW9sMW49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75cbe86c-6171-4d90-a6d7-828a22730ea4"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "smart_common_words.txt   \u001b[0m\u001b[01;36mWordNet-2.0.exc.db\u001b[0m@\n",
            "\u001b[01;34mWordNet-1.6-Exceptions\u001b[0m/  \u001b[01;34mWordNet-2.0-Exceptions\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPYNYNJIMeuy"
      },
      "source": [
        "!rm WordNet-2.0.exc.db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT2A4lYcNI4L"
      },
      "source": [
        "!perl ./WordNet-2.0-Exceptions/buildExeptionDB.pl ./WordNet-2.0-Exceptions ./smart_common_words.txt ./WordNet-2.0.exc.db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4O9Z6dCNR2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07fcdd2-a614-4b88-da0e-555bff8a41f0"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfnPudjgbVOn",
        "outputId": "f173dd3e-d0b5-4f8a-9a9c-5404d9dbbb91"
      },
      "source": [
        "!python train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/bert_data_cnndm_final/cnndm -log_file ../logs/test_ext_bert_cnndm.log -model_path ../data/trained_models/ -sep_optim true -use_interval true -visible_gpus 0,1,2 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/ext_bert_cnndm -test_from ../data/trained_models/bertext_cnndm_transformer.pt "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'train.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O4Uhdl-oakj"
      },
      "source": [
        "## CNN Abs Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt_oAhc8onSQ",
        "outputId": "7d0bb7a1-0760-41aa-a161-307fb2e5eb3f"
      },
      "source": [
        "cd trained_models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/data/trained_models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvrnqCZuocv4",
        "outputId": "33a24a19-a62e-42b4-c8d9-6e9a3e2e8014"
      },
      "source": [
        "!unzip bertsumextabs_cnndm_final_model.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  bertsumextabs_cnndm_final_model.zip\n",
            "  inflating: model_step_148000.pt    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cARe5eTOpz5G",
        "outputId": "137bdf9b-1281-49ef-83c7-e54e0fcebf44"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " cal_rouge.py                        presumm_evaluation.ipynb\n",
            "'Copy of presumm_evaluation.ipynb'   \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            " distributed.py                      \u001b[01;34mpyrouge\u001b[0m/\n",
            " \u001b[01;34mmodels\u001b[0m/                             script_PreSumm.ipynb\n",
            " \u001b[01;34mothers\u001b[0m/                             train_abstractive.py\n",
            " post_stats.py                       train_extractive.py\n",
            " \u001b[01;34mprepro\u001b[0m/                             train.py\n",
            " preprocess.py                       \u001b[01;34mtranslate\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlCqhp8_okdW",
        "outputId": "6a8ce8cc-18f2-4d64-f483-217631400b07"
      },
      "source": [
        "!python train.py -task abs -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/bert_data_cnndm_final/cnndm -log_file ../logs/test_abs_bert_cnndm.log -model_path ../data/trained_models/ -sep_optim true -use_interval true -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/abs_bert_cnndm -test_from ../data/trained_models/model_step_148000.pt "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "[2021-04-05 07:07:15,754 INFO] Loading checkpoint from ../data/trained_models/model_step_148000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/bert_data_cnndm_final/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_abs_bert_cnndm.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/abs_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/model_step_148000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-04-05 07:07:18,685 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "[2021-04-05 07:07:18,686 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[2021-04-05 07:07:18,724 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "[2021-04-05 07:07:27,030 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.0.bert.pt, number of examples: 2001\n",
            "[2021-04-05 07:07:27,073 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 135, in <module>\n",
            "    test_abs(args, device_id, cp, step)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/train_abstractive.py\", line 225, in test_abs\n",
            "    predictor.translate(test_iter, step)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/models/predictor.py\", line 149, in translate\n",
            "    batch_data = self.translate_batch(batch)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/models/predictor.py\", line 218, in translate_batch\n",
            "    min_length=self.min_length)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/models/predictor.py\", line 331, in _fast_translate_batch\n",
            "    [alive_seq.index_select(0, select_indices),\n",
            "RuntimeError: \"index_select_out_cuda_impl\" not implemented for 'Float'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCfwKiRUzX4L",
        "outputId": "c8d8b044-521e-4867-f162-ce39b77af5bc"
      },
      "source": [
        "!python train.py -task abs -mode validate -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/bert_data_cnndm_final/cnndm -log_file ../logs/val_abs_bert_cnndm -model_path ../data/models/model_step_148000.pt -sep_optim true -use_interval true -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/abs_bert_cnndm "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 124, in <module>\n",
            "    validate_abs(args, device_id)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/train_abstractive.py\", line 165, in validate_abs\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6p7g3YeTYeR"
      },
      "source": [
        "## Test on my trained ext model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JURsDVC6UdmT",
        "outputId": "0b0f010a-2374-46f0-ec47-3e24485c73c6"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " cal_rouge.py                        presumm_evaluation.ipynb\n",
            "'Copy of presumm_evaluation.ipynb'   \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            " distributed.py                      \u001b[01;34mpyrouge\u001b[0m/\n",
            " \u001b[01;34mmodels\u001b[0m/                             script_PreSumm.ipynb\n",
            " \u001b[01;34mothers\u001b[0m/                             train_abstractive.py\n",
            " post_stats.py                       train_extractive.py\n",
            " \u001b[01;34mprepro\u001b[0m/                             train.py\n",
            " preprocess.py                       \u001b[01;34mtranslate\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrg6TKTPTiPX",
        "outputId": "dcaa4e13-eb6b-418a-df1e-15bfaaea8f5e"
      },
      "source": [
        "!python train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/bert_data_cnndm_final/cnndm -log_file ../logs/test_my_ext_bert_cnndm.log -model_path ../data/trained_models/ -sep_optim true -use_interval true -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_ext_bert_cnndm -test_from ../data/trained_models/model_step_50000.pt "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-04-07 03:14:25,135 INFO] Loading checkpoint from ../data/trained_models/model_step_50000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/bert_data_cnndm_final/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_ext_bert_cnndm.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_ext_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/model_step_50000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-04-07 03:14:37,903 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "[2021-04-07 03:14:38,404 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[2021-04-07 03:14:38,698 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "[2021-04-07 03:15:04,360 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-04-07 03:15:04,368 INFO] * number of parameters: 120512513\n",
            "[2021-04-07 03:16:23,823 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.1.bert.pt, number of examples: 2001\n",
            "[2021-04-07 03:17:47,639 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.2.bert.pt, number of examples: 2001\n",
            "[2021-04-07 03:19:11,869 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.3.bert.pt, number of examples: 2001\n",
            "[2021-04-07 03:20:35,922 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.4.bert.pt, number of examples: 2000\n",
            "[2021-04-07 03:22:00,378 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.5.bert.pt, number of examples: 1485\n",
            "11489\n",
            "11489\n",
            "2021-04-07 03:26:24,131 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-04-07 03:26:24,131 INFO] Writing summaries.\n",
            "2021-04-07 03:26:24,136 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmpxasrixd1/system and model files to ../temp/tmpxasrixd1/model.\n",
            "[2021-04-07 03:26:24,136 INFO] Processing summaries. Saving system files to ../temp/tmpxasrixd1/system and model files to ../temp/tmpxasrixd1/model.\n",
            "2021-04-07 03:26:24,136 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-04-07-03-23-02/candidate/.\n",
            "[2021-04-07 03:26:24,136 INFO] Processing files in ../temp/rouge-tmp-2021-04-07-03-23-02/candidate/.\n",
            "2021-04-07 03:29:29,868 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpxasrixd1/system.\n",
            "[2021-04-07 03:29:29,868 INFO] Saved processed files to ../temp/tmpxasrixd1/system.\n",
            "2021-04-07 03:29:29,869 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-04-07-03-23-02/reference/.\n",
            "[2021-04-07 03:29:29,869 INFO] Processing files in ../temp/rouge-tmp-2021-04-07-03-23-02/reference/.\n",
            "2021-04-07 03:32:39,143 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpxasrixd1/model.\n",
            "[2021-04-07 03:32:39,143 INFO] Saved processed files to ../temp/tmpxasrixd1/model.\n",
            "2021-04-07 03:32:39,347 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpmkhb_4he/rouge_conf.xml\n",
            "[2021-04-07 03:32:39,347 INFO] Written ROUGE configuration to ../temp/tmpmkhb_4he/rouge_conf.xml\n",
            "2021-04-07 03:32:39,348 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpmkhb_4he/rouge_conf.xml\n",
            "[2021-04-07 03:32:39,348 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpmkhb_4he/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.51367 (95%-conf.int. 0.51102 - 0.51627)\n",
            "1 ROUGE-1 Average_P: 0.37345 (95%-conf.int. 0.37102 - 0.37604)\n",
            "1 ROUGE-1 Average_F: 0.41754 (95%-conf.int. 0.41527 - 0.41979)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.23346 (95%-conf.int. 0.23059 - 0.23617)\n",
            "1 ROUGE-2 Average_P: 0.17089 (95%-conf.int. 0.16864 - 0.17319)\n",
            "1 ROUGE-2 Average_F: 0.19022 (95%-conf.int. 0.18786 - 0.19249)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.46956 (95%-conf.int. 0.46691 - 0.47219)\n",
            "1 ROUGE-L Average_P: 0.34212 (95%-conf.int. 0.33976 - 0.34464)\n",
            "1 ROUGE-L Average_F: 0.38216 (95%-conf.int. 0.37995 - 0.38439)\n",
            "\n",
            "[2021-04-07 03:37:01,535 INFO] Rouges at step 50000 \n",
            ">> ROUGE-F(1/2/3/l): 41.75/19.02/38.22\n",
            "ROUGE-R(1/2/3/l): 51.37/23.35/46.96\n",
            "\n",
            "[2021-04-07 03:37:01,536 INFO] Validation xent: 5.82127 at step 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQvOaraPabqe"
      },
      "source": [
        "## Test on my baseline model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsOyOTjoagDI",
        "outputId": "182e3710-a381-4ead-d91f-4817985d94cb"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " base.py                             \u001b[0m\u001b[01;34mprepro\u001b[0m/\n",
            " \u001b[01;34mbert_data\u001b[0m/                          preprocess.py\n",
            " bert_data_cnndm_final.zip           presumm_evaluation.ipynb\n",
            " bertext_cnndm_transformer.pt        \u001b[01;34m__pycache__\u001b[0m/\n",
            " bertext_cnndm_transformer.zip       \u001b[01;34mpyrouge\u001b[0m/\n",
            " \u001b[01;34mBertSum\u001b[0m/                            script_PreSumm.ipynb\n",
            " cal_rouge.py                        train_abstractive.py\n",
            "'Copy of presumm_evaluation.ipynb'   train_extractive.py\n",
            " distributed.py                      train.py\n",
            " \u001b[01;34mmodels\u001b[0m/                             train_xsum.ipynb\n",
            " \u001b[01;34mothers\u001b[0m/                             \u001b[01;34mtranslate\u001b[0m/\n",
            " post_stats.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne3U9dt-adwe",
        "outputId": "b1e454a0-fbe8-4359-c7b2-ae2f7e6eb30d"
      },
      "source": [
        "!python train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/bert_data_cnndm_final/cnndm -log_file ../logs/test_my_baseline_ext_bert_cnndm.log -model_path ../data/trained_models/Daniella -sep_optim true -use_interval true -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_baseline_ext_bert_cnndm -test_from ../data/trained_models/Daniella/baseline_model_step_50000.pt "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-04-12 04:50:38,847 INFO] Loading checkpoint from ../data/trained_models/Daniella/baseline_model_step_50000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/bert_data_cnndm_final/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='baseline', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_baseline_ext_bert_cnndm.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/Daniella', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_baseline_ext_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/Daniella/baseline_model_step_50000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-04-12 04:50:46,831 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "[2021-04-12 04:50:47,003 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[2021-04-12 04:50:47,055 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "[2021-04-12 04:51:13,749 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-04-12 04:51:13,755 INFO] * number of parameters: 35456513\n",
            "[2021-04-12 04:51:25,523 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.1.bert.pt, number of examples: 2001\n",
            "[2021-04-12 04:51:37,209 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.2.bert.pt, number of examples: 2001\n",
            "[2021-04-12 04:51:49,284 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.3.bert.pt, number of examples: 2001\n",
            "[2021-04-12 04:52:01,449 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.4.bert.pt, number of examples: 2000\n",
            "[2021-04-12 04:52:14,527 INFO] Loading test dataset from ../data/preprocessed_data/bert_data_cnndm_final/cnndm.test.5.bert.pt, number of examples: 1485\n",
            "11489\n",
            "11489\n",
            "2021-04-12 04:55:45,484 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-04-12 04:55:45,484 INFO] Writing summaries.\n",
            "2021-04-12 04:55:45,490 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmpnpr61nx2/system and model files to ../temp/tmpnpr61nx2/model.\n",
            "[2021-04-12 04:55:45,490 INFO] Processing summaries. Saving system files to ../temp/tmpnpr61nx2/system and model files to ../temp/tmpnpr61nx2/model.\n",
            "2021-04-12 04:55:45,490 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-04-12-04-52-23/candidate/.\n",
            "[2021-04-12 04:55:45,490 INFO] Processing files in ../temp/rouge-tmp-2021-04-12-04-52-23/candidate/.\n",
            "2021-04-12 04:58:51,683 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpnpr61nx2/system.\n",
            "[2021-04-12 04:58:51,683 INFO] Saved processed files to ../temp/tmpnpr61nx2/system.\n",
            "2021-04-12 04:58:51,684 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-04-12-04-52-23/reference/.\n",
            "[2021-04-12 04:58:51,684 INFO] Processing files in ../temp/rouge-tmp-2021-04-12-04-52-23/reference/.\n",
            "2021-04-12 05:01:58,976 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpnpr61nx2/model.\n",
            "[2021-04-12 05:01:58,976 INFO] Saved processed files to ../temp/tmpnpr61nx2/model.\n",
            "2021-04-12 05:01:59,215 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpe1s1gge2/rouge_conf.xml\n",
            "[2021-04-12 05:01:59,215 INFO] Written ROUGE configuration to ../temp/tmpe1s1gge2/rouge_conf.xml\n",
            "2021-04-12 05:01:59,215 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpe1s1gge2/rouge_conf.xml\n",
            "[2021-04-12 05:01:59,215 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpe1s1gge2/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.52861 (95%-conf.int. 0.52571 - 0.53164)\n",
            "1 ROUGE-1 Average_P: 0.34843 (95%-conf.int. 0.34605 - 0.35075)\n",
            "1 ROUGE-1 Average_F: 0.40596 (95%-conf.int. 0.40376 - 0.40817)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.23481 (95%-conf.int. 0.23206 - 0.23767)\n",
            "1 ROUGE-2 Average_P: 0.15480 (95%-conf.int. 0.15277 - 0.15691)\n",
            "1 ROUGE-2 Average_F: 0.18010 (95%-conf.int. 0.17795 - 0.18235)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.48029 (95%-conf.int. 0.47749 - 0.48312)\n",
            "1 ROUGE-L Average_P: 0.31709 (95%-conf.int. 0.31492 - 0.31941)\n",
            "1 ROUGE-L Average_F: 0.36921 (95%-conf.int. 0.36702 - 0.37143)\n",
            "\n",
            "[2021-04-12 05:06:23,938 INFO] Rouges at step 50000 \n",
            ">> ROUGE-F(1/2/3/l): 40.60/18.01/36.92\n",
            "ROUGE-R(1/2/3/l): 52.86/23.48/48.03\n",
            "\n",
            "[2021-04-12 05:06:23,939 INFO] Validation xent: 5.96931 at step 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDEEwwBgS1WA",
        "outputId": "619e0976-290f-4a20-b576-046cc603dbae"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " base.py                             \u001b[0m\u001b[01;34mprepro\u001b[0m/\n",
            " \u001b[01;34mbert_data\u001b[0m/                          preprocess.py\n",
            " bert_data_cnndm_final.zip           presumm_evaluation.ipynb\n",
            " bertext_cnndm_transformer.pt        \u001b[01;34m__pycache__\u001b[0m/\n",
            " bertext_cnndm_transformer.zip       \u001b[01;34mpyrouge\u001b[0m/\n",
            " \u001b[01;34mBertSum\u001b[0m/                            script_PreSumm.ipynb\n",
            " cal_rouge.py                        train_abstractive.py\n",
            "'Copy of presumm_evaluation.ipynb'   train_extractive.py\n",
            " distributed.py                      train.py\n",
            " \u001b[01;34mmodels\u001b[0m/                             train_xsum.ipynb\n",
            " \u001b[01;34mothers\u001b[0m/                             \u001b[01;34mtranslate\u001b[0m/\n",
            " post_stats.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnYrxXdVpVeW"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9uY9iyksXQB",
        "outputId": "09d357e6-b0aa-436c-ff2a-058d0e519a21"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6taYpIcTHFd",
        "outputId": "d36e0b96-dc65-4ba9-f523-b299f3db2fae"
      },
      "source": [
        "!python3 train.py -task ext -mode train -bert_data_path ../data/preprocessed_data/bert_data_cnndm_final/cnndm -ext_dropout 0.1 -model_path ../models -lr 2e-3 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file ../logs/ext_bert_cnndm -use_interval true -warmup_steps 10000 -max_pos 800"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 9, in <module>\n",
            "    from others.logging import init_logger\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 818, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 917, in get_data\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7f7hbh6tbxR"
      },
      "source": [
        "## Train Roberta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K41dDavtdVG",
        "outputId": "3533794c-c5e2-42a5-a308-a2971e99a81a"
      },
      "source": [
        "!python3 train.py -task ext -encoder roberta -mode train -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -ext_dropout 0.1 -model_path ../data/trained_models/Daniella -lr 2e-3 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file ../logs/ext_roberta_cnndm -use_interval true -warmup_steps 10000 -max_pos 700"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "----TRAIN EXTRACTIVE----\n",
            "[2021-04-30 02:12:41,428 INFO] Device ID 0\n",
            "[2021-04-30 02:12:42,208 INFO] Device cuda\n",
            "[2021-04-30 02:12:42,584 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-04-30 02:12:42,914 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-04-30 02:12:43,281 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-04-30 02:13:02,907 INFO] ExtSummarizer(\n",
            "  (bert): Roberta(\n",
            "    (model): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(702, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ext_layer): ExtTransformerEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2021-04-30 02:13:02,924 INFO] * number of parameters: 135821057\n",
            "[2021-04-30 02:13:02,924 INFO] Start training...\n",
            "[2021-04-30 02:13:06,357 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.123.bert.pt, number of examples: 2000\n",
            "[2021-04-30 02:13:27,764 INFO] Step 50/50000; xent: 4.64; lr: 0.0000001;  39 docs/s;     21 sec\n",
            "[2021-04-30 02:13:48,938 INFO] Step 100/50000; xent: 4.26; lr: 0.0000002;  43 docs/s;     43 sec\n",
            "[2021-04-30 02:14:10,131 INFO] Step 150/50000; xent: 4.06; lr: 0.0000003;  41 docs/s;     64 sec\n",
            "[2021-04-30 02:14:31,346 INFO] Step 200/50000; xent: 4.02; lr: 0.0000004;  41 docs/s;     85 sec\n",
            "[2021-04-30 02:14:45,962 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.91.bert.pt, number of examples: 1995\n",
            "[2021-04-30 02:14:54,549 INFO] Step 250/50000; xent: 3.94; lr: 0.0000005;  38 docs/s;    108 sec\n",
            "[2021-04-30 02:15:15,820 INFO] Step 300/50000; xent: 3.88; lr: 0.0000006;  39 docs/s;    129 sec\n",
            "[2021-04-30 02:15:37,021 INFO] Step 350/50000; xent: 3.77; lr: 0.0000007;  42 docs/s;    151 sec\n",
            "[2021-04-30 02:15:58,296 INFO] Step 400/50000; xent: 3.72; lr: 0.0000008;  40 docs/s;    172 sec\n",
            "[2021-04-30 02:16:19,602 INFO] Step 450/50000; xent: 3.67; lr: 0.0000009;  40 docs/s;    193 sec\n",
            "[2021-04-30 02:16:26,171 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.39.bert.pt, number of examples: 2001\n",
            "[2021-04-30 02:16:42,453 INFO] Step 500/50000; xent: 3.51; lr: 0.0000010;  37 docs/s;    216 sec\n",
            "[2021-04-30 02:17:03,763 INFO] Step 550/50000; xent: 3.64; lr: 0.0000011;  40 docs/s;    237 sec\n",
            "[2021-04-30 02:17:24,953 INFO] Step 600/50000; xent: 3.47; lr: 0.0000012;  43 docs/s;    259 sec\n",
            "[2021-04-30 02:17:46,213 INFO] Step 650/50000; xent: 3.50; lr: 0.0000013;  41 docs/s;    280 sec\n",
            "[2021-04-30 02:18:06,894 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.6.bert.pt, number of examples: 2001\n",
            "[2021-04-30 02:18:09,579 INFO] Step 700/50000; xent: 3.60; lr: 0.0000014;  37 docs/s;    303 sec\n",
            "[2021-04-30 02:18:30,863 INFO] Step 750/50000; xent: 3.60; lr: 0.0000015;  40 docs/s;    325 sec\n",
            "[2021-04-30 02:18:52,134 INFO] Step 800/50000; xent: 3.69; lr: 0.0000016;  40 docs/s;    346 sec\n",
            "[2021-04-30 02:19:13,453 INFO] Step 850/50000; xent: 3.59; lr: 0.0000017;  41 docs/s;    367 sec\n",
            "[2021-04-30 02:19:34,685 INFO] Step 900/50000; xent: 3.56; lr: 0.0000018;  41 docs/s;    388 sec\n",
            "[2021-04-30 02:19:47,769 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.81.bert.pt, number of examples: 2001\n",
            "[2021-04-30 02:19:58,177 INFO] Step 950/50000; xent: 3.44; lr: 0.0000019;  36 docs/s;    412 sec\n",
            "[2021-04-30 02:20:19,488 INFO] Step 1000/50000; xent: 3.52; lr: 0.0000020;  41 docs/s;    433 sec\n",
            "[2021-04-30 02:20:19,492 INFO] Saving checkpoint ../data/trained_models/Daniella/model_step_1000.pt\n",
            "[2021-04-30 02:20:47,004 INFO] Step 1050/50000; xent: 3.44; lr: 0.0000021;  32 docs/s;    461 sec\n",
            "[2021-04-30 02:21:08,484 INFO] Step 1100/50000; xent: 3.52; lr: 0.0000022;  40 docs/s;    482 sec\n",
            "[2021-04-30 02:21:29,795 INFO] Step 1150/50000; xent: 3.61; lr: 0.0000023;  40 docs/s;    503 sec\n",
            "[2021-04-30 02:21:34,759 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.98.bert.pt, number of examples: 2001\n",
            "[2021-04-30 02:21:52,723 INFO] Step 1200/50000; xent: 3.56; lr: 0.0000024;  38 docs/s;    526 sec\n",
            "[2021-04-30 02:22:14,018 INFO] Step 1250/50000; xent: 3.52; lr: 0.0000025;  39 docs/s;    548 sec\n",
            "[2021-04-30 02:22:35,208 INFO] Step 1300/50000; xent: 3.53; lr: 0.0000026;  43 docs/s;    569 sec\n",
            "[2021-04-30 02:22:56,536 INFO] Step 1350/50000; xent: 3.44; lr: 0.0000027;  41 docs/s;    590 sec\n",
            "[2021-04-30 02:23:15,761 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.93.bert.pt, number of examples: 2001\n",
            "[2021-04-30 02:23:20,577 INFO] Step 1400/50000; xent: 3.57; lr: 0.0000028;  36 docs/s;    614 sec\n",
            "[2021-04-30 02:23:41,962 INFO] Step 1450/50000; xent: 3.44; lr: 0.0000029;  39 docs/s;    636 sec\n",
            "[2021-04-30 02:24:03,206 INFO] Step 1500/50000; xent: 3.53; lr: 0.0000030;  40 docs/s;    657 sec\n",
            "[2021-04-30 02:24:24,655 INFO] Step 1550/50000; xent: 3.47; lr: 0.0000031;  40 docs/s;    678 sec\n",
            "[2021-04-30 02:24:45,721 INFO] Step 1600/50000; xent: 3.50; lr: 0.0000032;  41 docs/s;    699 sec\n",
            "[2021-04-30 02:24:57,377 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.63.bert.pt, number of examples: 2001\n",
            "[2021-04-30 02:25:08,910 INFO] Step 1650/50000; xent: 3.51; lr: 0.0000033;  37 docs/s;    723 sec\n",
            "[2021-04-30 02:25:30,204 INFO] Step 1700/50000; xent: 3.44; lr: 0.0000034;  41 docs/s;    744 sec\n",
            "[2021-04-30 02:25:51,821 INFO] Step 1750/50000; xent: 3.48; lr: 0.0000035;  39 docs/s;    765 sec\n",
            "[2021-04-30 02:26:13,158 INFO] Step 1800/50000; xent: 3.54; lr: 0.0000036;  41 docs/s;    787 sec\n",
            "[2021-04-30 02:26:34,416 INFO] Step 1850/50000; xent: 3.54; lr: 0.0000037;  40 docs/s;    808 sec\n",
            "[2021-04-30 02:26:38,566 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.15.bert.pt, number of examples: 2000\n",
            "[2021-04-30 02:26:58,779 INFO] Step 1900/50000; xent: 3.54; lr: 0.0000038;  36 docs/s;    832 sec\n",
            "[2021-04-30 02:27:19,955 INFO] Step 1950/50000; xent: 3.42; lr: 0.0000039;  41 docs/s;    854 sec\n",
            "[2021-04-30 02:27:41,132 INFO] Step 2000/50000; xent: 3.43; lr: 0.0000040;  41 docs/s;    875 sec\n",
            "[2021-04-30 02:27:41,134 INFO] Saving checkpoint ../data/trained_models/Daniella/model_step_2000.pt\n",
            "[2021-04-30 02:28:08,983 INFO] Step 2050/50000; xent: 3.52; lr: 0.0000041;  31 docs/s;    903 sec\n",
            "[2021-04-30 02:28:26,498 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.64.bert.pt, number of examples: 1998\n",
            "[2021-04-30 02:28:33,045 INFO] Step 2100/50000; xent: 3.46; lr: 0.0000042;  36 docs/s;    927 sec\n",
            "[2021-04-30 02:28:54,342 INFO] Step 2150/50000; xent: 3.60; lr: 0.0000043;  40 docs/s;    948 sec\n",
            "[2021-04-30 02:29:15,647 INFO] Step 2200/50000; xent: 3.47; lr: 0.0000044;  40 docs/s;    969 sec\n",
            "[2021-04-30 02:29:36,935 INFO] Step 2250/50000; xent: 3.45; lr: 0.0000045;  41 docs/s;    991 sec\n",
            "[2021-04-30 02:29:58,230 INFO] Step 2300/50000; xent: 3.40; lr: 0.0000046;  40 docs/s;   1012 sec\n",
            "[2021-04-30 02:30:07,359 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.28.bert.pt, number of examples: 1999\n",
            "[2021-04-30 02:30:21,512 INFO] Step 2350/50000; xent: 3.39; lr: 0.0000047;  38 docs/s;   1035 sec\n",
            "[2021-04-30 02:30:43,007 INFO] Step 2400/50000; xent: 3.43; lr: 0.0000048;  40 docs/s;   1057 sec\n",
            "[2021-04-30 02:31:04,377 INFO] Step 2450/50000; xent: 3.40; lr: 0.0000049;  39 docs/s;   1078 sec\n",
            "[2021-04-30 02:31:25,803 INFO] Step 2500/50000; xent: 3.53; lr: 0.0000050;  40 docs/s;   1099 sec\n",
            "[2021-04-30 02:31:47,007 INFO] Step 2550/50000; xent: 3.55; lr: 0.0000051;  40 docs/s;   1121 sec\n",
            "[2021-04-30 02:31:48,567 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.32.bert.pt, number of examples: 2001\n",
            "[2021-04-30 02:32:09,951 INFO] Step 2600/50000; xent: 3.51; lr: 0.0000052;  37 docs/s;   1144 sec\n",
            "[2021-04-30 02:32:31,188 INFO] Step 2650/50000; xent: 3.46; lr: 0.0000053;  40 docs/s;   1165 sec\n",
            "[2021-04-30 02:32:52,576 INFO] Step 2700/50000; xent: 3.35; lr: 0.0000054;  42 docs/s;   1186 sec\n",
            "[2021-04-30 02:33:14,242 INFO] Step 2750/50000; xent: 3.44; lr: 0.0000055;  41 docs/s;   1208 sec\n",
            "[2021-04-30 02:33:29,419 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.111.bert.pt, number of examples: 2001\n",
            "[2021-04-30 02:33:37,605 INFO] Step 2800/50000; xent: 3.37; lr: 0.0000056;  38 docs/s;   1231 sec\n",
            "[2021-04-30 02:33:58,858 INFO] Step 2850/50000; xent: 3.50; lr: 0.0000057;  40 docs/s;   1252 sec\n",
            "[2021-04-30 02:34:20,062 INFO] Step 2900/50000; xent: 3.50; lr: 0.0000058;  41 docs/s;   1274 sec\n",
            "[2021-04-30 02:34:41,489 INFO] Step 2950/50000; xent: 3.45; lr: 0.0000059;  39 docs/s;   1295 sec\n",
            "[2021-04-30 02:35:02,521 INFO] Step 3000/50000; xent: 3.42; lr: 0.0000060;  42 docs/s;   1316 sec\n",
            "[2021-04-30 02:35:02,524 INFO] Saving checkpoint ../data/trained_models/Daniella/model_step_3000.pt\n",
            "[2021-04-30 02:35:16,377 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.49.bert.pt, number of examples: 2000\n",
            "[2021-04-30 02:35:33,108 INFO] Step 3050/50000; xent: 3.48; lr: 0.0000061;  28 docs/s;   1347 sec\n",
            "[2021-04-30 02:35:54,866 INFO] Step 3100/50000; xent: 3.40; lr: 0.0000062;  41 docs/s;   1369 sec\n",
            "[2021-04-30 02:36:16,050 INFO] Step 3150/50000; xent: 3.39; lr: 0.0000063;  41 docs/s;   1390 sec\n",
            "[2021-04-30 02:36:37,333 INFO] Step 3200/50000; xent: 3.42; lr: 0.0000064;  41 docs/s;   1411 sec\n",
            "[2021-04-30 02:36:57,667 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.59.bert.pt, number of examples: 2000\n",
            "[2021-04-30 02:37:00,760 INFO] Step 3250/50000; xent: 3.44; lr: 0.0000065;  37 docs/s;   1434 sec\n",
            "[2021-04-30 02:37:22,073 INFO] Step 3300/50000; xent: 3.49; lr: 0.0000066;  41 docs/s;   1456 sec\n",
            "[2021-04-30 02:37:43,302 INFO] Step 3350/50000; xent: 3.41; lr: 0.0000067;  40 docs/s;   1477 sec\n",
            "[2021-04-30 02:38:04,667 INFO] Step 3400/50000; xent: 3.48; lr: 0.0000068;  41 docs/s;   1498 sec\n",
            "[2021-04-30 02:38:26,200 INFO] Step 3450/50000; xent: 3.41; lr: 0.0000069;  39 docs/s;   1520 sec\n",
            "[2021-04-30 02:38:38,164 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.84.bert.pt, number of examples: 2001\n",
            "[2021-04-30 02:38:48,911 INFO] Step 3500/50000; xent: 3.38; lr: 0.0000070;  39 docs/s;   1543 sec\n",
            "[2021-04-30 02:39:10,124 INFO] Step 3550/50000; xent: 3.36; lr: 0.0000071;  41 docs/s;   1564 sec\n",
            "[2021-04-30 02:39:31,407 INFO] Step 3600/50000; xent: 3.50; lr: 0.0000072;  41 docs/s;   1585 sec\n",
            "[2021-04-30 02:39:52,602 INFO] Step 3650/50000; xent: 3.53; lr: 0.0000073;  41 docs/s;   1606 sec\n",
            "[2021-04-30 02:40:13,932 INFO] Step 3700/50000; xent: 3.46; lr: 0.0000074;  40 docs/s;   1628 sec\n",
            "[2021-04-30 02:40:18,160 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.137.bert.pt, number of examples: 2001\n",
            "[2021-04-30 02:40:36,768 INFO] Step 3750/50000; xent: 3.50; lr: 0.0000075;  37 docs/s;   1650 sec\n",
            "[2021-04-30 02:40:58,118 INFO] Step 3800/50000; xent: 3.56; lr: 0.0000076;  40 docs/s;   1672 sec\n",
            "[2021-04-30 02:41:19,357 INFO] Step 3850/50000; xent: 3.40; lr: 0.0000077;  41 docs/s;   1693 sec\n",
            "[2021-04-30 02:41:40,481 INFO] Step 3900/50000; xent: 3.47; lr: 0.0000078;  41 docs/s;   1714 sec\n",
            "[2021-04-30 02:41:59,636 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.13.bert.pt, number of examples: 2000\n",
            "[2021-04-30 02:42:03,927 INFO] Step 3950/50000; xent: 3.44; lr: 0.0000079;  37 docs/s;   1738 sec\n",
            "[2021-04-30 02:42:25,269 INFO] Step 4000/50000; xent: 3.37; lr: 0.0000080;  41 docs/s;   1759 sec\n",
            "[2021-04-30 02:42:25,272 INFO] Saving checkpoint ../data/trained_models/Daniella/model_step_4000.pt\n",
            "[2021-04-30 02:42:52,720 INFO] Step 4050/50000; xent: 3.36; lr: 0.0000081;  32 docs/s;   1786 sec\n",
            "[2021-04-30 02:43:14,696 INFO] Step 4100/50000; xent: 3.33; lr: 0.0000082;  39 docs/s;   1808 sec\n",
            "[2021-04-30 02:43:35,910 INFO] Step 4150/50000; xent: 3.51; lr: 0.0000083;  41 docs/s;   1830 sec\n",
            "[2021-04-30 02:43:46,016 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.135.bert.pt, number of examples: 2000\n",
            "[2021-04-30 02:43:58,773 INFO] Step 4200/50000; xent: 3.38; lr: 0.0000084;  38 docs/s;   1852 sec\n",
            "[2021-04-30 02:44:20,100 INFO] Step 4250/50000; xent: 3.47; lr: 0.0000085;  40 docs/s;   1874 sec\n",
            "[2021-04-30 02:44:41,332 INFO] Step 4300/50000; xent: 3.42; lr: 0.0000086;  41 docs/s;   1895 sec\n",
            "[2021-04-30 02:45:02,502 INFO] Step 4350/50000; xent: 3.44; lr: 0.0000087;  41 docs/s;   1916 sec\n",
            "[2021-04-30 02:45:23,777 INFO] Step 4400/50000; xent: 3.50; lr: 0.0000088;  39 docs/s;   1937 sec\n",
            "[2021-04-30 02:45:26,807 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.71.bert.pt, number of examples: 1999\n",
            "[2021-04-30 02:45:47,117 INFO] Step 4450/50000; xent: 3.39; lr: 0.0000089;  38 docs/s;   1961 sec\n",
            "[2021-04-30 02:46:08,353 INFO] Step 4500/50000; xent: 3.43; lr: 0.0000090;  39 docs/s;   1982 sec\n",
            "[2021-04-30 02:46:29,518 INFO] Step 4550/50000; xent: 3.46; lr: 0.0000091;  41 docs/s;   2003 sec\n",
            "[2021-04-30 02:46:50,714 INFO] Step 4600/50000; xent: 3.37; lr: 0.0000092;  41 docs/s;   2024 sec\n",
            "[2021-04-30 02:47:07,320 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.9.bert.pt, number of examples: 2000\n",
            "[2021-04-30 02:47:13,735 INFO] Step 4650/50000; xent: 3.42; lr: 0.0000093;  37 docs/s;   2047 sec\n",
            "[2021-04-30 02:47:34,988 INFO] Step 4700/50000; xent: 3.40; lr: 0.0000094;  41 docs/s;   2069 sec\n",
            "[2021-04-30 02:47:56,446 INFO] Step 4750/50000; xent: 3.45; lr: 0.0000095;  40 docs/s;   2090 sec\n",
            "[2021-04-30 02:48:18,093 INFO] Step 4800/50000; xent: 3.49; lr: 0.0000096;  39 docs/s;   2112 sec\n",
            "[2021-04-30 02:48:39,400 INFO] Step 4850/50000; xent: 3.29; lr: 0.0000097;  41 docs/s;   2133 sec\n",
            "[2021-04-30 02:48:48,041 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.105.bert.pt, number of examples: 2000\n",
            "[2021-04-30 02:49:01,989 INFO] Step 4900/50000; xent: 3.48; lr: 0.0000098;  39 docs/s;   2156 sec\n",
            "[2021-04-30 02:49:23,341 INFO] Step 4950/50000; xent: 3.55; lr: 0.0000099;  40 docs/s;   2177 sec\n",
            "[2021-04-30 02:49:44,668 INFO] Step 5000/50000; xent: 3.47; lr: 0.0000100;  40 docs/s;   2198 sec\n",
            "[2021-04-30 02:49:44,671 INFO] Saving checkpoint ../data/trained_models/Daniella/model_step_5000.pt\n",
            "[2021-04-30 02:50:13,116 INFO] Step 5050/50000; xent: 3.48; lr: 0.0000101;  30 docs/s;   2227 sec\n",
            "[2021-04-30 02:50:36,629 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.50.bert.pt, number of examples: 1999\n",
            "[2021-04-30 02:50:37,171 INFO] Step 5100/50000; xent: 3.56; lr: 0.0000102;  35 docs/s;   2251 sec\n",
            "[2021-04-30 02:50:58,719 INFO] Step 5150/50000; xent: 3.42; lr: 0.0000103;  39 docs/s;   2272 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv_7YX3wsyIu",
        "outputId": "a12dfb58-2003-47ed-c3a2-a94dbfb656dc"
      },
      "source": [
        "!python3 train.py -task ext -encoder roberta -mode train -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -ext_dropout 0.1 -model_path ../data/trained_models/Tushar -lr 1e-4 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file ../logs/ext_roberta_cnndm -use_interval true -warmup_steps 10000 -max_pos 514"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "----TRAIN EXTRACTIVE----\n",
            "[2021-04-30 02:57:46,299 INFO] Device ID 0\n",
            "[2021-04-30 02:57:46,972 INFO] Device cuda\n",
            "[2021-04-30 02:57:47,354 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-04-30 02:57:47,730 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-04-30 02:57:48,095 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-04-30 02:58:13,281 INFO] ExtSummarizer(\n",
            "  (bert): Roberta(\n",
            "    (model): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(516, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ext_layer): ExtTransformerEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2021-04-30 02:58:13,382 INFO] * number of parameters: 135678209\n",
            "[2021-04-30 02:58:13,382 INFO] Start training...\n",
            "[2021-04-30 02:58:18,306 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.123.bert.pt, number of examples: 2000\n",
            "[2021-04-30 02:58:53,705 INFO] Step 50/50000; xent: 4.99; lr: 0.0000000;  29 docs/s;     35 sec\n",
            "[2021-04-30 02:59:28,750 INFO] Step 100/50000; xent: 4.74; lr: 0.0000000;  30 docs/s;     70 sec\n",
            "[2021-04-30 03:00:04,094 INFO] Step 150/50000; xent: 4.31; lr: 0.0000000;  30 docs/s;    106 sec\n",
            "[2021-04-30 03:00:34,561 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.91.bert.pt, number of examples: 1995\n",
            "[2021-04-30 03:00:40,981 INFO] Step 200/50000; xent: 3.95; lr: 0.0000000;  28 docs/s;    143 sec\n",
            "[2021-04-30 03:01:16,090 INFO] Step 250/50000; xent: 3.71; lr: 0.0000000;  29 docs/s;    178 sec\n",
            "[2021-04-30 03:01:51,121 INFO] Step 300/50000; xent: 3.53; lr: 0.0000000;  29 docs/s;    213 sec\n",
            "[2021-04-30 03:02:26,032 INFO] Step 350/50000; xent: 3.44; lr: 0.0000000;  30 docs/s;    248 sec\n",
            "[2021-04-30 03:02:52,665 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.39.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:03:04,028 INFO] Step 400/50000; xent: 3.38; lr: 0.0000000;  27 docs/s;    286 sec\n",
            "[2021-04-30 03:03:39,120 INFO] Step 450/50000; xent: 3.38; lr: 0.0000000;  29 docs/s;    321 sec\n",
            "[2021-04-30 03:04:14,228 INFO] Step 500/50000; xent: 3.30; lr: 0.0000001;  31 docs/s;    356 sec\n",
            "[2021-04-30 03:04:49,333 INFO] Step 550/50000; xent: 3.30; lr: 0.0000001;  29 docs/s;    391 sec\n",
            "[2021-04-30 03:05:10,965 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.6.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:05:27,925 INFO] Step 600/50000; xent: 3.36; lr: 0.0000001;  26 docs/s;    430 sec\n",
            "[2021-04-30 03:06:03,072 INFO] Step 650/50000; xent: 3.43; lr: 0.0000001;  29 docs/s;    465 sec\n",
            "[2021-04-30 03:06:38,152 INFO] Step 700/50000; xent: 3.36; lr: 0.0000001;  29 docs/s;    500 sec\n",
            "[2021-04-30 03:07:13,310 INFO] Step 750/50000; xent: 3.30; lr: 0.0000001;  30 docs/s;    535 sec\n",
            "[2021-04-30 03:07:27,658 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.81.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:07:50,170 INFO] Step 800/50000; xent: 3.29; lr: 0.0000001;  28 docs/s;    572 sec\n",
            "[2021-04-30 03:08:25,257 INFO] Step 850/50000; xent: 3.25; lr: 0.0000001;  30 docs/s;    607 sec\n",
            "[2021-04-30 03:09:00,322 INFO] Step 900/50000; xent: 3.32; lr: 0.0000001;  29 docs/s;    642 sec\n",
            "[2021-04-30 03:09:35,038 INFO] Step 950/50000; xent: 3.25; lr: 0.0000001;  30 docs/s;    677 sec\n",
            "[2021-04-30 03:09:44,793 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.98.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:10:12,291 INFO] Step 1000/50000; xent: 3.23; lr: 0.0000001;  28 docs/s;    714 sec\n",
            "[2021-04-30 03:10:12,305 INFO] Saving checkpoint ../data/trained_models/Tushar/model_step_1000.pt\n",
            "[2021-04-30 03:10:56,459 INFO] Step 1050/50000; xent: 3.28; lr: 0.0000001;  23 docs/s;    758 sec\n",
            "[2021-04-30 03:11:31,607 INFO] Step 1100/50000; xent: 3.27; lr: 0.0000001;  30 docs/s;    793 sec\n",
            "[2021-04-30 03:12:06,551 INFO] Step 1150/50000; xent: 3.29; lr: 0.0000001;  29 docs/s;    828 sec\n",
            "[2021-04-30 03:12:10,723 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.93.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:12:43,485 INFO] Step 1200/50000; xent: 3.16; lr: 0.0000001;  28 docs/s;    865 sec\n",
            "[2021-04-30 03:13:18,593 INFO] Step 1250/50000; xent: 3.23; lr: 0.0000001;  29 docs/s;    900 sec\n",
            "[2021-04-30 03:13:53,711 INFO] Step 1300/50000; xent: 3.21; lr: 0.0000001;  29 docs/s;    935 sec\n",
            "[2021-04-30 03:14:29,036 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.63.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:14:31,254 INFO] Step 1350/50000; xent: 3.25; lr: 0.0000001;  27 docs/s;    973 sec\n",
            "[2021-04-30 03:15:06,083 INFO] Step 1400/50000; xent: 3.22; lr: 0.0000001;  30 docs/s;   1008 sec\n",
            "[2021-04-30 03:15:41,212 INFO] Step 1450/50000; xent: 3.23; lr: 0.0000001;  29 docs/s;   1043 sec\n",
            "[2021-04-30 03:16:16,297 INFO] Step 1500/50000; xent: 3.18; lr: 0.0000002;  30 docs/s;   1078 sec\n",
            "[2021-04-30 03:16:45,673 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.15.bert.pt, number of examples: 2000\n",
            "[2021-04-30 03:16:53,507 INFO] Step 1550/50000; xent: 3.22; lr: 0.0000002;  28 docs/s;   1115 sec\n",
            "[2021-04-30 03:17:28,472 INFO] Step 1600/50000; xent: 3.23; lr: 0.0000002;  30 docs/s;   1150 sec\n",
            "[2021-04-30 03:18:03,572 INFO] Step 1650/50000; xent: 3.14; lr: 0.0000002;  30 docs/s;   1185 sec\n",
            "[2021-04-30 03:18:38,675 INFO] Step 1700/50000; xent: 3.11; lr: 0.0000002;  29 docs/s;   1220 sec\n",
            "[2021-04-30 03:19:03,356 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.64.bert.pt, number of examples: 1998\n",
            "[2021-04-30 03:19:16,142 INFO] Step 1750/50000; xent: 3.15; lr: 0.0000002;  27 docs/s;   1258 sec\n",
            "[2021-04-30 03:19:51,073 INFO] Step 1800/50000; xent: 3.19; lr: 0.0000002;  29 docs/s;   1293 sec\n",
            "[2021-04-30 03:20:26,101 INFO] Step 1850/50000; xent: 3.10; lr: 0.0000002;  31 docs/s;   1328 sec\n",
            "[2021-04-30 03:21:01,277 INFO] Step 1900/50000; xent: 3.18; lr: 0.0000002;  29 docs/s;   1363 sec\n",
            "[2021-04-30 03:21:20,472 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.28.bert.pt, number of examples: 1999\n",
            "[2021-04-30 03:21:38,885 INFO] Step 1950/50000; xent: 3.08; lr: 0.0000002;  27 docs/s;   1401 sec\n",
            "[2021-04-30 03:22:13,991 INFO] Step 2000/50000; xent: 3.12; lr: 0.0000002;  30 docs/s;   1436 sec\n",
            "[2021-04-30 03:22:14,005 INFO] Saving checkpoint ../data/trained_models/Tushar/model_step_2000.pt\n",
            "[2021-04-30 03:22:58,392 INFO] Step 2050/50000; xent: 3.17; lr: 0.0000002;  24 docs/s;   1480 sec\n",
            "[2021-04-30 03:23:33,517 INFO] Step 2100/50000; xent: 3.11; lr: 0.0000002;  29 docs/s;   1515 sec\n",
            "[2021-04-30 03:23:47,704 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.32.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:24:10,744 INFO] Step 2150/50000; xent: 3.11; lr: 0.0000002;  28 docs/s;   1552 sec\n",
            "[2021-04-30 03:24:45,817 INFO] Step 2200/50000; xent: 3.08; lr: 0.0000002;  30 docs/s;   1588 sec\n",
            "[2021-04-30 03:25:20,804 INFO] Step 2250/50000; xent: 3.04; lr: 0.0000002;  31 docs/s;   1622 sec\n",
            "[2021-04-30 03:25:55,776 INFO] Step 2300/50000; xent: 3.09; lr: 0.0000002;  30 docs/s;   1657 sec\n",
            "[2021-04-30 03:26:04,378 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.111.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:26:33,249 INFO] Step 2350/50000; xent: 3.11; lr: 0.0000002;  28 docs/s;   1695 sec\n",
            "[2021-04-30 03:27:08,241 INFO] Step 2400/50000; xent: 3.11; lr: 0.0000002;  30 docs/s;   1730 sec\n",
            "[2021-04-30 03:27:43,292 INFO] Step 2450/50000; xent: 3.07; lr: 0.0000002;  30 docs/s;   1765 sec\n",
            "[2021-04-30 03:28:18,165 INFO] Step 2500/50000; xent: 3.07; lr: 0.0000003;  30 docs/s;   1800 sec\n",
            "[2021-04-30 03:28:21,949 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.49.bert.pt, number of examples: 2000\n",
            "[2021-04-30 03:28:56,428 INFO] Step 2550/50000; xent: 3.07; lr: 0.0000003;  27 docs/s;   1838 sec\n",
            "[2021-04-30 03:29:31,404 INFO] Step 2600/50000; xent: 3.09; lr: 0.0000003;  30 docs/s;   1873 sec\n",
            "[2021-04-30 03:30:06,434 INFO] Step 2650/50000; xent: 3.06; lr: 0.0000003;  29 docs/s;   1908 sec\n",
            "[2021-04-30 03:30:38,914 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.59.bert.pt, number of examples: 2000\n",
            "[2021-04-30 03:30:43,923 INFO] Step 2700/50000; xent: 3.06; lr: 0.0000003;  28 docs/s;   1946 sec\n",
            "[2021-04-30 03:31:18,965 INFO] Step 2750/50000; xent: 3.06; lr: 0.0000003;  29 docs/s;   1981 sec\n",
            "[2021-04-30 03:31:53,815 INFO] Step 2800/50000; xent: 3.14; lr: 0.0000003;  30 docs/s;   2016 sec\n",
            "[2021-04-30 03:32:28,906 INFO] Step 2850/50000; xent: 3.02; lr: 0.0000003;  29 docs/s;   2051 sec\n",
            "[2021-04-30 03:32:56,205 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.84.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:33:06,115 INFO] Step 2900/50000; xent: 3.06; lr: 0.0000003;  27 docs/s;   2088 sec\n",
            "[2021-04-30 03:33:41,204 INFO] Step 2950/50000; xent: 3.06; lr: 0.0000003;  29 docs/s;   2123 sec\n",
            "[2021-04-30 03:34:16,196 INFO] Step 3000/50000; xent: 3.15; lr: 0.0000003;  31 docs/s;   2158 sec\n",
            "[2021-04-30 03:34:16,211 INFO] Saving checkpoint ../data/trained_models/Tushar/model_step_3000.pt\n",
            "[2021-04-30 03:35:00,326 INFO] Step 3050/50000; xent: 3.06; lr: 0.0000003;  23 docs/s;   2202 sec\n",
            "[2021-04-30 03:35:22,853 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.137.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:35:37,695 INFO] Step 3100/50000; xent: 3.07; lr: 0.0000003;  28 docs/s;   2239 sec\n",
            "[2021-04-30 03:36:12,806 INFO] Step 3150/50000; xent: 3.07; lr: 0.0000003;  29 docs/s;   2274 sec\n",
            "[2021-04-30 03:36:47,652 INFO] Step 3200/50000; xent: 3.19; lr: 0.0000003;  29 docs/s;   2309 sec\n",
            "[2021-04-30 03:37:22,674 INFO] Step 3250/50000; xent: 3.13; lr: 0.0000003;  30 docs/s;   2344 sec\n",
            "[2021-04-30 03:37:41,040 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.13.bert.pt, number of examples: 2000\n",
            "[2021-04-30 03:38:00,092 INFO] Step 3300/50000; xent: 3.01; lr: 0.0000003;  28 docs/s;   2382 sec\n",
            "[2021-04-30 03:38:35,054 INFO] Step 3350/50000; xent: 3.09; lr: 0.0000003;  29 docs/s;   2417 sec\n",
            "[2021-04-30 03:39:10,084 INFO] Step 3400/50000; xent: 2.99; lr: 0.0000003;  31 docs/s;   2452 sec\n",
            "[2021-04-30 03:39:45,138 INFO] Step 3450/50000; xent: 3.06; lr: 0.0000003;  30 docs/s;   2487 sec\n",
            "[2021-04-30 03:39:56,688 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.135.bert.pt, number of examples: 2000\n",
            "[2021-04-30 03:40:22,104 INFO] Step 3500/50000; xent: 3.10; lr: 0.0000003;  27 docs/s;   2524 sec\n",
            "[2021-04-30 03:40:57,261 INFO] Step 3550/50000; xent: 3.06; lr: 0.0000004;  30 docs/s;   2559 sec\n",
            "[2021-04-30 03:41:32,273 INFO] Step 3600/50000; xent: 3.11; lr: 0.0000004;  30 docs/s;   2594 sec\n",
            "[2021-04-30 03:42:07,210 INFO] Step 3650/50000; xent: 3.12; lr: 0.0000004;  30 docs/s;   2629 sec\n",
            "[2021-04-30 03:42:14,674 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.71.bert.pt, number of examples: 1999\n",
            "[2021-04-30 03:42:44,820 INFO] Step 3700/50000; xent: 3.07; lr: 0.0000004;  27 docs/s;   2667 sec\n",
            "[2021-04-30 03:43:19,969 INFO] Step 3750/50000; xent: 3.03; lr: 0.0000004;  30 docs/s;   2702 sec\n",
            "[2021-04-30 03:43:55,143 INFO] Step 3800/50000; xent: 3.07; lr: 0.0000004;  30 docs/s;   2737 sec\n",
            "[2021-04-30 03:44:31,905 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.9.bert.pt, number of examples: 2000\n",
            "[2021-04-30 03:44:32,725 INFO] Step 3850/50000; xent: 3.06; lr: 0.0000004;  28 docs/s;   2774 sec\n",
            "[2021-04-30 03:45:07,852 INFO] Step 3900/50000; xent: 3.03; lr: 0.0000004;  30 docs/s;   2810 sec\n",
            "[2021-04-30 03:45:42,788 INFO] Step 3950/50000; xent: 3.04; lr: 0.0000004;  29 docs/s;   2844 sec\n",
            "[2021-04-30 03:46:17,893 INFO] Step 4000/50000; xent: 3.06; lr: 0.0000004;  30 docs/s;   2880 sec\n",
            "[2021-04-30 03:46:17,907 INFO] Saving checkpoint ../data/trained_models/Tushar/model_step_4000.pt\n",
            "[2021-04-30 03:46:59,152 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.105.bert.pt, number of examples: 2000\n",
            "[2021-04-30 03:47:04,923 INFO] Step 4050/50000; xent: 3.02; lr: 0.0000004;  22 docs/s;   2927 sec\n",
            "[2021-04-30 03:47:40,046 INFO] Step 4100/50000; xent: 3.13; lr: 0.0000004;  30 docs/s;   2962 sec\n",
            "[2021-04-30 03:48:15,264 INFO] Step 4150/50000; xent: 3.19; lr: 0.0000004;  30 docs/s;   2997 sec\n",
            "[2021-04-30 03:48:50,329 INFO] Step 4200/50000; xent: 3.05; lr: 0.0000004;  30 docs/s;   3032 sec\n",
            "[2021-04-30 03:49:17,351 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.50.bert.pt, number of examples: 1999\n",
            "[2021-04-30 03:49:27,986 INFO] Step 4250/50000; xent: 3.14; lr: 0.0000004;  27 docs/s;   3070 sec\n",
            "[2021-04-30 03:50:03,034 INFO] Step 4300/50000; xent: 3.10; lr: 0.0000004;  30 docs/s;   3105 sec\n",
            "[2021-04-30 03:50:37,987 INFO] Step 4350/50000; xent: 3.04; lr: 0.0000004;  30 docs/s;   3140 sec\n",
            "[2021-04-30 03:51:13,051 INFO] Step 4400/50000; xent: 3.10; lr: 0.0000004;  29 docs/s;   3175 sec\n",
            "[2021-04-30 03:51:34,615 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.106.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:51:50,181 INFO] Step 4450/50000; xent: 3.11; lr: 0.0000004;  28 docs/s;   3212 sec\n",
            "[2021-04-30 03:52:25,391 INFO] Step 4500/50000; xent: 3.14; lr: 0.0000004;  31 docs/s;   3247 sec\n",
            "[2021-04-30 03:53:00,550 INFO] Step 4550/50000; xent: 3.05; lr: 0.0000005;  29 docs/s;   3282 sec\n",
            "[2021-04-30 03:53:35,746 INFO] Step 4600/50000; xent: 3.01; lr: 0.0000005;  29 docs/s;   3317 sec\n",
            "[2021-04-30 03:53:51,401 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.38.bert.pt, number of examples: 2001\n",
            "[2021-04-30 03:54:12,626 INFO] Step 4650/50000; xent: 3.06; lr: 0.0000005;  28 docs/s;   3354 sec\n",
            "[2021-04-30 03:54:47,875 INFO] Step 4700/50000; xent: 3.04; lr: 0.0000005;  29 docs/s;   3390 sec\n",
            "[2021-04-30 03:55:23,098 INFO] Step 4750/50000; xent: 3.08; lr: 0.0000005;  30 docs/s;   3425 sec\n",
            "[2021-04-30 03:55:58,103 INFO] Step 4800/50000; xent: 3.10; lr: 0.0000005;  29 docs/s;   3460 sec\n",
            "[2021-04-30 03:56:09,100 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.24.bert.pt, number of examples: 1999\n",
            "[2021-04-30 03:56:35,344 INFO] Step 4850/50000; xent: 3.00; lr: 0.0000005;  28 docs/s;   3497 sec\n",
            "[2021-04-30 03:57:10,311 INFO] Step 4900/50000; xent: 3.09; lr: 0.0000005;  30 docs/s;   3532 sec\n",
            "[2021-04-30 03:57:45,632 INFO] Step 4950/50000; xent: 3.14; lr: 0.0000005;  29 docs/s;   3567 sec\n",
            "[2021-04-30 03:58:20,607 INFO] Step 5000/50000; xent: 3.05; lr: 0.0000005;  30 docs/s;   3602 sec\n",
            "[2021-04-30 03:58:20,610 INFO] Saving checkpoint ../data/trained_models/Tushar/model_step_5000.pt\n",
            "[2021-04-30 03:58:34,687 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.143.bert.pt, number of examples: 1084\n",
            "[2021-04-30 03:59:07,343 INFO] Step 5050/50000; xent: 3.02; lr: 0.0000005;  23 docs/s;   3649 sec\n",
            "[2021-04-30 03:59:42,419 INFO] Step 5100/50000; xent: 3.05; lr: 0.0000005;  29 docs/s;   3684 sec\n",
            "[2021-04-30 03:59:52,188 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.94.bert.pt, number of examples: 2001\n",
            "[2021-04-30 04:00:20,379 INFO] Step 5150/50000; xent: 2.97; lr: 0.0000005;  27 docs/s;   3722 sec\n",
            "[2021-04-30 04:00:55,361 INFO] Step 5200/50000; xent: 2.98; lr: 0.0000005;  29 docs/s;   3757 sec\n",
            "[2021-04-30 04:01:30,425 INFO] Step 5250/50000; xent: 3.14; lr: 0.0000005;  30 docs/s;   3792 sec\n",
            "[2021-04-30 04:02:05,348 INFO] Step 5300/50000; xent: 3.03; lr: 0.0000005;  30 docs/s;   3827 sec\n",
            "[2021-04-30 04:02:08,700 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.62.bert.pt, number of examples: 2001\n",
            "[2021-04-30 04:02:42,300 INFO] Step 5350/50000; xent: 3.09; lr: 0.0000005;  28 docs/s;   3864 sec\n",
            "[2021-04-30 04:03:17,443 INFO] Step 5400/50000; xent: 3.10; lr: 0.0000005;  30 docs/s;   3899 sec\n",
            "[2021-04-30 04:03:52,625 INFO] Step 5450/50000; xent: 2.99; lr: 0.0000005;  30 docs/s;   3934 sec\n",
            "[2021-04-30 04:04:25,592 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.139.bert.pt, number of examples: 2000\n",
            "[2021-04-30 04:04:29,894 INFO] Step 5500/50000; xent: 3.04; lr: 0.0000006;  27 docs/s;   3972 sec\n",
            "[2021-04-30 04:05:05,028 INFO] Step 5550/50000; xent: 3.00; lr: 0.0000006;  29 docs/s;   4007 sec\n",
            "[2021-04-30 04:05:40,059 INFO] Step 5600/50000; xent: 2.94; lr: 0.0000006;  30 docs/s;   4042 sec\n",
            "[2021-04-30 04:06:15,050 INFO] Step 5650/50000; xent: 3.13; lr: 0.0000006;  30 docs/s;   4077 sec\n",
            "[2021-04-30 04:06:42,761 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.88.bert.pt, number of examples: 2000\n",
            "[2021-04-30 04:06:51,969 INFO] Step 5700/50000; xent: 3.08; lr: 0.0000006;  29 docs/s;   4114 sec\n",
            "[2021-04-30 04:07:26,898 INFO] Step 5750/50000; xent: 3.04; lr: 0.0000006;  29 docs/s;   4149 sec\n",
            "[2021-04-30 04:08:01,966 INFO] Step 5800/50000; xent: 3.03; lr: 0.0000006;  30 docs/s;   4184 sec\n",
            "[2021-04-30 04:08:37,099 INFO] Step 5850/50000; xent: 3.04; lr: 0.0000006;  30 docs/s;   4219 sec\n",
            "[2021-04-30 04:09:00,573 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.92.bert.pt, number of examples: 1998\n",
            "[2021-04-30 04:09:14,759 INFO] Step 5900/50000; xent: 3.17; lr: 0.0000006;  27 docs/s;   4256 sec\n",
            "[2021-04-30 04:09:49,955 INFO] Step 5950/50000; xent: 3.03; lr: 0.0000006;  29 docs/s;   4292 sec\n",
            "[2021-04-30 04:10:24,855 INFO] Step 6000/50000; xent: 3.01; lr: 0.0000006;  29 docs/s;   4327 sec\n",
            "[2021-04-30 04:10:24,870 INFO] Saving checkpoint ../data/trained_models/Tushar/model_step_6000.pt\n",
            "[2021-04-30 04:11:12,682 INFO] Step 6050/50000; xent: 3.07; lr: 0.0000006;  23 docs/s;   4374 sec\n",
            "[2021-04-30 04:11:29,832 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.68.bert.pt, number of examples: 2001\n",
            "[2021-04-30 04:11:49,616 INFO] Step 6100/50000; xent: 3.08; lr: 0.0000006;  27 docs/s;   4411 sec\n",
            "[2021-04-30 04:12:24,702 INFO] Step 6150/50000; xent: 3.01; lr: 0.0000006;  30 docs/s;   4446 sec\n",
            "[2021-04-30 04:12:59,817 INFO] Step 6200/50000; xent: 3.06; lr: 0.0000006;  30 docs/s;   4482 sec\n",
            "[2021-04-30 04:13:34,906 INFO] Step 6250/50000; xent: 2.99; lr: 0.0000006;  30 docs/s;   4517 sec\n",
            "[2021-04-30 04:13:47,220 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.0.bert.pt, number of examples: 2000\n",
            "[2021-04-30 04:14:11,903 INFO] Step 6300/50000; xent: 2.96; lr: 0.0000006;  28 docs/s;   4554 sec\n",
            "[2021-04-30 04:14:47,076 INFO] Step 6350/50000; xent: 3.00; lr: 0.0000006;  30 docs/s;   4589 sec\n",
            "[2021-04-30 04:15:22,155 INFO] Step 6400/50000; xent: 3.06; lr: 0.0000006;  29 docs/s;   4624 sec\n",
            "[2021-04-30 04:15:57,080 INFO] Step 6450/50000; xent: 3.11; lr: 0.0000006;  30 docs/s;   4659 sec\n",
            "[2021-04-30 04:16:05,273 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.83.bert.pt, number of examples: 1999\n",
            "[2021-04-30 04:16:34,900 INFO] Step 6500/50000; xent: 3.07; lr: 0.0000007;  28 docs/s;   4697 sec\n",
            "[2021-04-30 04:17:09,934 INFO] Step 6550/50000; xent: 2.98; lr: 0.0000007;  30 docs/s;   4732 sec\n",
            "[2021-04-30 04:17:45,116 INFO] Step 6600/50000; xent: 3.02; lr: 0.0000007;  30 docs/s;   4767 sec\n",
            "[2021-04-30 04:18:21,349 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.138.bert.pt, number of examples: 2000\n",
            "[2021-04-30 04:18:22,169 INFO] Step 6650/50000; xent: 3.05; lr: 0.0000007;  28 docs/s;   4804 sec\n",
            "[2021-04-30 04:18:57,446 INFO] Step 6700/50000; xent: 3.05; lr: 0.0000007;  29 docs/s;   4839 sec\n",
            "[2021-04-30 04:19:32,648 INFO] Step 6750/50000; xent: 3.02; lr: 0.0000007;  31 docs/s;   4874 sec\n",
            "[2021-04-30 04:20:07,840 INFO] Step 6800/50000; xent: 3.03; lr: 0.0000007;  29 docs/s;   4910 sec\n",
            "[2021-04-30 04:20:38,637 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.72.bert.pt, number of examples: 2001\n",
            "[2021-04-30 04:20:45,075 INFO] Step 6850/50000; xent: 3.04; lr: 0.0000007;  28 docs/s;   4947 sec\n",
            "[2021-04-30 04:21:20,279 INFO] Step 6900/50000; xent: 3.02; lr: 0.0000007;  29 docs/s;   4982 sec\n",
            "[2021-04-30 04:21:55,585 INFO] Step 6950/50000; xent: 3.09; lr: 0.0000007;  30 docs/s;   5017 sec\n",
            "[2021-04-30 04:22:30,824 INFO] Step 7000/50000; xent: 3.02; lr: 0.0000007;  29 docs/s;   5053 sec\n",
            "[2021-04-30 04:22:30,839 INFO] Saving checkpoint ../data/trained_models/Tushar/model_step_7000.pt\n",
            "[2021-04-30 04:23:05,824 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.89.bert.pt, number of examples: 2001\n",
            "[2021-04-30 04:23:17,630 INFO] Step 7050/50000; xent: 2.98; lr: 0.0000007;  22 docs/s;   5099 sec\n",
            "[2021-04-30 04:23:52,832 INFO] Step 7100/50000; xent: 3.02; lr: 0.0000007;  30 docs/s;   5135 sec\n",
            "[2021-04-30 04:24:28,090 INFO] Step 7150/50000; xent: 3.06; lr: 0.0000007;  29 docs/s;   5170 sec\n",
            "[2021-04-30 04:25:03,422 INFO] Step 7200/50000; xent: 2.97; lr: 0.0000007;  30 docs/s;   5205 sec\n",
            "[2021-04-30 04:25:23,609 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.51.bert.pt, number of examples: 1999\n",
            "[2021-04-30 04:25:40,634 INFO] Step 7250/50000; xent: 2.98; lr: 0.0000007;  28 docs/s;   5242 sec\n",
            "[2021-04-30 04:26:15,985 INFO] Step 7300/50000; xent: 3.03; lr: 0.0000007;  29 docs/s;   5278 sec\n",
            "[2021-04-30 04:26:51,226 INFO] Step 7350/50000; xent: 3.03; lr: 0.0000007;  29 docs/s;   5313 sec\n",
            "[2021-04-30 04:27:26,477 INFO] Step 7400/50000; xent: 3.02; lr: 0.0000007;  30 docs/s;   5348 sec\n",
            "[2021-04-30 04:27:42,125 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.35.bert.pt, number of examples: 2001\n",
            "[2021-04-30 04:28:04,151 INFO] Step 7450/50000; xent: 3.09; lr: 0.0000007;  27 docs/s;   5386 sec\n",
            "[2021-04-30 04:28:39,335 INFO] Step 7500/50000; xent: 3.11; lr: 0.0000008;  29 docs/s;   5421 sec\n",
            "[2021-04-30 04:29:14,578 INFO] Step 7550/50000; xent: 2.97; lr: 0.0000008;  29 docs/s;   5456 sec\n",
            "[2021-04-30 04:29:49,582 INFO] Step 7600/50000; xent: 3.04; lr: 0.0000008;  31 docs/s;   5491 sec\n",
            "[2021-04-30 04:30:00,452 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.37.bert.pt, number of examples: 2001\n",
            "[2021-04-30 04:30:27,347 INFO] Step 7650/50000; xent: 2.96; lr: 0.0000008;  28 docs/s;   5529 sec\n",
            "[2021-04-30 04:31:02,403 INFO] Step 7700/50000; xent: 2.94; lr: 0.0000008;  30 docs/s;   5564 sec\n",
            "[2021-04-30 04:31:37,517 INFO] Step 7750/50000; xent: 3.04; lr: 0.0000008;  29 docs/s;   5599 sec\n",
            "[2021-04-30 04:32:12,574 INFO] Step 7800/50000; xent: 3.01; lr: 0.0000008;  29 docs/s;   5634 sec\n",
            "[2021-04-30 04:32:17,423 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.80.bert.pt, number of examples: 2000\n",
            "[2021-04-30 04:32:49,835 INFO] Step 7850/50000; xent: 3.05; lr: 0.0000008;  28 docs/s;   5672 sec\n",
            "[2021-04-30 04:33:24,774 INFO] Step 7900/50000; xent: 3.13; lr: 0.0000008;  29 docs/s;   5706 sec\n",
            "[2021-04-30 04:33:59,886 INFO] Step 7950/50000; xent: 2.97; lr: 0.0000008;  30 docs/s;   5742 sec\n",
            "[2021-04-30 04:34:35,619 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.52.bert.pt, number of examples: 1999\n",
            "[2021-04-30 04:34:37,843 INFO] Step 8000/50000; xent: 3.01; lr: 0.0000008;  27 docs/s;   5780 sec\n",
            "[2021-04-30 04:34:37,858 INFO] Saving checkpoint ../data/trained_models/Tushar/model_step_8000.pt\n",
            "[2021-04-30 04:35:23,222 INFO] Step 8050/50000; xent: 2.97; lr: 0.0000008;  23 docs/s;   5825 sec\n",
            "[2021-04-30 04:35:58,388 INFO] Step 8100/50000; xent: 3.02; lr: 0.0000008;  29 docs/s;   5860 sec\n",
            "[2021-04-30 04:36:33,461 INFO] Step 8150/50000; xent: 2.97; lr: 0.0000008;  29 docs/s;   5895 sec\n",
            "[2021-04-30 04:37:02,405 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.12.bert.pt, number of examples: 1998\n",
            "[2021-04-30 04:37:10,217 INFO] Step 8200/50000; xent: 3.08; lr: 0.0000008;  28 docs/s;   5932 sec\n",
            "[2021-04-30 04:37:45,284 INFO] Step 8250/50000; xent: 3.01; lr: 0.0000008;  30 docs/s;   5967 sec\n",
            "[2021-04-30 04:38:20,459 INFO] Step 8300/50000; xent: 3.02; lr: 0.0000008;  29 docs/s;   6002 sec\n",
            "[2021-04-30 04:38:55,529 INFO] Step 8350/50000; xent: 3.04; lr: 0.0000008;  30 docs/s;   6037 sec\n",
            "[2021-04-30 04:39:19,167 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.114.bert.pt, number of examples: 2001\n",
            "[2021-04-30 04:39:32,637 INFO] Step 8400/50000; xent: 2.95; lr: 0.0000008;  28 docs/s;   6074 sec\n",
            "[2021-04-30 04:40:07,653 INFO] Step 8450/50000; xent: 3.11; lr: 0.0000008;  29 docs/s;   6109 sec\n",
            "[2021-04-30 04:40:42,844 INFO] Step 8500/50000; xent: 3.12; lr: 0.0000008;  29 docs/s;   6145 sec\n",
            "[2021-04-30 04:41:18,042 INFO] Step 8550/50000; xent: 2.94; lr: 0.0000009;  30 docs/s;   6180 sec\n",
            "[2021-04-30 04:41:35,943 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.86.bert.pt, number of examples: 1999\n",
            "[2021-04-30 04:41:55,052 INFO] Step 8600/50000; xent: 3.02; lr: 0.0000009;  28 docs/s;   6217 sec\n",
            "[2021-04-30 04:42:30,185 INFO] Step 8650/50000; xent: 3.13; lr: 0.0000009;  30 docs/s;   6252 sec\n",
            "[2021-04-30 04:43:05,328 INFO] Step 8700/50000; xent: 2.94; lr: 0.0000009;  30 docs/s;   6287 sec\n",
            "[2021-04-30 04:43:40,189 INFO] Step 8750/50000; xent: 3.02; lr: 0.0000009;  30 docs/s;   6322 sec\n",
            "[2021-04-30 04:43:54,033 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.113.bert.pt, number of examples: 2000\n",
            "[2021-04-30 04:44:18,017 INFO] Step 8800/50000; xent: 3.05; lr: 0.0000009;  27 docs/s;   6360 sec\n",
            "[2021-04-30 04:44:53,183 INFO] Step 8850/50000; xent: 2.98; lr: 0.0000009;  30 docs/s;   6395 sec\n",
            "[2021-04-30 04:45:28,302 INFO] Step 8900/50000; xent: 3.05; lr: 0.0000009;  29 docs/s;   6430 sec\n",
            "[2021-04-30 04:46:03,242 INFO] Step 8950/50000; xent: 3.04; lr: 0.0000009;  30 docs/s;   6465 sec\n",
            "[2021-04-30 04:46:11,354 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.96.bert.pt, number of examples: 1999\n",
            "[2021-04-30 04:46:40,318 INFO] Step 9000/50000; xent: 3.04; lr: 0.0000009;  28 docs/s;   6502 sec\n",
            "[2021-04-30 04:46:40,335 INFO] Saving checkpoint ../data/trained_models/Tushar/model_step_9000.pt\n",
            "[2021-04-30 04:47:24,981 INFO] Step 9050/50000; xent: 3.01; lr: 0.0000009;  23 docs/s;   6547 sec\n",
            "[2021-04-30 04:48:00,091 INFO] Step 9100/50000; xent: 3.07; lr: 0.0000009;  30 docs/s;   6582 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaWK_LhQHnTZ",
        "outputId": "9f2da495-593d-4654-c184-04e7778c97a6"
      },
      "source": [
        "!python3 train.py -task ext -encoder roberta -mode train -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -ext_dropout 0.1 -model_path ../data/trained_models/reberta_default -lr 2e-3 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file ../logs/ext_roberta_cnndm -use_interval true -warmup_steps 10000 -max_pos 514"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "----TRAIN EXTRACTIVE----\n",
            "[2021-04-30 04:54:21,779 INFO] Device ID 0\n",
            "[2021-04-30 04:54:22,520 INFO] Device cuda\n",
            "[2021-04-30 04:54:23,308 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-04-30 04:54:24,048 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-04-30 04:54:24,802 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-04-30 04:54:46,910 INFO] ExtSummarizer(\n",
            "  (bert): Roberta(\n",
            "    (model): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(516, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ext_layer): ExtTransformerEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2021-04-30 04:54:46,935 INFO] * number of parameters: 135678209\n",
            "[2021-04-30 04:54:46,935 INFO] Start training...\n",
            "[2021-04-30 04:54:51,139 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.123.bert.pt, number of examples: 2000\n",
            "[2021-04-30 04:55:26,590 INFO] Step 50/50000; xent: 4.39; lr: 0.0000001;  29 docs/s;     35 sec\n",
            "[2021-04-30 04:56:02,089 INFO] Step 100/50000; xent: 3.48; lr: 0.0000002;  30 docs/s;     71 sec\n",
            "[2021-04-30 04:56:37,486 INFO] Step 150/50000; xent: 3.33; lr: 0.0000003;  30 docs/s;    106 sec\n",
            "[2021-04-30 04:57:07,898 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.91.bert.pt, number of examples: 1995\n",
            "[2021-04-30 04:57:14,345 INFO] Step 200/50000; xent: 3.31; lr: 0.0000004;  28 docs/s;    143 sec\n",
            "[2021-04-30 04:57:49,497 INFO] Step 250/50000; xent: 3.28; lr: 0.0000005;  29 docs/s;    178 sec\n",
            "[2021-04-30 04:58:24,576 INFO] Step 300/50000; xent: 3.20; lr: 0.0000006;  29 docs/s;    213 sec\n",
            "[2021-04-30 04:58:59,512 INFO] Step 350/50000; xent: 3.24; lr: 0.0000007;  30 docs/s;    248 sec\n",
            "[2021-04-30 04:59:25,143 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.39.bert.pt, number of examples: 2001\n",
            "[2021-04-30 04:59:36,480 INFO] Step 400/50000; xent: 3.15; lr: 0.0000008;  28 docs/s;    285 sec\n",
            "[2021-04-30 05:00:11,600 INFO] Step 450/50000; xent: 3.15; lr: 0.0000009;  29 docs/s;    320 sec\n",
            "[2021-04-30 05:00:46,712 INFO] Step 500/50000; xent: 3.12; lr: 0.0000010;  31 docs/s;    356 sec\n",
            "[2021-04-30 05:01:21,837 INFO] Step 550/50000; xent: 3.08; lr: 0.0000011;  29 docs/s;    391 sec\n",
            "[2021-04-30 05:01:41,821 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.6.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:01:58,768 INFO] Step 600/50000; xent: 3.14; lr: 0.0000012;  28 docs/s;    428 sec\n",
            "[2021-04-30 05:02:33,905 INFO] Step 650/50000; xent: 3.21; lr: 0.0000013;  29 docs/s;    463 sec\n",
            "[2021-04-30 05:03:09,006 INFO] Step 700/50000; xent: 3.17; lr: 0.0000014;  29 docs/s;    498 sec\n",
            "[2021-04-30 05:03:44,179 INFO] Step 750/50000; xent: 3.08; lr: 0.0000015;  30 docs/s;    533 sec\n",
            "[2021-04-30 05:03:58,417 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.81.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:04:20,969 INFO] Step 800/50000; xent: 3.10; lr: 0.0000016;  29 docs/s;    570 sec\n",
            "[2021-04-30 05:04:56,126 INFO] Step 850/50000; xent: 3.08; lr: 0.0000017;  29 docs/s;    605 sec\n",
            "[2021-04-30 05:05:31,214 INFO] Step 900/50000; xent: 3.14; lr: 0.0000018;  29 docs/s;    640 sec\n",
            "[2021-04-30 05:06:05,972 INFO] Step 950/50000; xent: 3.08; lr: 0.0000019;  30 docs/s;    675 sec\n",
            "[2021-04-30 05:06:16,287 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.98.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:06:43,804 INFO] Step 1000/50000; xent: 3.06; lr: 0.0000020;  27 docs/s;    713 sec\n",
            "[2021-04-30 05:06:43,819 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_1000.pt\n",
            "[2021-04-30 05:07:26,289 INFO] Step 1050/50000; xent: 3.06; lr: 0.0000021;  24 docs/s;    755 sec\n",
            "[2021-04-30 05:08:01,281 INFO] Step 1100/50000; xent: 3.07; lr: 0.0000022;  31 docs/s;    790 sec\n",
            "[2021-04-30 05:08:36,221 INFO] Step 1150/50000; xent: 3.15; lr: 0.0000023;  29 docs/s;    825 sec\n",
            "[2021-04-30 05:08:40,372 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.93.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:09:13,170 INFO] Step 1200/50000; xent: 2.97; lr: 0.0000024;  28 docs/s;    862 sec\n",
            "[2021-04-30 05:09:48,287 INFO] Step 1250/50000; xent: 3.08; lr: 0.0000025;  29 docs/s;    897 sec\n",
            "[2021-04-30 05:10:23,438 INFO] Step 1300/50000; xent: 3.08; lr: 0.0000026;  29 docs/s;    932 sec\n",
            "[2021-04-30 05:10:58,694 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.63.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:11:00,911 INFO] Step 1350/50000; xent: 3.07; lr: 0.0000027;  27 docs/s;    970 sec\n",
            "[2021-04-30 05:11:35,780 INFO] Step 1400/50000; xent: 3.10; lr: 0.0000028;  30 docs/s;   1005 sec\n",
            "[2021-04-30 05:12:10,915 INFO] Step 1450/50000; xent: 3.09; lr: 0.0000029;  29 docs/s;   1040 sec\n",
            "[2021-04-30 05:12:46,044 INFO] Step 1500/50000; xent: 3.03; lr: 0.0000030;  30 docs/s;   1075 sec\n",
            "[2021-04-30 05:13:15,107 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.15.bert.pt, number of examples: 2000\n",
            "[2021-04-30 05:13:22,953 INFO] Step 1550/50000; xent: 3.08; lr: 0.0000031;  29 docs/s;   1112 sec\n",
            "[2021-04-30 05:13:57,980 INFO] Step 1600/50000; xent: 3.09; lr: 0.0000032;  30 docs/s;   1147 sec\n",
            "[2021-04-30 05:14:33,103 INFO] Step 1650/50000; xent: 2.99; lr: 0.0000033;  30 docs/s;   1182 sec\n",
            "[2021-04-30 05:15:08,277 INFO] Step 1700/50000; xent: 3.02; lr: 0.0000034;  29 docs/s;   1217 sec\n",
            "[2021-04-30 05:15:32,441 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.64.bert.pt, number of examples: 1998\n",
            "[2021-04-30 05:15:45,216 INFO] Step 1750/50000; xent: 3.04; lr: 0.0000035;  28 docs/s;   1254 sec\n",
            "[2021-04-30 05:16:20,199 INFO] Step 1800/50000; xent: 3.09; lr: 0.0000036;  29 docs/s;   1289 sec\n",
            "[2021-04-30 05:16:55,274 INFO] Step 1850/50000; xent: 2.98; lr: 0.0000037;  31 docs/s;   1324 sec\n",
            "[2021-04-30 05:17:30,428 INFO] Step 1900/50000; xent: 3.09; lr: 0.0000038;  29 docs/s;   1359 sec\n",
            "[2021-04-30 05:17:49,182 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.28.bert.pt, number of examples: 1999\n",
            "[2021-04-30 05:18:07,557 INFO] Step 1950/50000; xent: 2.98; lr: 0.0000039;  28 docs/s;   1396 sec\n",
            "[2021-04-30 05:18:42,698 INFO] Step 2000/50000; xent: 3.01; lr: 0.0000040;  29 docs/s;   1432 sec\n",
            "[2021-04-30 05:18:42,713 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_2000.pt\n",
            "[2021-04-30 05:19:24,761 INFO] Step 2050/50000; xent: 3.08; lr: 0.0000041;  25 docs/s;   1474 sec\n",
            "[2021-04-30 05:19:59,930 INFO] Step 2100/50000; xent: 3.03; lr: 0.0000042;  29 docs/s;   1509 sec\n",
            "[2021-04-30 05:20:13,873 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.32.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:20:36,972 INFO] Step 2150/50000; xent: 3.03; lr: 0.0000043;  28 docs/s;   1546 sec\n",
            "[2021-04-30 05:21:12,176 INFO] Step 2200/50000; xent: 3.00; lr: 0.0000044;  30 docs/s;   1581 sec\n",
            "[2021-04-30 05:21:47,254 INFO] Step 2250/50000; xent: 2.93; lr: 0.0000045;  31 docs/s;   1616 sec\n",
            "[2021-04-30 05:22:22,294 INFO] Step 2300/50000; xent: 2.98; lr: 0.0000046;  30 docs/s;   1651 sec\n",
            "[2021-04-30 05:22:30,073 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.111.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:22:59,006 INFO] Step 2350/50000; xent: 3.04; lr: 0.0000047;  29 docs/s;   1688 sec\n",
            "[2021-04-30 05:23:34,102 INFO] Step 2400/50000; xent: 3.02; lr: 0.0000048;  30 docs/s;   1723 sec\n",
            "[2021-04-30 05:24:09,218 INFO] Step 2450/50000; xent: 2.99; lr: 0.0000049;  30 docs/s;   1758 sec\n",
            "[2021-04-30 05:24:44,182 INFO] Step 2500/50000; xent: 3.03; lr: 0.0000050;  30 docs/s;   1793 sec\n",
            "[2021-04-30 05:24:46,793 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.49.bert.pt, number of examples: 2000\n",
            "[2021-04-30 05:25:21,362 INFO] Step 2550/50000; xent: 3.02; lr: 0.0000051;  28 docs/s;   1830 sec\n",
            "[2021-04-30 05:25:56,435 INFO] Step 2600/50000; xent: 3.00; lr: 0.0000052;  30 docs/s;   1865 sec\n",
            "[2021-04-30 05:26:31,514 INFO] Step 2650/50000; xent: 2.98; lr: 0.0000053;  29 docs/s;   1900 sec\n",
            "[2021-04-30 05:27:03,323 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.59.bert.pt, number of examples: 2000\n",
            "[2021-04-30 05:27:08,351 INFO] Step 2700/50000; xent: 3.00; lr: 0.0000054;  28 docs/s;   1937 sec\n",
            "[2021-04-30 05:27:43,472 INFO] Step 2750/50000; xent: 2.99; lr: 0.0000055;  29 docs/s;   1972 sec\n",
            "[2021-04-30 05:28:18,432 INFO] Step 2800/50000; xent: 3.05; lr: 0.0000056;  30 docs/s;   2007 sec\n",
            "[2021-04-30 05:28:53,623 INFO] Step 2850/50000; xent: 2.96; lr: 0.0000057;  29 docs/s;   2042 sec\n",
            "[2021-04-30 05:29:20,418 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.84.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:29:30,342 INFO] Step 2900/50000; xent: 2.99; lr: 0.0000058;  28 docs/s;   2079 sec\n",
            "[2021-04-30 05:30:05,474 INFO] Step 2950/50000; xent: 3.00; lr: 0.0000059;  29 docs/s;   2114 sec\n",
            "[2021-04-30 05:30:40,508 INFO] Step 3000/50000; xent: 3.07; lr: 0.0000060;  31 docs/s;   2149 sec\n",
            "[2021-04-30 05:30:40,523 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_3000.pt\n",
            "[2021-04-30 05:31:22,244 INFO] Step 3050/50000; xent: 2.99; lr: 0.0000061;  24 docs/s;   2191 sec\n",
            "[2021-04-30 05:31:43,916 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.137.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:31:58,780 INFO] Step 3100/50000; xent: 3.00; lr: 0.0000062;  29 docs/s;   2228 sec\n",
            "[2021-04-30 05:32:33,976 INFO] Step 3150/50000; xent: 2.99; lr: 0.0000063;  29 docs/s;   2263 sec\n",
            "[2021-04-30 05:33:08,939 INFO] Step 3200/50000; xent: 3.11; lr: 0.0000064;  29 docs/s;   2298 sec\n",
            "[2021-04-30 05:33:44,038 INFO] Step 3250/50000; xent: 3.04; lr: 0.0000065;  30 docs/s;   2333 sec\n",
            "[2021-04-30 05:34:01,954 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.13.bert.pt, number of examples: 2000\n",
            "[2021-04-30 05:34:21,042 INFO] Step 3300/50000; xent: 2.95; lr: 0.0000066;  28 docs/s;   2370 sec\n",
            "[2021-04-30 05:34:56,131 INFO] Step 3350/50000; xent: 3.04; lr: 0.0000067;  29 docs/s;   2405 sec\n",
            "[2021-04-30 05:35:31,228 INFO] Step 3400/50000; xent: 2.93; lr: 0.0000068;  31 docs/s;   2440 sec\n",
            "[2021-04-30 05:36:06,346 INFO] Step 3450/50000; xent: 3.00; lr: 0.0000069;  30 docs/s;   2475 sec\n",
            "[2021-04-30 05:36:18,821 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.135.bert.pt, number of examples: 2000\n",
            "[2021-04-30 05:36:44,251 INFO] Step 3500/50000; xent: 3.04; lr: 0.0000070;  26 docs/s;   2513 sec\n",
            "[2021-04-30 05:37:19,386 INFO] Step 3550/50000; xent: 2.98; lr: 0.0000071;  30 docs/s;   2548 sec\n",
            "[2021-04-30 05:37:54,510 INFO] Step 3600/50000; xent: 3.04; lr: 0.0000072;  29 docs/s;   2583 sec\n",
            "[2021-04-30 05:38:29,535 INFO] Step 3650/50000; xent: 3.05; lr: 0.0000073;  30 docs/s;   2618 sec\n",
            "[2021-04-30 05:38:35,931 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.71.bert.pt, number of examples: 1999\n",
            "[2021-04-30 05:39:06,110 INFO] Step 3700/50000; xent: 3.01; lr: 0.0000074;  28 docs/s;   2655 sec\n",
            "[2021-04-30 05:39:41,198 INFO] Step 3750/50000; xent: 2.95; lr: 0.0000075;  30 docs/s;   2690 sec\n",
            "[2021-04-30 05:40:16,384 INFO] Step 3800/50000; xent: 3.01; lr: 0.0000076;  30 docs/s;   2725 sec\n",
            "[2021-04-30 05:40:52,665 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.9.bert.pt, number of examples: 2000\n",
            "[2021-04-30 05:40:53,484 INFO] Step 3850/50000; xent: 3.00; lr: 0.0000077;  28 docs/s;   2762 sec\n",
            "[2021-04-30 05:41:28,592 INFO] Step 3900/50000; xent: 2.96; lr: 0.0000078;  30 docs/s;   2797 sec\n",
            "[2021-04-30 05:42:03,458 INFO] Step 3950/50000; xent: 2.99; lr: 0.0000079;  30 docs/s;   2832 sec\n",
            "[2021-04-30 05:42:38,554 INFO] Step 4000/50000; xent: 2.98; lr: 0.0000080;  30 docs/s;   2867 sec\n",
            "[2021-04-30 05:42:38,569 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_4000.pt\n",
            "[2021-04-30 05:43:16,875 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.105.bert.pt, number of examples: 2000\n",
            "[2021-04-30 05:43:22,676 INFO] Step 4050/50000; xent: 2.96; lr: 0.0000081;  23 docs/s;   2912 sec\n",
            "[2021-04-30 05:43:57,947 INFO] Step 4100/50000; xent: 3.07; lr: 0.0000082;  29 docs/s;   2947 sec\n",
            "[2021-04-30 05:44:33,131 INFO] Step 4150/50000; xent: 3.14; lr: 0.0000083;  30 docs/s;   2982 sec\n",
            "[2021-04-30 05:45:08,223 INFO] Step 4200/50000; xent: 2.99; lr: 0.0000084;  30 docs/s;   3017 sec\n",
            "[2021-04-30 05:45:34,635 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.50.bert.pt, number of examples: 1999\n",
            "[2021-04-30 05:45:45,281 INFO] Step 4250/50000; xent: 3.08; lr: 0.0000085;  27 docs/s;   3054 sec\n",
            "[2021-04-30 05:46:20,390 INFO] Step 4300/50000; xent: 3.04; lr: 0.0000086;  30 docs/s;   3089 sec\n",
            "[2021-04-30 05:46:55,469 INFO] Step 4350/50000; xent: 2.98; lr: 0.0000087;  30 docs/s;   3124 sec\n",
            "[2021-04-30 05:47:30,566 INFO] Step 4400/50000; xent: 3.03; lr: 0.0000088;  29 docs/s;   3159 sec\n",
            "[2021-04-30 05:47:51,741 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.106.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:48:07,327 INFO] Step 4450/50000; xent: 3.05; lr: 0.0000089;  28 docs/s;   3196 sec\n",
            "[2021-04-30 05:48:42,483 INFO] Step 4500/50000; xent: 3.07; lr: 0.0000090;  31 docs/s;   3231 sec\n",
            "[2021-04-30 05:49:17,564 INFO] Step 4550/50000; xent: 2.98; lr: 0.0000091;  29 docs/s;   3266 sec\n",
            "[2021-04-30 05:49:52,704 INFO] Step 4600/50000; xent: 2.95; lr: 0.0000092;  29 docs/s;   3302 sec\n",
            "[2021-04-30 05:50:08,238 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.38.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:50:29,428 INFO] Step 4650/50000; xent: 2.98; lr: 0.0000093;  28 docs/s;   3338 sec\n",
            "[2021-04-30 05:51:04,605 INFO] Step 4700/50000; xent: 2.98; lr: 0.0000094;  29 docs/s;   3373 sec\n",
            "[2021-04-30 05:51:39,710 INFO] Step 4750/50000; xent: 3.01; lr: 0.0000095;  30 docs/s;   3409 sec\n",
            "[2021-04-30 05:52:14,585 INFO] Step 4800/50000; xent: 3.03; lr: 0.0000096;  29 docs/s;   3443 sec\n",
            "[2021-04-30 05:52:25,554 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.24.bert.pt, number of examples: 1999\n",
            "[2021-04-30 05:52:51,704 INFO] Step 4850/50000; xent: 2.94; lr: 0.0000097;  28 docs/s;   3481 sec\n",
            "[2021-04-30 05:53:26,566 INFO] Step 4900/50000; xent: 3.04; lr: 0.0000098;  30 docs/s;   3515 sec\n",
            "[2021-04-30 05:54:01,722 INFO] Step 4950/50000; xent: 3.07; lr: 0.0000099;  29 docs/s;   3551 sec\n",
            "[2021-04-30 05:54:36,560 INFO] Step 5000/50000; xent: 3.00; lr: 0.0000100;  30 docs/s;   3585 sec\n",
            "[2021-04-30 05:54:36,564 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_5000.pt\n",
            "[2021-04-30 05:54:48,354 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.143.bert.pt, number of examples: 1084\n",
            "[2021-04-30 05:55:20,391 INFO] Step 5050/50000; xent: 2.97; lr: 0.0000101;  24 docs/s;   3629 sec\n",
            "[2021-04-30 05:55:55,301 INFO] Step 5100/50000; xent: 2.98; lr: 0.0000102;  29 docs/s;   3664 sec\n",
            "[2021-04-30 05:56:04,073 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.94.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:56:32,287 INFO] Step 5150/50000; xent: 2.91; lr: 0.0000103;  28 docs/s;   3701 sec\n",
            "[2021-04-30 05:57:07,332 INFO] Step 5200/50000; xent: 2.92; lr: 0.0000104;  29 docs/s;   3736 sec\n",
            "[2021-04-30 05:57:42,420 INFO] Step 5250/50000; xent: 3.07; lr: 0.0000105;  30 docs/s;   3771 sec\n",
            "[2021-04-30 05:58:17,409 INFO] Step 5300/50000; xent: 2.97; lr: 0.0000106;  30 docs/s;   3806 sec\n",
            "[2021-04-30 05:58:20,600 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.62.bert.pt, number of examples: 2001\n",
            "[2021-04-30 05:58:54,240 INFO] Step 5350/50000; xent: 3.04; lr: 0.0000107;  28 docs/s;   3843 sec\n",
            "[2021-04-30 05:59:29,363 INFO] Step 5400/50000; xent: 3.04; lr: 0.0000108;  30 docs/s;   3878 sec\n",
            "[2021-04-30 06:00:04,500 INFO] Step 5450/50000; xent: 2.93; lr: 0.0000109;  30 docs/s;   3913 sec\n",
            "[2021-04-30 06:00:36,890 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.139.bert.pt, number of examples: 2000\n",
            "[2021-04-30 06:00:41,200 INFO] Step 5500/50000; xent: 2.98; lr: 0.0000110;  28 docs/s;   3950 sec\n",
            "[2021-04-30 06:01:16,359 INFO] Step 5550/50000; xent: 2.95; lr: 0.0000111;  29 docs/s;   3985 sec\n",
            "[2021-04-30 06:01:51,444 INFO] Step 5600/50000; xent: 2.89; lr: 0.0000112;  30 docs/s;   4020 sec\n",
            "[2021-04-30 06:02:26,492 INFO] Step 5650/50000; xent: 3.10; lr: 0.0000113;  30 docs/s;   4055 sec\n",
            "[2021-04-30 06:02:54,509 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.88.bert.pt, number of examples: 2000\n",
            "[2021-04-30 06:03:03,715 INFO] Step 5700/50000; xent: 3.02; lr: 0.0000114;  28 docs/s;   4093 sec\n",
            "[2021-04-30 06:03:38,623 INFO] Step 5750/50000; xent: 2.98; lr: 0.0000115;  29 docs/s;   4127 sec\n",
            "[2021-04-30 06:04:13,712 INFO] Step 5800/50000; xent: 2.98; lr: 0.0000116;  30 docs/s;   4163 sec\n",
            "[2021-04-30 06:04:48,867 INFO] Step 5850/50000; xent: 3.01; lr: 0.0000117;  30 docs/s;   4198 sec\n",
            "[2021-04-30 06:05:12,077 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.92.bert.pt, number of examples: 1998\n",
            "[2021-04-30 06:05:26,259 INFO] Step 5900/50000; xent: 3.10; lr: 0.0000118;  27 docs/s;   4235 sec\n",
            "[2021-04-30 06:06:01,441 INFO] Step 5950/50000; xent: 2.98; lr: 0.0000119;  30 docs/s;   4270 sec\n",
            "[2021-04-30 06:06:36,364 INFO] Step 6000/50000; xent: 2.94; lr: 0.0000120;  29 docs/s;   4305 sec\n",
            "[2021-04-30 06:06:36,379 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_6000.pt\n",
            "[2021-04-30 06:07:18,557 INFO] Step 6050/50000; xent: 3.00; lr: 0.0000121;  26 docs/s;   4347 sec\n",
            "[2021-04-30 06:07:35,615 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.68.bert.pt, number of examples: 2001\n",
            "[2021-04-30 06:07:55,386 INFO] Step 6100/50000; xent: 3.02; lr: 0.0000122;  27 docs/s;   4384 sec\n",
            "[2021-04-30 06:08:30,520 INFO] Step 6150/50000; xent: 2.96; lr: 0.0000123;  29 docs/s;   4419 sec\n",
            "[2021-04-30 06:09:05,653 INFO] Step 6200/50000; xent: 3.00; lr: 0.0000124;  30 docs/s;   4455 sec\n",
            "[2021-04-30 06:09:40,746 INFO] Step 6250/50000; xent: 2.94; lr: 0.0000125;  30 docs/s;   4490 sec\n",
            "[2021-04-30 06:09:53,583 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.0.bert.pt, number of examples: 2000\n",
            "[2021-04-30 06:10:18,238 INFO] Step 6300/50000; xent: 2.94; lr: 0.0000126;  27 docs/s;   4527 sec\n",
            "[2021-04-30 06:10:53,343 INFO] Step 6350/50000; xent: 2.97; lr: 0.0000127;  30 docs/s;   4562 sec\n",
            "[2021-04-30 06:11:28,443 INFO] Step 6400/50000; xent: 3.04; lr: 0.0000128;  29 docs/s;   4597 sec\n",
            "[2021-04-30 06:12:03,393 INFO] Step 6450/50000; xent: 3.07; lr: 0.0000129;  30 docs/s;   4632 sec\n",
            "[2021-04-30 06:12:10,820 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.83.bert.pt, number of examples: 1999\n",
            "[2021-04-30 06:12:40,425 INFO] Step 6500/50000; xent: 3.03; lr: 0.0000130;  28 docs/s;   4669 sec\n",
            "[2021-04-30 06:13:15,430 INFO] Step 6550/50000; xent: 2.93; lr: 0.0000131;  30 docs/s;   4704 sec\n",
            "[2021-04-30 06:13:50,515 INFO] Step 6600/50000; xent: 2.97; lr: 0.0000132;  30 docs/s;   4739 sec\n",
            "[2021-04-30 06:14:26,593 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.138.bert.pt, number of examples: 2000\n",
            "[2021-04-30 06:14:27,404 INFO] Step 6650/50000; xent: 3.00; lr: 0.0000133;  28 docs/s;   4776 sec\n",
            "[2021-04-30 06:15:02,569 INFO] Step 6700/50000; xent: 3.01; lr: 0.0000134;  29 docs/s;   4811 sec\n",
            "[2021-04-30 06:15:37,640 INFO] Step 6750/50000; xent: 2.99; lr: 0.0000135;  31 docs/s;   4847 sec\n",
            "[2021-04-30 06:16:12,713 INFO] Step 6800/50000; xent: 2.99; lr: 0.0000136;  29 docs/s;   4882 sec\n",
            "[2021-04-30 06:16:43,028 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.72.bert.pt, number of examples: 2001\n",
            "[2021-04-30 06:16:49,427 INFO] Step 6850/50000; xent: 2.99; lr: 0.0000137;  28 docs/s;   4918 sec\n",
            "[2021-04-30 06:17:24,493 INFO] Step 6900/50000; xent: 2.96; lr: 0.0000138;  29 docs/s;   4953 sec\n",
            "[2021-04-30 06:17:59,686 INFO] Step 6950/50000; xent: 3.04; lr: 0.0000139;  30 docs/s;   4989 sec\n",
            "[2021-04-30 06:18:34,783 INFO] Step 7000/50000; xent: 2.99; lr: 0.0000140;  30 docs/s;   5024 sec\n",
            "[2021-04-30 06:18:34,797 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_7000.pt\n",
            "[2021-04-30 06:19:06,855 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.89.bert.pt, number of examples: 2001\n",
            "[2021-04-30 06:19:18,359 INFO] Step 7050/50000; xent: 2.93; lr: 0.0000141;  24 docs/s;   5067 sec\n",
            "[2021-04-30 06:19:53,523 INFO] Step 7100/50000; xent: 3.00; lr: 0.0000142;  30 docs/s;   5102 sec\n",
            "[2021-04-30 06:20:28,625 INFO] Step 7150/50000; xent: 3.01; lr: 0.0000143;  29 docs/s;   5137 sec\n",
            "[2021-04-30 06:21:03,747 INFO] Step 7200/50000; xent: 2.93; lr: 0.0000144;  30 docs/s;   5173 sec\n",
            "[2021-04-30 06:21:24,063 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.51.bert.pt, number of examples: 1999\n",
            "[2021-04-30 06:21:40,977 INFO] Step 7250/50000; xent: 2.95; lr: 0.0000145;  28 docs/s;   5210 sec\n",
            "[2021-04-30 06:22:16,091 INFO] Step 7300/50000; xent: 2.98; lr: 0.0000146;  29 docs/s;   5245 sec\n",
            "[2021-04-30 06:22:51,126 INFO] Step 7350/50000; xent: 2.98; lr: 0.0000147;  29 docs/s;   5280 sec\n",
            "[2021-04-30 06:23:26,181 INFO] Step 7400/50000; xent: 2.96; lr: 0.0000148;  30 docs/s;   5315 sec\n",
            "[2021-04-30 06:23:41,318 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.35.bert.pt, number of examples: 2001\n",
            "[2021-04-30 06:24:03,195 INFO] Step 7450/50000; xent: 3.04; lr: 0.0000149;  27 docs/s;   5352 sec\n",
            "[2021-04-30 06:24:38,205 INFO] Step 7500/50000; xent: 3.04; lr: 0.0000150;  30 docs/s;   5387 sec\n",
            "[2021-04-30 06:25:13,250 INFO] Step 7550/50000; xent: 2.95; lr: 0.0000151;  30 docs/s;   5422 sec\n",
            "[2021-04-30 06:25:48,207 INFO] Step 7600/50000; xent: 2.99; lr: 0.0000152;  31 docs/s;   5457 sec\n",
            "[2021-04-30 06:25:58,264 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.37.bert.pt, number of examples: 2001\n",
            "[2021-04-30 06:26:25,095 INFO] Step 7650/50000; xent: 2.94; lr: 0.0000153;  28 docs/s;   5494 sec\n",
            "[2021-04-30 06:27:00,029 INFO] Step 7700/50000; xent: 2.89; lr: 0.0000154;  30 docs/s;   5529 sec\n",
            "[2021-04-30 06:27:35,112 INFO] Step 7750/50000; xent: 3.01; lr: 0.0000155;  29 docs/s;   5564 sec\n",
            "[2021-04-30 06:28:10,192 INFO] Step 7800/50000; xent: 2.97; lr: 0.0000156;  29 docs/s;   5599 sec\n",
            "[2021-04-30 06:28:14,764 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.80.bert.pt, number of examples: 2000\n",
            "[2021-04-30 06:28:47,165 INFO] Step 7850/50000; xent: 3.01; lr: 0.0000157;  28 docs/s;   5636 sec\n",
            "[2021-04-30 06:29:22,106 INFO] Step 7900/50000; xent: 3.09; lr: 0.0000158;  29 docs/s;   5671 sec\n",
            "[2021-04-30 06:29:57,181 INFO] Step 7950/50000; xent: 2.94; lr: 0.0000159;  30 docs/s;   5706 sec\n",
            "[2021-04-30 06:30:31,957 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.52.bert.pt, number of examples: 1999\n",
            "[2021-04-30 06:30:34,165 INFO] Step 8000/50000; xent: 2.97; lr: 0.0000160;  28 docs/s;   5743 sec\n",
            "[2021-04-30 06:30:34,180 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_8000.pt\n",
            "[2021-04-30 06:31:15,972 INFO] Step 8050/50000; xent: 2.94; lr: 0.0000161;  25 docs/s;   5785 sec\n",
            "[2021-04-30 06:31:51,173 INFO] Step 8100/50000; xent: 2.98; lr: 0.0000162;  29 docs/s;   5820 sec\n",
            "[2021-04-30 06:32:26,249 INFO] Step 8150/50000; xent: 2.93; lr: 0.0000163;  29 docs/s;   5855 sec\n",
            "[2021-04-30 06:32:55,431 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.12.bert.pt, number of examples: 1998\n",
            "[2021-04-30 06:33:03,243 INFO] Step 8200/50000; xent: 3.03; lr: 0.0000164;  28 docs/s;   5892 sec\n",
            "[2021-04-30 06:33:38,286 INFO] Step 8250/50000; xent: 2.97; lr: 0.0000165;  30 docs/s;   5927 sec\n",
            "[2021-04-30 06:34:13,468 INFO] Step 8300/50000; xent: 2.99; lr: 0.0000166;  29 docs/s;   5962 sec\n",
            "[2021-04-30 06:34:48,499 INFO] Step 8350/50000; xent: 2.99; lr: 0.0000167;  30 docs/s;   5997 sec\n",
            "[2021-04-30 06:35:11,965 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.114.bert.pt, number of examples: 2001\n",
            "[2021-04-30 06:35:25,419 INFO] Step 8400/50000; xent: 2.92; lr: 0.0000168;  29 docs/s;   6034 sec\n",
            "[2021-04-30 06:36:00,386 INFO] Step 8450/50000; xent: 3.07; lr: 0.0000169;  30 docs/s;   6069 sec\n",
            "[2021-04-30 06:36:35,503 INFO] Step 8500/50000; xent: 3.09; lr: 0.0000170;  29 docs/s;   6104 sec\n",
            "[2021-04-30 06:37:10,664 INFO] Step 8550/50000; xent: 2.92; lr: 0.0000171;  30 docs/s;   6140 sec\n",
            "[2021-04-30 06:37:28,603 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.86.bert.pt, number of examples: 1999\n",
            "[2021-04-30 06:37:47,686 INFO] Step 8600/50000; xent: 2.98; lr: 0.0000172;  27 docs/s;   6177 sec\n",
            "[2021-04-30 06:38:22,752 INFO] Step 8650/50000; xent: 3.08; lr: 0.0000173;  30 docs/s;   6212 sec\n",
            "[2021-04-30 06:38:57,872 INFO] Step 8700/50000; xent: 2.89; lr: 0.0000174;  30 docs/s;   6247 sec\n",
            "[2021-04-30 06:39:32,678 INFO] Step 8750/50000; xent: 2.97; lr: 0.0000175;  30 docs/s;   6282 sec\n",
            "[2021-04-30 06:39:45,550 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.113.bert.pt, number of examples: 2000\n",
            "[2021-04-30 06:40:09,480 INFO] Step 8800/50000; xent: 3.02; lr: 0.0000176;  28 docs/s;   6318 sec\n",
            "[2021-04-30 06:40:44,621 INFO] Step 8850/50000; xent: 2.95; lr: 0.0000177;  30 docs/s;   6353 sec\n",
            "[2021-04-30 06:41:19,738 INFO] Step 8900/50000; xent: 3.03; lr: 0.0000178;  29 docs/s;   6389 sec\n",
            "[2021-04-30 06:41:54,652 INFO] Step 8950/50000; xent: 3.00; lr: 0.0000179;  30 docs/s;   6424 sec\n",
            "[2021-04-30 06:42:02,609 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.96.bert.pt, number of examples: 1999\n",
            "[2021-04-30 06:42:31,520 INFO] Step 9000/50000; xent: 3.02; lr: 0.0000180;  29 docs/s;   6460 sec\n",
            "[2021-04-30 06:42:31,536 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_9000.pt\n",
            "[2021-04-30 06:43:13,344 INFO] Step 9050/50000; xent: 2.98; lr: 0.0000181;  25 docs/s;   6502 sec\n",
            "[2021-04-30 06:43:48,526 INFO] Step 9100/50000; xent: 3.04; lr: 0.0000182;  30 docs/s;   6537 sec\n",
            "[2021-04-30 06:44:23,630 INFO] Step 9150/50000; xent: 2.98; lr: 0.0000183;  30 docs/s;   6572 sec\n",
            "[2021-04-30 06:44:25,248 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.131.bert.pt, number of examples: 2001\n",
            "[2021-04-30 06:45:00,255 INFO] Step 9200/50000; xent: 3.01; lr: 0.0000184;  28 docs/s;   6609 sec\n",
            "[2021-04-30 06:45:35,352 INFO] Step 9250/50000; xent: 3.07; lr: 0.0000185;  29 docs/s;   6644 sec\n",
            "[2021-04-30 06:46:10,438 INFO] Step 9300/50000; xent: 3.00; lr: 0.0000186;  30 docs/s;   6679 sec\n",
            "[2021-04-30 06:46:41,775 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.97.bert.pt, number of examples: 2000\n",
            "[2021-04-30 06:46:47,519 INFO] Step 9350/50000; xent: 3.01; lr: 0.0000187;  28 docs/s;   6716 sec\n",
            "[2021-04-30 06:47:22,595 INFO] Step 9400/50000; xent: 2.97; lr: 0.0000188;  30 docs/s;   6751 sec\n",
            "[2021-04-30 06:47:57,724 INFO] Step 9450/50000; xent: 2.97; lr: 0.0000189;  30 docs/s;   6787 sec\n",
            "[2021-04-30 06:48:32,862 INFO] Step 9500/50000; xent: 3.04; lr: 0.0000190;  29 docs/s;   6822 sec\n",
            "[2021-04-30 06:48:59,207 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.55.bert.pt, number of examples: 1999\n",
            "[2021-04-30 06:49:09,828 INFO] Step 9550/50000; xent: 3.04; lr: 0.0000191;  28 docs/s;   6859 sec\n",
            "[2021-04-30 06:49:44,778 INFO] Step 9600/50000; xent: 2.97; lr: 0.0000192;  30 docs/s;   6894 sec\n",
            "[2021-04-30 06:50:19,881 INFO] Step 9650/50000; xent: 2.97; lr: 0.0000193;  30 docs/s;   6929 sec\n",
            "[2021-04-30 06:50:55,016 INFO] Step 9700/50000; xent: 3.02; lr: 0.0000194;  29 docs/s;   6964 sec\n",
            "[2021-04-30 06:51:16,429 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.128.bert.pt, number of examples: 2000\n",
            "[2021-04-30 06:51:32,702 INFO] Step 9750/50000; xent: 3.04; lr: 0.0000195;  27 docs/s;   7002 sec\n",
            "[2021-04-30 06:52:07,766 INFO] Step 9800/50000; xent: 2.91; lr: 0.0000196;  30 docs/s;   7037 sec\n",
            "[2021-04-30 06:52:42,629 INFO] Step 9850/50000; xent: 2.99; lr: 0.0000197;  30 docs/s;   7071 sec\n",
            "[2021-04-30 06:53:17,570 INFO] Step 9900/50000; xent: 3.04; lr: 0.0000198;  29 docs/s;   7106 sec\n",
            "[2021-04-30 06:53:32,700 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.104.bert.pt, number of examples: 2000\n",
            "[2021-04-30 06:53:54,291 INFO] Step 9950/50000; xent: 2.92; lr: 0.0000199;  29 docs/s;   7143 sec\n",
            "[2021-04-30 06:54:29,394 INFO] Step 10000/50000; xent: 3.05; lr: 0.0000200;  29 docs/s;   7178 sec\n",
            "[2021-04-30 06:54:29,408 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_10000.pt\n",
            "[2021-04-30 06:55:11,054 INFO] Step 10050/50000; xent: 2.92; lr: 0.0000200;  26 docs/s;   7220 sec\n",
            "[2021-04-30 06:55:46,235 INFO] Step 10100/50000; xent: 2.94; lr: 0.0000199;  29 docs/s;   7255 sec\n",
            "[2021-04-30 06:55:55,392 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.118.bert.pt, number of examples: 2001\n",
            "[2021-04-30 06:56:22,965 INFO] Step 10150/50000; xent: 3.04; lr: 0.0000199;  28 docs/s;   7292 sec\n",
            "[2021-04-30 06:56:57,998 INFO] Step 10200/50000; xent: 2.92; lr: 0.0000198;  30 docs/s;   7327 sec\n",
            "[2021-04-30 06:57:32,882 INFO] Step 10250/50000; xent: 3.03; lr: 0.0000198;  30 docs/s;   7362 sec\n",
            "[2021-04-30 06:58:08,053 INFO] Step 10300/50000; xent: 2.87; lr: 0.0000197;  29 docs/s;   7397 sec\n",
            "[2021-04-30 06:58:12,100 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.47.bert.pt, number of examples: 2000\n",
            "[2021-04-30 06:58:45,161 INFO] Step 10350/50000; xent: 2.97; lr: 0.0000197;  28 docs/s;   7434 sec\n",
            "[2021-04-30 06:59:20,261 INFO] Step 10400/50000; xent: 2.98; lr: 0.0000196;  29 docs/s;   7469 sec\n",
            "[2021-04-30 06:59:55,202 INFO] Step 10450/50000; xent: 3.08; lr: 0.0000196;  30 docs/s;   7504 sec\n",
            "[2021-04-30 07:00:29,392 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.8.bert.pt, number of examples: 2001\n",
            "[2021-04-30 07:00:32,311 INFO] Step 10500/50000; xent: 2.99; lr: 0.0000195;  27 docs/s;   7541 sec\n",
            "[2021-04-30 07:01:07,466 INFO] Step 10550/50000; xent: 2.97; lr: 0.0000195;  30 docs/s;   7576 sec\n",
            "[2021-04-30 07:01:42,526 INFO] Step 10600/50000; xent: 2.98; lr: 0.0000194;  30 docs/s;   7611 sec\n",
            "[2021-04-30 07:02:17,638 INFO] Step 10650/50000; xent: 3.03; lr: 0.0000194;  29 docs/s;   7646 sec\n",
            "[2021-04-30 07:02:46,127 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.11.bert.pt, number of examples: 2001\n",
            "[2021-04-30 07:02:54,435 INFO] Step 10700/50000; xent: 2.93; lr: 0.0000193;  28 docs/s;   7683 sec\n",
            "[2021-04-30 07:03:29,512 INFO] Step 10750/50000; xent: 2.89; lr: 0.0000193;  30 docs/s;   7718 sec\n",
            "[2021-04-30 07:04:04,663 INFO] Step 10800/50000; xent: 2.99; lr: 0.0000192;  30 docs/s;   7754 sec\n",
            "[2021-04-30 07:04:39,508 INFO] Step 10850/50000; xent: 2.91; lr: 0.0000192;  30 docs/s;   7788 sec\n",
            "[2021-04-30 07:05:02,628 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.66.bert.pt, number of examples: 2001\n",
            "[2021-04-30 07:05:16,080 INFO] Step 10900/50000; xent: 3.05; lr: 0.0000192;  28 docs/s;   7825 sec\n",
            "[2021-04-30 07:05:51,151 INFO] Step 10950/50000; xent: 3.00; lr: 0.0000191;  30 docs/s;   7860 sec\n",
            "[2021-04-30 07:06:26,234 INFO] Step 11000/50000; xent: 3.01; lr: 0.0000191;  30 docs/s;   7895 sec\n",
            "[2021-04-30 07:06:26,250 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_11000.pt\n",
            "[2021-04-30 07:07:08,335 INFO] Step 11050/50000; xent: 3.05; lr: 0.0000190;  24 docs/s;   7937 sec\n",
            "[2021-04-30 07:07:26,169 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.36.bert.pt, number of examples: 2001\n",
            "[2021-04-30 07:07:45,025 INFO] Step 11100/50000; xent: 2.96; lr: 0.0000190;  28 docs/s;   7974 sec\n",
            "[2021-04-30 07:08:20,169 INFO] Step 11150/50000; xent: 2.99; lr: 0.0000189;  30 docs/s;   8009 sec\n",
            "[2021-04-30 07:08:55,249 INFO] Step 11200/50000; xent: 2.95; lr: 0.0000189;  30 docs/s;   8044 sec\n",
            "[2021-04-30 07:09:30,383 INFO] Step 11250/50000; xent: 2.91; lr: 0.0000189;  29 docs/s;   8079 sec\n",
            "[2021-04-30 07:09:43,236 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.73.bert.pt, number of examples: 2001\n",
            "[2021-04-30 07:10:07,252 INFO] Step 11300/50000; xent: 3.07; lr: 0.0000188;  28 docs/s;   8116 sec\n",
            "[2021-04-30 07:10:42,089 INFO] Step 11350/50000; xent: 2.95; lr: 0.0000188;  30 docs/s;   8151 sec\n",
            "[2021-04-30 07:11:17,172 INFO] Step 11400/50000; xent: 3.00; lr: 0.0000187;  30 docs/s;   8186 sec\n",
            "[2021-04-30 07:11:52,342 INFO] Step 11450/50000; xent: 2.96; lr: 0.0000187;  29 docs/s;   8221 sec\n",
            "[2021-04-30 07:12:00,299 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.33.bert.pt, number of examples: 1997\n",
            "[2021-04-30 07:12:28,999 INFO] Step 11500/50000; xent: 3.01; lr: 0.0000187;  28 docs/s;   8258 sec\n",
            "[2021-04-30 07:13:04,126 INFO] Step 11550/50000; xent: 3.04; lr: 0.0000186;  29 docs/s;   8293 sec\n",
            "[2021-04-30 07:13:39,179 INFO] Step 11600/50000; xent: 3.01; lr: 0.0000186;  30 docs/s;   8328 sec\n",
            "[2021-04-30 07:14:14,260 INFO] Step 11650/50000; xent: 3.00; lr: 0.0000185;  30 docs/s;   8363 sec\n",
            "[2021-04-30 07:14:16,486 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.121.bert.pt, number of examples: 1999\n",
            "[2021-04-30 07:14:50,982 INFO] Step 11700/50000; xent: 3.05; lr: 0.0000185;  29 docs/s;   8400 sec\n",
            "[2021-04-30 07:15:26,068 INFO] Step 11750/50000; xent: 2.98; lr: 0.0000185;  29 docs/s;   8435 sec\n",
            "[2021-04-30 07:16:00,968 INFO] Step 11800/50000; xent: 3.01; lr: 0.0000184;  30 docs/s;   8470 sec\n",
            "[2021-04-30 07:16:32,862 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.136.bert.pt, number of examples: 1998\n",
            "[2021-04-30 07:16:37,884 INFO] Step 11850/50000; xent: 2.92; lr: 0.0000184;  28 docs/s;   8507 sec\n",
            "[2021-04-30 07:17:12,989 INFO] Step 11900/50000; xent: 2.99; lr: 0.0000183;  30 docs/s;   8542 sec\n",
            "[2021-04-30 07:17:48,026 INFO] Step 11950/50000; xent: 2.91; lr: 0.0000183;  30 docs/s;   8577 sec\n",
            "[2021-04-30 07:18:23,143 INFO] Step 12000/50000; xent: 3.03; lr: 0.0000183;  30 docs/s;   8612 sec\n",
            "[2021-04-30 07:18:23,158 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_12000.pt\n",
            "[2021-04-30 07:18:56,793 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.20.bert.pt, number of examples: 2000\n",
            "[2021-04-30 07:19:06,887 INFO] Step 12050/50000; xent: 2.93; lr: 0.0000182;  23 docs/s;   8656 sec\n",
            "[2021-04-30 07:19:41,771 INFO] Step 12100/50000; xent: 3.03; lr: 0.0000182;  30 docs/s;   8691 sec\n",
            "[2021-04-30 07:20:16,845 INFO] Step 12150/50000; xent: 3.02; lr: 0.0000181;  30 docs/s;   8726 sec\n",
            "[2021-04-30 07:20:51,913 INFO] Step 12200/50000; xent: 2.96; lr: 0.0000181;  30 docs/s;   8761 sec\n",
            "[2021-04-30 07:21:13,482 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.61.bert.pt, number of examples: 1999\n",
            "[2021-04-30 07:21:28,993 INFO] Step 12250/50000; xent: 2.97; lr: 0.0000181;  28 docs/s;   8798 sec\n",
            "[2021-04-30 07:22:04,122 INFO] Step 12300/50000; xent: 3.02; lr: 0.0000180;  29 docs/s;   8833 sec\n",
            "[2021-04-30 07:22:39,195 INFO] Step 12350/50000; xent: 3.03; lr: 0.0000180;  29 docs/s;   8868 sec\n",
            "[2021-04-30 07:23:14,191 INFO] Step 12400/50000; xent: 2.94; lr: 0.0000180;  30 docs/s;   8903 sec\n",
            "[2021-04-30 07:23:30,399 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.45.bert.pt, number of examples: 2000\n",
            "[2021-04-30 07:23:50,816 INFO] Step 12450/50000; xent: 2.92; lr: 0.0000179;  28 docs/s;   8940 sec\n",
            "[2021-04-30 07:24:25,900 INFO] Step 12500/50000; xent: 2.99; lr: 0.0000179;  30 docs/s;   8975 sec\n",
            "[2021-04-30 07:25:01,014 INFO] Step 12550/50000; xent: 2.97; lr: 0.0000179;  29 docs/s;   9010 sec\n",
            "[2021-04-30 07:25:36,133 INFO] Step 12600/50000; xent: 2.97; lr: 0.0000178;  30 docs/s;   9045 sec\n",
            "[2021-04-30 07:25:47,589 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.134.bert.pt, number of examples: 2000\n",
            "[2021-04-30 07:26:13,022 INFO] Step 12650/50000; xent: 2.95; lr: 0.0000178;  28 docs/s;   9082 sec\n",
            "[2021-04-30 07:26:48,109 INFO] Step 12700/50000; xent: 3.06; lr: 0.0000177;  29 docs/s;   9117 sec\n",
            "[2021-04-30 07:27:23,182 INFO] Step 12750/50000; xent: 2.96; lr: 0.0000177;  30 docs/s;   9152 sec\n",
            "[2021-04-30 07:27:57,831 INFO] Step 12800/50000; xent: 3.04; lr: 0.0000177;  31 docs/s;   9187 sec\n",
            "[2021-04-30 07:28:03,815 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.21.bert.pt, number of examples: 2001\n",
            "[2021-04-30 07:28:34,729 INFO] Step 12850/50000; xent: 3.04; lr: 0.0000176;  28 docs/s;   9224 sec\n",
            "[2021-04-30 07:29:09,862 INFO] Step 12900/50000; xent: 2.99; lr: 0.0000176;  30 docs/s;   9259 sec\n",
            "[2021-04-30 07:29:44,966 INFO] Step 12950/50000; xent: 2.98; lr: 0.0000176;  30 docs/s;   9294 sec\n",
            "[2021-04-30 07:30:20,682 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.43.bert.pt, number of examples: 2001\n",
            "[2021-04-30 07:30:21,502 INFO] Step 13000/50000; xent: 2.92; lr: 0.0000175;  28 docs/s;   9330 sec\n",
            "[2021-04-30 07:30:21,518 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_13000.pt\n",
            "[2021-04-30 07:31:04,067 INFO] Step 13050/50000; xent: 3.05; lr: 0.0000175;  25 docs/s;   9373 sec\n",
            "[2021-04-30 07:31:39,181 INFO] Step 13100/50000; xent: 3.01; lr: 0.0000175;  29 docs/s;   9408 sec\n",
            "[2021-04-30 07:32:14,270 INFO] Step 13150/50000; xent: 3.00; lr: 0.0000174;  30 docs/s;   9443 sec\n",
            "[2021-04-30 07:32:44,528 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.141.bert.pt, number of examples: 1998\n",
            "[2021-04-30 07:32:50,973 INFO] Step 13200/50000; xent: 2.95; lr: 0.0000174;  28 docs/s;   9480 sec\n",
            "[2021-04-30 07:33:25,979 INFO] Step 13250/50000; xent: 3.01; lr: 0.0000174;  29 docs/s;   9515 sec\n",
            "[2021-04-30 07:34:01,076 INFO] Step 13300/50000; xent: 3.00; lr: 0.0000173;  30 docs/s;   9550 sec\n",
            "[2021-04-30 07:34:36,114 INFO] Step 13350/50000; xent: 2.91; lr: 0.0000173;  30 docs/s;   9585 sec\n",
            "[2021-04-30 07:35:00,974 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.16.bert.pt, number of examples: 2001\n",
            "[2021-04-30 07:35:13,027 INFO] Step 13400/50000; xent: 2.98; lr: 0.0000173;  28 docs/s;   9622 sec\n",
            "[2021-04-30 07:35:48,129 INFO] Step 13450/50000; xent: 2.97; lr: 0.0000172;  30 docs/s;   9657 sec\n",
            "[2021-04-30 07:36:23,209 INFO] Step 13500/50000; xent: 2.98; lr: 0.0000172;  30 docs/s;   9692 sec\n",
            "[2021-04-30 07:36:58,286 INFO] Step 13550/50000; xent: 2.90; lr: 0.0000172;  29 docs/s;   9727 sec\n",
            "[2021-04-30 07:37:18,007 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.116.bert.pt, number of examples: 1997\n",
            "[2021-04-30 07:37:35,005 INFO] Step 13600/50000; xent: 3.06; lr: 0.0000171;  28 docs/s;   9764 sec\n",
            "[2021-04-30 07:38:10,157 INFO] Step 13650/50000; xent: 3.04; lr: 0.0000171;  29 docs/s;   9799 sec\n",
            "[2021-04-30 07:38:45,160 INFO] Step 13700/50000; xent: 2.96; lr: 0.0000171;  31 docs/s;   9834 sec\n",
            "[2021-04-30 07:39:20,147 INFO] Step 13750/50000; xent: 2.97; lr: 0.0000171;  29 docs/s;   9869 sec\n",
            "[2021-04-30 07:39:34,703 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.76.bert.pt, number of examples: 2001\n",
            "[2021-04-30 07:39:57,284 INFO] Step 13800/50000; xent: 3.00; lr: 0.0000170;  28 docs/s;   9906 sec\n",
            "[2021-04-30 07:40:32,450 INFO] Step 13850/50000; xent: 2.95; lr: 0.0000170;  30 docs/s;   9941 sec\n",
            "[2021-04-30 07:41:07,495 INFO] Step 13900/50000; xent: 2.89; lr: 0.0000170;  30 docs/s;   9976 sec\n",
            "[2021-04-30 07:41:42,599 INFO] Step 13950/50000; xent: 2.96; lr: 0.0000169;  30 docs/s;  10011 sec\n",
            "[2021-04-30 07:41:52,242 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.19.bert.pt, number of examples: 1999\n",
            "[2021-04-30 07:42:18,925 INFO] Step 14000/50000; xent: 2.98; lr: 0.0000169;  28 docs/s;  10048 sec\n",
            "[2021-04-30 07:42:18,942 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_14000.pt\n",
            "[2021-04-30 07:43:00,845 INFO] Step 14050/50000; xent: 2.98; lr: 0.0000169;  25 docs/s;  10090 sec\n",
            "[2021-04-30 07:43:35,977 INFO] Step 14100/50000; xent: 3.00; lr: 0.0000168;  29 docs/s;  10125 sec\n",
            "[2021-04-30 07:44:10,925 INFO] Step 14150/50000; xent: 3.02; lr: 0.0000168;  30 docs/s;  10160 sec\n",
            "[2021-04-30 07:44:15,580 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.107.bert.pt, number of examples: 1999\n",
            "[2021-04-30 07:44:47,699 INFO] Step 14200/50000; xent: 2.99; lr: 0.0000168;  28 docs/s;  10197 sec\n",
            "[2021-04-30 07:45:22,840 INFO] Step 14250/50000; xent: 3.00; lr: 0.0000168;  30 docs/s;  10232 sec\n",
            "[2021-04-30 07:45:57,896 INFO] Step 14300/50000; xent: 2.90; lr: 0.0000167;  30 docs/s;  10267 sec\n",
            "[2021-04-30 07:46:32,958 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.125.bert.pt, number of examples: 2000\n",
            "[2021-04-30 07:46:35,178 INFO] Step 14350/50000; xent: 3.05; lr: 0.0000167;  27 docs/s;  10304 sec\n",
            "[2021-04-30 07:47:10,086 INFO] Step 14400/50000; xent: 3.04; lr: 0.0000167;  30 docs/s;  10339 sec\n",
            "[2021-04-30 07:47:45,129 INFO] Step 14450/50000; xent: 2.92; lr: 0.0000166;  30 docs/s;  10374 sec\n",
            "[2021-04-30 07:48:20,227 INFO] Step 14500/50000; xent: 2.97; lr: 0.0000166;  30 docs/s;  10409 sec\n",
            "[2021-04-30 07:48:49,388 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.142.bert.pt, number of examples: 1996\n",
            "[2021-04-30 07:48:57,221 INFO] Step 14550/50000; xent: 2.98; lr: 0.0000166;  28 docs/s;  10446 sec\n",
            "[2021-04-30 07:49:32,220 INFO] Step 14600/50000; xent: 2.96; lr: 0.0000166;  30 docs/s;  10481 sec\n",
            "[2021-04-30 07:50:07,372 INFO] Step 14650/50000; xent: 3.02; lr: 0.0000165;  29 docs/s;  10516 sec\n",
            "[2021-04-30 07:50:42,247 INFO] Step 14700/50000; xent: 2.99; lr: 0.0000165;  30 docs/s;  10551 sec\n",
            "[2021-04-30 07:51:05,161 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.41.bert.pt, number of examples: 2000\n",
            "[2021-04-30 07:51:19,287 INFO] Step 14750/50000; xent: 3.00; lr: 0.0000165;  28 docs/s;  10588 sec\n",
            "[2021-04-30 07:51:54,390 INFO] Step 14800/50000; xent: 2.98; lr: 0.0000164;  30 docs/s;  10623 sec\n",
            "[2021-04-30 07:52:29,189 INFO] Step 14850/50000; xent: 2.94; lr: 0.0000164;  29 docs/s;  10658 sec\n",
            "[2021-04-30 07:53:04,370 INFO] Step 14900/50000; xent: 2.91; lr: 0.0000164;  30 docs/s;  10693 sec\n",
            "[2021-04-30 07:53:21,563 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.44.bert.pt, number of examples: 2000\n",
            "[2021-04-30 07:53:41,305 INFO] Step 14950/50000; xent: 2.95; lr: 0.0000164;  29 docs/s;  10730 sec\n",
            "[2021-04-30 07:54:16,277 INFO] Step 15000/50000; xent: 2.93; lr: 0.0000163;  29 docs/s;  10765 sec\n",
            "[2021-04-30 07:54:16,292 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_15000.pt\n",
            "[2021-04-30 07:54:57,759 INFO] Step 15050/50000; xent: 3.01; lr: 0.0000163;  25 docs/s;  10807 sec\n",
            "[2021-04-30 07:55:32,666 INFO] Step 15100/50000; xent: 2.99; lr: 0.0000163;  30 docs/s;  10842 sec\n",
            "[2021-04-30 07:55:44,230 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.95.bert.pt, number of examples: 2000\n",
            "[2021-04-30 07:56:09,607 INFO] Step 15150/50000; xent: 2.94; lr: 0.0000162;  28 docs/s;  10878 sec\n",
            "[2021-04-30 07:56:44,677 INFO] Step 15200/50000; xent: 2.94; lr: 0.0000162;  30 docs/s;  10914 sec\n",
            "[2021-04-30 07:57:19,816 INFO] Step 15250/50000; xent: 2.97; lr: 0.0000162;  30 docs/s;  10949 sec\n",
            "[2021-04-30 07:57:54,663 INFO] Step 15300/50000; xent: 3.05; lr: 0.0000162;  30 docs/s;  10984 sec\n",
            "[2021-04-30 07:58:00,791 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.79.bert.pt, number of examples: 2001\n",
            "[2021-04-30 07:58:31,780 INFO] Step 15350/50000; xent: 2.98; lr: 0.0000161;  28 docs/s;  11021 sec\n",
            "[2021-04-30 07:59:06,873 INFO] Step 15400/50000; xent: 2.93; lr: 0.0000161;  30 docs/s;  11056 sec\n",
            "[2021-04-30 07:59:41,902 INFO] Step 15450/50000; xent: 2.99; lr: 0.0000161;  30 docs/s;  11091 sec\n",
            "[2021-04-30 08:00:17,174 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.110.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:00:18,692 INFO] Step 15500/50000; xent: 3.00; lr: 0.0000161;  28 docs/s;  11128 sec\n",
            "[2021-04-30 08:00:53,778 INFO] Step 15550/50000; xent: 2.97; lr: 0.0000160;  31 docs/s;  11163 sec\n",
            "[2021-04-30 08:01:28,961 INFO] Step 15600/50000; xent: 2.95; lr: 0.0000160;  29 docs/s;  11198 sec\n",
            "[2021-04-30 08:02:03,920 INFO] Step 15650/50000; xent: 2.97; lr: 0.0000160;  29 docs/s;  11233 sec\n",
            "[2021-04-30 08:02:34,454 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.23.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:02:40,874 INFO] Step 15700/50000; xent: 2.99; lr: 0.0000160;  28 docs/s;  11270 sec\n",
            "[2021-04-30 08:03:15,751 INFO] Step 15750/50000; xent: 3.04; lr: 0.0000159;  30 docs/s;  11305 sec\n",
            "[2021-04-30 08:03:50,866 INFO] Step 15800/50000; xent: 2.99; lr: 0.0000159;  29 docs/s;  11340 sec\n",
            "[2021-04-30 08:04:25,918 INFO] Step 15850/50000; xent: 2.94; lr: 0.0000159;  30 docs/s;  11375 sec\n",
            "[2021-04-30 08:04:50,902 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.53.bert.pt, number of examples: 2000\n",
            "[2021-04-30 08:05:02,809 INFO] Step 15900/50000; xent: 2.92; lr: 0.0000159;  29 docs/s;  11412 sec\n",
            "[2021-04-30 08:05:37,929 INFO] Step 15950/50000; xent: 3.03; lr: 0.0000158;  29 docs/s;  11447 sec\n",
            "[2021-04-30 08:06:13,035 INFO] Step 16000/50000; xent: 2.98; lr: 0.0000158;  30 docs/s;  11482 sec\n",
            "[2021-04-30 08:06:13,050 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_16000.pt\n",
            "[2021-04-30 08:06:54,618 INFO] Step 16050/50000; xent: 3.03; lr: 0.0000158;  25 docs/s;  11523 sec\n",
            "[2021-04-30 08:07:13,491 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.27.bert.pt, number of examples: 1999\n",
            "[2021-04-30 08:07:31,156 INFO] Step 16100/50000; xent: 2.97; lr: 0.0000158;  28 docs/s;  11560 sec\n",
            "[2021-04-30 08:08:06,296 INFO] Step 16150/50000; xent: 2.97; lr: 0.0000157;  31 docs/s;  11595 sec\n",
            "[2021-04-30 08:08:41,442 INFO] Step 16200/50000; xent: 3.01; lr: 0.0000157;  29 docs/s;  11630 sec\n",
            "[2021-04-30 08:09:16,386 INFO] Step 16250/50000; xent: 2.97; lr: 0.0000157;  29 docs/s;  11665 sec\n",
            "[2021-04-30 08:09:29,898 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.14.bert.pt, number of examples: 1998\n",
            "[2021-04-30 08:09:53,115 INFO] Step 16300/50000; xent: 2.96; lr: 0.0000157;  28 docs/s;  11702 sec\n",
            "[2021-04-30 08:10:28,114 INFO] Step 16350/50000; xent: 3.05; lr: 0.0000156;  29 docs/s;  11737 sec\n",
            "[2021-04-30 08:11:03,218 INFO] Step 16400/50000; xent: 2.94; lr: 0.0000156;  30 docs/s;  11772 sec\n",
            "[2021-04-30 08:11:38,126 INFO] Step 16450/50000; xent: 2.95; lr: 0.0000156;  30 docs/s;  11807 sec\n",
            "[2021-04-30 08:11:47,037 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.82.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:12:15,258 INFO] Step 16500/50000; xent: 2.97; lr: 0.0000156;  28 docs/s;  11844 sec\n",
            "[2021-04-30 08:12:50,290 INFO] Step 16550/50000; xent: 2.92; lr: 0.0000155;  30 docs/s;  11879 sec\n",
            "[2021-04-30 08:13:25,217 INFO] Step 16600/50000; xent: 3.06; lr: 0.0000155;  30 docs/s;  11914 sec\n",
            "[2021-04-30 08:14:00,280 INFO] Step 16650/50000; xent: 3.04; lr: 0.0000155;  29 docs/s;  11949 sec\n",
            "[2021-04-30 08:14:03,789 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.18.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:14:36,934 INFO] Step 16700/50000; xent: 3.00; lr: 0.0000155;  29 docs/s;  11986 sec\n",
            "[2021-04-30 08:15:12,065 INFO] Step 16750/50000; xent: 2.95; lr: 0.0000155;  30 docs/s;  12021 sec\n",
            "[2021-04-30 08:15:47,151 INFO] Step 16800/50000; xent: 2.99; lr: 0.0000154;  29 docs/s;  12056 sec\n",
            "[2021-04-30 08:16:19,944 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.87.bert.pt, number of examples: 2000\n",
            "[2021-04-30 08:16:23,564 INFO] Step 16850/50000; xent: 2.96; lr: 0.0000154;  29 docs/s;  12092 sec\n",
            "[2021-04-30 08:16:58,704 INFO] Step 16900/50000; xent: 2.93; lr: 0.0000154;  29 docs/s;  12128 sec\n",
            "[2021-04-30 08:17:33,729 INFO] Step 16950/50000; xent: 2.97; lr: 0.0000154;  30 docs/s;  12163 sec\n",
            "[2021-04-30 08:18:08,849 INFO] Step 17000/50000; xent: 2.96; lr: 0.0000153;  30 docs/s;  12198 sec\n",
            "[2021-04-30 08:18:08,865 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_17000.pt\n",
            "[2021-04-30 08:18:44,434 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.2.bert.pt, number of examples: 2000\n",
            "[2021-04-30 08:18:53,653 INFO] Step 17050/50000; xent: 3.00; lr: 0.0000153;  23 docs/s;  12243 sec\n",
            "[2021-04-30 08:19:28,831 INFO] Step 17100/50000; xent: 2.95; lr: 0.0000153;  30 docs/s;  12278 sec\n",
            "[2021-04-30 08:20:03,897 INFO] Step 17150/50000; xent: 3.02; lr: 0.0000153;  30 docs/s;  12313 sec\n",
            "[2021-04-30 08:20:38,946 INFO] Step 17200/50000; xent: 3.00; lr: 0.0000152;  30 docs/s;  12348 sec\n",
            "[2021-04-30 08:21:01,592 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.69.bert.pt, number of examples: 2000\n",
            "[2021-04-30 08:21:15,738 INFO] Step 17250/50000; xent: 2.96; lr: 0.0000152;  28 docs/s;  12385 sec\n",
            "[2021-04-30 08:21:50,895 INFO] Step 17300/50000; xent: 3.03; lr: 0.0000152;  30 docs/s;  12420 sec\n",
            "[2021-04-30 08:22:25,900 INFO] Step 17350/50000; xent: 3.00; lr: 0.0000152;  30 docs/s;  12455 sec\n",
            "[2021-04-30 08:23:01,068 INFO] Step 17400/50000; xent: 2.96; lr: 0.0000152;  30 docs/s;  12490 sec\n",
            "[2021-04-30 08:23:18,120 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.25.bert.pt, number of examples: 1999\n",
            "[2021-04-30 08:23:37,822 INFO] Step 17450/50000; xent: 2.93; lr: 0.0000151;  29 docs/s;  12527 sec\n",
            "[2021-04-30 08:24:12,850 INFO] Step 17500/50000; xent: 3.02; lr: 0.0000151;  30 docs/s;  12562 sec\n",
            "[2021-04-30 08:24:47,808 INFO] Step 17550/50000; xent: 2.95; lr: 0.0000151;  29 docs/s;  12597 sec\n",
            "[2021-04-30 08:25:22,952 INFO] Step 17600/50000; xent: 3.02; lr: 0.0000151;  29 docs/s;  12632 sec\n",
            "[2021-04-30 08:25:35,013 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.22.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:25:59,496 INFO] Step 17650/50000; xent: 3.00; lr: 0.0000151;  27 docs/s;  12668 sec\n",
            "[2021-04-30 08:26:34,559 INFO] Step 17700/50000; xent: 3.05; lr: 0.0000150;  30 docs/s;  12703 sec\n",
            "[2021-04-30 08:27:09,602 INFO] Step 17750/50000; xent: 2.98; lr: 0.0000150;  30 docs/s;  12738 sec\n",
            "[2021-04-30 08:27:44,795 INFO] Step 17800/50000; xent: 3.00; lr: 0.0000150;  30 docs/s;  12774 sec\n",
            "[2021-04-30 08:27:51,163 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.127.bert.pt, number of examples: 2000\n",
            "[2021-04-30 08:28:21,483 INFO] Step 17850/50000; xent: 2.95; lr: 0.0000150;  28 docs/s;  12810 sec\n",
            "[2021-04-30 08:28:56,537 INFO] Step 17900/50000; xent: 2.97; lr: 0.0000149;  30 docs/s;  12845 sec\n",
            "[2021-04-30 08:29:31,338 INFO] Step 17950/50000; xent: 2.95; lr: 0.0000149;  30 docs/s;  12880 sec\n",
            "[2021-04-30 08:30:07,807 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.57.bert.pt, number of examples: 2000\n",
            "[2021-04-30 08:30:08,616 INFO] Step 18000/50000; xent: 2.90; lr: 0.0000149;  28 docs/s;  12917 sec\n",
            "[2021-04-30 08:30:08,632 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_18000.pt\n",
            "[2021-04-30 08:30:50,708 INFO] Step 18050/50000; xent: 2.98; lr: 0.0000149;  25 docs/s;  12960 sec\n",
            "[2021-04-30 08:31:25,847 INFO] Step 18100/50000; xent: 2.94; lr: 0.0000149;  29 docs/s;  12995 sec\n",
            "[2021-04-30 08:32:01,011 INFO] Step 18150/50000; xent: 2.93; lr: 0.0000148;  30 docs/s;  13030 sec\n",
            "[2021-04-30 08:32:31,249 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.99.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:32:37,673 INFO] Step 18200/50000; xent: 3.01; lr: 0.0000148;  28 docs/s;  13067 sec\n",
            "[2021-04-30 08:33:12,767 INFO] Step 18250/50000; xent: 2.94; lr: 0.0000148;  30 docs/s;  13102 sec\n",
            "[2021-04-30 08:33:47,807 INFO] Step 18300/50000; xent: 2.93; lr: 0.0000148;  30 docs/s;  13137 sec\n",
            "[2021-04-30 08:34:22,946 INFO] Step 18350/50000; xent: 3.00; lr: 0.0000148;  29 docs/s;  13172 sec\n",
            "[2021-04-30 08:34:47,772 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.65.bert.pt, number of examples: 2000\n",
            "[2021-04-30 08:34:59,870 INFO] Step 18400/50000; xent: 3.04; lr: 0.0000147;  28 docs/s;  13209 sec\n",
            "[2021-04-30 08:35:34,971 INFO] Step 18450/50000; xent: 3.01; lr: 0.0000147;  29 docs/s;  13244 sec\n",
            "[2021-04-30 08:36:10,103 INFO] Step 18500/50000; xent: 2.97; lr: 0.0000147;  30 docs/s;  13279 sec\n",
            "[2021-04-30 08:36:45,170 INFO] Step 18550/50000; xent: 2.94; lr: 0.0000147;  31 docs/s;  13314 sec\n",
            "[2021-04-30 08:37:03,803 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.119.bert.pt, number of examples: 1998\n",
            "[2021-04-30 08:37:22,127 INFO] Step 18600/50000; xent: 3.04; lr: 0.0000147;  28 docs/s;  13351 sec\n",
            "[2021-04-30 08:37:57,267 INFO] Step 18650/50000; xent: 3.08; lr: 0.0000146;  30 docs/s;  13386 sec\n",
            "[2021-04-30 08:38:32,291 INFO] Step 18700/50000; xent: 3.01; lr: 0.0000146;  29 docs/s;  13421 sec\n",
            "[2021-04-30 08:39:07,487 INFO] Step 18750/50000; xent: 2.98; lr: 0.0000146;  30 docs/s;  13456 sec\n",
            "[2021-04-30 08:39:20,457 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.70.bert.pt, number of examples: 1999\n",
            "[2021-04-30 08:39:44,416 INFO] Step 18800/50000; xent: 3.01; lr: 0.0000146;  28 docs/s;  13493 sec\n",
            "[2021-04-30 08:40:19,462 INFO] Step 18850/50000; xent: 2.93; lr: 0.0000146;  30 docs/s;  13528 sec\n",
            "[2021-04-30 08:40:54,305 INFO] Step 18900/50000; xent: 2.87; lr: 0.0000145;  30 docs/s;  13563 sec\n",
            "[2021-04-30 08:41:29,437 INFO] Step 18950/50000; xent: 3.01; lr: 0.0000145;  29 docs/s;  13598 sec\n",
            "[2021-04-30 08:41:37,087 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.54.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:42:05,963 INFO] Step 19000/50000; xent: 2.96; lr: 0.0000145;  29 docs/s;  13635 sec\n",
            "[2021-04-30 08:42:05,979 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_19000.pt\n",
            "[2021-04-30 08:42:47,717 INFO] Step 19050/50000; xent: 2.97; lr: 0.0000145;  25 docs/s;  13677 sec\n",
            "[2021-04-30 08:43:22,712 INFO] Step 19100/50000; xent: 2.99; lr: 0.0000145;  29 docs/s;  13712 sec\n",
            "[2021-04-30 08:43:57,683 INFO] Step 19150/50000; xent: 2.97; lr: 0.0000145;  30 docs/s;  13747 sec\n",
            "[2021-04-30 08:44:00,455 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.103.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:44:34,925 INFO] Step 19200/50000; xent: 2.92; lr: 0.0000144;  28 docs/s;  13784 sec\n",
            "[2021-04-30 08:45:09,840 INFO] Step 19250/50000; xent: 2.98; lr: 0.0000144;  29 docs/s;  13819 sec\n",
            "[2021-04-30 08:45:44,948 INFO] Step 19300/50000; xent: 2.94; lr: 0.0000144;  30 docs/s;  13854 sec\n",
            "[2021-04-30 08:46:16,753 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.1.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:46:21,797 INFO] Step 19350/50000; xent: 3.09; lr: 0.0000144;  28 docs/s;  13891 sec\n",
            "[2021-04-30 08:46:56,937 INFO] Step 19400/50000; xent: 3.00; lr: 0.0000144;  30 docs/s;  13926 sec\n",
            "[2021-04-30 08:47:31,808 INFO] Step 19450/50000; xent: 2.99; lr: 0.0000143;  30 docs/s;  13961 sec\n",
            "[2021-04-30 08:48:06,957 INFO] Step 19500/50000; xent: 3.01; lr: 0.0000143;  29 docs/s;  13996 sec\n",
            "[2021-04-30 08:48:32,878 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.3.bert.pt, number of examples: 2000\n",
            "[2021-04-30 08:48:43,528 INFO] Step 19550/50000; xent: 2.92; lr: 0.0000143;  28 docs/s;  14032 sec\n",
            "[2021-04-30 08:49:18,394 INFO] Step 19600/50000; xent: 3.03; lr: 0.0000143;  30 docs/s;  14067 sec\n",
            "[2021-04-30 08:49:53,462 INFO] Step 19650/50000; xent: 3.01; lr: 0.0000143;  30 docs/s;  14102 sec\n",
            "[2021-04-30 08:50:28,562 INFO] Step 19700/50000; xent: 2.99; lr: 0.0000142;  29 docs/s;  14137 sec\n",
            "[2021-04-30 08:50:50,532 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.10.bert.pt, number of examples: 2000\n",
            "[2021-04-30 08:51:05,393 INFO] Step 19750/50000; xent: 2.98; lr: 0.0000142;  28 docs/s;  14174 sec\n",
            "[2021-04-30 08:51:40,486 INFO] Step 19800/50000; xent: 3.08; lr: 0.0000142;  29 docs/s;  14209 sec\n",
            "[2021-04-30 08:52:15,514 INFO] Step 19850/50000; xent: 2.95; lr: 0.0000142;  30 docs/s;  14244 sec\n",
            "[2021-04-30 08:52:50,366 INFO] Step 19900/50000; xent: 3.02; lr: 0.0000142;  29 docs/s;  14279 sec\n",
            "[2021-04-30 08:53:06,987 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.78.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:53:27,440 INFO] Step 19950/50000; xent: 2.98; lr: 0.0000142;  28 docs/s;  14316 sec\n",
            "[2021-04-30 08:54:02,278 INFO] Step 20000/50000; xent: 2.96; lr: 0.0000141;  29 docs/s;  14351 sec\n",
            "[2021-04-30 08:54:02,294 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_20000.pt\n",
            "[2021-04-30 08:54:44,129 INFO] Step 20050/50000; xent: 2.98; lr: 0.0000141;  25 docs/s;  14393 sec\n",
            "[2021-04-30 08:55:19,291 INFO] Step 20100/50000; xent: 2.96; lr: 0.0000141;  30 docs/s;  14428 sec\n",
            "[2021-04-30 08:55:30,739 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.112.bert.pt, number of examples: 2001\n",
            "[2021-04-30 08:55:55,873 INFO] Step 20150/50000; xent: 2.98; lr: 0.0000141;  29 docs/s;  14465 sec\n",
            "[2021-04-30 08:56:30,929 INFO] Step 20200/50000; xent: 3.01; lr: 0.0000141;  29 docs/s;  14500 sec\n",
            "[2021-04-30 08:57:06,010 INFO] Step 20250/50000; xent: 2.97; lr: 0.0000141;  30 docs/s;  14535 sec\n",
            "[2021-04-30 08:57:40,858 INFO] Step 20300/50000; xent: 2.98; lr: 0.0000140;  30 docs/s;  14570 sec\n",
            "[2021-04-30 08:57:47,564 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.102.bert.pt, number of examples: 2000\n",
            "[2021-04-30 08:58:17,840 INFO] Step 20350/50000; xent: 2.95; lr: 0.0000140;  29 docs/s;  14607 sec\n",
            "[2021-04-30 08:58:52,840 INFO] Step 20400/50000; xent: 2.95; lr: 0.0000140;  30 docs/s;  14642 sec\n",
            "[2021-04-30 08:59:27,882 INFO] Step 20450/50000; xent: 2.96; lr: 0.0000140;  29 docs/s;  14677 sec\n",
            "[2021-04-30 09:00:03,947 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.40.bert.pt, number of examples: 2000\n",
            "[2021-04-30 09:00:04,761 INFO] Step 20500/50000; xent: 2.97; lr: 0.0000140;  28 docs/s;  14714 sec\n",
            "[2021-04-30 09:00:39,798 INFO] Step 20550/50000; xent: 3.03; lr: 0.0000140;  30 docs/s;  14749 sec\n",
            "[2021-04-30 09:01:14,659 INFO] Step 20600/50000; xent: 2.99; lr: 0.0000139;  29 docs/s;  14784 sec\n",
            "[2021-04-30 09:01:49,728 INFO] Step 20650/50000; xent: 2.99; lr: 0.0000139;  30 docs/s;  14819 sec\n",
            "[2021-04-30 09:02:20,048 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.122.bert.pt, number of examples: 2001\n",
            "[2021-04-30 09:02:26,471 INFO] Step 20700/50000; xent: 2.98; lr: 0.0000139;  28 docs/s;  14855 sec\n",
            "[2021-04-30 09:03:01,574 INFO] Step 20750/50000; xent: 2.98; lr: 0.0000139;  29 docs/s;  14890 sec\n",
            "[2021-04-30 09:03:36,625 INFO] Step 20800/50000; xent: 2.90; lr: 0.0000139;  30 docs/s;  14925 sec\n",
            "[2021-04-30 09:04:11,680 INFO] Step 20850/50000; xent: 2.97; lr: 0.0000139;  30 docs/s;  14961 sec\n",
            "[2021-04-30 09:04:37,283 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.133.bert.pt, number of examples: 1999\n",
            "[2021-04-30 09:04:48,619 INFO] Step 20900/50000; xent: 2.89; lr: 0.0000138;  29 docs/s;  14997 sec\n",
            "[2021-04-30 09:05:23,460 INFO] Step 20950/50000; xent: 3.03; lr: 0.0000138;  29 docs/s;  15032 sec\n",
            "[2021-04-30 09:05:58,550 INFO] Step 21000/50000; xent: 2.97; lr: 0.0000138;  29 docs/s;  15067 sec\n",
            "[2021-04-30 09:05:58,566 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_21000.pt\n",
            "[2021-04-30 09:06:40,461 INFO] Step 21050/50000; xent: 3.04; lr: 0.0000138;  25 docs/s;  15109 sec\n",
            "[2021-04-30 09:07:01,095 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.67.bert.pt, number of examples: 2001\n",
            "[2021-04-30 09:07:17,327 INFO] Step 21100/50000; xent: 2.91; lr: 0.0000138;  28 docs/s;  15146 sec\n",
            "[2021-04-30 09:07:52,395 INFO] Step 21150/50000; xent: 3.02; lr: 0.0000138;  29 docs/s;  15181 sec\n",
            "[2021-04-30 09:08:27,188 INFO] Step 21200/50000; xent: 2.93; lr: 0.0000137;  30 docs/s;  15216 sec\n",
            "[2021-04-30 09:09:02,127 INFO] Step 21250/50000; xent: 2.95; lr: 0.0000137;  30 docs/s;  15251 sec\n",
            "[2021-04-30 09:09:18,036 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.108.bert.pt, number of examples: 2000\n",
            "[2021-04-30 09:09:39,195 INFO] Step 21300/50000; xent: 2.96; lr: 0.0000137;  28 docs/s;  15288 sec\n",
            "[2021-04-30 09:10:14,269 INFO] Step 21350/50000; xent: 2.99; lr: 0.0000137;  30 docs/s;  15323 sec\n",
            "[2021-04-30 09:10:49,104 INFO] Step 21400/50000; xent: 2.95; lr: 0.0000137;  29 docs/s;  15358 sec\n",
            "[2021-04-30 09:11:24,111 INFO] Step 21450/50000; xent: 2.95; lr: 0.0000137;  29 docs/s;  15393 sec\n",
            "[2021-04-30 09:11:35,450 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.60.bert.pt, number of examples: 2000\n",
            "[2021-04-30 09:12:01,508 INFO] Step 21500/50000; xent: 2.92; lr: 0.0000136;  29 docs/s;  15430 sec\n",
            "[2021-04-30 09:12:36,547 INFO] Step 21550/50000; xent: 2.94; lr: 0.0000136;  29 docs/s;  15465 sec\n",
            "[2021-04-30 09:13:11,561 INFO] Step 21600/50000; xent: 2.96; lr: 0.0000136;  29 docs/s;  15500 sec\n",
            "[2021-04-30 09:13:46,675 INFO] Step 21650/50000; xent: 2.95; lr: 0.0000136;  30 docs/s;  15536 sec\n",
            "[2021-04-30 09:13:51,946 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.29.bert.pt, number of examples: 2001\n",
            "[2021-04-30 09:14:23,587 INFO] Step 21700/50000; xent: 2.93; lr: 0.0000136;  28 docs/s;  15572 sec\n",
            "[2021-04-30 09:14:58,608 INFO] Step 21750/50000; xent: 2.98; lr: 0.0000136;  30 docs/s;  15607 sec\n",
            "[2021-04-30 09:15:33,664 INFO] Step 21800/50000; xent: 2.93; lr: 0.0000135;  31 docs/s;  15643 sec\n",
            "[2021-04-30 09:16:09,055 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.90.bert.pt, number of examples: 2000\n",
            "[2021-04-30 09:16:10,571 INFO] Step 21850/50000; xent: 3.04; lr: 0.0000135;  27 docs/s;  15679 sec\n",
            "[2021-04-30 09:16:45,701 INFO] Step 21900/50000; xent: 3.01; lr: 0.0000135;  29 docs/s;  15715 sec\n",
            "[2021-04-30 09:17:20,772 INFO] Step 21950/50000; xent: 2.95; lr: 0.0000135;  30 docs/s;  15750 sec\n",
            "[2021-04-30 09:17:55,826 INFO] Step 22000/50000; xent: 2.99; lr: 0.0000135;  30 docs/s;  15785 sec\n",
            "[2021-04-30 09:17:55,843 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_22000.pt\n",
            "[2021-04-30 09:18:32,248 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.5.bert.pt, number of examples: 2000\n",
            "[2021-04-30 09:18:39,489 INFO] Step 22050/50000; xent: 2.96; lr: 0.0000135;  24 docs/s;  15828 sec\n",
            "[2021-04-30 09:19:14,678 INFO] Step 22100/50000; xent: 3.04; lr: 0.0000135;  30 docs/s;  15864 sec\n",
            "[2021-04-30 09:19:49,769 INFO] Step 22150/50000; xent: 2.96; lr: 0.0000134;  30 docs/s;  15899 sec\n",
            "[2021-04-30 09:20:24,729 INFO] Step 22200/50000; xent: 2.98; lr: 0.0000134;  29 docs/s;  15934 sec\n",
            "[2021-04-30 09:20:49,667 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.140.bert.pt, number of examples: 1999\n",
            "[2021-04-30 09:21:01,700 INFO] Step 22250/50000; xent: 2.90; lr: 0.0000134;  28 docs/s;  15971 sec\n",
            "[2021-04-30 09:21:36,623 INFO] Step 22300/50000; xent: 2.98; lr: 0.0000134;  30 docs/s;  16005 sec\n",
            "[2021-04-30 09:22:11,787 INFO] Step 22350/50000; xent: 3.02; lr: 0.0000134;  29 docs/s;  16041 sec\n",
            "[2021-04-30 09:22:46,817 INFO] Step 22400/50000; xent: 3.06; lr: 0.0000134;  30 docs/s;  16076 sec\n",
            "[2021-04-30 09:23:06,866 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.17.bert.pt, number of examples: 1999\n",
            "[2021-04-30 09:23:23,687 INFO] Step 22450/50000; xent: 2.96; lr: 0.0000133;  28 docs/s;  16113 sec\n",
            "[2021-04-30 09:23:58,715 INFO] Step 22500/50000; xent: 2.94; lr: 0.0000133;  31 docs/s;  16148 sec\n",
            "[2021-04-30 09:24:33,775 INFO] Step 22550/50000; xent: 3.04; lr: 0.0000133;  30 docs/s;  16183 sec\n",
            "[2021-04-30 09:25:08,652 INFO] Step 22600/50000; xent: 3.10; lr: 0.0000133;  29 docs/s;  16218 sec\n",
            "[2021-04-30 09:25:23,330 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.31.bert.pt, number of examples: 2001\n",
            "[2021-04-30 09:25:45,894 INFO] Step 22650/50000; xent: 2.99; lr: 0.0000133;  28 docs/s;  16255 sec\n",
            "[2021-04-30 09:26:20,875 INFO] Step 22700/50000; xent: 2.94; lr: 0.0000133;  31 docs/s;  16290 sec\n",
            "[2021-04-30 09:26:55,909 INFO] Step 22750/50000; xent: 2.96; lr: 0.0000133;  30 docs/s;  16325 sec\n",
            "[2021-04-30 09:27:30,823 INFO] Step 22800/50000; xent: 2.99; lr: 0.0000132;  29 docs/s;  16360 sec\n",
            "[2021-04-30 09:27:39,271 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.4.bert.pt, number of examples: 2000\n",
            "[2021-04-30 09:28:07,479 INFO] Step 22850/50000; xent: 2.94; lr: 0.0000132;  28 docs/s;  16396 sec\n",
            "[2021-04-30 09:28:42,513 INFO] Step 22900/50000; xent: 2.99; lr: 0.0000132;  30 docs/s;  16431 sec\n",
            "[2021-04-30 09:29:17,578 INFO] Step 22950/50000; xent: 3.00; lr: 0.0000132;  30 docs/s;  16466 sec\n",
            "[2021-04-30 09:29:52,740 INFO] Step 23000/50000; xent: 2.91; lr: 0.0000132;  29 docs/s;  16502 sec\n",
            "[2021-04-30 09:29:52,743 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_23000.pt\n",
            "[2021-04-30 09:30:03,529 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.42.bert.pt, number of examples: 2000\n",
            "[2021-04-30 09:30:36,877 INFO] Step 23050/50000; xent: 3.00; lr: 0.0000132;  23 docs/s;  16546 sec\n",
            "[2021-04-30 09:31:11,973 INFO] Step 23100/50000; xent: 2.93; lr: 0.0000132;  30 docs/s;  16581 sec\n",
            "[2021-04-30 09:31:47,004 INFO] Step 23150/50000; xent: 2.92; lr: 0.0000131;  29 docs/s;  16616 sec\n",
            "[2021-04-30 09:32:20,596 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.75.bert.pt, number of examples: 1999\n",
            "[2021-04-30 09:32:23,503 INFO] Step 23200/50000; xent: 2.99; lr: 0.0000131;  28 docs/s;  16652 sec\n",
            "[2021-04-30 09:32:58,569 INFO] Step 23250/50000; xent: 2.91; lr: 0.0000131;  30 docs/s;  16687 sec\n",
            "[2021-04-30 09:33:33,621 INFO] Step 23300/50000; xent: 3.01; lr: 0.0000131;  29 docs/s;  16722 sec\n",
            "[2021-04-30 09:34:08,510 INFO] Step 23350/50000; xent: 2.96; lr: 0.0000131;  29 docs/s;  16757 sec\n",
            "[2021-04-30 09:34:38,080 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.129.bert.pt, number of examples: 1999\n",
            "[2021-04-30 09:34:45,864 INFO] Step 23400/50000; xent: 2.96; lr: 0.0000131;  28 docs/s;  16795 sec\n",
            "[2021-04-30 09:35:20,982 INFO] Step 23450/50000; xent: 2.96; lr: 0.0000131;  30 docs/s;  16830 sec\n",
            "[2021-04-30 09:35:56,033 INFO] Step 23500/50000; xent: 3.01; lr: 0.0000130;  30 docs/s;  16865 sec\n",
            "[2021-04-30 09:36:30,898 INFO] Step 23550/50000; xent: 3.06; lr: 0.0000130;  29 docs/s;  16900 sec\n",
            "[2021-04-30 09:36:55,058 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.117.bert.pt, number of examples: 2001\n",
            "[2021-04-30 09:37:07,794 INFO] Step 23600/50000; xent: 2.88; lr: 0.0000130;  28 docs/s;  16937 sec\n",
            "[2021-04-30 09:37:42,885 INFO] Step 23650/50000; xent: 2.94; lr: 0.0000130;  30 docs/s;  16972 sec\n",
            "[2021-04-30 09:38:17,930 INFO] Step 23700/50000; xent: 2.98; lr: 0.0000130;  30 docs/s;  17007 sec\n",
            "[2021-04-30 09:38:52,975 INFO] Step 23750/50000; xent: 3.02; lr: 0.0000130;  30 docs/s;  17042 sec\n",
            "[2021-04-30 09:39:11,573 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.115.bert.pt, number of examples: 2000\n",
            "[2021-04-30 09:39:29,895 INFO] Step 23800/50000; xent: 2.98; lr: 0.0000130;  28 docs/s;  17079 sec\n",
            "[2021-04-30 09:40:04,898 INFO] Step 23850/50000; xent: 2.97; lr: 0.0000130;  30 docs/s;  17114 sec\n",
            "[2021-04-30 09:40:39,981 INFO] Step 23900/50000; xent: 3.00; lr: 0.0000129;  29 docs/s;  17149 sec\n",
            "[2021-04-30 09:41:14,869 INFO] Step 23950/50000; xent: 2.99; lr: 0.0000129;  30 docs/s;  17184 sec\n",
            "[2021-04-30 09:41:30,519 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.48.bert.pt, number of examples: 2000\n",
            "[2021-04-30 09:41:53,127 INFO] Step 24000/50000; xent: 2.98; lr: 0.0000129;  27 docs/s;  17222 sec\n",
            "[2021-04-30 09:41:53,142 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_24000.pt\n",
            "[2021-04-30 09:42:34,647 INFO] Step 24050/50000; xent: 2.93; lr: 0.0000129;  25 docs/s;  17264 sec\n",
            "[2021-04-30 09:43:09,825 INFO] Step 24100/50000; xent: 3.05; lr: 0.0000129;  29 docs/s;  17299 sec\n",
            "[2021-04-30 09:43:44,797 INFO] Step 24150/50000; xent: 3.02; lr: 0.0000129;  30 docs/s;  17334 sec\n",
            "[2021-04-30 09:43:54,323 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.132.bert.pt, number of examples: 2001\n",
            "[2021-04-30 09:44:21,681 INFO] Step 24200/50000; xent: 3.01; lr: 0.0000129;  28 docs/s;  17371 sec\n",
            "[2021-04-30 09:44:56,701 INFO] Step 24250/50000; xent: 2.90; lr: 0.0000128;  30 docs/s;  17406 sec\n",
            "[2021-04-30 09:45:31,677 INFO] Step 24300/50000; xent: 3.02; lr: 0.0000128;  30 docs/s;  17441 sec\n",
            "[2021-04-30 09:46:06,521 INFO] Step 24350/50000; xent: 2.99; lr: 0.0000128;  29 docs/s;  17475 sec\n",
            "[2021-04-30 09:46:11,619 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.120.bert.pt, number of examples: 2000\n",
            "[2021-04-30 09:46:43,964 INFO] Step 24400/50000; xent: 2.96; lr: 0.0000128;  28 docs/s;  17513 sec\n",
            "[2021-04-30 09:47:19,059 INFO] Step 24450/50000; xent: 2.91; lr: 0.0000128;  29 docs/s;  17548 sec\n",
            "[2021-04-30 09:47:53,843 INFO] Step 24500/50000; xent: 2.94; lr: 0.0000128;  30 docs/s;  17583 sec\n",
            "[2021-04-30 09:48:27,806 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.30.bert.pt, number of examples: 2001\n",
            "[2021-04-30 09:48:30,721 INFO] Step 24550/50000; xent: 2.99; lr: 0.0000128;  28 docs/s;  17620 sec\n",
            "[2021-04-30 09:49:05,701 INFO] Step 24600/50000; xent: 2.97; lr: 0.0000128;  29 docs/s;  17655 sec\n",
            "[2021-04-30 09:49:40,779 INFO] Step 24650/50000; xent: 3.03; lr: 0.0000127;  30 docs/s;  17690 sec\n",
            "[2021-04-30 09:50:15,815 INFO] Step 24700/50000; xent: 2.96; lr: 0.0000127;  30 docs/s;  17725 sec\n",
            "[2021-04-30 09:50:44,907 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.124.bert.pt, number of examples: 2001\n",
            "[2021-04-30 09:50:52,718 INFO] Step 24750/50000; xent: 3.00; lr: 0.0000127;  28 docs/s;  17762 sec\n",
            "[2021-04-30 09:51:27,781 INFO] Step 24800/50000; xent: 2.98; lr: 0.0000127;  30 docs/s;  17797 sec\n",
            "[2021-04-30 09:52:02,853 INFO] Step 24850/50000; xent: 2.96; lr: 0.0000127;  30 docs/s;  17832 sec\n",
            "[2021-04-30 09:52:37,769 INFO] Step 24900/50000; xent: 3.04; lr: 0.0000127;  29 docs/s;  17867 sec\n",
            "[2021-04-30 09:53:01,850 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.101.bert.pt, number of examples: 1998\n",
            "[2021-04-30 09:53:14,584 INFO] Step 24950/50000; xent: 3.01; lr: 0.0000127;  28 docs/s;  17903 sec\n",
            "[2021-04-30 09:53:49,487 INFO] Step 25000/50000; xent: 3.04; lr: 0.0000126;  30 docs/s;  17938 sec\n",
            "[2021-04-30 09:53:49,503 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_25000.pt\n",
            "[2021-04-30 09:54:31,477 INFO] Step 25050/50000; xent: 3.00; lr: 0.0000126;  25 docs/s;  17980 sec\n",
            "[2021-04-30 09:55:06,669 INFO] Step 25100/50000; xent: 3.01; lr: 0.0000126;  29 docs/s;  18016 sec\n",
            "[2021-04-30 09:55:25,038 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.26.bert.pt, number of examples: 1998\n",
            "[2021-04-30 09:55:43,393 INFO] Step 25150/50000; xent: 2.91; lr: 0.0000126;  28 docs/s;  18052 sec\n",
            "[2021-04-30 09:56:18,538 INFO] Step 25200/50000; xent: 3.03; lr: 0.0000126;  29 docs/s;  18087 sec\n",
            "[2021-04-30 09:56:53,547 INFO] Step 25250/50000; xent: 3.01; lr: 0.0000126;  30 docs/s;  18122 sec\n",
            "[2021-04-30 09:57:28,215 INFO] Step 25300/50000; xent: 2.94; lr: 0.0000126;  29 docs/s;  18157 sec\n",
            "[2021-04-30 09:57:41,239 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.77.bert.pt, number of examples: 2001\n",
            "[2021-04-30 09:58:05,277 INFO] Step 25350/50000; xent: 3.03; lr: 0.0000126;  28 docs/s;  18194 sec\n",
            "[2021-04-30 09:58:40,176 INFO] Step 25400/50000; xent: 3.00; lr: 0.0000125;  30 docs/s;  18229 sec\n",
            "[2021-04-30 09:59:15,184 INFO] Step 25450/50000; xent: 2.97; lr: 0.0000125;  30 docs/s;  18264 sec\n",
            "[2021-04-30 09:59:50,117 INFO] Step 25500/50000; xent: 3.01; lr: 0.0000125;  30 docs/s;  18299 sec\n",
            "[2021-04-30 09:59:57,886 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.58.bert.pt, number of examples: 2001\n",
            "[2021-04-30 10:00:26,775 INFO] Step 25550/50000; xent: 2.95; lr: 0.0000125;  29 docs/s;  18336 sec\n",
            "[2021-04-30 10:01:01,827 INFO] Step 25600/50000; xent: 2.93; lr: 0.0000125;  30 docs/s;  18371 sec\n",
            "[2021-04-30 10:01:36,677 INFO] Step 25650/50000; xent: 2.99; lr: 0.0000125;  29 docs/s;  18406 sec\n",
            "[2021-04-30 10:02:11,586 INFO] Step 25700/50000; xent: 3.03; lr: 0.0000125;  30 docs/s;  18440 sec\n",
            "[2021-04-30 10:02:14,850 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.130.bert.pt, number of examples: 2001\n",
            "[2021-04-30 10:02:48,682 INFO] Step 25750/50000; xent: 3.03; lr: 0.0000125;  29 docs/s;  18478 sec\n",
            "[2021-04-30 10:03:23,753 INFO] Step 25800/50000; xent: 3.04; lr: 0.0000125;  29 docs/s;  18513 sec\n",
            "[2021-04-30 10:03:58,630 INFO] Step 25850/50000; xent: 2.92; lr: 0.0000124;  30 docs/s;  18547 sec\n",
            "[2021-04-30 10:04:31,531 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.109.bert.pt, number of examples: 1999\n",
            "[2021-04-30 10:04:35,142 INFO] Step 25900/50000; xent: 2.97; lr: 0.0000124;  28 docs/s;  18584 sec\n",
            "[2021-04-30 10:05:10,174 INFO] Step 25950/50000; xent: 2.94; lr: 0.0000124;  30 docs/s;  18619 sec\n",
            "[2021-04-30 10:05:45,268 INFO] Step 26000/50000; xent: 3.00; lr: 0.0000124;  29 docs/s;  18654 sec\n",
            "[2021-04-30 10:05:45,284 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_26000.pt\n",
            "[2021-04-30 10:06:26,671 INFO] Step 26050/50000; xent: 2.97; lr: 0.0000124;  25 docs/s;  18696 sec\n",
            "[2021-04-30 10:06:55,113 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.126.bert.pt, number of examples: 2001\n",
            "[2021-04-30 10:07:03,634 INFO] Step 26100/50000; xent: 3.00; lr: 0.0000124;  28 docs/s;  18732 sec\n",
            "[2021-04-30 10:07:38,701 INFO] Step 26150/50000; xent: 2.97; lr: 0.0000124;  29 docs/s;  18768 sec\n",
            "[2021-04-30 10:08:13,749 INFO] Step 26200/50000; xent: 2.96; lr: 0.0000124;  30 docs/s;  18803 sec\n",
            "[2021-04-30 10:08:48,832 INFO] Step 26250/50000; xent: 3.03; lr: 0.0000123;  30 docs/s;  18838 sec\n",
            "[2021-04-30 10:09:12,290 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.46.bert.pt, number of examples: 2001\n",
            "[2021-04-30 10:09:25,748 INFO] Step 26300/50000; xent: 2.96; lr: 0.0000123;  28 docs/s;  18875 sec\n",
            "[2021-04-30 10:10:00,878 INFO] Step 26350/50000; xent: 2.96; lr: 0.0000123;  29 docs/s;  18910 sec\n",
            "[2021-04-30 10:10:35,891 INFO] Step 26400/50000; xent: 3.00; lr: 0.0000123;  29 docs/s;  18945 sec\n",
            "[2021-04-30 10:11:10,935 INFO] Step 26450/50000; xent: 2.97; lr: 0.0000123;  30 docs/s;  18980 sec\n",
            "[2021-04-30 10:11:28,639 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.100.bert.pt, number of examples: 2000\n",
            "[2021-04-30 10:11:47,701 INFO] Step 26500/50000; xent: 2.98; lr: 0.0000123;  28 docs/s;  19017 sec\n",
            "[2021-04-30 10:12:22,750 INFO] Step 26550/50000; xent: 2.90; lr: 0.0000123;  30 docs/s;  19052 sec\n",
            "[2021-04-30 10:12:57,822 INFO] Step 26600/50000; xent: 3.04; lr: 0.0000123;  30 docs/s;  19087 sec\n",
            "[2021-04-30 10:13:32,880 INFO] Step 26650/50000; xent: 2.93; lr: 0.0000123;  30 docs/s;  19122 sec\n",
            "[2021-04-30 10:13:44,744 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.85.bert.pt, number of examples: 1998\n",
            "[2021-04-30 10:14:09,253 INFO] Step 26700/50000; xent: 2.96; lr: 0.0000122;  29 docs/s;  19158 sec\n",
            "[2021-04-30 10:14:44,287 INFO] Step 26750/50000; xent: 3.04; lr: 0.0000122;  29 docs/s;  19193 sec\n",
            "[2021-04-30 10:15:19,349 INFO] Step 26800/50000; xent: 3.02; lr: 0.0000122;  30 docs/s;  19228 sec\n",
            "[2021-04-30 10:15:54,448 INFO] Step 26850/50000; xent: 2.92; lr: 0.0000122;  30 docs/s;  19263 sec\n",
            "[2021-04-30 10:16:01,168 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.34.bert.pt, number of examples: 2000\n",
            "[2021-04-30 10:16:31,450 INFO] Step 26900/50000; xent: 2.93; lr: 0.0000122;  28 docs/s;  19300 sec\n",
            "[2021-04-30 10:17:06,307 INFO] Step 26950/50000; xent: 2.96; lr: 0.0000122;  31 docs/s;  19335 sec\n",
            "[2021-04-30 10:17:41,360 INFO] Step 27000/50000; xent: 3.00; lr: 0.0000122;  29 docs/s;  19370 sec\n",
            "[2021-04-30 10:17:41,377 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_27000.pt\n",
            "[2021-04-30 10:18:24,688 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.7.bert.pt, number of examples: 2000\n",
            "[2021-04-30 10:18:25,507 INFO] Step 27050/50000; xent: 3.00; lr: 0.0000122;  23 docs/s;  19414 sec\n",
            "[2021-04-30 10:19:00,596 INFO] Step 27100/50000; xent: 2.96; lr: 0.0000121;  30 docs/s;  19449 sec\n",
            "[2021-04-30 10:19:35,637 INFO] Step 27150/50000; xent: 3.00; lr: 0.0000121;  29 docs/s;  19484 sec\n",
            "[2021-04-30 10:20:10,705 INFO] Step 27200/50000; xent: 2.95; lr: 0.0000121;  30 docs/s;  19520 sec\n",
            "[2021-04-30 10:20:41,590 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.56.bert.pt, number of examples: 2001\n",
            "[2021-04-30 10:20:47,334 INFO] Step 27250/50000; xent: 2.92; lr: 0.0000121;  29 docs/s;  19556 sec\n",
            "[2021-04-30 10:21:22,362 INFO] Step 27300/50000; xent: 2.97; lr: 0.0000121;  29 docs/s;  19591 sec\n",
            "[2021-04-30 10:21:57,405 INFO] Step 27350/50000; xent: 2.94; lr: 0.0000121;  31 docs/s;  19626 sec\n",
            "[2021-04-30 10:22:32,451 INFO] Step 27400/50000; xent: 2.95; lr: 0.0000121;  30 docs/s;  19661 sec\n",
            "[2021-04-30 10:22:57,623 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.74.bert.pt, number of examples: 2000\n",
            "[2021-04-30 10:23:08,969 INFO] Step 27450/50000; xent: 2.97; lr: 0.0000121;  28 docs/s;  19698 sec\n",
            "[2021-04-30 10:23:44,067 INFO] Step 27500/50000; xent: 3.00; lr: 0.0000121;  30 docs/s;  19733 sec\n",
            "[2021-04-30 10:24:19,134 INFO] Step 27550/50000; xent: 3.03; lr: 0.0000120;  29 docs/s;  19768 sec\n",
            "[2021-04-30 10:24:54,054 INFO] Step 27600/50000; xent: 2.91; lr: 0.0000120;  30 docs/s;  19803 sec\n",
            "[2021-04-30 10:25:14,475 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.21.bert.pt, number of examples: 2001\n",
            "[2021-04-30 10:25:30,681 INFO] Step 27650/50000; xent: 2.98; lr: 0.0000120;  28 docs/s;  19840 sec\n",
            "[2021-04-30 10:26:05,683 INFO] Step 27700/50000; xent: 2.98; lr: 0.0000120;  30 docs/s;  19875 sec\n",
            "[2021-04-30 10:26:40,687 INFO] Step 27750/50000; xent: 3.01; lr: 0.0000120;  30 docs/s;  19910 sec\n",
            "[2021-04-30 10:27:15,742 INFO] Step 27800/50000; xent: 2.97; lr: 0.0000120;  30 docs/s;  19945 sec\n",
            "[2021-04-30 10:27:31,128 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.86.bert.pt, number of examples: 1999\n",
            "[2021-04-30 10:27:52,261 INFO] Step 27850/50000; xent: 2.85; lr: 0.0000120;  28 docs/s;  19981 sec\n",
            "[2021-04-30 10:28:27,337 INFO] Step 27900/50000; xent: 3.00; lr: 0.0000120;  29 docs/s;  20016 sec\n",
            "[2021-04-30 10:29:02,363 INFO] Step 27950/50000; xent: 3.02; lr: 0.0000120;  30 docs/s;  20051 sec\n",
            "[2021-04-30 10:29:37,421 INFO] Step 28000/50000; xent: 2.93; lr: 0.0000120;  30 docs/s;  20086 sec\n",
            "[2021-04-30 10:29:37,425 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_28000.pt\n",
            "[2021-04-30 10:29:54,657 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.0.bert.pt, number of examples: 2000\n",
            "[2021-04-30 10:30:21,135 INFO] Step 28050/50000; xent: 2.91; lr: 0.0000119;  24 docs/s;  20130 sec\n",
            "[2021-04-30 10:30:56,230 INFO] Step 28100/50000; xent: 2.97; lr: 0.0000119;  29 docs/s;  20165 sec\n",
            "[2021-04-30 10:31:31,318 INFO] Step 28150/50000; xent: 3.08; lr: 0.0000119;  30 docs/s;  20200 sec\n",
            "[2021-04-30 10:32:06,209 INFO] Step 28200/50000; xent: 2.98; lr: 0.0000119;  30 docs/s;  20235 sec\n",
            "[2021-04-30 10:32:10,093 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.22.bert.pt, number of examples: 2001\n",
            "[2021-04-30 10:32:41,754 INFO] Step 28250/50000; xent: 2.93; lr: 0.0000119;  29 docs/s;  20271 sec\n",
            "[2021-04-30 10:33:16,862 INFO] Step 28300/50000; xent: 3.01; lr: 0.0000119;  29 docs/s;  20306 sec\n",
            "[2021-04-30 10:33:51,686 INFO] Step 28350/50000; xent: 3.03; lr: 0.0000119;  31 docs/s;  20341 sec\n",
            "[2021-04-30 10:34:27,002 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.43.bert.pt, number of examples: 2001\n",
            "[2021-04-30 10:34:28,513 INFO] Step 28400/50000; xent: 3.00; lr: 0.0000119;  28 docs/s;  20377 sec\n",
            "[2021-04-30 10:35:03,564 INFO] Step 28450/50000; xent: 2.92; lr: 0.0000119;  30 docs/s;  20412 sec\n",
            "[2021-04-30 10:35:38,390 INFO] Step 28500/50000; xent: 3.01; lr: 0.0000118;  30 docs/s;  20447 sec\n",
            "[2021-04-30 10:36:13,380 INFO] Step 28550/50000; xent: 2.97; lr: 0.0000118;  30 docs/s;  20482 sec\n",
            "[2021-04-30 10:36:44,543 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.105.bert.pt, number of examples: 2000\n",
            "[2021-04-30 10:36:51,653 INFO] Step 28600/50000; xent: 3.07; lr: 0.0000118;  27 docs/s;  20521 sec\n",
            "[2021-04-30 10:37:26,610 INFO] Step 28650/50000; xent: 2.97; lr: 0.0000118;  29 docs/s;  20555 sec\n",
            "[2021-04-30 10:38:01,714 INFO] Step 28700/50000; xent: 3.09; lr: 0.0000118;  29 docs/s;  20591 sec\n",
            "[2021-04-30 10:38:36,760 INFO] Step 28750/50000; xent: 3.04; lr: 0.0000118;  30 docs/s;  20626 sec\n",
            "[2021-04-30 10:39:01,699 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.33.bert.pt, number of examples: 1997\n",
            "[2021-04-30 10:39:13,592 INFO] Step 28800/50000; xent: 3.09; lr: 0.0000118;  28 docs/s;  20662 sec\n",
            "[2021-04-30 10:39:48,652 INFO] Step 28850/50000; xent: 3.00; lr: 0.0000118;  30 docs/s;  20698 sec\n",
            "[2021-04-30 10:40:23,683 INFO] Step 28900/50000; xent: 2.97; lr: 0.0000118;  30 docs/s;  20733 sec\n",
            "[2021-04-30 10:40:58,777 INFO] Step 28950/50000; xent: 3.03; lr: 0.0000118;  30 docs/s;  20768 sec\n",
            "[2021-04-30 10:41:15,901 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.34.bert.pt, number of examples: 2000\n",
            "[2021-04-30 10:41:34,214 INFO] Step 29000/50000; xent: 3.06; lr: 0.0000117;  29 docs/s;  20803 sec\n",
            "[2021-04-30 10:41:34,228 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_29000.pt\n",
            "[2021-04-30 10:42:16,012 INFO] Step 29050/50000; xent: 2.96; lr: 0.0000117;  25 docs/s;  20845 sec\n",
            "[2021-04-30 10:42:51,147 INFO] Step 29100/50000; xent: 2.99; lr: 0.0000117;  29 docs/s;  20880 sec\n",
            "[2021-04-30 10:43:26,200 INFO] Step 29150/50000; xent: 2.93; lr: 0.0000117;  30 docs/s;  20915 sec\n",
            "[2021-04-30 10:43:39,540 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.110.bert.pt, number of examples: 2001\n",
            "[2021-04-30 10:44:02,563 INFO] Step 29200/50000; xent: 2.98; lr: 0.0000117;  28 docs/s;  20951 sec\n",
            "[2021-04-30 10:44:37,600 INFO] Step 29250/50000; xent: 2.97; lr: 0.0000117;  30 docs/s;  20986 sec\n",
            "[2021-04-30 10:45:12,702 INFO] Step 29300/50000; xent: 2.96; lr: 0.0000117;  29 docs/s;  21022 sec\n",
            "[2021-04-30 10:45:47,731 INFO] Step 29350/50000; xent: 2.97; lr: 0.0000117;  30 docs/s;  21057 sec\n",
            "[2021-04-30 10:45:56,579 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.139.bert.pt, number of examples: 2000\n",
            "[2021-04-30 10:46:24,676 INFO] Step 29400/50000; xent: 2.94; lr: 0.0000117;  29 docs/s;  21094 sec\n",
            "[2021-04-30 10:46:59,615 INFO] Step 29450/50000; xent: 2.94; lr: 0.0000117;  29 docs/s;  21128 sec\n",
            "[2021-04-30 10:47:34,716 INFO] Step 29500/50000; xent: 3.01; lr: 0.0000116;  29 docs/s;  21164 sec\n",
            "[2021-04-30 10:48:09,645 INFO] Step 29550/50000; xent: 2.95; lr: 0.0000116;  30 docs/s;  21199 sec\n",
            "[2021-04-30 10:48:12,860 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.118.bert.pt, number of examples: 2001\n",
            "[2021-04-30 10:48:46,580 INFO] Step 29600/50000; xent: 2.95; lr: 0.0000116;  29 docs/s;  21235 sec\n",
            "[2021-04-30 10:49:21,726 INFO] Step 29650/50000; xent: 2.96; lr: 0.0000116;  29 docs/s;  21271 sec\n",
            "[2021-04-30 10:49:56,734 INFO] Step 29700/50000; xent: 2.92; lr: 0.0000116;  30 docs/s;  21306 sec\n",
            "[2021-04-30 10:50:27,902 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.140.bert.pt, number of examples: 1999\n",
            "[2021-04-30 10:50:32,239 INFO] Step 29750/50000; xent: 2.96; lr: 0.0000116;  30 docs/s;  21341 sec\n",
            "[2021-04-30 10:51:07,358 INFO] Step 29800/50000; xent: 3.02; lr: 0.0000116;  30 docs/s;  21376 sec\n",
            "[2021-04-30 10:51:42,407 INFO] Step 29850/50000; xent: 2.96; lr: 0.0000116;  30 docs/s;  21411 sec\n",
            "[2021-04-30 10:52:17,479 INFO] Step 29900/50000; xent: 3.03; lr: 0.0000116;  30 docs/s;  21446 sec\n",
            "[2021-04-30 10:52:45,078 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.91.bert.pt, number of examples: 1995\n",
            "[2021-04-30 10:52:54,315 INFO] Step 29950/50000; xent: 3.00; lr: 0.0000116;  28 docs/s;  21483 sec\n",
            "[2021-04-30 10:53:29,115 INFO] Step 30000/50000; xent: 2.99; lr: 0.0000115;  30 docs/s;  21518 sec\n",
            "[2021-04-30 10:53:29,117 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_30000.pt\n",
            "[2021-04-30 10:54:11,109 INFO] Step 30050/50000; xent: 2.97; lr: 0.0000115;  25 docs/s;  21560 sec\n",
            "[2021-04-30 10:54:46,271 INFO] Step 30100/50000; xent: 2.86; lr: 0.0000115;  30 docs/s;  21595 sec\n",
            "[2021-04-30 10:55:07,772 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.133.bert.pt, number of examples: 1999\n",
            "[2021-04-30 10:55:21,943 INFO] Step 30150/50000; xent: 2.99; lr: 0.0000115;  30 docs/s;  21631 sec\n",
            "[2021-04-30 10:55:56,830 INFO] Step 30200/50000; xent: 2.96; lr: 0.0000115;  30 docs/s;  21666 sec\n",
            "[2021-04-30 10:56:31,926 INFO] Step 30250/50000; xent: 2.96; lr: 0.0000115;  29 docs/s;  21701 sec\n",
            "[2021-04-30 10:57:07,020 INFO] Step 30300/50000; xent: 3.05; lr: 0.0000115;  29 docs/s;  21736 sec\n",
            "[2021-04-30 10:57:24,892 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.47.bert.pt, number of examples: 2000\n",
            "[2021-04-30 10:57:43,695 INFO] Step 30350/50000; xent: 2.94; lr: 0.0000115;  28 docs/s;  21773 sec\n",
            "[2021-04-30 10:58:18,815 INFO] Step 30400/50000; xent: 2.96; lr: 0.0000115;  29 docs/s;  21808 sec\n",
            "[2021-04-30 10:58:53,823 INFO] Step 30450/50000; xent: 2.99; lr: 0.0000115;  30 docs/s;  21843 sec\n",
            "[2021-04-30 10:59:28,962 INFO] Step 30500/50000; xent: 3.03; lr: 0.0000115;  30 docs/s;  21878 sec\n",
            "[2021-04-30 10:59:40,393 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.1.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:00:04,345 INFO] Step 30550/50000; xent: 3.02; lr: 0.0000114;  29 docs/s;  21913 sec\n",
            "[2021-04-30 11:00:39,415 INFO] Step 30600/50000; xent: 3.00; lr: 0.0000114;  30 docs/s;  21948 sec\n",
            "[2021-04-30 11:01:14,511 INFO] Step 30650/50000; xent: 3.02; lr: 0.0000114;  30 docs/s;  21983 sec\n",
            "[2021-04-30 11:01:49,212 INFO] Step 30700/50000; xent: 2.97; lr: 0.0000114;  30 docs/s;  22018 sec\n",
            "[2021-04-30 11:01:55,248 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.103.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:02:24,513 INFO] Step 30750/50000; xent: 3.01; lr: 0.0000114;  30 docs/s;  22053 sec\n",
            "[2021-04-30 11:02:59,551 INFO] Step 30800/50000; xent: 2.92; lr: 0.0000114;  30 docs/s;  22088 sec\n",
            "[2021-04-30 11:03:34,648 INFO] Step 30850/50000; xent: 3.00; lr: 0.0000114;  29 docs/s;  22124 sec\n",
            "[2021-04-30 11:04:09,566 INFO] Step 30900/50000; xent: 2.98; lr: 0.0000114;  29 docs/s;  22158 sec\n",
            "[2021-04-30 11:04:12,418 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.27.bert.pt, number of examples: 1999\n",
            "[2021-04-30 11:04:46,917 INFO] Step 30950/50000; xent: 2.96; lr: 0.0000114;  29 docs/s;  22196 sec\n",
            "[2021-04-30 11:05:21,912 INFO] Step 31000/50000; xent: 2.99; lr: 0.0000114;  30 docs/s;  22231 sec\n",
            "[2021-04-30 11:05:21,928 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_31000.pt\n",
            "[2021-04-30 11:06:03,444 INFO] Step 31050/50000; xent: 2.99; lr: 0.0000114;  25 docs/s;  22272 sec\n",
            "[2021-04-30 11:06:33,900 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.7.bert.pt, number of examples: 2000\n",
            "[2021-04-30 11:06:38,901 INFO] Step 31100/50000; xent: 2.98; lr: 0.0000113;  29 docs/s;  22308 sec\n",
            "[2021-04-30 11:07:13,964 INFO] Step 31150/50000; xent: 2.93; lr: 0.0000113;  30 docs/s;  22343 sec\n",
            "[2021-04-30 11:07:49,002 INFO] Step 31200/50000; xent: 2.97; lr: 0.0000113;  30 docs/s;  22378 sec\n",
            "[2021-04-30 11:08:24,031 INFO] Step 31250/50000; xent: 2.97; lr: 0.0000113;  30 docs/s;  22413 sec\n",
            "[2021-04-30 11:08:49,526 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.3.bert.pt, number of examples: 2000\n",
            "[2021-04-30 11:08:59,494 INFO] Step 31300/50000; xent: 3.00; lr: 0.0000113;  29 docs/s;  22448 sec\n",
            "[2021-04-30 11:09:34,462 INFO] Step 31350/50000; xent: 2.90; lr: 0.0000113;  31 docs/s;  22483 sec\n",
            "[2021-04-30 11:10:09,539 INFO] Step 31400/50000; xent: 3.09; lr: 0.0000113;  29 docs/s;  22518 sec\n",
            "[2021-04-30 11:10:44,516 INFO] Step 31450/50000; xent: 2.94; lr: 0.0000113;  29 docs/s;  22553 sec\n",
            "[2021-04-30 11:11:05,191 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.117.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:11:20,060 INFO] Step 31500/50000; xent: 3.00; lr: 0.0000113;  29 docs/s;  22589 sec\n",
            "[2021-04-30 11:11:55,163 INFO] Step 31550/50000; xent: 2.96; lr: 0.0000113;  29 docs/s;  22624 sec\n",
            "[2021-04-30 11:12:30,130 INFO] Step 31600/50000; xent: 2.99; lr: 0.0000113;  30 docs/s;  22659 sec\n",
            "[2021-04-30 11:13:05,188 INFO] Step 31650/50000; xent: 2.89; lr: 0.0000112;  30 docs/s;  22694 sec\n",
            "[2021-04-30 11:13:20,223 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.119.bert.pt, number of examples: 1998\n",
            "[2021-04-30 11:13:40,710 INFO] Step 31700/50000; xent: 2.99; lr: 0.0000112;  29 docs/s;  22730 sec\n",
            "[2021-04-30 11:14:15,806 INFO] Step 31750/50000; xent: 3.02; lr: 0.0000112;  30 docs/s;  22765 sec\n",
            "[2021-04-30 11:14:50,829 INFO] Step 31800/50000; xent: 2.97; lr: 0.0000112;  30 docs/s;  22800 sec\n",
            "[2021-04-30 11:15:25,840 INFO] Step 31850/50000; xent: 3.06; lr: 0.0000112;  30 docs/s;  22835 sec\n",
            "[2021-04-30 11:15:36,144 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.84.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:16:02,174 INFO] Step 31900/50000; xent: 2.96; lr: 0.0000112;  29 docs/s;  22871 sec\n",
            "[2021-04-30 11:16:37,052 INFO] Step 31950/50000; xent: 3.02; lr: 0.0000112;  30 docs/s;  22906 sec\n",
            "[2021-04-30 11:17:12,114 INFO] Step 32000/50000; xent: 2.94; lr: 0.0000112;  29 docs/s;  22941 sec\n",
            "[2021-04-30 11:17:12,128 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_32000.pt\n",
            "[2021-04-30 11:17:53,098 INFO] Step 32050/50000; xent: 2.89; lr: 0.0000112;  25 docs/s;  22982 sec\n",
            "[2021-04-30 11:17:59,133 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.71.bert.pt, number of examples: 1999\n",
            "[2021-04-30 11:18:30,113 INFO] Step 32100/50000; xent: 3.00; lr: 0.0000112;  28 docs/s;  23019 sec\n",
            "[2021-04-30 11:19:05,145 INFO] Step 32150/50000; xent: 2.91; lr: 0.0000112;  30 docs/s;  23054 sec\n",
            "[2021-04-30 11:19:40,160 INFO] Step 32200/50000; xent: 2.96; lr: 0.0000111;  30 docs/s;  23089 sec\n",
            "[2021-04-30 11:20:14,710 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.124.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:20:15,514 INFO] Step 32250/50000; xent: 2.97; lr: 0.0000111;  29 docs/s;  23124 sec\n",
            "[2021-04-30 11:20:50,566 INFO] Step 32300/50000; xent: 2.97; lr: 0.0000111;  30 docs/s;  23159 sec\n",
            "[2021-04-30 11:21:25,432 INFO] Step 32350/50000; xent: 3.02; lr: 0.0000111;  29 docs/s;  23194 sec\n",
            "[2021-04-30 11:22:00,490 INFO] Step 32400/50000; xent: 3.02; lr: 0.0000111;  30 docs/s;  23229 sec\n",
            "[2021-04-30 11:22:30,959 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.35.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:22:37,357 INFO] Step 32450/50000; xent: 3.00; lr: 0.0000111;  29 docs/s;  23266 sec\n",
            "[2021-04-30 11:23:12,406 INFO] Step 32500/50000; xent: 3.08; lr: 0.0000111;  29 docs/s;  23301 sec\n",
            "[2021-04-30 11:23:47,430 INFO] Step 32550/50000; xent: 2.96; lr: 0.0000111;  30 docs/s;  23336 sec\n",
            "[2021-04-30 11:24:22,359 INFO] Step 32600/50000; xent: 2.95; lr: 0.0000111;  29 docs/s;  23371 sec\n",
            "[2021-04-30 11:24:46,452 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.31.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:24:57,762 INFO] Step 32650/50000; xent: 2.94; lr: 0.0000111;  29 docs/s;  23407 sec\n",
            "[2021-04-30 11:25:32,635 INFO] Step 32700/50000; xent: 2.98; lr: 0.0000111;  30 docs/s;  23441 sec\n",
            "[2021-04-30 11:26:07,744 INFO] Step 32750/50000; xent: 2.95; lr: 0.0000111;  30 docs/s;  23477 sec\n",
            "[2021-04-30 11:26:42,766 INFO] Step 32800/50000; xent: 2.95; lr: 0.0000110;  30 docs/s;  23512 sec\n",
            "[2021-04-30 11:27:02,599 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.62.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:27:19,550 INFO] Step 32850/50000; xent: 3.01; lr: 0.0000110;  28 docs/s;  23548 sec\n",
            "[2021-04-30 11:27:54,444 INFO] Step 32900/50000; xent: 2.98; lr: 0.0000110;  29 docs/s;  23583 sec\n",
            "[2021-04-30 11:28:29,518 INFO] Step 32950/50000; xent: 2.95; lr: 0.0000110;  30 docs/s;  23618 sec\n",
            "[2021-04-30 11:29:04,565 INFO] Step 33000/50000; xent: 2.97; lr: 0.0000110;  30 docs/s;  23653 sec\n",
            "[2021-04-30 11:29:04,568 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_33000.pt\n",
            "[2021-04-30 11:29:26,077 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.52.bert.pt, number of examples: 1999\n",
            "[2021-04-30 11:29:48,957 INFO] Step 33050/50000; xent: 2.98; lr: 0.0000110;  23 docs/s;  23698 sec\n",
            "[2021-04-30 11:30:24,025 INFO] Step 33100/50000; xent: 2.95; lr: 0.0000110;  30 docs/s;  23733 sec\n",
            "[2021-04-30 11:30:59,111 INFO] Step 33150/50000; xent: 2.89; lr: 0.0000110;  29 docs/s;  23768 sec\n",
            "[2021-04-30 11:31:34,179 INFO] Step 33200/50000; xent: 2.93; lr: 0.0000110;  30 docs/s;  23803 sec\n",
            "[2021-04-30 11:31:43,439 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.25.bert.pt, number of examples: 1999\n",
            "[2021-04-30 11:32:10,886 INFO] Step 33250/50000; xent: 3.03; lr: 0.0000110;  28 docs/s;  23840 sec\n",
            "[2021-04-30 11:32:45,922 INFO] Step 33300/50000; xent: 3.02; lr: 0.0000110;  30 docs/s;  23875 sec\n",
            "[2021-04-30 11:33:20,989 INFO] Step 33350/50000; xent: 2.95; lr: 0.0000110;  29 docs/s;  23910 sec\n",
            "[2021-04-30 11:33:55,868 INFO] Step 33400/50000; xent: 2.96; lr: 0.0000109;  30 docs/s;  23945 sec\n",
            "[2021-04-30 11:33:59,901 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.136.bert.pt, number of examples: 1998\n",
            "[2021-04-30 11:34:32,772 INFO] Step 33450/50000; xent: 3.02; lr: 0.0000109;  27 docs/s;  23982 sec\n",
            "[2021-04-30 11:35:07,743 INFO] Step 33500/50000; xent: 2.96; lr: 0.0000109;  31 docs/s;  24017 sec\n",
            "[2021-04-30 11:35:42,811 INFO] Step 33550/50000; xent: 2.92; lr: 0.0000109;  29 docs/s;  24052 sec\n",
            "[2021-04-30 11:36:15,891 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.82.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:36:19,505 INFO] Step 33600/50000; xent: 2.95; lr: 0.0000109;  28 docs/s;  24088 sec\n",
            "[2021-04-30 11:36:54,550 INFO] Step 33650/50000; xent: 2.99; lr: 0.0000109;  30 docs/s;  24123 sec\n",
            "[2021-04-30 11:37:29,606 INFO] Step 33700/50000; xent: 2.94; lr: 0.0000109;  30 docs/s;  24158 sec\n",
            "[2021-04-30 11:38:04,529 INFO] Step 33750/50000; xent: 2.98; lr: 0.0000109;  29 docs/s;  24193 sec\n",
            "[2021-04-30 11:38:32,957 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.55.bert.pt, number of examples: 1999\n",
            "[2021-04-30 11:38:41,478 INFO] Step 33800/50000; xent: 3.05; lr: 0.0000109;  28 docs/s;  24230 sec\n",
            "[2021-04-30 11:39:16,520 INFO] Step 33850/50000; xent: 2.99; lr: 0.0000109;  31 docs/s;  24265 sec\n",
            "[2021-04-30 11:39:51,445 INFO] Step 33900/50000; xent: 3.02; lr: 0.0000109;  29 docs/s;  24300 sec\n",
            "[2021-04-30 11:40:26,451 INFO] Step 33950/50000; xent: 3.01; lr: 0.0000109;  29 docs/s;  24335 sec\n",
            "[2021-04-30 11:40:49,034 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.116.bert.pt, number of examples: 1997\n",
            "[2021-04-30 11:41:03,175 INFO] Step 34000/50000; xent: 2.93; lr: 0.0000108;  28 docs/s;  24372 sec\n",
            "[2021-04-30 11:41:03,190 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_34000.pt\n",
            "[2021-04-30 11:41:45,192 INFO] Step 34050/50000; xent: 3.01; lr: 0.0000108;  25 docs/s;  24414 sec\n",
            "[2021-04-30 11:42:20,283 INFO] Step 34100/50000; xent: 2.94; lr: 0.0000108;  31 docs/s;  24449 sec\n",
            "[2021-04-30 11:42:55,339 INFO] Step 34150/50000; xent: 3.01; lr: 0.0000108;  29 docs/s;  24484 sec\n",
            "[2021-04-30 11:43:11,780 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.101.bert.pt, number of examples: 1998\n",
            "[2021-04-30 11:43:30,784 INFO] Step 34200/50000; xent: 3.03; lr: 0.0000108;  29 docs/s;  24520 sec\n",
            "[2021-04-30 11:44:05,814 INFO] Step 34250/50000; xent: 2.94; lr: 0.0000108;  30 docs/s;  24555 sec\n",
            "[2021-04-30 11:44:40,836 INFO] Step 34300/50000; xent: 3.00; lr: 0.0000108;  30 docs/s;  24590 sec\n",
            "[2021-04-30 11:45:15,871 INFO] Step 34350/50000; xent: 3.02; lr: 0.0000108;  29 docs/s;  24625 sec\n",
            "[2021-04-30 11:45:28,125 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.95.bert.pt, number of examples: 2000\n",
            "[2021-04-30 11:45:52,802 INFO] Step 34400/50000; xent: 2.96; lr: 0.0000108;  28 docs/s;  24662 sec\n",
            "[2021-04-30 11:46:27,817 INFO] Step 34450/50000; xent: 2.99; lr: 0.0000108;  29 docs/s;  24697 sec\n",
            "[2021-04-30 11:47:02,860 INFO] Step 34500/50000; xent: 2.94; lr: 0.0000108;  30 docs/s;  24732 sec\n",
            "[2021-04-30 11:47:37,711 INFO] Step 34550/50000; xent: 3.01; lr: 0.0000108;  30 docs/s;  24767 sec\n",
            "[2021-04-30 11:47:44,444 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.81.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:48:14,794 INFO] Step 34600/50000; xent: 3.01; lr: 0.0000108;  28 docs/s;  24804 sec\n",
            "[2021-04-30 11:48:49,821 INFO] Step 34650/50000; xent: 2.94; lr: 0.0000107;  30 docs/s;  24839 sec\n",
            "[2021-04-30 11:49:24,861 INFO] Step 34700/50000; xent: 2.97; lr: 0.0000107;  30 docs/s;  24874 sec\n",
            "[2021-04-30 11:50:00,917 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.12.bert.pt, number of examples: 1998\n",
            "[2021-04-30 11:50:01,725 INFO] Step 34750/50000; xent: 2.97; lr: 0.0000107;  28 docs/s;  24911 sec\n",
            "[2021-04-30 11:50:36,836 INFO] Step 34800/50000; xent: 2.99; lr: 0.0000107;  29 docs/s;  24946 sec\n",
            "[2021-04-30 11:51:11,890 INFO] Step 34850/50000; xent: 2.94; lr: 0.0000107;  30 docs/s;  24981 sec\n",
            "[2021-04-30 11:51:46,915 INFO] Step 34900/50000; xent: 2.98; lr: 0.0000107;  30 docs/s;  25016 sec\n",
            "[2021-04-30 11:52:16,923 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.131.bert.pt, number of examples: 2001\n",
            "[2021-04-30 11:52:23,341 INFO] Step 34950/50000; xent: 2.99; lr: 0.0000107;  29 docs/s;  25052 sec\n",
            "[2021-04-30 11:52:58,403 INFO] Step 35000/50000; xent: 2.98; lr: 0.0000107;  30 docs/s;  25087 sec\n",
            "[2021-04-30 11:52:58,418 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_35000.pt\n",
            "[2021-04-30 11:53:41,860 INFO] Step 35050/50000; xent: 3.05; lr: 0.0000107;  24 docs/s;  25131 sec\n",
            "[2021-04-30 11:54:16,885 INFO] Step 35100/50000; xent: 2.98; lr: 0.0000107;  30 docs/s;  25166 sec\n",
            "[2021-04-30 11:54:41,378 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.97.bert.pt, number of examples: 2000\n",
            "[2021-04-30 11:54:53,408 INFO] Step 35150/50000; xent: 2.99; lr: 0.0000107;  28 docs/s;  25202 sec\n",
            "[2021-04-30 11:55:28,473 INFO] Step 35200/50000; xent: 3.01; lr: 0.0000107;  29 docs/s;  25237 sec\n",
            "[2021-04-30 11:56:03,431 INFO] Step 35250/50000; xent: 2.98; lr: 0.0000107;  30 docs/s;  25272 sec\n",
            "[2021-04-30 11:56:38,487 INFO] Step 35300/50000; xent: 2.94; lr: 0.0000106;  29 docs/s;  25307 sec\n",
            "[2021-04-30 11:56:58,884 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.83.bert.pt, number of examples: 1999\n",
            "[2021-04-30 11:57:14,879 INFO] Step 35350/50000; xent: 2.99; lr: 0.0000106;  28 docs/s;  25344 sec\n",
            "[2021-04-30 11:57:49,980 INFO] Step 35400/50000; xent: 2.99; lr: 0.0000106;  29 docs/s;  25379 sec\n",
            "[2021-04-30 11:58:25,008 INFO] Step 35450/50000; xent: 2.97; lr: 0.0000106;  30 docs/s;  25414 sec\n",
            "[2021-04-30 11:58:59,866 INFO] Step 35500/50000; xent: 2.94; lr: 0.0000106;  31 docs/s;  25449 sec\n",
            "[2021-04-30 11:59:13,607 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.100.bert.pt, number of examples: 2000\n",
            "[2021-04-30 11:59:35,446 INFO] Step 35550/50000; xent: 3.01; lr: 0.0000106;  29 docs/s;  25484 sec\n",
            "[2021-04-30 12:00:10,490 INFO] Step 35600/50000; xent: 2.89; lr: 0.0000106;  30 docs/s;  25519 sec\n",
            "[2021-04-30 12:00:45,450 INFO] Step 35650/50000; xent: 3.05; lr: 0.0000106;  30 docs/s;  25554 sec\n",
            "[2021-04-30 12:01:20,573 INFO] Step 35700/50000; xent: 2.93; lr: 0.0000106;  30 docs/s;  25589 sec\n",
            "[2021-04-30 12:01:29,141 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.15.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:01:57,277 INFO] Step 35750/50000; xent: 2.93; lr: 0.0000106;  28 docs/s;  25626 sec\n",
            "[2021-04-30 12:02:32,132 INFO] Step 35800/50000; xent: 2.97; lr: 0.0000106;  29 docs/s;  25661 sec\n",
            "[2021-04-30 12:03:07,204 INFO] Step 35850/50000; xent: 2.98; lr: 0.0000106;  29 docs/s;  25696 sec\n",
            "[2021-04-30 12:03:42,010 INFO] Step 35900/50000; xent: 2.96; lr: 0.0000106;  30 docs/s;  25731 sec\n",
            "[2021-04-30 12:03:45,934 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.137.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:04:18,915 INFO] Step 35950/50000; xent: 2.96; lr: 0.0000105;  28 docs/s;  25768 sec\n",
            "[2021-04-30 12:04:53,916 INFO] Step 36000/50000; xent: 2.99; lr: 0.0000105;  29 docs/s;  25803 sec\n",
            "[2021-04-30 12:04:53,932 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_36000.pt\n",
            "[2021-04-30 12:05:35,865 INFO] Step 36050/50000; xent: 3.01; lr: 0.0000105;  25 docs/s;  25845 sec\n",
            "[2021-04-30 12:06:10,881 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.106.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:06:13,100 INFO] Step 36100/50000; xent: 2.96; lr: 0.0000105;  28 docs/s;  25882 sec\n",
            "[2021-04-30 12:06:48,086 INFO] Step 36150/50000; xent: 2.96; lr: 0.0000105;  30 docs/s;  25917 sec\n",
            "[2021-04-30 12:07:23,135 INFO] Step 36200/50000; xent: 3.00; lr: 0.0000105;  30 docs/s;  25952 sec\n",
            "[2021-04-30 12:07:58,158 INFO] Step 36250/50000; xent: 3.01; lr: 0.0000105;  29 docs/s;  25987 sec\n",
            "[2021-04-30 12:08:27,485 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.94.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:08:35,294 INFO] Step 36300/50000; xent: 2.94; lr: 0.0000105;  27 docs/s;  26024 sec\n",
            "[2021-04-30 12:09:10,320 INFO] Step 36350/50000; xent: 2.95; lr: 0.0000105;  30 docs/s;  26059 sec\n",
            "[2021-04-30 12:09:45,371 INFO] Step 36400/50000; xent: 2.92; lr: 0.0000105;  30 docs/s;  26094 sec\n",
            "[2021-04-30 12:10:20,348 INFO] Step 36450/50000; xent: 3.02; lr: 0.0000105;  30 docs/s;  26129 sec\n",
            "[2021-04-30 12:10:43,858 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.112.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:10:57,300 INFO] Step 36500/50000; xent: 2.98; lr: 0.0000105;  28 docs/s;  26166 sec\n",
            "[2021-04-30 12:11:32,163 INFO] Step 36550/50000; xent: 2.99; lr: 0.0000105;  29 docs/s;  26201 sec\n",
            "[2021-04-30 12:12:07,196 INFO] Step 36600/50000; xent: 2.98; lr: 0.0000105;  30 docs/s;  26236 sec\n",
            "[2021-04-30 12:12:42,289 INFO] Step 36650/50000; xent: 2.94; lr: 0.0000104;  30 docs/s;  26271 sec\n",
            "[2021-04-30 12:13:00,504 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.96.bert.pt, number of examples: 1999\n",
            "[2021-04-30 12:13:18,808 INFO] Step 36700/50000; xent: 2.96; lr: 0.0000104;  29 docs/s;  26308 sec\n",
            "[2021-04-30 12:13:53,871 INFO] Step 36750/50000; xent: 3.00; lr: 0.0000104;  30 docs/s;  26343 sec\n",
            "[2021-04-30 12:14:28,800 INFO] Step 36800/50000; xent: 3.02; lr: 0.0000104;  30 docs/s;  26378 sec\n",
            "[2021-04-30 12:15:03,850 INFO] Step 36850/50000; xent: 3.01; lr: 0.0000104;  29 docs/s;  26413 sec\n",
            "[2021-04-30 12:15:15,784 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.20.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:15:40,426 INFO] Step 36900/50000; xent: 3.01; lr: 0.0000104;  28 docs/s;  26449 sec\n",
            "[2021-04-30 12:16:15,521 INFO] Step 36950/50000; xent: 2.97; lr: 0.0000104;  29 docs/s;  26484 sec\n",
            "[2021-04-30 12:16:50,506 INFO] Step 37000/50000; xent: 2.98; lr: 0.0000104;  30 docs/s;  26519 sec\n",
            "[2021-04-30 12:16:50,522 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_37000.pt\n",
            "[2021-04-30 12:17:32,370 INFO] Step 37050/50000; xent: 2.98; lr: 0.0000104;  25 docs/s;  26561 sec\n",
            "[2021-04-30 12:17:37,457 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.74.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:18:07,741 INFO] Step 37100/50000; xent: 2.96; lr: 0.0000104;  29 docs/s;  26597 sec\n",
            "[2021-04-30 12:18:42,793 INFO] Step 37150/50000; xent: 2.94; lr: 0.0000104;  29 docs/s;  26632 sec\n",
            "[2021-04-30 12:19:17,637 INFO] Step 37200/50000; xent: 2.97; lr: 0.0000104;  30 docs/s;  26666 sec\n",
            "[2021-04-30 12:19:52,575 INFO] Step 37250/50000; xent: 3.04; lr: 0.0000104;  30 docs/s;  26701 sec\n",
            "[2021-04-30 12:19:54,462 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.129.bert.pt, number of examples: 1999\n",
            "[2021-04-30 12:20:29,566 INFO] Step 37300/50000; xent: 2.88; lr: 0.0000104;  29 docs/s;  26738 sec\n",
            "[2021-04-30 12:21:04,632 INFO] Step 37350/50000; xent: 3.04; lr: 0.0000103;  29 docs/s;  26773 sec\n",
            "[2021-04-30 12:21:39,681 INFO] Step 37400/50000; xent: 3.01; lr: 0.0000103;  29 docs/s;  26809 sec\n",
            "[2021-04-30 12:22:10,965 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.113.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:22:16,670 INFO] Step 37450/50000; xent: 2.99; lr: 0.0000103;  28 docs/s;  26846 sec\n",
            "[2021-04-30 12:22:51,711 INFO] Step 37500/50000; xent: 2.95; lr: 0.0000103;  30 docs/s;  26881 sec\n",
            "[2021-04-30 12:23:26,522 INFO] Step 37550/50000; xent: 3.05; lr: 0.0000103;  29 docs/s;  26915 sec\n",
            "[2021-04-30 12:24:01,560 INFO] Step 37600/50000; xent: 2.96; lr: 0.0000103;  30 docs/s;  26950 sec\n",
            "[2021-04-30 12:24:27,852 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.23.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:24:38,485 INFO] Step 37650/50000; xent: 3.01; lr: 0.0000103;  28 docs/s;  26987 sec\n",
            "[2021-04-30 12:25:13,528 INFO] Step 37700/50000; xent: 2.97; lr: 0.0000103;  30 docs/s;  27022 sec\n",
            "[2021-04-30 12:25:48,571 INFO] Step 37750/50000; xent: 2.96; lr: 0.0000103;  30 docs/s;  27057 sec\n",
            "[2021-04-30 12:26:23,543 INFO] Step 37800/50000; xent: 2.96; lr: 0.0000103;  30 docs/s;  27092 sec\n",
            "[2021-04-30 12:26:42,749 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.46.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:26:58,998 INFO] Step 37850/50000; xent: 3.02; lr: 0.0000103;  29 docs/s;  27128 sec\n",
            "[2021-04-30 12:27:33,982 INFO] Step 37900/50000; xent: 2.98; lr: 0.0000103;  30 docs/s;  27163 sec\n",
            "[2021-04-30 12:28:09,036 INFO] Step 37950/50000; xent: 2.99; lr: 0.0000103;  30 docs/s;  27198 sec\n",
            "[2021-04-30 12:28:44,095 INFO] Step 38000/50000; xent: 2.93; lr: 0.0000103;  30 docs/s;  27233 sec\n",
            "[2021-04-30 12:28:44,098 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_38000.pt\n",
            "[2021-04-30 12:29:05,893 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.104.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:29:27,414 INFO] Step 38050/50000; xent: 2.92; lr: 0.0000103;  24 docs/s;  27276 sec\n",
            "[2021-04-30 12:30:02,471 INFO] Step 38100/50000; xent: 2.98; lr: 0.0000102;  30 docs/s;  27311 sec\n",
            "[2021-04-30 12:30:37,422 INFO] Step 38150/50000; xent: 2.88; lr: 0.0000102;  30 docs/s;  27346 sec\n",
            "[2021-04-30 12:31:12,306 INFO] Step 38200/50000; xent: 2.97; lr: 0.0000102;  29 docs/s;  27381 sec\n",
            "[2021-04-30 12:31:20,346 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.126.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:31:47,750 INFO] Step 38250/50000; xent: 3.02; lr: 0.0000102;  30 docs/s;  27417 sec\n",
            "[2021-04-30 12:32:22,814 INFO] Step 38300/50000; xent: 2.96; lr: 0.0000102;  29 docs/s;  27452 sec\n",
            "[2021-04-30 12:32:57,602 INFO] Step 38350/50000; xent: 3.02; lr: 0.0000102;  29 docs/s;  27486 sec\n",
            "[2021-04-30 12:33:32,416 INFO] Step 38400/50000; xent: 2.96; lr: 0.0000102;  30 docs/s;  27521 sec\n",
            "[2021-04-30 12:33:37,650 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.114.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:34:09,269 INFO] Step 38450/50000; xent: 2.98; lr: 0.0000102;  28 docs/s;  27558 sec\n",
            "[2021-04-30 12:34:44,306 INFO] Step 38500/50000; xent: 3.03; lr: 0.0000102;  30 docs/s;  27593 sec\n",
            "[2021-04-30 12:35:19,145 INFO] Step 38550/50000; xent: 2.99; lr: 0.0000102;  30 docs/s;  27628 sec\n",
            "[2021-04-30 12:35:54,162 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.87.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:35:55,673 INFO] Step 38600/50000; xent: 2.97; lr: 0.0000102;  28 docs/s;  27665 sec\n",
            "[2021-04-30 12:36:30,699 INFO] Step 38650/50000; xent: 2.99; lr: 0.0000102;  30 docs/s;  27700 sec\n",
            "[2021-04-30 12:37:05,449 INFO] Step 38700/50000; xent: 2.92; lr: 0.0000102;  30 docs/s;  27734 sec\n",
            "[2021-04-30 12:37:40,518 INFO] Step 38750/50000; xent: 3.00; lr: 0.0000102;  30 docs/s;  27769 sec\n",
            "[2021-04-30 12:38:11,312 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.49.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:38:17,552 INFO] Step 38800/50000; xent: 2.93; lr: 0.0000102;  27 docs/s;  27806 sec\n",
            "[2021-04-30 12:38:52,557 INFO] Step 38850/50000; xent: 2.96; lr: 0.0000101;  30 docs/s;  27841 sec\n",
            "[2021-04-30 12:39:27,583 INFO] Step 38900/50000; xent: 2.96; lr: 0.0000101;  29 docs/s;  27876 sec\n",
            "[2021-04-30 12:40:02,603 INFO] Step 38950/50000; xent: 2.91; lr: 0.0000101;  30 docs/s;  27911 sec\n",
            "[2021-04-30 12:40:29,851 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.141.bert.pt, number of examples: 1998\n",
            "[2021-04-30 12:40:41,925 INFO] Step 39000/50000; xent: 2.95; lr: 0.0000101;  26 docs/s;  27951 sec\n",
            "[2021-04-30 12:40:41,942 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_39000.pt\n",
            "[2021-04-30 12:41:23,102 INFO] Step 39050/50000; xent: 3.00; lr: 0.0000101;  25 docs/s;  27992 sec\n",
            "[2021-04-30 12:41:58,185 INFO] Step 39100/50000; xent: 2.90; lr: 0.0000101;  31 docs/s;  28027 sec\n",
            "[2021-04-30 12:42:33,042 INFO] Step 39150/50000; xent: 2.96; lr: 0.0000101;  29 docs/s;  28062 sec\n",
            "[2021-04-30 12:42:52,461 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.50.bert.pt, number of examples: 1999\n",
            "[2021-04-30 12:43:09,371 INFO] Step 39200/50000; xent: 3.01; lr: 0.0000101;  28 docs/s;  28098 sec\n",
            "[2021-04-30 12:43:44,318 INFO] Step 39250/50000; xent: 3.03; lr: 0.0000101;  30 docs/s;  28133 sec\n",
            "[2021-04-30 12:44:19,459 INFO] Step 39300/50000; xent: 2.97; lr: 0.0000101;  29 docs/s;  28168 sec\n",
            "[2021-04-30 12:44:54,363 INFO] Step 39350/50000; xent: 2.98; lr: 0.0000101;  30 docs/s;  28203 sec\n",
            "[2021-04-30 12:45:09,424 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.48.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:45:31,178 INFO] Step 39400/50000; xent: 2.97; lr: 0.0000101;  29 docs/s;  28240 sec\n",
            "[2021-04-30 12:46:06,224 INFO] Step 39450/50000; xent: 3.02; lr: 0.0000101;  29 docs/s;  28275 sec\n",
            "[2021-04-30 12:46:41,169 INFO] Step 39500/50000; xent: 3.03; lr: 0.0000101;  29 docs/s;  28310 sec\n",
            "[2021-04-30 12:47:16,272 INFO] Step 39550/50000; xent: 2.96; lr: 0.0000101;  29 docs/s;  28345 sec\n",
            "[2021-04-30 12:47:26,229 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.76.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:47:52,980 INFO] Step 39600/50000; xent: 2.98; lr: 0.0000101;  28 docs/s;  28382 sec\n",
            "[2021-04-30 12:48:28,014 INFO] Step 39650/50000; xent: 2.91; lr: 0.0000100;  29 docs/s;  28417 sec\n",
            "[2021-04-30 12:49:03,117 INFO] Step 39700/50000; xent: 2.99; lr: 0.0000100;  30 docs/s;  28452 sec\n",
            "[2021-04-30 12:49:37,925 INFO] Step 39750/50000; xent: 2.93; lr: 0.0000100;  30 docs/s;  28487 sec\n",
            "[2021-04-30 12:49:43,237 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.132.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:50:14,880 INFO] Step 39800/50000; xent: 2.96; lr: 0.0000100;  28 docs/s;  28524 sec\n",
            "[2021-04-30 12:50:49,721 INFO] Step 39850/50000; xent: 3.04; lr: 0.0000100;  30 docs/s;  28559 sec\n",
            "[2021-04-30 12:51:24,741 INFO] Step 39900/50000; xent: 2.91; lr: 0.0000100;  30 docs/s;  28594 sec\n",
            "[2021-04-30 12:52:00,113 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.58.bert.pt, number of examples: 2001\n",
            "[2021-04-30 12:52:01,624 INFO] Step 39950/50000; xent: 3.01; lr: 0.0000100;  28 docs/s;  28630 sec\n",
            "[2021-04-30 12:52:36,446 INFO] Step 40000/50000; xent: 2.98; lr: 0.0000100;  30 docs/s;  28665 sec\n",
            "[2021-04-30 12:52:36,462 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_40000.pt\n",
            "[2021-04-30 12:53:18,688 INFO] Step 40050/50000; xent: 2.98; lr: 0.0000100;  25 docs/s;  28708 sec\n",
            "[2021-04-30 12:53:53,851 INFO] Step 40100/50000; xent: 2.98; lr: 0.0000100;  29 docs/s;  28743 sec\n",
            "[2021-04-30 12:54:23,942 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.41.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:54:30,352 INFO] Step 40150/50000; xent: 2.97; lr: 0.0000100;  28 docs/s;  28779 sec\n",
            "[2021-04-30 12:55:05,255 INFO] Step 40200/50000; xent: 3.03; lr: 0.0000100;  29 docs/s;  28814 sec\n",
            "[2021-04-30 12:55:40,233 INFO] Step 40250/50000; xent: 2.90; lr: 0.0000100;  30 docs/s;  28849 sec\n",
            "[2021-04-30 12:56:15,242 INFO] Step 40300/50000; xent: 2.91; lr: 0.0000100;  30 docs/s;  28884 sec\n",
            "[2021-04-30 12:56:40,045 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.108.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:56:52,079 INFO] Step 40350/50000; xent: 2.93; lr: 0.0000100;  28 docs/s;  28921 sec\n",
            "[2021-04-30 12:57:27,167 INFO] Step 40400/50000; xent: 2.97; lr: 0.0000100;  29 docs/s;  28956 sec\n",
            "[2021-04-30 12:58:02,211 INFO] Step 40450/50000; xent: 2.93; lr: 0.0000099;  30 docs/s;  28991 sec\n",
            "[2021-04-30 12:58:37,228 INFO] Step 40500/50000; xent: 2.93; lr: 0.0000099;  30 docs/s;  29026 sec\n",
            "[2021-04-30 12:58:56,325 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.45.bert.pt, number of examples: 2000\n",
            "[2021-04-30 12:59:13,927 INFO] Step 40550/50000; xent: 2.93; lr: 0.0000099;  28 docs/s;  29063 sec\n",
            "[2021-04-30 12:59:48,928 INFO] Step 40600/50000; xent: 2.96; lr: 0.0000099;  30 docs/s;  29098 sec\n",
            "[2021-04-30 13:00:24,009 INFO] Step 40650/50000; xent: 2.98; lr: 0.0000099;  29 docs/s;  29133 sec\n",
            "[2021-04-30 13:00:58,873 INFO] Step 40700/50000; xent: 2.99; lr: 0.0000099;  29 docs/s;  29168 sec\n",
            "[2021-04-30 13:01:13,568 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.107.bert.pt, number of examples: 1999\n",
            "[2021-04-30 13:01:36,129 INFO] Step 40750/50000; xent: 2.99; lr: 0.0000099;  28 docs/s;  29205 sec\n",
            "[2021-04-30 13:02:11,089 INFO] Step 40800/50000; xent: 2.93; lr: 0.0000099;  30 docs/s;  29240 sec\n",
            "[2021-04-30 13:02:46,133 INFO] Step 40850/50000; xent: 2.95; lr: 0.0000099;  29 docs/s;  29275 sec\n",
            "[2021-04-30 13:03:21,193 INFO] Step 40900/50000; xent: 3.00; lr: 0.0000099;  30 docs/s;  29310 sec\n",
            "[2021-04-30 13:03:30,745 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.67.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:03:57,977 INFO] Step 40950/50000; xent: 2.91; lr: 0.0000099;  29 docs/s;  29347 sec\n",
            "[2021-04-30 13:04:33,006 INFO] Step 41000/50000; xent: 2.95; lr: 0.0000099;  30 docs/s;  29382 sec\n",
            "[2021-04-30 13:04:33,024 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_41000.pt\n",
            "[2021-04-30 13:05:14,824 INFO] Step 41050/50000; xent: 3.00; lr: 0.0000099;  24 docs/s;  29424 sec\n",
            "[2021-04-30 13:05:49,844 INFO] Step 41100/50000; xent: 2.97; lr: 0.0000099;  29 docs/s;  29459 sec\n",
            "[2021-04-30 13:05:54,475 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.138.bert.pt, number of examples: 2000\n",
            "[2021-04-30 13:06:26,793 INFO] Step 41150/50000; xent: 3.03; lr: 0.0000099;  28 docs/s;  29496 sec\n",
            "[2021-04-30 13:07:01,890 INFO] Step 41200/50000; xent: 2.99; lr: 0.0000099;  30 docs/s;  29531 sec\n",
            "[2021-04-30 13:07:36,963 INFO] Step 41250/50000; xent: 2.98; lr: 0.0000098;  29 docs/s;  29566 sec\n",
            "[2021-04-30 13:08:10,022 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.4.bert.pt, number of examples: 2000\n",
            "[2021-04-30 13:08:13,648 INFO] Step 41300/50000; xent: 2.90; lr: 0.0000098;  29 docs/s;  29603 sec\n",
            "[2021-04-30 13:08:48,711 INFO] Step 41350/50000; xent: 2.92; lr: 0.0000098;  30 docs/s;  29638 sec\n",
            "[2021-04-30 13:09:23,705 INFO] Step 41400/50000; xent: 2.95; lr: 0.0000098;  30 docs/s;  29673 sec\n",
            "[2021-04-30 13:09:58,779 INFO] Step 41450/50000; xent: 2.98; lr: 0.0000098;  29 docs/s;  29708 sec\n",
            "[2021-04-30 13:10:27,479 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.93.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:10:36,001 INFO] Step 41500/50000; xent: 3.00; lr: 0.0000098;  27 docs/s;  29745 sec\n",
            "[2021-04-30 13:11:10,964 INFO] Step 41550/50000; xent: 2.97; lr: 0.0000098;  29 docs/s;  29780 sec\n",
            "[2021-04-30 13:11:46,063 INFO] Step 41600/50000; xent: 2.94; lr: 0.0000098;  29 docs/s;  29815 sec\n",
            "[2021-04-30 13:12:21,012 INFO] Step 41650/50000; xent: 2.92; lr: 0.0000098;  31 docs/s;  29850 sec\n",
            "[2021-04-30 13:12:44,619 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.26.bert.pt, number of examples: 1998\n",
            "[2021-04-30 13:12:58,094 INFO] Step 41700/50000; xent: 2.97; lr: 0.0000098;  28 docs/s;  29887 sec\n",
            "[2021-04-30 13:13:33,073 INFO] Step 41750/50000; xent: 2.99; lr: 0.0000098;  31 docs/s;  29922 sec\n",
            "[2021-04-30 13:14:08,088 INFO] Step 41800/50000; xent: 2.99; lr: 0.0000098;  30 docs/s;  29957 sec\n",
            "[2021-04-30 13:14:43,165 INFO] Step 41850/50000; xent: 2.98; lr: 0.0000098;  29 docs/s;  29992 sec\n",
            "[2021-04-30 13:15:00,973 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.99.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:15:19,983 INFO] Step 41900/50000; xent: 2.99; lr: 0.0000098;  28 docs/s;  30029 sec\n",
            "[2021-04-30 13:15:55,018 INFO] Step 41950/50000; xent: 2.98; lr: 0.0000098;  31 docs/s;  30064 sec\n",
            "[2021-04-30 13:16:30,031 INFO] Step 42000/50000; xent: 2.93; lr: 0.0000098;  29 docs/s;  30099 sec\n",
            "[2021-04-30 13:16:30,047 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_42000.pt\n",
            "[2021-04-30 13:17:12,260 INFO] Step 42050/50000; xent: 2.98; lr: 0.0000098;  25 docs/s;  30141 sec\n",
            "[2021-04-30 13:17:24,419 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.77.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:17:49,098 INFO] Step 42100/50000; xent: 2.99; lr: 0.0000097;  29 docs/s;  30178 sec\n",
            "[2021-04-30 13:18:24,184 INFO] Step 42150/50000; xent: 2.93; lr: 0.0000097;  30 docs/s;  30213 sec\n",
            "[2021-04-30 13:18:59,214 INFO] Step 42200/50000; xent: 3.03; lr: 0.0000097;  30 docs/s;  30248 sec\n",
            "[2021-04-30 13:19:34,321 INFO] Step 42250/50000; xent: 3.03; lr: 0.0000097;  29 docs/s;  30283 sec\n",
            "[2021-04-30 13:19:40,672 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.73.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:20:11,035 INFO] Step 42300/50000; xent: 3.01; lr: 0.0000097;  28 docs/s;  30320 sec\n",
            "[2021-04-30 13:20:46,110 INFO] Step 42350/50000; xent: 3.04; lr: 0.0000097;  29 docs/s;  30355 sec\n",
            "[2021-04-30 13:21:21,034 INFO] Step 42400/50000; xent: 2.91; lr: 0.0000097;  30 docs/s;  30390 sec\n",
            "[2021-04-30 13:21:56,137 INFO] Step 42450/50000; xent: 2.93; lr: 0.0000097;  30 docs/s;  30425 sec\n",
            "[2021-04-30 13:21:57,995 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.127.bert.pt, number of examples: 2000\n",
            "[2021-04-30 13:22:33,242 INFO] Step 42500/50000; xent: 2.93; lr: 0.0000097;  29 docs/s;  30462 sec\n",
            "[2021-04-30 13:23:08,348 INFO] Step 42550/50000; xent: 2.94; lr: 0.0000097;  30 docs/s;  30497 sec\n",
            "[2021-04-30 13:23:43,202 INFO] Step 42600/50000; xent: 2.92; lr: 0.0000097;  29 docs/s;  30532 sec\n",
            "[2021-04-30 13:24:14,200 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.143.bert.pt, number of examples: 1084\n",
            "[2021-04-30 13:24:19,659 INFO] Step 42650/50000; xent: 3.00; lr: 0.0000097;  28 docs/s;  30569 sec\n",
            "[2021-04-30 13:24:54,761 INFO] Step 42700/50000; xent: 2.94; lr: 0.0000097;  30 docs/s;  30604 sec\n",
            "[2021-04-30 13:25:29,635 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.6.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:25:31,830 INFO] Step 42750/50000; xent: 2.93; lr: 0.0000097;  28 docs/s;  30641 sec\n",
            "[2021-04-30 13:26:06,753 INFO] Step 42800/50000; xent: 3.02; lr: 0.0000097;  31 docs/s;  30676 sec\n",
            "[2021-04-30 13:26:41,845 INFO] Step 42850/50000; xent: 2.97; lr: 0.0000097;  29 docs/s;  30711 sec\n",
            "[2021-04-30 13:27:16,971 INFO] Step 42900/50000; xent: 3.06; lr: 0.0000097;  29 docs/s;  30746 sec\n",
            "[2021-04-30 13:27:46,292 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.90.bert.pt, number of examples: 2000\n",
            "[2021-04-30 13:27:53,453 INFO] Step 42950/50000; xent: 3.08; lr: 0.0000097;  28 docs/s;  30782 sec\n",
            "[2021-04-30 13:28:28,578 INFO] Step 43000/50000; xent: 3.06; lr: 0.0000096;  30 docs/s;  30817 sec\n",
            "[2021-04-30 13:28:28,594 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_43000.pt\n",
            "[2021-04-30 13:29:10,262 INFO] Step 43050/50000; xent: 2.93; lr: 0.0000096;  25 docs/s;  30859 sec\n",
            "[2021-04-30 13:29:45,424 INFO] Step 43100/50000; xent: 2.93; lr: 0.0000096;  30 docs/s;  30894 sec\n",
            "[2021-04-30 13:30:10,324 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.88.bert.pt, number of examples: 2000\n",
            "[2021-04-30 13:30:22,400 INFO] Step 43150/50000; xent: 3.00; lr: 0.0000096;  28 docs/s;  30931 sec\n",
            "[2021-04-30 13:30:57,343 INFO] Step 43200/50000; xent: 2.99; lr: 0.0000096;  29 docs/s;  30966 sec\n",
            "[2021-04-30 13:31:32,342 INFO] Step 43250/50000; xent: 2.95; lr: 0.0000096;  30 docs/s;  31001 sec\n",
            "[2021-04-30 13:32:07,430 INFO] Step 43300/50000; xent: 3.00; lr: 0.0000096;  29 docs/s;  31036 sec\n",
            "[2021-04-30 13:32:27,333 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.69.bert.pt, number of examples: 2000\n",
            "[2021-04-30 13:32:44,262 INFO] Step 43350/50000; xent: 2.92; lr: 0.0000096;  28 docs/s;  31073 sec\n",
            "[2021-04-30 13:33:19,375 INFO] Step 43400/50000; xent: 2.94; lr: 0.0000096;  30 docs/s;  31108 sec\n",
            "[2021-04-30 13:33:54,174 INFO] Step 43450/50000; xent: 3.03; lr: 0.0000096;  30 docs/s;  31143 sec\n",
            "[2021-04-30 13:34:29,294 INFO] Step 43500/50000; xent: 3.02; lr: 0.0000096;  29 docs/s;  31178 sec\n",
            "[2021-04-30 13:34:43,327 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.102.bert.pt, number of examples: 2000\n",
            "[2021-04-30 13:35:05,661 INFO] Step 43550/50000; xent: 2.96; lr: 0.0000096;  29 docs/s;  31215 sec\n",
            "[2021-04-30 13:35:40,632 INFO] Step 43600/50000; xent: 2.94; lr: 0.0000096;  30 docs/s;  31249 sec\n",
            "[2021-04-30 13:36:15,718 INFO] Step 43650/50000; xent: 3.01; lr: 0.0000096;  30 docs/s;  31285 sec\n",
            "[2021-04-30 13:36:50,736 INFO] Step 43700/50000; xent: 2.92; lr: 0.0000096;  30 docs/s;  31320 sec\n",
            "[2021-04-30 13:36:59,587 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.98.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:37:27,716 INFO] Step 43750/50000; xent: 2.98; lr: 0.0000096;  28 docs/s;  31357 sec\n",
            "[2021-04-30 13:38:02,773 INFO] Step 43800/50000; xent: 3.02; lr: 0.0000096;  29 docs/s;  31392 sec\n",
            "[2021-04-30 13:38:37,692 INFO] Step 43850/50000; xent: 2.93; lr: 0.0000096;  30 docs/s;  31427 sec\n",
            "[2021-04-30 13:39:12,648 INFO] Step 43900/50000; xent: 2.99; lr: 0.0000095;  29 docs/s;  31462 sec\n",
            "[2021-04-30 13:39:15,877 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.80.bert.pt, number of examples: 2000\n",
            "[2021-04-30 13:39:49,559 INFO] Step 43950/50000; xent: 2.98; lr: 0.0000095;  29 docs/s;  31498 sec\n",
            "[2021-04-30 13:40:24,713 INFO] Step 44000/50000; xent: 3.03; lr: 0.0000095;  29 docs/s;  31534 sec\n",
            "[2021-04-30 13:40:24,730 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_44000.pt\n",
            "[2021-04-30 13:41:06,807 INFO] Step 44050/50000; xent: 2.95; lr: 0.0000095;  25 docs/s;  31576 sec\n",
            "[2021-04-30 13:41:39,969 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.122.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:41:43,585 INFO] Step 44100/50000; xent: 2.94; lr: 0.0000095;  28 docs/s;  31612 sec\n",
            "[2021-04-30 13:42:18,357 INFO] Step 44150/50000; xent: 2.93; lr: 0.0000095;  29 docs/s;  31647 sec\n",
            "[2021-04-30 13:42:53,415 INFO] Step 44200/50000; xent: 2.97; lr: 0.0000095;  30 docs/s;  31682 sec\n",
            "[2021-04-30 13:43:28,494 INFO] Step 44250/50000; xent: 2.96; lr: 0.0000095;  30 docs/s;  31717 sec\n",
            "[2021-04-30 13:43:57,018 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.18.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:44:05,578 INFO] Step 44300/50000; xent: 2.95; lr: 0.0000095;  28 docs/s;  31754 sec\n",
            "[2021-04-30 13:44:40,641 INFO] Step 44350/50000; xent: 3.01; lr: 0.0000095;  29 docs/s;  31790 sec\n",
            "[2021-04-30 13:45:15,619 INFO] Step 44400/50000; xent: 2.96; lr: 0.0000095;  30 docs/s;  31824 sec\n",
            "[2021-04-30 13:45:50,377 INFO] Step 44450/50000; xent: 2.93; lr: 0.0000095;  30 docs/s;  31859 sec\n",
            "[2021-04-30 13:46:13,393 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.36.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:46:27,512 INFO] Step 44500/50000; xent: 2.99; lr: 0.0000095;  28 docs/s;  31896 sec\n",
            "[2021-04-30 13:47:02,419 INFO] Step 44550/50000; xent: 2.91; lr: 0.0000095;  30 docs/s;  31931 sec\n",
            "[2021-04-30 13:47:37,452 INFO] Step 44600/50000; xent: 3.01; lr: 0.0000095;  30 docs/s;  31966 sec\n",
            "[2021-04-30 13:48:12,545 INFO] Step 44650/50000; xent: 2.96; lr: 0.0000095;  30 docs/s;  32001 sec\n",
            "[2021-04-30 13:48:30,036 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.8.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:48:49,038 INFO] Step 44700/50000; xent: 2.89; lr: 0.0000095;  29 docs/s;  32038 sec\n",
            "[2021-04-30 13:49:24,058 INFO] Step 44750/50000; xent: 2.94; lr: 0.0000095;  30 docs/s;  32073 sec\n",
            "[2021-04-30 13:49:59,113 INFO] Step 44800/50000; xent: 3.01; lr: 0.0000094;  29 docs/s;  32108 sec\n",
            "[2021-04-30 13:50:34,100 INFO] Step 44850/50000; xent: 2.99; lr: 0.0000094;  30 docs/s;  32143 sec\n",
            "[2021-04-30 13:50:46,844 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.38.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:51:11,480 INFO] Step 44900/50000; xent: 2.95; lr: 0.0000094;  28 docs/s;  32180 sec\n",
            "[2021-04-30 13:51:46,476 INFO] Step 44950/50000; xent: 2.91; lr: 0.0000094;  30 docs/s;  32215 sec\n",
            "[2021-04-30 13:52:21,558 INFO] Step 45000/50000; xent: 3.00; lr: 0.0000094;  30 docs/s;  32250 sec\n",
            "[2021-04-30 13:52:21,575 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_45000.pt\n",
            "[2021-04-30 13:53:03,301 INFO] Step 45050/50000; xent: 3.00; lr: 0.0000094;  25 docs/s;  32292 sec\n",
            "[2021-04-30 13:53:09,844 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.125.bert.pt, number of examples: 2000\n",
            "[2021-04-30 13:53:40,110 INFO] Step 45100/50000; xent: 2.98; lr: 0.0000094;  28 docs/s;  32329 sec\n",
            "[2021-04-30 13:54:15,201 INFO] Step 45150/50000; xent: 2.99; lr: 0.0000094;  29 docs/s;  32364 sec\n",
            "[2021-04-30 13:54:49,987 INFO] Step 45200/50000; xent: 2.99; lr: 0.0000094;  30 docs/s;  32399 sec\n",
            "[2021-04-30 13:55:25,703 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.85.bert.pt, number of examples: 1998\n",
            "[2021-04-30 13:55:26,514 INFO] Step 45250/50000; xent: 2.92; lr: 0.0000094;  29 docs/s;  32435 sec\n",
            "[2021-04-30 13:56:01,519 INFO] Step 45300/50000; xent: 2.92; lr: 0.0000094;  30 docs/s;  32470 sec\n",
            "[2021-04-30 13:56:36,565 INFO] Step 45350/50000; xent: 3.00; lr: 0.0000094;  30 docs/s;  32505 sec\n",
            "[2021-04-30 13:57:11,527 INFO] Step 45400/50000; xent: 3.00; lr: 0.0000094;  29 docs/s;  32540 sec\n",
            "[2021-04-30 13:57:41,554 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.111.bert.pt, number of examples: 2001\n",
            "[2021-04-30 13:57:47,951 INFO] Step 45450/50000; xent: 3.00; lr: 0.0000094;  29 docs/s;  32577 sec\n",
            "[2021-04-30 13:58:22,983 INFO] Step 45500/50000; xent: 2.95; lr: 0.0000094;  29 docs/s;  32612 sec\n",
            "[2021-04-30 13:58:57,928 INFO] Step 45550/50000; xent: 3.00; lr: 0.0000094;  30 docs/s;  32647 sec\n",
            "[2021-04-30 13:59:32,971 INFO] Step 45600/50000; xent: 2.96; lr: 0.0000094;  29 docs/s;  32682 sec\n",
            "[2021-04-30 13:59:57,478 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.37.bert.pt, number of examples: 2001\n",
            "[2021-04-30 14:00:09,503 INFO] Step 45650/50000; xent: 2.88; lr: 0.0000094;  29 docs/s;  32718 sec\n",
            "[2021-04-30 14:00:44,549 INFO] Step 45700/50000; xent: 2.95; lr: 0.0000094;  30 docs/s;  32753 sec\n",
            "[2021-04-30 14:01:19,657 INFO] Step 45750/50000; xent: 2.91; lr: 0.0000094;  30 docs/s;  32789 sec\n",
            "[2021-04-30 14:01:54,711 INFO] Step 45800/50000; xent: 2.97; lr: 0.0000093;  29 docs/s;  32824 sec\n",
            "[2021-04-30 14:02:13,626 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.44.bert.pt, number of examples: 2000\n",
            "[2021-04-30 14:02:31,310 INFO] Step 45850/50000; xent: 2.99; lr: 0.0000093;  29 docs/s;  32860 sec\n",
            "[2021-04-30 14:03:06,083 INFO] Step 45900/50000; xent: 2.90; lr: 0.0000093;  30 docs/s;  32895 sec\n",
            "[2021-04-30 14:03:41,121 INFO] Step 45950/50000; xent: 2.98; lr: 0.0000093;  29 docs/s;  32930 sec\n",
            "[2021-04-30 14:04:16,182 INFO] Step 46000/50000; xent: 2.93; lr: 0.0000093;  30 docs/s;  32965 sec\n",
            "[2021-04-30 14:04:16,185 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_46000.pt\n",
            "[2021-04-30 14:04:37,772 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.9.bert.pt, number of examples: 2000\n",
            "[2021-04-30 14:05:01,454 INFO] Step 46050/50000; xent: 2.89; lr: 0.0000093;  23 docs/s;  33010 sec\n",
            "[2021-04-30 14:05:36,298 INFO] Step 46100/50000; xent: 2.92; lr: 0.0000093;  29 docs/s;  33045 sec\n",
            "[2021-04-30 14:06:11,327 INFO] Step 46150/50000; xent: 2.93; lr: 0.0000093;  30 docs/s;  33080 sec\n",
            "[2021-04-30 14:06:46,331 INFO] Step 46200/50000; xent: 2.98; lr: 0.0000093;  30 docs/s;  33115 sec\n",
            "[2021-04-30 14:06:54,999 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.78.bert.pt, number of examples: 2001\n",
            "[2021-04-30 14:07:23,142 INFO] Step 46250/50000; xent: 3.05; lr: 0.0000093;  27 docs/s;  33152 sec\n",
            "[2021-04-30 14:07:58,103 INFO] Step 46300/50000; xent: 2.89; lr: 0.0000093;  30 docs/s;  33187 sec\n",
            "[2021-04-30 14:08:33,063 INFO] Step 46350/50000; xent: 2.95; lr: 0.0000093;  30 docs/s;  33222 sec\n",
            "[2021-04-30 14:09:07,993 INFO] Step 46400/50000; xent: 2.99; lr: 0.0000093;  30 docs/s;  33257 sec\n",
            "[2021-04-30 14:09:12,372 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.142.bert.pt, number of examples: 1996\n",
            "[2021-04-30 14:09:45,383 INFO] Step 46450/50000; xent: 2.98; lr: 0.0000093;  28 docs/s;  33294 sec\n",
            "[2021-04-30 14:10:20,446 INFO] Step 46500/50000; xent: 3.00; lr: 0.0000093;  30 docs/s;  33329 sec\n",
            "[2021-04-30 14:10:55,415 INFO] Step 46550/50000; xent: 2.98; lr: 0.0000093;  30 docs/s;  33364 sec\n",
            "[2021-04-30 14:11:27,593 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.134.bert.pt, number of examples: 2000\n",
            "[2021-04-30 14:11:31,892 INFO] Step 46600/50000; xent: 2.99; lr: 0.0000093;  29 docs/s;  33401 sec\n",
            "[2021-04-30 14:12:06,799 INFO] Step 46650/50000; xent: 3.03; lr: 0.0000093;  30 docs/s;  33436 sec\n",
            "[2021-04-30 14:12:41,790 INFO] Step 46700/50000; xent: 2.97; lr: 0.0000093;  30 docs/s;  33471 sec\n",
            "[2021-04-30 14:13:16,851 INFO] Step 46750/50000; xent: 3.02; lr: 0.0000092;  29 docs/s;  33506 sec\n",
            "[2021-04-30 14:13:43,663 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.13.bert.pt, number of examples: 2000\n",
            "[2021-04-30 14:13:53,583 INFO] Step 46800/50000; xent: 2.98; lr: 0.0000092;  29 docs/s;  33542 sec\n",
            "[2021-04-30 14:14:28,540 INFO] Step 46850/50000; xent: 2.92; lr: 0.0000092;  30 docs/s;  33577 sec\n",
            "[2021-04-30 14:15:03,559 INFO] Step 46900/50000; xent: 2.92; lr: 0.0000092;  30 docs/s;  33612 sec\n",
            "[2021-04-30 14:15:38,546 INFO] Step 46950/50000; xent: 3.00; lr: 0.0000092;  30 docs/s;  33647 sec\n",
            "[2021-04-30 14:15:59,014 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.72.bert.pt, number of examples: 2001\n",
            "[2021-04-30 14:16:15,201 INFO] Step 47000/50000; xent: 2.91; lr: 0.0000092;  29 docs/s;  33684 sec\n",
            "[2021-04-30 14:16:15,217 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_47000.pt\n",
            "[2021-04-30 14:16:57,069 INFO] Step 47050/50000; xent: 2.90; lr: 0.0000092;  24 docs/s;  33726 sec\n",
            "[2021-04-30 14:17:32,151 INFO] Step 47100/50000; xent: 2.96; lr: 0.0000092;  29 docs/s;  33761 sec\n",
            "[2021-04-30 14:18:07,151 INFO] Step 47150/50000; xent: 3.00; lr: 0.0000092;  30 docs/s;  33796 sec\n",
            "[2021-04-30 14:18:22,601 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.89.bert.pt, number of examples: 2001\n",
            "[2021-04-30 14:18:43,720 INFO] Step 47200/50000; xent: 3.03; lr: 0.0000092;  28 docs/s;  33833 sec\n",
            "[2021-04-30 14:19:18,701 INFO] Step 47250/50000; xent: 2.94; lr: 0.0000092;  30 docs/s;  33868 sec\n",
            "[2021-04-30 14:19:53,687 INFO] Step 47300/50000; xent: 2.96; lr: 0.0000092;  30 docs/s;  33903 sec\n",
            "[2021-04-30 14:20:28,750 INFO] Step 47350/50000; xent: 2.94; lr: 0.0000092;  30 docs/s;  33938 sec\n",
            "[2021-04-30 14:20:38,871 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.65.bert.pt, number of examples: 2000\n",
            "[2021-04-30 14:21:05,354 INFO] Step 47400/50000; xent: 2.98; lr: 0.0000092;  29 docs/s;  33974 sec\n",
            "[2021-04-30 14:21:40,403 INFO] Step 47450/50000; xent: 3.03; lr: 0.0000092;  29 docs/s;  34009 sec\n",
            "[2021-04-30 14:22:15,428 INFO] Step 47500/50000; xent: 3.00; lr: 0.0000092;  30 docs/s;  34044 sec\n",
            "[2021-04-30 14:22:50,460 INFO] Step 47550/50000; xent: 2.98; lr: 0.0000092;  30 docs/s;  34079 sec\n",
            "[2021-04-30 14:22:54,805 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.32.bert.pt, number of examples: 2001\n",
            "[2021-04-30 14:23:27,159 INFO] Step 47600/50000; xent: 2.98; lr: 0.0000092;  28 docs/s;  34116 sec\n",
            "[2021-04-30 14:24:02,144 INFO] Step 47650/50000; xent: 2.94; lr: 0.0000092;  29 docs/s;  34151 sec\n",
            "[2021-04-30 14:24:37,154 INFO] Step 47700/50000; xent: 2.88; lr: 0.0000092;  30 docs/s;  34186 sec\n",
            "[2021-04-30 14:25:10,109 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.121.bert.pt, number of examples: 1999\n",
            "[2021-04-30 14:25:13,729 INFO] Step 47750/50000; xent: 2.93; lr: 0.0000092;  29 docs/s;  34223 sec\n",
            "[2021-04-30 14:25:48,732 INFO] Step 47800/50000; xent: 2.98; lr: 0.0000091;  29 docs/s;  34258 sec\n",
            "[2021-04-30 14:26:23,710 INFO] Step 47850/50000; xent: 3.07; lr: 0.0000091;  30 docs/s;  34293 sec\n",
            "[2021-04-30 14:26:58,728 INFO] Step 47900/50000; xent: 2.97; lr: 0.0000091;  30 docs/s;  34328 sec\n",
            "[2021-04-30 14:27:26,207 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.79.bert.pt, number of examples: 2001\n",
            "[2021-04-30 14:27:35,431 INFO] Step 47950/50000; xent: 2.95; lr: 0.0000091;  28 docs/s;  34364 sec\n",
            "[2021-04-30 14:28:10,307 INFO] Step 48000/50000; xent: 2.99; lr: 0.0000091;  31 docs/s;  34399 sec\n",
            "[2021-04-30 14:28:10,323 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_48000.pt\n",
            "[2021-04-30 14:28:52,194 INFO] Step 48050/50000; xent: 3.00; lr: 0.0000091;  25 docs/s;  34441 sec\n",
            "[2021-04-30 14:29:27,347 INFO] Step 48100/50000; xent: 2.86; lr: 0.0000091;  29 docs/s;  34476 sec\n",
            "[2021-04-30 14:29:49,897 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.59.bert.pt, number of examples: 2000\n",
            "[2021-04-30 14:30:03,975 INFO] Step 48150/50000; xent: 2.97; lr: 0.0000091;  28 docs/s;  34513 sec\n",
            "[2021-04-30 14:30:38,943 INFO] Step 48200/50000; xent: 2.97; lr: 0.0000091;  30 docs/s;  34548 sec\n",
            "[2021-04-30 14:31:13,947 INFO] Step 48250/50000; xent: 3.00; lr: 0.0000091;  30 docs/s;  34583 sec\n",
            "[2021-04-30 14:31:48,987 INFO] Step 48300/50000; xent: 2.98; lr: 0.0000091;  29 docs/s;  34618 sec\n",
            "[2021-04-30 14:32:06,593 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.24.bert.pt, number of examples: 1999\n",
            "[2021-04-30 14:32:25,650 INFO] Step 48350/50000; xent: 2.95; lr: 0.0000091;  28 docs/s;  34655 sec\n",
            "[2021-04-30 14:33:00,708 INFO] Step 48400/50000; xent: 2.95; lr: 0.0000091;  29 docs/s;  34690 sec\n",
            "[2021-04-30 14:33:35,786 INFO] Step 48450/50000; xent: 2.96; lr: 0.0000091;  30 docs/s;  34725 sec\n",
            "[2021-04-30 14:34:10,882 INFO] Step 48500/50000; xent: 3.06; lr: 0.0000091;  30 docs/s;  34760 sec\n",
            "[2021-04-30 14:34:22,329 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.40.bert.pt, number of examples: 2000\n",
            "[2021-04-30 14:34:47,644 INFO] Step 48550/50000; xent: 3.02; lr: 0.0000091;  29 docs/s;  34797 sec\n",
            "[2021-04-30 14:35:22,691 INFO] Step 48600/50000; xent: 2.98; lr: 0.0000091;  29 docs/s;  34832 sec\n",
            "[2021-04-30 14:35:57,730 INFO] Step 48650/50000; xent: 2.96; lr: 0.0000091;  30 docs/s;  34867 sec\n",
            "[2021-04-30 14:36:32,604 INFO] Step 48700/50000; xent: 3.00; lr: 0.0000091;  30 docs/s;  34901 sec\n",
            "[2021-04-30 14:36:39,370 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.120.bert.pt, number of examples: 2000\n",
            "[2021-04-30 14:37:09,642 INFO] Step 48750/50000; xent: 3.02; lr: 0.0000091;  28 docs/s;  34939 sec\n",
            "[2021-04-30 14:37:44,661 INFO] Step 48800/50000; xent: 2.89; lr: 0.0000091;  29 docs/s;  34974 sec\n",
            "[2021-04-30 14:38:19,668 INFO] Step 48850/50000; xent: 2.85; lr: 0.0000090;  30 docs/s;  35009 sec\n",
            "[2021-04-30 14:38:55,994 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.14.bert.pt, number of examples: 1998\n",
            "[2021-04-30 14:38:56,801 INFO] Step 48900/50000; xent: 3.05; lr: 0.0000090;  28 docs/s;  35046 sec\n",
            "[2021-04-30 14:39:31,866 INFO] Step 48950/50000; xent: 2.94; lr: 0.0000090;  29 docs/s;  35081 sec\n",
            "[2021-04-30 14:40:06,944 INFO] Step 49000/50000; xent: 2.94; lr: 0.0000090;  30 docs/s;  35116 sec\n",
            "[2021-04-30 14:40:06,960 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_49000.pt\n",
            "[2021-04-30 14:40:48,815 INFO] Step 49050/50000; xent: 3.03; lr: 0.0000090;  25 docs/s;  35158 sec\n",
            "[2021-04-30 14:41:19,602 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.57.bert.pt, number of examples: 2000\n",
            "[2021-04-30 14:41:26,051 INFO] Step 49100/50000; xent: 2.98; lr: 0.0000090;  28 docs/s;  35195 sec\n",
            "[2021-04-30 14:42:01,039 INFO] Step 49150/50000; xent: 2.96; lr: 0.0000090;  30 docs/s;  35230 sec\n",
            "[2021-04-30 14:42:36,074 INFO] Step 49200/50000; xent: 2.95; lr: 0.0000090;  30 docs/s;  35265 sec\n",
            "[2021-04-30 14:43:11,180 INFO] Step 49250/50000; xent: 2.95; lr: 0.0000090;  30 docs/s;  35300 sec\n",
            "[2021-04-30 14:43:35,164 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.28.bert.pt, number of examples: 1999\n",
            "[2021-04-30 14:43:47,910 INFO] Step 49300/50000; xent: 2.93; lr: 0.0000090;  28 docs/s;  35337 sec\n",
            "[2021-04-30 14:44:23,018 INFO] Step 49350/50000; xent: 2.99; lr: 0.0000090;  29 docs/s;  35372 sec\n",
            "[2021-04-30 14:44:58,087 INFO] Step 49400/50000; xent: 2.99; lr: 0.0000090;  30 docs/s;  35407 sec\n",
            "[2021-04-30 14:45:33,099 INFO] Step 49450/50000; xent: 2.96; lr: 0.0000090;  30 docs/s;  35442 sec\n",
            "[2021-04-30 14:45:52,151 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.54.bert.pt, number of examples: 2001\n",
            "[2021-04-30 14:46:09,814 INFO] Step 49500/50000; xent: 2.95; lr: 0.0000090;  28 docs/s;  35479 sec\n",
            "[2021-04-30 14:46:44,888 INFO] Step 49550/50000; xent: 3.01; lr: 0.0000090;  30 docs/s;  35514 sec\n",
            "[2021-04-30 14:47:19,943 INFO] Step 49600/50000; xent: 2.98; lr: 0.0000090;  30 docs/s;  35549 sec\n",
            "[2021-04-30 14:47:54,839 INFO] Step 49650/50000; xent: 2.95; lr: 0.0000090;  29 docs/s;  35584 sec\n",
            "[2021-04-30 14:48:08,311 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.63.bert.pt, number of examples: 2001\n",
            "[2021-04-30 14:48:31,436 INFO] Step 49700/50000; xent: 2.96; lr: 0.0000090;  28 docs/s;  35620 sec\n",
            "[2021-04-30 14:49:06,487 INFO] Step 49750/50000; xent: 3.01; lr: 0.0000090;  29 docs/s;  35655 sec\n",
            "[2021-04-30 14:49:41,523 INFO] Step 49800/50000; xent: 3.01; lr: 0.0000090;  30 docs/s;  35690 sec\n",
            "[2021-04-30 14:50:16,567 INFO] Step 49850/50000; xent: 2.97; lr: 0.0000090;  30 docs/s;  35725 sec\n",
            "[2021-04-30 14:50:24,724 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.123.bert.pt, number of examples: 2000\n",
            "[2021-04-30 14:50:53,595 INFO] Step 49900/50000; xent: 3.03; lr: 0.0000090;  28 docs/s;  35762 sec\n",
            "[2021-04-30 14:51:28,530 INFO] Step 49950/50000; xent: 3.02; lr: 0.0000089;  30 docs/s;  35797 sec\n",
            "[2021-04-30 14:52:03,562 INFO] Step 50000/50000; xent: 2.97; lr: 0.0000089;  30 docs/s;  35832 sec\n",
            "[2021-04-30 14:52:03,579 INFO] Saving checkpoint ../data/trained_models/reberta_default/model_step_50000.pt\n",
            "[2021-04-30 14:52:11,758 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.42.bert.pt, number of examples: 2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AuR5koRmLLF"
      },
      "source": [
        "## lr=2e-3 layer=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjxypjXq8GrS",
        "outputId": "fca11648-e867-414f-e737-23161e33c00f"
      },
      "source": [
        "!python3 train.py -task ext -encoder roberta -mode train -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -ext_dropout 0.1 -model_path ../data/trained_models/reberta_smaller -lr 2e-3 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file ../logs/ext_roberta_cnndm -use_interval true -warmup_steps 10000 -max_pos 512 -ext_layers 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "----TRAIN EXTRACTIVE----\n",
            "[2021-04-30 18:02:49,128 INFO] Device ID 0\n",
            "[2021-04-30 18:02:49,681 INFO] Device cuda\n",
            "[2021-04-30 18:02:50,442 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-04-30 18:02:50,444 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-04-30 18:02:51,233 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-04-30 18:02:59,581 INFO] ExtSummarizer(\n",
            "  (bert): Roberta(\n",
            "    (model): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(514, 768)\n",
            "        (token_type_embeddings): Embedding(1, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ext_layer): ExtTransformerEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2021-04-30 18:02:59,669 INFO] * number of parameters: 130161921\n",
            "[2021-04-30 18:02:59,669 INFO] Start training...\n",
            "[2021-04-30 18:02:59,937 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.123.bert.pt, number of examples: 2000\n",
            "[2021-04-30 18:03:33,796 INFO] Step 50/50000; xent: 4.22; lr: 0.0000001;  30 docs/s;     34 sec\n",
            "[2021-04-30 18:04:08,004 INFO] Step 100/50000; xent: 3.63; lr: 0.0000002;  31 docs/s;     68 sec\n",
            "[2021-04-30 18:04:41,949 INFO] Step 150/50000; xent: 3.32; lr: 0.0000003;  32 docs/s;    102 sec\n",
            "[2021-04-30 18:05:11,549 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.91.bert.pt, number of examples: 1995\n",
            "[2021-04-30 18:05:17,760 INFO] Step 200/50000; xent: 3.28; lr: 0.0000004;  29 docs/s;    138 sec\n",
            "[2021-04-30 18:05:51,717 INFO] Step 250/50000; xent: 3.23; lr: 0.0000005;  30 docs/s;    172 sec\n",
            "[2021-04-30 18:06:25,581 INFO] Step 300/50000; xent: 3.17; lr: 0.0000006;  30 docs/s;    206 sec\n",
            "[2021-04-30 18:06:59,484 INFO] Step 350/50000; xent: 3.18; lr: 0.0000007;  31 docs/s;    240 sec\n",
            "[2021-04-30 18:07:24,503 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.39.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:07:35,448 INFO] Step 400/50000; xent: 3.08; lr: 0.0000008;  29 docs/s;    276 sec\n",
            "[2021-04-30 18:08:09,238 INFO] Step 450/50000; xent: 3.12; lr: 0.0000009;  30 docs/s;    309 sec\n",
            "[2021-04-30 18:08:43,270 INFO] Step 500/50000; xent: 3.02; lr: 0.0000010;  32 docs/s;    343 sec\n",
            "[2021-04-30 18:09:17,158 INFO] Step 550/50000; xent: 3.03; lr: 0.0000011;  30 docs/s;    377 sec\n",
            "[2021-04-30 18:09:35,229 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.6.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:09:51,584 INFO] Step 600/50000; xent: 3.09; lr: 0.0000012;  30 docs/s;    412 sec\n",
            "[2021-04-30 18:10:25,570 INFO] Step 650/50000; xent: 3.12; lr: 0.0000013;  30 docs/s;    446 sec\n",
            "[2021-04-30 18:10:59,495 INFO] Step 700/50000; xent: 3.09; lr: 0.0000014;  30 docs/s;    480 sec\n",
            "[2021-04-30 18:11:33,263 INFO] Step 750/50000; xent: 2.99; lr: 0.0000015;  31 docs/s;    513 sec\n",
            "[2021-04-30 18:11:48,442 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.81.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:12:09,534 INFO] Step 800/50000; xent: 2.96; lr: 0.0000016;  29 docs/s;    550 sec\n",
            "[2021-04-30 18:12:43,456 INFO] Step 850/50000; xent: 2.97; lr: 0.0000017;  31 docs/s;    584 sec\n",
            "[2021-04-30 18:13:17,311 INFO] Step 900/50000; xent: 2.99; lr: 0.0000018;  30 docs/s;    617 sec\n",
            "[2021-04-30 18:13:51,198 INFO] Step 950/50000; xent: 3.03; lr: 0.0000019;  31 docs/s;    651 sec\n",
            "[2021-04-30 18:13:59,090 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.98.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:14:25,654 INFO] Step 1000/50000; xent: 2.90; lr: 0.0000020;  30 docs/s;    686 sec\n",
            "[2021-04-30 18:14:25,670 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_1000.pt\n",
            "[2021-04-30 18:15:07,025 INFO] Step 1050/50000; xent: 2.91; lr: 0.0000021;  25 docs/s;    727 sec\n",
            "[2021-04-30 18:15:40,916 INFO] Step 1100/50000; xent: 2.96; lr: 0.0000022;  32 docs/s;    761 sec\n",
            "[2021-04-30 18:16:14,581 INFO] Step 1150/50000; xent: 2.97; lr: 0.0000023;  30 docs/s;    795 sec\n",
            "[2021-04-30 18:16:17,027 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.93.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:16:48,968 INFO] Step 1200/50000; xent: 2.84; lr: 0.0000024;  31 docs/s;    829 sec\n",
            "[2021-04-30 18:17:22,895 INFO] Step 1250/50000; xent: 2.90; lr: 0.0000025;  30 docs/s;    863 sec\n",
            "[2021-04-30 18:17:56,798 INFO] Step 1300/50000; xent: 2.89; lr: 0.0000026;  30 docs/s;    897 sec\n",
            "[2021-04-30 18:18:28,859 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.63.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:18:31,003 INFO] Step 1350/50000; xent: 2.89; lr: 0.0000027;  30 docs/s;    931 sec\n",
            "[2021-04-30 18:19:04,655 INFO] Step 1400/50000; xent: 2.84; lr: 0.0000028;  31 docs/s;    965 sec\n",
            "[2021-04-30 18:19:38,614 INFO] Step 1450/50000; xent: 2.96; lr: 0.0000029;  30 docs/s;    999 sec\n",
            "[2021-04-30 18:20:12,563 INFO] Step 1500/50000; xent: 2.88; lr: 0.0000030;  31 docs/s;   1033 sec\n",
            "[2021-04-30 18:20:40,975 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.15.bert.pt, number of examples: 2000\n",
            "[2021-04-30 18:20:48,568 INFO] Step 1550/50000; xent: 2.87; lr: 0.0000031;  29 docs/s;   1069 sec\n",
            "[2021-04-30 18:21:22,424 INFO] Step 1600/50000; xent: 2.92; lr: 0.0000032;  31 docs/s;   1102 sec\n",
            "[2021-04-30 18:21:56,308 INFO] Step 1650/50000; xent: 2.75; lr: 0.0000033;  31 docs/s;   1136 sec\n",
            "[2021-04-30 18:22:30,234 INFO] Step 1700/50000; xent: 2.82; lr: 0.0000034;  30 docs/s;   1170 sec\n",
            "[2021-04-30 18:22:53,555 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.64.bert.pt, number of examples: 1998\n",
            "[2021-04-30 18:23:05,879 INFO] Step 1750/50000; xent: 2.86; lr: 0.0000035;  29 docs/s;   1206 sec\n",
            "[2021-04-30 18:23:39,717 INFO] Step 1800/50000; xent: 2.94; lr: 0.0000036;  30 docs/s;   1240 sec\n",
            "[2021-04-30 18:24:13,602 INFO] Step 1850/50000; xent: 2.71; lr: 0.0000037;  32 docs/s;   1274 sec\n",
            "[2021-04-30 18:24:47,490 INFO] Step 1900/50000; xent: 2.90; lr: 0.0000038;  30 docs/s;   1308 sec\n",
            "[2021-04-30 18:25:04,046 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.28.bert.pt, number of examples: 1999\n",
            "[2021-04-30 18:25:21,542 INFO] Step 1950/50000; xent: 2.77; lr: 0.0000039;  30 docs/s;   1342 sec\n",
            "[2021-04-30 18:25:55,541 INFO] Step 2000/50000; xent: 2.85; lr: 0.0000040;  31 docs/s;   1376 sec\n",
            "[2021-04-30 18:25:55,556 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_2000.pt\n",
            "[2021-04-30 18:26:36,346 INFO] Step 2050/50000; xent: 2.82; lr: 0.0000041;  26 docs/s;   1416 sec\n",
            "[2021-04-30 18:27:10,216 INFO] Step 2100/50000; xent: 2.79; lr: 0.0000042;  31 docs/s;   1450 sec\n",
            "[2021-04-30 18:27:22,678 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.32.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:27:44,482 INFO] Step 2150/50000; xent: 2.74; lr: 0.0000043;  30 docs/s;   1485 sec\n",
            "[2021-04-30 18:28:18,368 INFO] Step 2200/50000; xent: 2.70; lr: 0.0000044;  31 docs/s;   1518 sec\n",
            "[2021-04-30 18:28:52,178 INFO] Step 2250/50000; xent: 2.80; lr: 0.0000045;  32 docs/s;   1552 sec\n",
            "[2021-04-30 18:29:25,871 INFO] Step 2300/50000; xent: 2.72; lr: 0.0000046;  30 docs/s;   1586 sec\n",
            "[2021-04-30 18:29:33,066 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.111.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:30:00,347 INFO] Step 2350/50000; xent: 2.76; lr: 0.0000047;  31 docs/s;   1620 sec\n",
            "[2021-04-30 18:30:34,247 INFO] Step 2400/50000; xent: 2.73; lr: 0.0000048;  31 docs/s;   1654 sec\n",
            "[2021-04-30 18:31:08,136 INFO] Step 2450/50000; xent: 2.76; lr: 0.0000049;  31 docs/s;   1688 sec\n",
            "[2021-04-30 18:31:42,119 INFO] Step 2500/50000; xent: 2.84; lr: 0.0000050;  31 docs/s;   1722 sec\n",
            "[2021-04-30 18:31:43,215 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.49.bert.pt, number of examples: 2000\n",
            "[2021-04-30 18:32:16,318 INFO] Step 2550/50000; xent: 2.70; lr: 0.0000051;  30 docs/s;   1756 sec\n",
            "[2021-04-30 18:32:50,129 INFO] Step 2600/50000; xent: 2.74; lr: 0.0000052;  31 docs/s;   1790 sec\n",
            "[2021-04-30 18:33:24,032 INFO] Step 2650/50000; xent: 2.73; lr: 0.0000053;  31 docs/s;   1824 sec\n",
            "[2021-04-30 18:33:54,089 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.59.bert.pt, number of examples: 2000\n",
            "[2021-04-30 18:33:58,281 INFO] Step 2700/50000; xent: 2.74; lr: 0.0000054;  30 docs/s;   1858 sec\n",
            "[2021-04-30 18:34:32,184 INFO] Step 2750/50000; xent: 2.74; lr: 0.0000055;  30 docs/s;   1892 sec\n",
            "[2021-04-30 18:35:06,010 INFO] Step 2800/50000; xent: 2.78; lr: 0.0000056;  31 docs/s;   1926 sec\n",
            "[2021-04-30 18:35:39,916 INFO] Step 2850/50000; xent: 2.72; lr: 0.0000057;  30 docs/s;   1960 sec\n",
            "[2021-04-30 18:36:06,107 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.84.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:36:15,697 INFO] Step 2900/50000; xent: 2.71; lr: 0.0000058;  29 docs/s;   1996 sec\n",
            "[2021-04-30 18:36:49,613 INFO] Step 2950/50000; xent: 2.75; lr: 0.0000059;  30 docs/s;   2030 sec\n",
            "[2021-04-30 18:37:23,485 INFO] Step 3000/50000; xent: 2.68; lr: 0.0000060;  32 docs/s;   2064 sec\n",
            "[2021-04-30 18:37:23,500 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_3000.pt\n",
            "[2021-04-30 18:38:04,744 INFO] Step 3050/50000; xent: 2.71; lr: 0.0000061;  25 docs/s;   2105 sec\n",
            "[2021-04-30 18:38:26,084 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.137.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:38:40,426 INFO] Step 3100/50000; xent: 2.74; lr: 0.0000062;  29 docs/s;   2140 sec\n",
            "[2021-04-30 18:39:14,376 INFO] Step 3150/50000; xent: 2.76; lr: 0.0000063;  30 docs/s;   2174 sec\n",
            "[2021-04-30 18:39:48,225 INFO] Step 3200/50000; xent: 2.79; lr: 0.0000064;  30 docs/s;   2208 sec\n",
            "[2021-04-30 18:40:22,134 INFO] Step 3250/50000; xent: 2.71; lr: 0.0000065;  31 docs/s;   2242 sec\n",
            "[2021-04-30 18:40:37,295 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.13.bert.pt, number of examples: 2000\n",
            "[2021-04-30 18:40:56,365 INFO] Step 3300/50000; xent: 2.69; lr: 0.0000066;  30 docs/s;   2276 sec\n",
            "[2021-04-30 18:41:30,028 INFO] Step 3350/50000; xent: 2.74; lr: 0.0000067;  30 docs/s;   2310 sec\n",
            "[2021-04-30 18:42:03,916 INFO] Step 3400/50000; xent: 2.69; lr: 0.0000068;  32 docs/s;   2344 sec\n",
            "[2021-04-30 18:42:37,790 INFO] Step 3450/50000; xent: 2.70; lr: 0.0000069;  31 docs/s;   2378 sec\n",
            "[2021-04-30 18:42:48,483 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.135.bert.pt, number of examples: 2000\n",
            "[2021-04-30 18:43:12,947 INFO] Step 3500/50000; xent: 2.73; lr: 0.0000070;  29 docs/s;   2413 sec\n",
            "[2021-04-30 18:43:46,800 INFO] Step 3550/50000; xent: 2.76; lr: 0.0000071;  31 docs/s;   2447 sec\n",
            "[2021-04-30 18:44:20,686 INFO] Step 3600/50000; xent: 2.69; lr: 0.0000072;  31 docs/s;   2481 sec\n",
            "[2021-04-30 18:44:54,504 INFO] Step 3650/50000; xent: 2.73; lr: 0.0000073;  31 docs/s;   2515 sec\n",
            "[2021-04-30 18:45:00,900 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.71.bert.pt, number of examples: 1999\n",
            "[2021-04-30 18:45:30,145 INFO] Step 3700/50000; xent: 2.72; lr: 0.0000074;  29 docs/s;   2550 sec\n",
            "[2021-04-30 18:46:03,979 INFO] Step 3750/50000; xent: 2.70; lr: 0.0000075;  31 docs/s;   2584 sec\n",
            "[2021-04-30 18:46:37,897 INFO] Step 3800/50000; xent: 2.82; lr: 0.0000076;  31 docs/s;   2618 sec\n",
            "[2021-04-30 18:47:11,281 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.9.bert.pt, number of examples: 2000\n",
            "[2021-04-30 18:47:12,061 INFO] Step 3850/50000; xent: 2.69; lr: 0.0000077;  30 docs/s;   2652 sec\n",
            "[2021-04-30 18:47:45,898 INFO] Step 3900/50000; xent: 2.65; lr: 0.0000078;  31 docs/s;   2686 sec\n",
            "[2021-04-30 18:48:19,579 INFO] Step 3950/50000; xent: 2.73; lr: 0.0000079;  31 docs/s;   2720 sec\n",
            "[2021-04-30 18:48:53,425 INFO] Step 4000/50000; xent: 2.63; lr: 0.0000080;  31 docs/s;   2753 sec\n",
            "[2021-04-30 18:48:53,439 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_4000.pt\n",
            "[2021-04-30 18:49:29,686 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.105.bert.pt, number of examples: 2000\n",
            "[2021-04-30 18:49:35,107 INFO] Step 4050/50000; xent: 2.66; lr: 0.0000081;  25 docs/s;   2795 sec\n",
            "[2021-04-30 18:50:09,051 INFO] Step 4100/50000; xent: 2.73; lr: 0.0000082;  31 docs/s;   2829 sec\n",
            "[2021-04-30 18:50:42,963 INFO] Step 4150/50000; xent: 2.84; lr: 0.0000083;  31 docs/s;   2863 sec\n",
            "[2021-04-30 18:51:16,785 INFO] Step 4200/50000; xent: 2.76; lr: 0.0000084;  31 docs/s;   2897 sec\n",
            "[2021-04-30 18:51:40,970 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.50.bert.pt, number of examples: 1999\n",
            "[2021-04-30 18:51:51,209 INFO] Step 4250/50000; xent: 2.69; lr: 0.0000085;  30 docs/s;   2931 sec\n",
            "[2021-04-30 18:52:25,057 INFO] Step 4300/50000; xent: 2.73; lr: 0.0000086;  31 docs/s;   2965 sec\n",
            "[2021-04-30 18:52:58,991 INFO] Step 4350/50000; xent: 2.75; lr: 0.0000087;  31 docs/s;   2999 sec\n",
            "[2021-04-30 18:53:32,899 INFO] Step 4400/50000; xent: 2.69; lr: 0.0000088;  30 docs/s;   3033 sec\n",
            "[2021-04-30 18:53:53,430 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.106.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:54:08,450 INFO] Step 4450/50000; xent: 2.66; lr: 0.0000089;  29 docs/s;   3069 sec\n",
            "[2021-04-30 18:54:42,449 INFO] Step 4500/50000; xent: 2.70; lr: 0.0000090;  32 docs/s;   3103 sec\n",
            "[2021-04-30 18:55:16,288 INFO] Step 4550/50000; xent: 2.73; lr: 0.0000091;  30 docs/s;   3136 sec\n",
            "[2021-04-30 18:55:49,899 INFO] Step 4600/50000; xent: 2.67; lr: 0.0000092;  30 docs/s;   3170 sec\n",
            "[2021-04-30 18:56:03,833 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.38.bert.pt, number of examples: 2001\n",
            "[2021-04-30 18:56:24,309 INFO] Step 4650/50000; xent: 2.62; lr: 0.0000093;  30 docs/s;   3204 sec\n",
            "[2021-04-30 18:56:58,018 INFO] Step 4700/50000; xent: 2.68; lr: 0.0000094;  30 docs/s;   3238 sec\n",
            "[2021-04-30 18:57:31,871 INFO] Step 4750/50000; xent: 2.72; lr: 0.0000095;  31 docs/s;   3272 sec\n",
            "[2021-04-30 18:58:05,671 INFO] Step 4800/50000; xent: 2.71; lr: 0.0000096;  30 docs/s;   3306 sec\n",
            "[2021-04-30 18:58:14,906 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.24.bert.pt, number of examples: 1999\n",
            "[2021-04-30 18:58:40,097 INFO] Step 4850/50000; xent: 2.65; lr: 0.0000097;  30 docs/s;   3340 sec\n",
            "[2021-04-30 18:59:13,822 INFO] Step 4900/50000; xent: 2.74; lr: 0.0000098;  31 docs/s;   3374 sec\n",
            "[2021-04-30 18:59:47,725 INFO] Step 4950/50000; xent: 2.69; lr: 0.0000099;  31 docs/s;   3408 sec\n",
            "[2021-04-30 19:00:21,486 INFO] Step 5000/50000; xent: 2.67; lr: 0.0000100;  31 docs/s;   3442 sec\n",
            "[2021-04-30 19:00:21,489 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_5000.pt\n",
            "[2021-04-30 19:00:32,564 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.143.bert.pt, number of examples: 1084\n",
            "[2021-04-30 19:01:03,149 INFO] Step 5050/50000; xent: 2.68; lr: 0.0000101;  26 docs/s;   3483 sec\n",
            "[2021-04-30 19:01:36,775 INFO] Step 5100/50000; xent: 2.70; lr: 0.0000102;  30 docs/s;   3517 sec\n",
            "[2021-04-30 19:01:44,562 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.94.bert.pt, number of examples: 2001\n",
            "[2021-04-30 19:02:12,455 INFO] Step 5150/50000; xent: 2.67; lr: 0.0000103;  29 docs/s;   3553 sec\n",
            "[2021-04-30 19:02:46,242 INFO] Step 5200/50000; xent: 2.68; lr: 0.0000104;  30 docs/s;   3586 sec\n",
            "[2021-04-30 19:03:19,895 INFO] Step 5250/50000; xent: 2.73; lr: 0.0000105;  31 docs/s;   3620 sec\n",
            "[2021-04-30 19:03:53,532 INFO] Step 5300/50000; xent: 2.57; lr: 0.0000106;  31 docs/s;   3654 sec\n",
            "[2021-04-30 19:03:56,582 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.62.bert.pt, number of examples: 2001\n",
            "[2021-04-30 19:04:29,221 INFO] Step 5350/50000; xent: 2.74; lr: 0.0000107;  29 docs/s;   3689 sec\n",
            "[2021-04-30 19:05:03,051 INFO] Step 5400/50000; xent: 2.70; lr: 0.0000108;  31 docs/s;   3723 sec\n",
            "[2021-04-30 19:05:36,904 INFO] Step 5450/50000; xent: 2.64; lr: 0.0000109;  31 docs/s;   3757 sec\n",
            "[2021-04-30 19:06:08,013 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.139.bert.pt, number of examples: 2000\n",
            "[2021-04-30 19:06:12,169 INFO] Step 5500/50000; xent: 2.68; lr: 0.0000110;  29 docs/s;   3792 sec\n",
            "[2021-04-30 19:06:46,037 INFO] Step 5550/50000; xent: 2.65; lr: 0.0000111;  30 docs/s;   3826 sec\n",
            "[2021-04-30 19:07:19,640 INFO] Step 5600/50000; xent: 2.65; lr: 0.0000112;  31 docs/s;   3860 sec\n",
            "[2021-04-30 19:07:53,561 INFO] Step 5650/50000; xent: 2.65; lr: 0.0000113;  31 docs/s;   3894 sec\n",
            "[2021-04-30 19:08:19,075 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.88.bert.pt, number of examples: 2000\n",
            "[2021-04-30 19:08:27,966 INFO] Step 5700/50000; xent: 2.69; lr: 0.0000114;  31 docs/s;   3928 sec\n",
            "[2021-04-30 19:09:01,697 INFO] Step 5750/50000; xent: 2.63; lr: 0.0000115;  30 docs/s;   3962 sec\n",
            "[2021-04-30 19:09:35,532 INFO] Step 5800/50000; xent: 2.66; lr: 0.0000116;  31 docs/s;   3996 sec\n",
            "[2021-04-30 19:10:09,435 INFO] Step 5850/50000; xent: 2.73; lr: 0.0000117;  31 docs/s;   4029 sec\n",
            "[2021-04-30 19:10:31,692 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.92.bert.pt, number of examples: 1998\n",
            "[2021-04-30 19:10:45,367 INFO] Step 5900/50000; xent: 2.76; lr: 0.0000118;  28 docs/s;   4065 sec\n",
            "[2021-04-30 19:11:19,294 INFO] Step 5950/50000; xent: 2.67; lr: 0.0000119;  31 docs/s;   4099 sec\n",
            "[2021-04-30 19:11:53,020 INFO] Step 6000/50000; xent: 2.65; lr: 0.0000120;  30 docs/s;   4133 sec\n",
            "[2021-04-30 19:11:53,035 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_6000.pt\n",
            "[2021-04-30 19:12:33,049 INFO] Step 6050/50000; xent: 2.58; lr: 0.0000121;  27 docs/s;   4173 sec\n",
            "[2021-04-30 19:12:49,554 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.68.bert.pt, number of examples: 2001\n",
            "[2021-04-30 19:13:08,585 INFO] Step 6100/50000; xent: 2.64; lr: 0.0000122;  29 docs/s;   4209 sec\n",
            "[2021-04-30 19:13:42,460 INFO] Step 6150/50000; xent: 2.62; lr: 0.0000123;  31 docs/s;   4243 sec\n",
            "[2021-04-30 19:14:16,141 INFO] Step 6200/50000; xent: 2.76; lr: 0.0000124;  31 docs/s;   4276 sec\n",
            "[2021-04-30 19:14:50,028 INFO] Step 6250/50000; xent: 2.65; lr: 0.0000125;  31 docs/s;   4310 sec\n",
            "[2021-04-30 19:15:01,758 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.0.bert.pt, number of examples: 2000\n",
            "[2021-04-30 19:15:25,593 INFO] Step 6300/50000; xent: 2.63; lr: 0.0000126;  29 docs/s;   4346 sec\n",
            "[2021-04-30 19:15:59,476 INFO] Step 6350/50000; xent: 2.66; lr: 0.0000127;  31 docs/s;   4380 sec\n",
            "[2021-04-30 19:16:33,339 INFO] Step 6400/50000; xent: 2.70; lr: 0.0000128;  30 docs/s;   4413 sec\n",
            "[2021-04-30 19:17:06,964 INFO] Step 6450/50000; xent: 2.66; lr: 0.0000129;  31 docs/s;   4447 sec\n",
            "[2021-04-30 19:17:13,595 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.83.bert.pt, number of examples: 1999\n",
            "[2021-04-30 19:17:42,170 INFO] Step 6500/50000; xent: 2.68; lr: 0.0000130;  30 docs/s;   4482 sec\n",
            "[2021-04-30 19:18:15,749 INFO] Step 6550/50000; xent: 2.64; lr: 0.0000131;  31 docs/s;   4516 sec\n",
            "[2021-04-30 19:18:49,673 INFO] Step 6600/50000; xent: 2.63; lr: 0.0000132;  31 docs/s;   4550 sec\n",
            "[2021-04-30 19:19:23,345 INFO] Step 6650/50000; xent: 2.63; lr: 0.0000133;  30 docs/s;   4583 sec\n",
            "[2021-04-30 19:19:23,765 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.138.bert.pt, number of examples: 2000\n",
            "[2021-04-30 19:19:57,804 INFO] Step 6700/50000; xent: 2.64; lr: 0.0000134;  30 docs/s;   4618 sec\n",
            "[2021-04-30 19:20:31,693 INFO] Step 6750/50000; xent: 2.69; lr: 0.0000135;  32 docs/s;   4652 sec\n",
            "[2021-04-30 19:21:05,535 INFO] Step 6800/50000; xent: 2.72; lr: 0.0000136;  30 docs/s;   4686 sec\n",
            "[2021-04-30 19:21:34,103 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.72.bert.pt, number of examples: 2001\n",
            "[2021-04-30 19:21:39,617 INFO] Step 6850/50000; xent: 2.61; lr: 0.0000137;  31 docs/s;   4720 sec\n",
            "[2021-04-30 19:22:13,353 INFO] Step 6900/50000; xent: 2.65; lr: 0.0000138;  31 docs/s;   4753 sec\n",
            "[2021-04-30 19:22:47,284 INFO] Step 6950/50000; xent: 2.72; lr: 0.0000139;  31 docs/s;   4787 sec\n",
            "[2021-04-30 19:23:21,121 INFO] Step 7000/50000; xent: 2.58; lr: 0.0000140;  31 docs/s;   4821 sec\n",
            "[2021-04-30 19:23:21,136 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_7000.pt\n",
            "[2021-04-30 19:23:51,242 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.89.bert.pt, number of examples: 2001\n",
            "[2021-04-30 19:24:01,466 INFO] Step 7050/50000; xent: 2.58; lr: 0.0000141;  25 docs/s;   4862 sec\n",
            "[2021-04-30 19:24:35,290 INFO] Step 7100/50000; xent: 2.59; lr: 0.0000142;  31 docs/s;   4895 sec\n",
            "[2021-04-30 19:25:09,002 INFO] Step 7150/50000; xent: 2.69; lr: 0.0000143;  31 docs/s;   4929 sec\n",
            "[2021-04-30 19:25:42,859 INFO] Step 7200/50000; xent: 2.67; lr: 0.0000144;  30 docs/s;   4963 sec\n",
            "[2021-04-30 19:26:03,524 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.51.bert.pt, number of examples: 1999\n",
            "[2021-04-30 19:26:18,506 INFO] Step 7250/50000; xent: 2.63; lr: 0.0000145;  29 docs/s;   4999 sec\n",
            "[2021-04-30 19:26:52,418 INFO] Step 7300/50000; xent: 2.69; lr: 0.0000146;  31 docs/s;   5032 sec\n",
            "[2021-04-30 19:27:26,034 INFO] Step 7350/50000; xent: 2.64; lr: 0.0000147;  30 docs/s;   5066 sec\n",
            "[2021-04-30 19:27:59,924 INFO] Step 7400/50000; xent: 2.57; lr: 0.0000148;  31 docs/s;   5100 sec\n",
            "[2021-04-30 19:28:16,338 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.35.bert.pt, number of examples: 2001\n",
            "[2021-04-30 19:28:35,382 INFO] Step 7450/50000; xent: 2.60; lr: 0.0000149;  29 docs/s;   5135 sec\n",
            "[2021-04-30 19:29:09,267 INFO] Step 7500/50000; xent: 2.72; lr: 0.0000150;  31 docs/s;   5169 sec\n",
            "[2021-04-30 19:29:43,117 INFO] Step 7550/50000; xent: 2.67; lr: 0.0000151;  31 docs/s;   5203 sec\n",
            "[2021-04-30 19:30:17,139 INFO] Step 7600/50000; xent: 2.68; lr: 0.0000152;  31 docs/s;   5237 sec\n",
            "[2021-04-30 19:30:27,040 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.37.bert.pt, number of examples: 2001\n",
            "[2021-04-30 19:30:51,422 INFO] Step 7650/50000; xent: 2.67; lr: 0.0000153;  30 docs/s;   5271 sec\n",
            "[2021-04-30 19:31:25,297 INFO] Step 7700/50000; xent: 2.60; lr: 0.0000154;  31 docs/s;   5305 sec\n",
            "[2021-04-30 19:31:59,305 INFO] Step 7750/50000; xent: 2.65; lr: 0.0000155;  31 docs/s;   5339 sec\n",
            "[2021-04-30 19:32:35,113 INFO] Step 7800/50000; xent: 2.63; lr: 0.0000156;  31 docs/s;   5375 sec\n",
            "[2021-04-30 19:32:49,288 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.80.bert.pt, number of examples: 2000\n",
            "[2021-04-30 19:33:19,294 INFO] Step 7850/50000; xent: 2.65; lr: 0.0000157;  24 docs/s;   5419 sec\n",
            "[2021-04-30 19:33:53,241 INFO] Step 7900/50000; xent: 2.66; lr: 0.0000158;  30 docs/s;   5453 sec\n",
            "[2021-04-30 19:34:27,193 INFO] Step 7950/50000; xent: 2.72; lr: 0.0000159;  31 docs/s;   5487 sec\n",
            "[2021-04-30 19:35:01,771 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.52.bert.pt, number of examples: 1999\n",
            "[2021-04-30 19:35:02,553 INFO] Step 8000/50000; xent: 2.63; lr: 0.0000160;  30 docs/s;   5523 sec\n",
            "[2021-04-30 19:35:02,573 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_8000.pt\n",
            "[2021-04-30 19:35:43,031 INFO] Step 8050/50000; xent: 2.57; lr: 0.0000161;  26 docs/s;   5563 sec\n",
            "[2021-04-30 19:36:16,845 INFO] Step 8100/50000; xent: 2.60; lr: 0.0000162;  31 docs/s;   5597 sec\n",
            "[2021-04-30 19:36:50,882 INFO] Step 8150/50000; xent: 2.63; lr: 0.0000163;  30 docs/s;   5631 sec\n",
            "[2021-04-30 19:37:20,402 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.12.bert.pt, number of examples: 1998\n",
            "[2021-04-30 19:37:26,621 INFO] Step 8200/50000; xent: 2.73; lr: 0.0000164;  29 docs/s;   5667 sec\n",
            "[2021-04-30 19:38:00,458 INFO] Step 8250/50000; xent: 2.64; lr: 0.0000165;  31 docs/s;   5701 sec\n",
            "[2021-04-30 19:38:34,366 INFO] Step 8300/50000; xent: 2.67; lr: 0.0000166;  31 docs/s;   5734 sec\n",
            "[2021-04-30 19:39:08,295 INFO] Step 8350/50000; xent: 2.66; lr: 0.0000167;  30 docs/s;   5768 sec\n",
            "[2021-04-30 19:39:30,940 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.114.bert.pt, number of examples: 2001\n",
            "[2021-04-30 19:39:42,572 INFO] Step 8400/50000; xent: 2.60; lr: 0.0000168;  30 docs/s;   5803 sec\n",
            "[2021-04-30 19:40:16,456 INFO] Step 8450/50000; xent: 2.64; lr: 0.0000169;  31 docs/s;   5837 sec\n",
            "[2021-04-30 19:40:50,090 INFO] Step 8500/50000; xent: 2.66; lr: 0.0000170;  31 docs/s;   5870 sec\n",
            "[2021-04-30 19:41:24,046 INFO] Step 8550/50000; xent: 2.73; lr: 0.0000171;  30 docs/s;   5904 sec\n",
            "[2021-04-30 19:41:42,916 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.86.bert.pt, number of examples: 1999\n",
            "[2021-04-30 19:41:59,278 INFO] Step 8600/50000; xent: 2.69; lr: 0.0000172;  29 docs/s;   5939 sec\n",
            "[2021-04-30 19:42:33,141 INFO] Step 8650/50000; xent: 2.69; lr: 0.0000173;  30 docs/s;   5973 sec\n",
            "[2021-04-30 19:43:06,778 INFO] Step 8700/50000; xent: 2.68; lr: 0.0000174;  32 docs/s;   6007 sec\n",
            "[2021-04-30 19:43:40,683 INFO] Step 8750/50000; xent: 2.55; lr: 0.0000175;  31 docs/s;   6041 sec\n",
            "[2021-04-30 19:43:54,505 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.113.bert.pt, number of examples: 2000\n",
            "[2021-04-30 19:44:16,085 INFO] Step 8800/50000; xent: 2.69; lr: 0.0000176;  29 docs/s;   6076 sec\n",
            "[2021-04-30 19:44:49,976 INFO] Step 8850/50000; xent: 2.63; lr: 0.0000177;  31 docs/s;   6110 sec\n",
            "[2021-04-30 19:45:23,914 INFO] Step 8900/50000; xent: 2.74; lr: 0.0000178;  30 docs/s;   6144 sec\n",
            "[2021-04-30 19:45:57,700 INFO] Step 8950/50000; xent: 2.66; lr: 0.0000179;  31 docs/s;   6178 sec\n",
            "[2021-04-30 19:46:06,646 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.96.bert.pt, number of examples: 1999\n",
            "[2021-04-30 19:46:33,220 INFO] Step 9000/50000; xent: 2.67; lr: 0.0000180;  30 docs/s;   6213 sec\n",
            "[2021-04-30 19:46:33,234 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_9000.pt\n",
            "[2021-04-30 19:47:14,010 INFO] Step 9050/50000; xent: 2.67; lr: 0.0000181;  26 docs/s;   6254 sec\n",
            "[2021-04-30 19:47:47,904 INFO] Step 9100/50000; xent: 2.64; lr: 0.0000182;  30 docs/s;   6288 sec\n",
            "[2021-04-30 19:48:21,697 INFO] Step 9150/50000; xent: 2.65; lr: 0.0000183;  31 docs/s;   6322 sec\n",
            "[2021-04-30 19:48:25,487 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.131.bert.pt, number of examples: 2001\n",
            "[2021-04-30 19:48:57,297 INFO] Step 9200/50000; xent: 2.65; lr: 0.0000184;  29 docs/s;   6357 sec\n",
            "[2021-04-30 19:49:31,156 INFO] Step 9250/50000; xent: 2.73; lr: 0.0000185;  31 docs/s;   6391 sec\n",
            "[2021-04-30 19:50:04,988 INFO] Step 9300/50000; xent: 2.66; lr: 0.0000186;  31 docs/s;   6425 sec\n",
            "[2021-04-30 19:50:37,648 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.97.bert.pt, number of examples: 2000\n",
            "[2021-04-30 19:50:41,128 INFO] Step 9350/50000; xent: 2.72; lr: 0.0000187;  29 docs/s;   6461 sec\n",
            "[2021-04-30 19:51:14,933 INFO] Step 9400/50000; xent: 2.64; lr: 0.0000188;  31 docs/s;   6495 sec\n",
            "[2021-04-30 19:51:48,804 INFO] Step 9450/50000; xent: 2.62; lr: 0.0000189;  31 docs/s;   6529 sec\n",
            "[2021-04-30 19:52:22,530 INFO] Step 9500/50000; xent: 2.71; lr: 0.0000190;  30 docs/s;   6563 sec\n",
            "[2021-04-30 19:52:50,444 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.55.bert.pt, number of examples: 1999\n",
            "[2021-04-30 19:52:57,983 INFO] Step 9550/50000; xent: 2.70; lr: 0.0000191;  29 docs/s;   6598 sec\n",
            "[2021-04-30 19:53:31,881 INFO] Step 9600/50000; xent: 2.63; lr: 0.0000192;  31 docs/s;   6632 sec\n",
            "[2021-04-30 19:54:05,722 INFO] Step 9650/50000; xent: 2.67; lr: 0.0000193;  31 docs/s;   6666 sec\n",
            "[2021-04-30 19:54:39,535 INFO] Step 9700/50000; xent: 2.62; lr: 0.0000194;  31 docs/s;   6700 sec\n",
            "[2021-04-30 19:55:01,557 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.128.bert.pt, number of examples: 2000\n",
            "[2021-04-30 19:55:15,204 INFO] Step 9750/50000; xent: 2.64; lr: 0.0000195;  29 docs/s;   6735 sec\n",
            "[2021-04-30 19:55:49,063 INFO] Step 9800/50000; xent: 2.64; lr: 0.0000196;  31 docs/s;   6769 sec\n",
            "[2021-04-30 19:56:22,722 INFO] Step 9850/50000; xent: 2.69; lr: 0.0000197;  31 docs/s;   6803 sec\n",
            "[2021-04-30 19:56:56,552 INFO] Step 9900/50000; xent: 2.58; lr: 0.0000198;  31 docs/s;   6837 sec\n",
            "[2021-04-30 19:57:12,945 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.104.bert.pt, number of examples: 2000\n",
            "[2021-04-30 19:57:31,813 INFO] Step 9950/50000; xent: 2.57; lr: 0.0000199;  29 docs/s;   6872 sec\n",
            "[2021-04-30 19:58:05,665 INFO] Step 10000/50000; xent: 2.66; lr: 0.0000200;  30 docs/s;   6906 sec\n",
            "[2021-04-30 19:58:05,680 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_10000.pt\n",
            "[2021-04-30 19:58:45,930 INFO] Step 10050/50000; xent: 2.62; lr: 0.0000200;  27 docs/s;   6946 sec\n",
            "[2021-04-30 19:59:19,744 INFO] Step 10100/50000; xent: 2.62; lr: 0.0000199;  30 docs/s;   6980 sec\n",
            "[2021-04-30 19:59:30,888 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.118.bert.pt, number of examples: 2001\n",
            "[2021-04-30 19:59:55,461 INFO] Step 10150/50000; xent: 2.66; lr: 0.0000199;  29 docs/s;   7016 sec\n",
            "[2021-04-30 20:00:29,268 INFO] Step 10200/50000; xent: 2.57; lr: 0.0000198;  31 docs/s;   7049 sec\n",
            "[2021-04-30 20:01:03,022 INFO] Step 10250/50000; xent: 2.70; lr: 0.0000198;  31 docs/s;   7083 sec\n",
            "[2021-04-30 20:01:36,981 INFO] Step 10300/50000; xent: 2.49; lr: 0.0000197;  31 docs/s;   7117 sec\n",
            "[2021-04-30 20:01:42,977 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.47.bert.pt, number of examples: 2000\n",
            "[2021-04-30 20:02:12,867 INFO] Step 10350/50000; xent: 2.66; lr: 0.0000197;  29 docs/s;   7153 sec\n",
            "[2021-04-30 20:02:46,665 INFO] Step 10400/50000; xent: 2.65; lr: 0.0000196;  30 docs/s;   7187 sec\n",
            "[2021-04-30 20:03:20,477 INFO] Step 10450/50000; xent: 2.67; lr: 0.0000196;  31 docs/s;   7221 sec\n",
            "[2021-04-30 20:03:53,440 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.8.bert.pt, number of examples: 2001\n",
            "[2021-04-30 20:03:54,890 INFO] Step 10500/50000; xent: 2.70; lr: 0.0000195;  30 docs/s;   7255 sec\n",
            "[2021-04-30 20:04:28,824 INFO] Step 10550/50000; xent: 2.66; lr: 0.0000195;  31 docs/s;   7289 sec\n",
            "[2021-04-30 20:05:02,511 INFO] Step 10600/50000; xent: 2.65; lr: 0.0000194;  31 docs/s;   7323 sec\n",
            "[2021-04-30 20:05:36,460 INFO] Step 10650/50000; xent: 2.61; lr: 0.0000194;  31 docs/s;   7357 sec\n",
            "[2021-04-30 20:06:05,283 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.11.bert.pt, number of examples: 2001\n",
            "[2021-04-30 20:06:12,196 INFO] Step 10700/50000; xent: 2.61; lr: 0.0000193;  29 docs/s;   7392 sec\n",
            "[2021-04-30 20:06:46,068 INFO] Step 10750/50000; xent: 2.65; lr: 0.0000193;  31 docs/s;   7426 sec\n",
            "[2021-04-30 20:07:19,982 INFO] Step 10800/50000; xent: 2.57; lr: 0.0000192;  31 docs/s;   7460 sec\n",
            "[2021-04-30 20:07:53,812 INFO] Step 10850/50000; xent: 2.54; lr: 0.0000192;  31 docs/s;   7494 sec\n",
            "[2021-04-30 20:08:17,718 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.66.bert.pt, number of examples: 2001\n",
            "[2021-04-30 20:08:29,339 INFO] Step 10900/50000; xent: 2.67; lr: 0.0000192;  29 docs/s;   7529 sec\n",
            "[2021-04-30 20:09:03,250 INFO] Step 10950/50000; xent: 2.65; lr: 0.0000191;  31 docs/s;   7563 sec\n",
            "[2021-04-30 20:09:37,116 INFO] Step 11000/50000; xent: 2.63; lr: 0.0000191;  31 docs/s;   7597 sec\n",
            "[2021-04-30 20:09:37,131 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_11000.pt\n",
            "[2021-04-30 20:10:17,324 INFO] Step 11050/50000; xent: 2.75; lr: 0.0000190;  26 docs/s;   7637 sec\n",
            "[2021-04-30 20:10:34,449 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.36.bert.pt, number of examples: 2001\n",
            "[2021-04-30 20:10:51,437 INFO] Step 11100/50000; xent: 2.53; lr: 0.0000190;  30 docs/s;   7671 sec\n",
            "[2021-04-30 20:11:25,289 INFO] Step 11150/50000; xent: 2.57; lr: 0.0000189;  31 docs/s;   7705 sec\n",
            "[2021-04-30 20:11:59,209 INFO] Step 11200/50000; xent: 2.60; lr: 0.0000189;  31 docs/s;   7739 sec\n",
            "[2021-04-30 20:12:32,957 INFO] Step 11250/50000; xent: 2.65; lr: 0.0000189;  30 docs/s;   7773 sec\n",
            "[2021-04-30 20:12:45,564 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.73.bert.pt, number of examples: 2001\n",
            "[2021-04-30 20:13:07,400 INFO] Step 11300/50000; xent: 2.69; lr: 0.0000188;  30 docs/s;   7807 sec\n",
            "[2021-04-30 20:13:41,280 INFO] Step 11350/50000; xent: 2.57; lr: 0.0000188;  31 docs/s;   7841 sec\n",
            "[2021-04-30 20:14:15,004 INFO] Step 11400/50000; xent: 2.66; lr: 0.0000187;  31 docs/s;   7875 sec\n",
            "[2021-04-30 20:14:48,904 INFO] Step 11450/50000; xent: 2.64; lr: 0.0000187;  30 docs/s;   7909 sec\n",
            "[2021-04-30 20:14:57,934 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.33.bert.pt, number of examples: 1997\n",
            "[2021-04-30 20:15:24,375 INFO] Step 11500/50000; xent: 2.62; lr: 0.0000187;  29 docs/s;   7944 sec\n",
            "[2021-04-30 20:15:58,226 INFO] Step 11550/50000; xent: 2.73; lr: 0.0000186;  30 docs/s;   7978 sec\n",
            "[2021-04-30 20:16:32,153 INFO] Step 11600/50000; xent: 2.62; lr: 0.0000186;  31 docs/s;   8012 sec\n",
            "[2021-04-30 20:17:05,930 INFO] Step 11650/50000; xent: 2.60; lr: 0.0000185;  31 docs/s;   8046 sec\n",
            "[2021-04-30 20:17:08,392 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.121.bert.pt, number of examples: 1999\n",
            "[2021-04-30 20:17:40,387 INFO] Step 11700/50000; xent: 2.69; lr: 0.0000185;  31 docs/s;   8080 sec\n",
            "[2021-04-30 20:18:14,255 INFO] Step 11750/50000; xent: 2.59; lr: 0.0000185;  30 docs/s;   8114 sec\n",
            "[2021-04-30 20:18:48,006 INFO] Step 11800/50000; xent: 2.63; lr: 0.0000184;  31 docs/s;   8148 sec\n",
            "[2021-04-30 20:19:20,477 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.136.bert.pt, number of examples: 1998\n",
            "[2021-04-30 20:19:23,968 INFO] Step 11850/50000; xent: 2.61; lr: 0.0000184;  29 docs/s;   8184 sec\n",
            "[2021-04-30 20:19:57,879 INFO] Step 11900/50000; xent: 2.64; lr: 0.0000183;  31 docs/s;   8218 sec\n",
            "[2021-04-30 20:20:31,718 INFO] Step 11950/50000; xent: 2.63; lr: 0.0000183;  31 docs/s;   8252 sec\n",
            "[2021-04-30 20:21:05,535 INFO] Step 12000/50000; xent: 2.64; lr: 0.0000183;  31 docs/s;   8286 sec\n",
            "[2021-04-30 20:21:05,550 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_12000.pt\n",
            "[2021-04-30 20:21:38,508 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.20.bert.pt, number of examples: 2000\n",
            "[2021-04-30 20:21:47,402 INFO] Step 12050/50000; xent: 2.59; lr: 0.0000182;  24 docs/s;   8327 sec\n",
            "[2021-04-30 20:22:21,342 INFO] Step 12100/50000; xent: 2.77; lr: 0.0000182;  31 docs/s;   8361 sec\n",
            "[2021-04-30 20:22:55,134 INFO] Step 12150/50000; xent: 2.57; lr: 0.0000181;  31 docs/s;   8395 sec\n",
            "[2021-04-30 20:23:28,761 INFO] Step 12200/50000; xent: 2.62; lr: 0.0000181;  31 docs/s;   8429 sec\n",
            "[2021-04-30 20:23:50,148 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.61.bert.pt, number of examples: 1999\n",
            "[2021-04-30 20:24:04,452 INFO] Step 12250/50000; xent: 2.65; lr: 0.0000181;  29 docs/s;   8465 sec\n",
            "[2021-04-30 20:24:38,277 INFO] Step 12300/50000; xent: 2.66; lr: 0.0000180;  31 docs/s;   8498 sec\n",
            "[2021-04-30 20:25:11,908 INFO] Step 12350/50000; xent: 2.68; lr: 0.0000180;  31 docs/s;   8532 sec\n",
            "[2021-04-30 20:25:45,765 INFO] Step 12400/50000; xent: 2.61; lr: 0.0000180;  31 docs/s;   8566 sec\n",
            "[2021-04-30 20:26:00,943 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.45.bert.pt, number of examples: 2000\n",
            "[2021-04-30 20:26:19,990 INFO] Step 12450/50000; xent: 2.57; lr: 0.0000179;  30 docs/s;   8600 sec\n",
            "[2021-04-30 20:26:53,817 INFO] Step 12500/50000; xent: 2.55; lr: 0.0000179;  31 docs/s;   8634 sec\n",
            "[2021-04-30 20:27:27,642 INFO] Step 12550/50000; xent: 2.58; lr: 0.0000179;  30 docs/s;   8668 sec\n",
            "[2021-04-30 20:28:01,465 INFO] Step 12600/50000; xent: 2.63; lr: 0.0000178;  30 docs/s;   8702 sec\n",
            "[2021-04-30 20:28:11,968 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.134.bert.pt, number of examples: 2000\n",
            "[2021-04-30 20:28:35,719 INFO] Step 12650/50000; xent: 2.60; lr: 0.0000178;  30 docs/s;   8736 sec\n",
            "[2021-04-30 20:29:09,540 INFO] Step 12700/50000; xent: 2.66; lr: 0.0000177;  30 docs/s;   8770 sec\n",
            "[2021-04-30 20:29:43,406 INFO] Step 12750/50000; xent: 2.60; lr: 0.0000177;  31 docs/s;   8803 sec\n",
            "[2021-04-30 20:30:17,304 INFO] Step 12800/50000; xent: 2.65; lr: 0.0000177;  31 docs/s;   8837 sec\n",
            "[2021-04-30 20:30:23,711 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.21.bert.pt, number of examples: 2001\n",
            "[2021-04-30 20:30:52,893 INFO] Step 12850/50000; xent: 2.74; lr: 0.0000176;  29 docs/s;   8873 sec\n",
            "[2021-04-30 20:31:26,490 INFO] Step 12900/50000; xent: 2.64; lr: 0.0000176;  31 docs/s;   8907 sec\n",
            "[2021-04-30 20:32:00,339 INFO] Step 12950/50000; xent: 2.62; lr: 0.0000176;  31 docs/s;   8940 sec\n",
            "[2021-04-30 20:32:33,990 INFO] Step 13000/50000; xent: 2.59; lr: 0.0000175;  30 docs/s;   8974 sec\n",
            "[2021-04-30 20:32:33,993 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_13000.pt\n",
            "[2021-04-30 20:32:41,686 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.43.bert.pt, number of examples: 2001\n",
            "[2021-04-30 20:33:15,804 INFO] Step 13050/50000; xent: 2.71; lr: 0.0000175;  26 docs/s;   9016 sec\n",
            "[2021-04-30 20:33:49,511 INFO] Step 13100/50000; xent: 2.66; lr: 0.0000175;  31 docs/s;   9050 sec\n",
            "[2021-04-30 20:34:23,350 INFO] Step 13150/50000; xent: 2.65; lr: 0.0000174;  31 docs/s;   9083 sec\n",
            "[2021-04-30 20:34:52,215 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.141.bert.pt, number of examples: 1998\n",
            "[2021-04-30 20:34:57,725 INFO] Step 13200/50000; xent: 2.58; lr: 0.0000174;  30 docs/s;   9118 sec\n",
            "[2021-04-30 20:35:31,585 INFO] Step 13250/50000; xent: 2.65; lr: 0.0000174;  30 docs/s;   9152 sec\n",
            "[2021-04-30 20:36:05,256 INFO] Step 13300/50000; xent: 2.65; lr: 0.0000173;  31 docs/s;   9185 sec\n",
            "[2021-04-30 20:36:39,194 INFO] Step 13350/50000; xent: 2.61; lr: 0.0000173;  31 docs/s;   9219 sec\n",
            "[2021-04-30 20:37:03,646 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.16.bert.pt, number of examples: 2001\n",
            "[2021-04-30 20:37:14,567 INFO] Step 13400/50000; xent: 2.60; lr: 0.0000173;  29 docs/s;   9255 sec\n",
            "[2021-04-30 20:37:48,398 INFO] Step 13450/50000; xent: 2.58; lr: 0.0000172;  31 docs/s;   9288 sec\n",
            "[2021-04-30 20:38:22,048 INFO] Step 13500/50000; xent: 2.64; lr: 0.0000172;  31 docs/s;   9322 sec\n",
            "[2021-04-30 20:38:55,927 INFO] Step 13550/50000; xent: 2.68; lr: 0.0000172;  31 docs/s;   9356 sec\n",
            "[2021-04-30 20:39:15,564 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.116.bert.pt, number of examples: 1997\n",
            "[2021-04-30 20:39:31,213 INFO] Step 13600/50000; xent: 2.75; lr: 0.0000171;  29 docs/s;   9391 sec\n",
            "[2021-04-30 20:40:05,047 INFO] Step 13650/50000; xent: 2.57; lr: 0.0000171;  31 docs/s;   9425 sec\n",
            "[2021-04-30 20:40:38,833 INFO] Step 13700/50000; xent: 2.64; lr: 0.0000171;  31 docs/s;   9459 sec\n",
            "[2021-04-30 20:41:12,670 INFO] Step 13750/50000; xent: 2.66; lr: 0.0000171;  30 docs/s;   9493 sec\n",
            "[2021-04-30 20:41:25,992 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.76.bert.pt, number of examples: 2001\n",
            "[2021-04-30 20:41:47,038 INFO] Step 13800/50000; xent: 2.63; lr: 0.0000170;  30 docs/s;   9527 sec\n",
            "[2021-04-30 20:42:20,983 INFO] Step 13850/50000; xent: 2.59; lr: 0.0000170;  30 docs/s;   9561 sec\n",
            "[2021-04-30 20:42:54,624 INFO] Step 13900/50000; xent: 2.57; lr: 0.0000170;  32 docs/s;   9595 sec\n",
            "[2021-04-30 20:43:28,454 INFO] Step 13950/50000; xent: 2.59; lr: 0.0000169;  30 docs/s;   9629 sec\n",
            "[2021-04-30 20:43:38,944 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.19.bert.pt, number of examples: 1999\n",
            "[2021-04-30 20:44:03,961 INFO] Step 14000/50000; xent: 2.63; lr: 0.0000169;  30 docs/s;   9664 sec\n",
            "[2021-04-30 20:44:03,976 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_14000.pt\n",
            "[2021-04-30 20:44:45,939 INFO] Step 14050/50000; xent: 2.97; lr: 0.0000169;  25 docs/s;   9706 sec\n",
            "[2021-04-30 20:45:19,823 INFO] Step 14100/50000; xent: 3.05; lr: 0.0000168;  31 docs/s;   9740 sec\n",
            "[2021-04-30 20:45:53,515 INFO] Step 14150/50000; xent: 3.04; lr: 0.0000168;  30 docs/s;   9774 sec\n",
            "[2021-04-30 20:45:57,307 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.107.bert.pt, number of examples: 1999\n",
            "[2021-04-30 20:46:27,882 INFO] Step 14200/50000; xent: 2.93; lr: 0.0000168;  30 docs/s;   9808 sec\n",
            "[2021-04-30 20:47:01,795 INFO] Step 14250/50000; xent: 3.01; lr: 0.0000168;  31 docs/s;   9842 sec\n",
            "[2021-04-30 20:47:35,355 INFO] Step 14300/50000; xent: 3.03; lr: 0.0000167;  31 docs/s;   9875 sec\n",
            "[2021-04-30 20:48:08,129 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.125.bert.pt, number of examples: 2000\n",
            "[2021-04-30 20:48:09,587 INFO] Step 14350/50000; xent: 3.01; lr: 0.0000167;  30 docs/s;   9910 sec\n",
            "[2021-04-30 20:48:43,328 INFO] Step 14400/50000; xent: 2.95; lr: 0.0000167;  31 docs/s;   9943 sec\n",
            "[2021-04-30 20:49:17,175 INFO] Step 14450/50000; xent: 2.92; lr: 0.0000166;  32 docs/s;   9977 sec\n",
            "[2021-04-30 20:49:51,010 INFO] Step 14500/50000; xent: 3.05; lr: 0.0000166;  30 docs/s;  10011 sec\n",
            "[2021-04-30 20:50:18,349 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.142.bert.pt, number of examples: 1996\n",
            "[2021-04-30 20:50:25,028 INFO] Step 14550/50000; xent: 2.97; lr: 0.0000166;  30 docs/s;  10045 sec\n",
            "[2021-04-30 20:50:58,969 INFO] Step 14600/50000; xent: 3.02; lr: 0.0000166;  31 docs/s;  10079 sec\n",
            "[2021-04-30 20:51:32,856 INFO] Step 14650/50000; xent: 3.07; lr: 0.0000165;  31 docs/s;  10113 sec\n",
            "[2021-04-30 20:52:06,675 INFO] Step 14700/50000; xent: 3.00; lr: 0.0000165;  30 docs/s;  10147 sec\n",
            "[2021-04-30 20:52:28,118 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.41.bert.pt, number of examples: 2000\n",
            "[2021-04-30 20:52:41,068 INFO] Step 14750/50000; xent: 2.94; lr: 0.0000165;  30 docs/s;  10181 sec\n",
            "[2021-04-30 20:53:14,774 INFO] Step 14800/50000; xent: 2.93; lr: 0.0000164;  31 docs/s;  10215 sec\n",
            "[2021-04-30 20:53:48,607 INFO] Step 14850/50000; xent: 3.01; lr: 0.0000164;  31 docs/s;  10249 sec\n",
            "[2021-04-30 20:54:22,466 INFO] Step 14900/50000; xent: 2.97; lr: 0.0000164;  31 docs/s;  10283 sec\n",
            "[2021-04-30 20:54:38,374 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.44.bert.pt, number of examples: 2000\n",
            "[2021-04-30 20:54:56,787 INFO] Step 14950/50000; xent: 2.94; lr: 0.0000164;  31 docs/s;  10317 sec\n",
            "[2021-04-30 20:55:30,577 INFO] Step 15000/50000; xent: 2.91; lr: 0.0000163;  30 docs/s;  10351 sec\n",
            "[2021-04-30 20:55:30,593 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_15000.pt\n",
            "[2021-04-30 20:56:11,372 INFO] Step 15050/50000; xent: 3.02; lr: 0.0000163;  25 docs/s;  10391 sec\n",
            "[2021-04-30 20:56:45,230 INFO] Step 15100/50000; xent: 2.96; lr: 0.0000163;  31 docs/s;  10425 sec\n",
            "[2021-04-30 20:56:57,452 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.95.bert.pt, number of examples: 2000\n",
            "[2021-04-30 20:57:21,279 INFO] Step 15150/50000; xent: 2.99; lr: 0.0000162;  29 docs/s;  10461 sec\n",
            "[2021-04-30 20:57:55,094 INFO] Step 15200/50000; xent: 2.94; lr: 0.0000162;  31 docs/s;  10495 sec\n",
            "[2021-04-30 20:58:28,914 INFO] Step 15250/50000; xent: 2.94; lr: 0.0000162;  32 docs/s;  10529 sec\n",
            "[2021-04-30 20:59:02,587 INFO] Step 15300/50000; xent: 3.03; lr: 0.0000162;  30 docs/s;  10563 sec\n",
            "[2021-04-30 20:59:08,264 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.79.bert.pt, number of examples: 2001\n",
            "[2021-04-30 20:59:36,788 INFO] Step 15350/50000; xent: 2.96; lr: 0.0000161;  30 docs/s;  10597 sec\n",
            "[2021-04-30 21:00:10,570 INFO] Step 15400/50000; xent: 2.93; lr: 0.0000161;  31 docs/s;  10631 sec\n",
            "[2021-04-30 21:00:44,503 INFO] Step 15450/50000; xent: 3.01; lr: 0.0000161;  31 docs/s;  10665 sec\n",
            "[2021-04-30 21:01:18,286 INFO] Step 15500/50000; xent: 3.03; lr: 0.0000161;  31 docs/s;  10698 sec\n",
            "[2021-04-30 21:01:19,748 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.110.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:01:53,716 INFO] Step 15550/50000; xent: 2.94; lr: 0.0000160;  30 docs/s;  10734 sec\n",
            "[2021-04-30 21:02:27,394 INFO] Step 15600/50000; xent: 2.97; lr: 0.0000160;  30 docs/s;  10767 sec\n",
            "[2021-04-30 21:03:01,259 INFO] Step 15650/50000; xent: 2.97; lr: 0.0000160;  31 docs/s;  10801 sec\n",
            "[2021-04-30 21:03:31,550 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.23.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:03:37,065 INFO] Step 15700/50000; xent: 2.98; lr: 0.0000160;  29 docs/s;  10837 sec\n",
            "[2021-04-30 21:04:10,611 INFO] Step 15750/50000; xent: 2.99; lr: 0.0000159;  32 docs/s;  10871 sec\n",
            "[2021-04-30 21:04:44,485 INFO] Step 15800/50000; xent: 2.98; lr: 0.0000159;  31 docs/s;  10905 sec\n",
            "[2021-04-30 21:05:18,301 INFO] Step 15850/50000; xent: 3.01; lr: 0.0000159;  31 docs/s;  10938 sec\n",
            "[2021-04-30 21:05:43,477 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.53.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:05:53,510 INFO] Step 15900/50000; xent: 3.00; lr: 0.0000159;  29 docs/s;  10974 sec\n",
            "[2021-04-30 21:06:27,385 INFO] Step 15950/50000; xent: 2.99; lr: 0.0000158;  31 docs/s;  11007 sec\n",
            "[2021-04-30 21:07:01,282 INFO] Step 16000/50000; xent: 2.95; lr: 0.0000158;  30 docs/s;  11041 sec\n",
            "[2021-04-30 21:07:01,297 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_16000.pt\n",
            "[2021-04-30 21:07:42,016 INFO] Step 16050/50000; xent: 2.96; lr: 0.0000158;  26 docs/s;  11082 sec\n",
            "[2021-04-30 21:08:01,699 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.27.bert.pt, number of examples: 1999\n",
            "[2021-04-30 21:08:17,394 INFO] Step 16100/50000; xent: 3.04; lr: 0.0000158;  29 docs/s;  11117 sec\n",
            "[2021-04-30 21:08:51,239 INFO] Step 16150/50000; xent: 3.02; lr: 0.0000157;  30 docs/s;  11151 sec\n",
            "[2021-04-30 21:09:25,091 INFO] Step 16200/50000; xent: 2.95; lr: 0.0000157;  31 docs/s;  11185 sec\n",
            "[2021-04-30 21:09:58,908 INFO] Step 16250/50000; xent: 3.00; lr: 0.0000157;  31 docs/s;  11219 sec\n",
            "[2021-04-30 21:10:12,014 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.14.bert.pt, number of examples: 1998\n",
            "[2021-04-30 21:10:33,142 INFO] Step 16300/50000; xent: 2.98; lr: 0.0000157;  30 docs/s;  11253 sec\n",
            "[2021-04-30 21:11:06,979 INFO] Step 16350/50000; xent: 3.00; lr: 0.0000156;  31 docs/s;  11287 sec\n",
            "[2021-04-30 21:11:40,750 INFO] Step 16400/50000; xent: 2.99; lr: 0.0000156;  31 docs/s;  11321 sec\n",
            "[2021-04-30 21:12:14,374 INFO] Step 16450/50000; xent: 2.91; lr: 0.0000156;  31 docs/s;  11354 sec\n",
            "[2021-04-30 21:12:24,125 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.82.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:12:49,956 INFO] Step 16500/50000; xent: 2.99; lr: 0.0000156;  29 docs/s;  11390 sec\n",
            "[2021-04-30 21:13:23,800 INFO] Step 16550/50000; xent: 2.97; lr: 0.0000155;  31 docs/s;  11424 sec\n",
            "[2021-04-30 21:13:57,575 INFO] Step 16600/50000; xent: 2.95; lr: 0.0000155;  30 docs/s;  11458 sec\n",
            "[2021-04-30 21:14:31,294 INFO] Step 16650/50000; xent: 3.04; lr: 0.0000155;  31 docs/s;  11491 sec\n",
            "[2021-04-30 21:14:35,093 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.18.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:15:05,433 INFO] Step 16700/50000; xent: 2.96; lr: 0.0000155;  31 docs/s;  11525 sec\n",
            "[2021-04-30 21:15:39,304 INFO] Step 16750/50000; xent: 3.02; lr: 0.0000155;  31 docs/s;  11559 sec\n",
            "[2021-04-30 21:16:13,139 INFO] Step 16800/50000; xent: 2.94; lr: 0.0000154;  31 docs/s;  11593 sec\n",
            "[2021-04-30 21:16:45,300 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.87.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:16:47,431 INFO] Step 16850/50000; xent: 2.94; lr: 0.0000154;  30 docs/s;  11627 sec\n",
            "[2021-04-30 21:17:21,360 INFO] Step 16900/50000; xent: 2.94; lr: 0.0000154;  30 docs/s;  11661 sec\n",
            "[2021-04-30 21:17:55,156 INFO] Step 16950/50000; xent: 2.93; lr: 0.0000154;  32 docs/s;  11695 sec\n",
            "[2021-04-30 21:18:28,905 INFO] Step 17000/50000; xent: 2.99; lr: 0.0000153;  31 docs/s;  11729 sec\n",
            "[2021-04-30 21:18:28,919 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_17000.pt\n",
            "[2021-04-30 21:19:03,393 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.2.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:19:10,928 INFO] Step 17050/50000; xent: 2.99; lr: 0.0000153;  24 docs/s;  11771 sec\n",
            "[2021-04-30 21:19:44,715 INFO] Step 17100/50000; xent: 2.96; lr: 0.0000153;  31 docs/s;  11805 sec\n",
            "[2021-04-30 21:20:18,521 INFO] Step 17150/50000; xent: 3.00; lr: 0.0000153;  30 docs/s;  11839 sec\n",
            "[2021-04-30 21:20:52,473 INFO] Step 17200/50000; xent: 3.02; lr: 0.0000152;  31 docs/s;  11873 sec\n",
            "[2021-04-30 21:21:14,592 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.69.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:21:26,848 INFO] Step 17250/50000; xent: 2.94; lr: 0.0000152;  30 docs/s;  11907 sec\n",
            "[2021-04-30 21:22:00,669 INFO] Step 17300/50000; xent: 3.00; lr: 0.0000152;  31 docs/s;  11941 sec\n",
            "[2021-04-30 21:22:34,411 INFO] Step 17350/50000; xent: 3.00; lr: 0.0000152;  31 docs/s;  11974 sec\n",
            "[2021-04-30 21:23:08,265 INFO] Step 17400/50000; xent: 3.04; lr: 0.0000152;  31 docs/s;  12008 sec\n",
            "[2021-04-30 21:23:26,077 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.25.bert.pt, number of examples: 1999\n",
            "[2021-04-30 21:23:43,723 INFO] Step 17450/50000; xent: 2.90; lr: 0.0000151;  30 docs/s;  12044 sec\n",
            "[2021-04-30 21:24:17,420 INFO] Step 17500/50000; xent: 3.02; lr: 0.0000151;  31 docs/s;  12077 sec\n",
            "[2021-04-30 21:24:51,252 INFO] Step 17550/50000; xent: 2.94; lr: 0.0000151;  30 docs/s;  12111 sec\n",
            "[2021-04-30 21:25:25,179 INFO] Step 17600/50000; xent: 3.00; lr: 0.0000151;  30 docs/s;  12145 sec\n",
            "[2021-04-30 21:25:37,117 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.22.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:26:00,267 INFO] Step 17650/50000; xent: 3.01; lr: 0.0000151;  29 docs/s;  12180 sec\n",
            "[2021-04-30 21:26:34,196 INFO] Step 17700/50000; xent: 3.10; lr: 0.0000150;  30 docs/s;  12214 sec\n",
            "[2021-04-30 21:27:08,002 INFO] Step 17750/50000; xent: 2.96; lr: 0.0000150;  31 docs/s;  12248 sec\n",
            "[2021-04-30 21:27:41,797 INFO] Step 17800/50000; xent: 2.92; lr: 0.0000150;  31 docs/s;  12282 sec\n",
            "[2021-04-30 21:27:48,048 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.127.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:28:15,943 INFO] Step 17850/50000; xent: 2.95; lr: 0.0000150;  30 docs/s;  12316 sec\n",
            "[2021-04-30 21:28:49,798 INFO] Step 17900/50000; xent: 2.93; lr: 0.0000149;  31 docs/s;  12350 sec\n",
            "[2021-04-30 21:29:23,353 INFO] Step 17950/50000; xent: 2.95; lr: 0.0000149;  30 docs/s;  12383 sec\n",
            "[2021-04-30 21:29:57,311 INFO] Step 18000/50000; xent: 2.95; lr: 0.0000149;  32 docs/s;  12417 sec\n",
            "[2021-04-30 21:29:57,314 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_18000.pt\n",
            "[2021-04-30 21:30:04,378 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.57.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:30:38,378 INFO] Step 18050/50000; xent: 2.90; lr: 0.0000149;  26 docs/s;  12458 sec\n",
            "[2021-04-30 21:31:12,839 INFO] Step 18100/50000; xent: 3.01; lr: 0.0000149;  31 docs/s;  12493 sec\n",
            "[2021-04-30 21:31:46,713 INFO] Step 18150/50000; xent: 2.96; lr: 0.0000148;  31 docs/s;  12527 sec\n",
            "[2021-04-30 21:32:15,392 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.99.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:32:20,932 INFO] Step 18200/50000; xent: 2.95; lr: 0.0000148;  31 docs/s;  12561 sec\n",
            "[2021-04-30 21:32:55,184 INFO] Step 18250/50000; xent: 2.91; lr: 0.0000148;  31 docs/s;  12595 sec\n",
            "[2021-04-30 21:33:29,860 INFO] Step 18300/50000; xent: 2.94; lr: 0.0000148;  30 docs/s;  12630 sec\n",
            "[2021-04-30 21:34:04,761 INFO] Step 18350/50000; xent: 3.05; lr: 0.0000148;  30 docs/s;  12665 sec\n",
            "[2021-04-30 21:34:30,826 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.65.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:34:42,163 INFO] Step 18400/50000; xent: 2.99; lr: 0.0000147;  28 docs/s;  12702 sec\n",
            "[2021-04-30 21:35:17,039 INFO] Step 18450/50000; xent: 3.01; lr: 0.0000147;  30 docs/s;  12737 sec\n",
            "[2021-04-30 21:35:51,974 INFO] Step 18500/50000; xent: 2.98; lr: 0.0000147;  31 docs/s;  12772 sec\n",
            "[2021-04-30 21:36:26,857 INFO] Step 18550/50000; xent: 2.97; lr: 0.0000147;  30 docs/s;  12807 sec\n",
            "[2021-04-30 21:36:46,621 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.119.bert.pt, number of examples: 1998\n",
            "[2021-04-30 21:37:04,240 INFO] Step 18600/50000; xent: 3.07; lr: 0.0000147;  28 docs/s;  12844 sec\n",
            "[2021-04-30 21:37:38,856 INFO] Step 18650/50000; xent: 3.02; lr: 0.0000146;  30 docs/s;  12879 sec\n",
            "[2021-04-30 21:38:13,744 INFO] Step 18700/50000; xent: 2.97; lr: 0.0000146;  30 docs/s;  12914 sec\n",
            "[2021-04-30 21:38:48,663 INFO] Step 18750/50000; xent: 3.02; lr: 0.0000146;  29 docs/s;  12949 sec\n",
            "[2021-04-30 21:39:03,022 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.70.bert.pt, number of examples: 1999\n",
            "[2021-04-30 21:39:25,979 INFO] Step 18800/50000; xent: 3.04; lr: 0.0000146;  28 docs/s;  12986 sec\n",
            "[2021-04-30 21:39:59,808 INFO] Step 18850/50000; xent: 2.94; lr: 0.0000146;  31 docs/s;  13020 sec\n",
            "[2021-04-30 21:40:33,737 INFO] Step 18900/50000; xent: 2.91; lr: 0.0000145;  31 docs/s;  13054 sec\n",
            "[2021-04-30 21:41:07,410 INFO] Step 18950/50000; xent: 2.93; lr: 0.0000145;  31 docs/s;  13087 sec\n",
            "[2021-04-30 21:41:15,497 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.54.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:41:43,418 INFO] Step 19000/50000; xent: 2.94; lr: 0.0000145;  29 docs/s;  13123 sec\n",
            "[2021-04-30 21:41:43,434 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_19000.pt\n",
            "[2021-04-30 21:42:24,771 INFO] Step 19050/50000; xent: 3.01; lr: 0.0000145;  25 docs/s;  13165 sec\n",
            "[2021-04-30 21:42:58,743 INFO] Step 19100/50000; xent: 2.93; lr: 0.0000145;  31 docs/s;  13199 sec\n",
            "[2021-04-30 21:43:32,358 INFO] Step 19150/50000; xent: 3.00; lr: 0.0000145;  30 docs/s;  13232 sec\n",
            "[2021-04-30 21:43:34,729 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.103.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:44:08,011 INFO] Step 19200/50000; xent: 2.92; lr: 0.0000144;  29 docs/s;  13268 sec\n",
            "[2021-04-30 21:44:41,884 INFO] Step 19250/50000; xent: 2.94; lr: 0.0000144;  31 docs/s;  13302 sec\n",
            "[2021-04-30 21:45:15,527 INFO] Step 19300/50000; xent: 3.00; lr: 0.0000144;  30 docs/s;  13336 sec\n",
            "[2021-04-30 21:45:46,755 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.1.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:45:50,918 INFO] Step 19350/50000; xent: 3.03; lr: 0.0000144;  30 docs/s;  13371 sec\n",
            "[2021-04-30 21:46:24,714 INFO] Step 19400/50000; xent: 3.01; lr: 0.0000144;  31 docs/s;  13405 sec\n",
            "[2021-04-30 21:46:58,649 INFO] Step 19450/50000; xent: 2.99; lr: 0.0000143;  31 docs/s;  13439 sec\n",
            "[2021-04-30 21:47:32,499 INFO] Step 19500/50000; xent: 2.98; lr: 0.0000143;  30 docs/s;  13473 sec\n",
            "[2021-04-30 21:47:59,093 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.3.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:48:08,711 INFO] Step 19550/50000; xent: 3.01; lr: 0.0000143;  29 docs/s;  13509 sec\n",
            "[2021-04-30 21:48:42,323 INFO] Step 19600/50000; xent: 2.97; lr: 0.0000143;  31 docs/s;  13542 sec\n",
            "[2021-04-30 21:49:16,228 INFO] Step 19650/50000; xent: 2.96; lr: 0.0000143;  31 docs/s;  13576 sec\n",
            "[2021-04-30 21:49:50,082 INFO] Step 19700/50000; xent: 2.98; lr: 0.0000142;  30 docs/s;  13610 sec\n",
            "[2021-04-30 21:50:10,935 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.10.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:50:25,256 INFO] Step 19750/50000; xent: 3.03; lr: 0.0000142;  29 docs/s;  13645 sec\n",
            "[2021-04-30 21:50:59,108 INFO] Step 19800/50000; xent: 2.96; lr: 0.0000142;  31 docs/s;  13679 sec\n",
            "[2021-04-30 21:51:32,936 INFO] Step 19850/50000; xent: 2.99; lr: 0.0000142;  31 docs/s;  13713 sec\n",
            "[2021-04-30 21:52:06,608 INFO] Step 19900/50000; xent: 3.04; lr: 0.0000142;  31 docs/s;  13747 sec\n",
            "[2021-04-30 21:52:22,933 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.78.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:52:42,021 INFO] Step 19950/50000; xent: 3.04; lr: 0.0000142;  29 docs/s;  13782 sec\n",
            "[2021-04-30 21:53:15,851 INFO] Step 20000/50000; xent: 2.96; lr: 0.0000141;  31 docs/s;  13816 sec\n",
            "[2021-04-30 21:53:15,866 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_20000.pt\n",
            "[2021-04-30 21:53:55,902 INFO] Step 20050/50000; xent: 2.96; lr: 0.0000141;  25 docs/s;  13856 sec\n",
            "[2021-04-30 21:54:29,911 INFO] Step 20100/50000; xent: 2.95; lr: 0.0000141;  31 docs/s;  13890 sec\n",
            "[2021-04-30 21:54:42,059 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.112.bert.pt, number of examples: 2001\n",
            "[2021-04-30 21:55:05,851 INFO] Step 20150/50000; xent: 2.95; lr: 0.0000141;  29 docs/s;  13926 sec\n",
            "[2021-04-30 21:55:39,666 INFO] Step 20200/50000; xent: 2.93; lr: 0.0000141;  31 docs/s;  13960 sec\n",
            "[2021-04-30 21:56:13,490 INFO] Step 20250/50000; xent: 3.03; lr: 0.0000141;  30 docs/s;  13994 sec\n",
            "[2021-04-30 21:56:47,869 INFO] Step 20300/50000; xent: 2.93; lr: 0.0000140;  30 docs/s;  14028 sec\n",
            "[2021-04-30 21:56:55,149 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.102.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:57:24,442 INFO] Step 20350/50000; xent: 2.99; lr: 0.0000140;  29 docs/s;  14065 sec\n",
            "[2021-04-30 21:57:58,331 INFO] Step 20400/50000; xent: 2.95; lr: 0.0000140;  31 docs/s;  14098 sec\n",
            "[2021-04-30 21:58:32,156 INFO] Step 20450/50000; xent: 2.97; lr: 0.0000140;  30 docs/s;  14132 sec\n",
            "[2021-04-30 21:59:06,986 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.40.bert.pt, number of examples: 2000\n",
            "[2021-04-30 21:59:07,794 INFO] Step 20500/50000; xent: 2.94; lr: 0.0000140;  29 docs/s;  14168 sec\n",
            "[2021-04-30 21:59:41,658 INFO] Step 20550/50000; xent: 2.96; lr: 0.0000140;  31 docs/s;  14202 sec\n",
            "[2021-04-30 22:00:15,321 INFO] Step 20600/50000; xent: 3.05; lr: 0.0000139;  30 docs/s;  14235 sec\n",
            "[2021-04-30 22:00:49,171 INFO] Step 20650/50000; xent: 3.02; lr: 0.0000139;  31 docs/s;  14269 sec\n",
            "[2021-04-30 22:01:18,667 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.122.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:01:24,757 INFO] Step 20700/50000; xent: 2.93; lr: 0.0000139;  29 docs/s;  14305 sec\n",
            "[2021-04-30 22:01:58,879 INFO] Step 20750/50000; xent: 2.93; lr: 0.0000139;  30 docs/s;  14339 sec\n",
            "[2021-04-30 22:02:32,780 INFO] Step 20800/50000; xent: 2.96; lr: 0.0000139;  31 docs/s;  14373 sec\n",
            "[2021-04-30 22:03:06,722 INFO] Step 20850/50000; xent: 2.97; lr: 0.0000139;  31 docs/s;  14407 sec\n",
            "[2021-04-30 22:03:34,132 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.133.bert.pt, number of examples: 1999\n",
            "[2021-04-30 22:03:45,090 INFO] Step 20900/50000; xent: 2.95; lr: 0.0000138;  29 docs/s;  14445 sec\n",
            "[2021-04-30 22:04:19,334 INFO] Step 20950/50000; xent: 2.91; lr: 0.0000138;  30 docs/s;  14479 sec\n",
            "[2021-04-30 22:04:53,202 INFO] Step 21000/50000; xent: 3.02; lr: 0.0000138;  30 docs/s;  14513 sec\n",
            "[2021-04-30 22:04:53,218 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_21000.pt\n",
            "[2021-04-30 22:05:33,145 INFO] Step 21050/50000; xent: 2.97; lr: 0.0000138;  26 docs/s;  14553 sec\n",
            "[2021-04-30 22:05:53,283 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.67.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:06:08,368 INFO] Step 21100/50000; xent: 2.91; lr: 0.0000138;  29 docs/s;  14588 sec\n",
            "[2021-04-30 22:06:42,723 INFO] Step 21150/50000; xent: 2.98; lr: 0.0000138;  31 docs/s;  14623 sec\n",
            "[2021-04-30 22:07:17,036 INFO] Step 21200/50000; xent: 2.94; lr: 0.0000137;  30 docs/s;  14657 sec\n",
            "[2021-04-30 22:07:50,646 INFO] Step 21250/50000; xent: 3.00; lr: 0.0000137;  30 docs/s;  14691 sec\n",
            "[2021-04-30 22:08:06,463 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.108.bert.pt, number of examples: 2000\n",
            "[2021-04-30 22:08:26,177 INFO] Step 21300/50000; xent: 2.96; lr: 0.0000137;  29 docs/s;  14726 sec\n",
            "[2021-04-30 22:09:00,076 INFO] Step 21350/50000; xent: 2.87; lr: 0.0000137;  31 docs/s;  14760 sec\n",
            "[2021-04-30 22:09:34,160 INFO] Step 21400/50000; xent: 3.02; lr: 0.0000137;  30 docs/s;  14794 sec\n",
            "[2021-04-30 22:10:07,942 INFO] Step 21450/50000; xent: 2.97; lr: 0.0000137;  31 docs/s;  14828 sec\n",
            "[2021-04-30 22:10:18,256 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.60.bert.pt, number of examples: 2000\n",
            "[2021-04-30 22:10:43,416 INFO] Step 21500/50000; xent: 2.91; lr: 0.0000136;  29 docs/s;  14863 sec\n",
            "[2021-04-30 22:11:17,223 INFO] Step 21550/50000; xent: 2.90; lr: 0.0000136;  31 docs/s;  14897 sec\n",
            "[2021-04-30 22:11:51,397 INFO] Step 21600/50000; xent: 2.97; lr: 0.0000136;  30 docs/s;  14931 sec\n",
            "[2021-04-30 22:12:25,253 INFO] Step 21650/50000; xent: 2.96; lr: 0.0000136;  31 docs/s;  14965 sec\n",
            "[2021-04-30 22:12:30,751 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.29.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:13:00,491 INFO] Step 21700/50000; xent: 2.94; lr: 0.0000136;  29 docs/s;  15001 sec\n",
            "[2021-04-30 22:13:34,338 INFO] Step 21750/50000; xent: 2.95; lr: 0.0000136;  31 docs/s;  15034 sec\n",
            "[2021-04-30 22:14:08,202 INFO] Step 21800/50000; xent: 3.00; lr: 0.0000135;  31 docs/s;  15068 sec\n",
            "[2021-04-30 22:14:42,616 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.90.bert.pt, number of examples: 2000\n",
            "[2021-04-30 22:14:44,113 INFO] Step 21850/50000; xent: 3.01; lr: 0.0000135;  28 docs/s;  15104 sec\n",
            "[2021-04-30 22:15:17,993 INFO] Step 21900/50000; xent: 2.98; lr: 0.0000135;  30 docs/s;  15138 sec\n",
            "[2021-04-30 22:15:51,813 INFO] Step 21950/50000; xent: 2.96; lr: 0.0000135;  30 docs/s;  15172 sec\n",
            "[2021-04-30 22:16:25,513 INFO] Step 22000/50000; xent: 3.00; lr: 0.0000135;  32 docs/s;  15206 sec\n",
            "[2021-04-30 22:16:25,528 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_22000.pt\n",
            "[2021-04-30 22:17:01,536 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.5.bert.pt, number of examples: 2000\n",
            "[2021-04-30 22:17:07,903 INFO] Step 22050/50000; xent: 2.98; lr: 0.0000135;  24 docs/s;  15248 sec\n",
            "[2021-04-30 22:17:41,808 INFO] Step 22100/50000; xent: 2.97; lr: 0.0000135;  31 docs/s;  15282 sec\n",
            "[2021-04-30 22:18:15,666 INFO] Step 22150/50000; xent: 2.96; lr: 0.0000134;  31 docs/s;  15316 sec\n",
            "[2021-04-30 22:18:49,496 INFO] Step 22200/50000; xent: 2.99; lr: 0.0000134;  30 docs/s;  15350 sec\n",
            "[2021-04-30 22:19:13,810 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.140.bert.pt, number of examples: 1999\n",
            "[2021-04-30 22:19:24,810 INFO] Step 22250/50000; xent: 2.88; lr: 0.0000134;  29 docs/s;  15385 sec\n",
            "[2021-04-30 22:19:58,715 INFO] Step 22300/50000; xent: 3.02; lr: 0.0000134;  30 docs/s;  15419 sec\n",
            "[2021-04-30 22:20:32,666 INFO] Step 22350/50000; xent: 2.99; lr: 0.0000134;  31 docs/s;  15453 sec\n",
            "[2021-04-30 22:21:06,430 INFO] Step 22400/50000; xent: 3.03; lr: 0.0000134;  31 docs/s;  15486 sec\n",
            "[2021-04-30 22:21:25,750 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.17.bert.pt, number of examples: 1999\n",
            "[2021-04-30 22:21:41,959 INFO] Step 22450/50000; xent: 2.94; lr: 0.0000133;  29 docs/s;  15522 sec\n",
            "[2021-04-30 22:22:16,068 INFO] Step 22500/50000; xent: 2.99; lr: 0.0000133;  32 docs/s;  15556 sec\n",
            "[2021-04-30 22:22:49,851 INFO] Step 22550/50000; xent: 3.02; lr: 0.0000133;  31 docs/s;  15590 sec\n",
            "[2021-04-30 22:23:23,490 INFO] Step 22600/50000; xent: 3.08; lr: 0.0000133;  30 docs/s;  15624 sec\n",
            "[2021-04-30 22:23:37,862 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.31.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:23:58,899 INFO] Step 22650/50000; xent: 3.00; lr: 0.0000133;  29 docs/s;  15659 sec\n",
            "[2021-04-30 22:24:32,929 INFO] Step 22700/50000; xent: 2.92; lr: 0.0000133;  32 docs/s;  15693 sec\n",
            "[2021-04-30 22:25:06,865 INFO] Step 22750/50000; xent: 2.97; lr: 0.0000133;  31 docs/s;  15727 sec\n",
            "[2021-04-30 22:25:40,438 INFO] Step 22800/50000; xent: 2.99; lr: 0.0000132;  30 docs/s;  15761 sec\n",
            "[2021-04-30 22:25:50,323 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.4.bert.pt, number of examples: 2000\n",
            "[2021-04-30 22:26:16,673 INFO] Step 22850/50000; xent: 3.00; lr: 0.0000132;  29 docs/s;  15797 sec\n",
            "[2021-04-30 22:26:50,430 INFO] Step 22900/50000; xent: 2.94; lr: 0.0000132;  31 docs/s;  15830 sec\n",
            "[2021-04-30 22:27:24,582 INFO] Step 22950/50000; xent: 2.98; lr: 0.0000132;  30 docs/s;  15865 sec\n",
            "[2021-04-30 22:27:58,275 INFO] Step 23000/50000; xent: 2.94; lr: 0.0000132;  30 docs/s;  15898 sec\n",
            "[2021-04-30 22:27:58,278 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_23000.pt\n",
            "[2021-04-30 22:28:09,029 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.42.bert.pt, number of examples: 2000\n",
            "[2021-04-30 22:28:40,274 INFO] Step 23050/50000; xent: 2.98; lr: 0.0000132;  25 docs/s;  15940 sec\n",
            "[2021-04-30 22:29:13,951 INFO] Step 23100/50000; xent: 2.88; lr: 0.0000132;  31 docs/s;  15974 sec\n",
            "[2021-04-30 22:29:48,628 INFO] Step 23150/50000; xent: 2.91; lr: 0.0000131;  30 docs/s;  16009 sec\n",
            "[2021-04-30 22:30:22,230 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.75.bert.pt, number of examples: 1999\n",
            "[2021-04-30 22:30:24,367 INFO] Step 23200/50000; xent: 3.03; lr: 0.0000131;  29 docs/s;  16044 sec\n",
            "[2021-04-30 22:30:58,188 INFO] Step 23250/50000; xent: 2.93; lr: 0.0000131;  31 docs/s;  16078 sec\n",
            "[2021-04-30 22:31:32,007 INFO] Step 23300/50000; xent: 2.99; lr: 0.0000131;  30 docs/s;  16112 sec\n",
            "[2021-04-30 22:32:05,777 INFO] Step 23350/50000; xent: 2.94; lr: 0.0000131;  30 docs/s;  16146 sec\n",
            "[2021-04-30 22:32:35,490 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.129.bert.pt, number of examples: 1999\n",
            "[2021-04-30 22:32:41,685 INFO] Step 23400/50000; xent: 2.97; lr: 0.0000131;  29 docs/s;  16182 sec\n",
            "[2021-04-30 22:33:15,559 INFO] Step 23450/50000; xent: 3.01; lr: 0.0000131;  31 docs/s;  16216 sec\n",
            "[2021-04-30 22:33:49,372 INFO] Step 23500/50000; xent: 2.99; lr: 0.0000130;  31 docs/s;  16249 sec\n",
            "[2021-04-30 22:34:23,071 INFO] Step 23550/50000; xent: 3.03; lr: 0.0000130;  30 docs/s;  16283 sec\n",
            "[2021-04-30 22:34:46,834 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.117.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:34:58,509 INFO] Step 23600/50000; xent: 2.86; lr: 0.0000130;  29 docs/s;  16319 sec\n",
            "[2021-04-30 22:35:32,387 INFO] Step 23650/50000; xent: 2.92; lr: 0.0000130;  31 docs/s;  16352 sec\n",
            "[2021-04-30 22:36:05,979 INFO] Step 23700/50000; xent: 2.99; lr: 0.0000130;  31 docs/s;  16386 sec\n",
            "[2021-04-30 22:36:39,726 INFO] Step 23750/50000; xent: 3.01; lr: 0.0000130;  31 docs/s;  16420 sec\n",
            "[2021-04-30 22:36:58,573 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.115.bert.pt, number of examples: 2000\n",
            "[2021-04-30 22:37:15,048 INFO] Step 23800/50000; xent: 2.97; lr: 0.0000130;  29 docs/s;  16455 sec\n",
            "[2021-04-30 22:37:48,988 INFO] Step 23850/50000; xent: 2.94; lr: 0.0000130;  31 docs/s;  16489 sec\n",
            "[2021-04-30 22:38:22,843 INFO] Step 23900/50000; xent: 3.03; lr: 0.0000129;  31 docs/s;  16523 sec\n",
            "[2021-04-30 22:38:56,525 INFO] Step 23950/50000; xent: 2.98; lr: 0.0000129;  31 docs/s;  16557 sec\n",
            "[2021-04-30 22:39:11,391 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.48.bert.pt, number of examples: 2000\n",
            "[2021-04-30 22:39:32,508 INFO] Step 24000/50000; xent: 3.02; lr: 0.0000129;  29 docs/s;  16593 sec\n",
            "[2021-04-30 22:39:32,523 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_24000.pt\n",
            "[2021-04-30 22:40:13,145 INFO] Step 24050/50000; xent: 2.94; lr: 0.0000129;  26 docs/s;  16633 sec\n",
            "[2021-04-30 22:40:47,075 INFO] Step 24100/50000; xent: 3.02; lr: 0.0000129;  30 docs/s;  16667 sec\n",
            "[2021-04-30 22:41:20,832 INFO] Step 24150/50000; xent: 2.98; lr: 0.0000129;  31 docs/s;  16701 sec\n",
            "[2021-04-30 22:41:30,455 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.132.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:41:56,302 INFO] Step 24200/50000; xent: 3.00; lr: 0.0000129;  29 docs/s;  16736 sec\n",
            "[2021-04-30 22:42:30,315 INFO] Step 24250/50000; xent: 2.97; lr: 0.0000128;  31 docs/s;  16770 sec\n",
            "[2021-04-30 22:43:04,203 INFO] Step 24300/50000; xent: 2.97; lr: 0.0000128;  31 docs/s;  16804 sec\n",
            "[2021-04-30 22:43:38,052 INFO] Step 24350/50000; xent: 2.94; lr: 0.0000128;  30 docs/s;  16838 sec\n",
            "[2021-04-30 22:43:43,418 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.120.bert.pt, number of examples: 2000\n",
            "[2021-04-30 22:44:14,040 INFO] Step 24400/50000; xent: 2.92; lr: 0.0000128;  29 docs/s;  16874 sec\n",
            "[2021-04-30 22:44:47,904 INFO] Step 24450/50000; xent: 2.91; lr: 0.0000128;  30 docs/s;  16908 sec\n",
            "[2021-04-30 22:45:22,022 INFO] Step 24500/50000; xent: 3.00; lr: 0.0000128;  30 docs/s;  16942 sec\n",
            "[2021-04-30 22:45:55,310 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.30.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:45:57,442 INFO] Step 24550/50000; xent: 2.98; lr: 0.0000128;  29 docs/s;  16978 sec\n",
            "[2021-04-30 22:46:30,991 INFO] Step 24600/50000; xent: 3.04; lr: 0.0000128;  30 docs/s;  17011 sec\n",
            "[2021-04-30 22:47:04,857 INFO] Step 24650/50000; xent: 2.96; lr: 0.0000127;  31 docs/s;  17045 sec\n",
            "[2021-04-30 22:47:38,925 INFO] Step 24700/50000; xent: 2.96; lr: 0.0000127;  30 docs/s;  17079 sec\n",
            "[2021-04-30 22:48:08,738 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.124.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:48:14,924 INFO] Step 24750/50000; xent: 2.94; lr: 0.0000127;  29 docs/s;  17115 sec\n",
            "[2021-04-30 22:48:48,783 INFO] Step 24800/50000; xent: 2.97; lr: 0.0000127;  31 docs/s;  17149 sec\n",
            "[2021-04-30 22:49:22,607 INFO] Step 24850/50000; xent: 2.98; lr: 0.0000127;  31 docs/s;  17183 sec\n",
            "[2021-04-30 22:49:56,361 INFO] Step 24900/50000; xent: 3.05; lr: 0.0000127;  31 docs/s;  17216 sec\n",
            "[2021-04-30 22:50:20,924 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.101.bert.pt, number of examples: 1998\n",
            "[2021-04-30 22:50:32,565 INFO] Step 24950/50000; xent: 2.95; lr: 0.0000127;  28 docs/s;  17253 sec\n",
            "[2021-04-30 22:51:06,340 INFO] Step 25000/50000; xent: 3.04; lr: 0.0000126;  31 docs/s;  17286 sec\n",
            "[2021-04-30 22:51:06,355 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_25000.pt\n",
            "[2021-04-30 22:51:45,994 INFO] Step 25050/50000; xent: 3.03; lr: 0.0000126;  26 docs/s;  17326 sec\n",
            "[2021-04-30 22:52:19,822 INFO] Step 25100/50000; xent: 2.99; lr: 0.0000126;  31 docs/s;  17360 sec\n",
            "[2021-04-30 22:52:39,352 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.26.bert.pt, number of examples: 1998\n",
            "[2021-04-30 22:52:56,118 INFO] Step 25150/50000; xent: 2.94; lr: 0.0000126;  29 docs/s;  17396 sec\n",
            "[2021-04-30 22:53:30,061 INFO] Step 25200/50000; xent: 3.00; lr: 0.0000126;  30 docs/s;  17430 sec\n",
            "[2021-04-30 22:54:03,909 INFO] Step 25250/50000; xent: 2.93; lr: 0.0000126;  31 docs/s;  17464 sec\n",
            "[2021-04-30 22:54:37,512 INFO] Step 25300/50000; xent: 3.00; lr: 0.0000126;  31 docs/s;  17498 sec\n",
            "[2021-04-30 22:54:51,630 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.77.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:55:13,252 INFO] Step 25350/50000; xent: 2.99; lr: 0.0000126;  29 docs/s;  17533 sec\n",
            "[2021-04-30 22:55:47,459 INFO] Step 25400/50000; xent: 2.94; lr: 0.0000125;  31 docs/s;  17568 sec\n",
            "[2021-04-30 22:56:21,140 INFO] Step 25450/50000; xent: 3.01; lr: 0.0000125;  31 docs/s;  17601 sec\n",
            "[2021-04-30 22:56:54,938 INFO] Step 25500/50000; xent: 3.03; lr: 0.0000125;  31 docs/s;  17635 sec\n",
            "[2021-04-30 22:57:03,973 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.58.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:57:30,508 INFO] Step 25550/50000; xent: 2.97; lr: 0.0000125;  30 docs/s;  17671 sec\n",
            "[2021-04-30 22:58:04,678 INFO] Step 25600/50000; xent: 2.98; lr: 0.0000125;  30 docs/s;  17705 sec\n",
            "[2021-04-30 22:58:38,469 INFO] Step 25650/50000; xent: 3.00; lr: 0.0000125;  30 docs/s;  17739 sec\n",
            "[2021-04-30 22:59:12,199 INFO] Step 25700/50000; xent: 2.98; lr: 0.0000125;  31 docs/s;  17772 sec\n",
            "[2021-04-30 22:59:16,419 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.130.bert.pt, number of examples: 2001\n",
            "[2021-04-30 22:59:48,348 INFO] Step 25750/50000; xent: 2.96; lr: 0.0000125;  29 docs/s;  17808 sec\n",
            "[2021-04-30 23:00:22,265 INFO] Step 25800/50000; xent: 2.97; lr: 0.0000125;  30 docs/s;  17842 sec\n",
            "[2021-04-30 23:00:56,195 INFO] Step 25850/50000; xent: 3.03; lr: 0.0000124;  30 docs/s;  17876 sec\n",
            "[2021-04-30 23:01:28,540 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.109.bert.pt, number of examples: 1999\n",
            "[2021-04-30 23:01:31,350 INFO] Step 25900/50000; xent: 2.99; lr: 0.0000124;  29 docs/s;  17911 sec\n",
            "[2021-04-30 23:02:05,144 INFO] Step 25950/50000; xent: 2.94; lr: 0.0000124;  31 docs/s;  17945 sec\n",
            "[2021-04-30 23:02:38,955 INFO] Step 26000/50000; xent: 2.93; lr: 0.0000124;  31 docs/s;  17979 sec\n",
            "[2021-04-30 23:02:38,971 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_26000.pt\n",
            "[2021-04-30 23:03:19,982 INFO] Step 26050/50000; xent: 2.99; lr: 0.0000124;  25 docs/s;  18020 sec\n",
            "[2021-04-30 23:03:47,799 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.126.bert.pt, number of examples: 2001\n",
            "[2021-04-30 23:03:55,381 INFO] Step 26100/50000; xent: 2.99; lr: 0.0000124;  29 docs/s;  18055 sec\n",
            "[2021-04-30 23:04:29,051 INFO] Step 26150/50000; xent: 3.03; lr: 0.0000124;  30 docs/s;  18089 sec\n",
            "[2021-04-30 23:05:02,908 INFO] Step 26200/50000; xent: 2.99; lr: 0.0000124;  31 docs/s;  18123 sec\n",
            "[2021-04-30 23:05:36,902 INFO] Step 26250/50000; xent: 2.98; lr: 0.0000123;  30 docs/s;  18157 sec\n",
            "[2021-04-30 23:06:00,799 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.46.bert.pt, number of examples: 2001\n",
            "[2021-04-30 23:06:13,113 INFO] Step 26300/50000; xent: 2.95; lr: 0.0000123;  29 docs/s;  18193 sec\n",
            "[2021-04-30 23:06:46,963 INFO] Step 26350/50000; xent: 2.96; lr: 0.0000123;  30 docs/s;  18227 sec\n",
            "[2021-04-30 23:07:20,764 INFO] Step 26400/50000; xent: 2.97; lr: 0.0000123;  30 docs/s;  18261 sec\n",
            "[2021-04-30 23:07:54,709 INFO] Step 26450/50000; xent: 2.96; lr: 0.0000123;  32 docs/s;  18295 sec\n",
            "[2021-04-30 23:08:13,628 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.100.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:08:30,572 INFO] Step 26500/50000; xent: 2.96; lr: 0.0000123;  28 docs/s;  18331 sec\n",
            "[2021-04-30 23:09:04,422 INFO] Step 26550/50000; xent: 3.02; lr: 0.0000123;  31 docs/s;  18364 sec\n",
            "[2021-04-30 23:09:38,195 INFO] Step 26600/50000; xent: 3.00; lr: 0.0000123;  32 docs/s;  18398 sec\n",
            "[2021-04-30 23:10:12,219 INFO] Step 26650/50000; xent: 2.85; lr: 0.0000123;  31 docs/s;  18432 sec\n",
            "[2021-04-30 23:10:24,582 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.85.bert.pt, number of examples: 1998\n",
            "[2021-04-30 23:10:48,013 INFO] Step 26700/50000; xent: 2.89; lr: 0.0000122;  29 docs/s;  18468 sec\n",
            "[2021-04-30 23:11:21,809 INFO] Step 26750/50000; xent: 2.89; lr: 0.0000122;  32 docs/s;  18502 sec\n",
            "[2021-04-30 23:11:55,577 INFO] Step 26800/50000; xent: 2.93; lr: 0.0000122;  31 docs/s;  18536 sec\n",
            "[2021-04-30 23:12:29,364 INFO] Step 26850/50000; xent: 2.89; lr: 0.0000122;  30 docs/s;  18569 sec\n",
            "[2021-04-30 23:12:36,185 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.34.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:13:04,760 INFO] Step 26900/50000; xent: 2.84; lr: 0.0000122;  30 docs/s;  18605 sec\n",
            "[2021-04-30 23:13:38,682 INFO] Step 26950/50000; xent: 2.65; lr: 0.0000122;  31 docs/s;  18639 sec\n",
            "[2021-04-30 23:14:12,546 INFO] Step 27000/50000; xent: 2.71; lr: 0.0000122;  30 docs/s;  18673 sec\n",
            "[2021-04-30 23:14:12,561 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_27000.pt\n",
            "[2021-04-30 23:14:52,488 INFO] Step 27050/50000; xent: 2.72; lr: 0.0000122;  26 docs/s;  18713 sec\n",
            "[2021-04-30 23:14:53,954 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.7.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:15:27,669 INFO] Step 27100/50000; xent: 2.64; lr: 0.0000121;  29 docs/s;  18748 sec\n",
            "[2021-04-30 23:16:02,206 INFO] Step 27150/50000; xent: 2.68; lr: 0.0000121;  30 docs/s;  18782 sec\n",
            "[2021-04-30 23:16:35,968 INFO] Step 27200/50000; xent: 2.59; lr: 0.0000121;  31 docs/s;  18816 sec\n",
            "[2021-04-30 23:17:06,244 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.56.bert.pt, number of examples: 2001\n",
            "[2021-04-30 23:17:11,138 INFO] Step 27250/50000; xent: 2.68; lr: 0.0000121;  29 docs/s;  18851 sec\n",
            "[2021-04-30 23:17:44,995 INFO] Step 27300/50000; xent: 2.60; lr: 0.0000121;  31 docs/s;  18885 sec\n",
            "[2021-04-30 23:18:18,901 INFO] Step 27350/50000; xent: 2.58; lr: 0.0000121;  30 docs/s;  18919 sec\n",
            "[2021-04-30 23:18:52,785 INFO] Step 27400/50000; xent: 2.62; lr: 0.0000121;  31 docs/s;  18953 sec\n",
            "[2021-04-30 23:19:18,724 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.74.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:19:28,304 INFO] Step 27450/50000; xent: 2.65; lr: 0.0000121;  29 docs/s;  18988 sec\n",
            "[2021-04-30 23:20:02,113 INFO] Step 27500/50000; xent: 2.58; lr: 0.0000121;  31 docs/s;  19022 sec\n",
            "[2021-04-30 23:20:35,942 INFO] Step 27550/50000; xent: 2.69; lr: 0.0000120;  31 docs/s;  19056 sec\n",
            "[2021-04-30 23:21:09,936 INFO] Step 27600/50000; xent: 2.59; lr: 0.0000120;  31 docs/s;  19090 sec\n",
            "[2021-04-30 23:21:30,952 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.105.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:21:45,262 INFO] Step 27650/50000; xent: 2.68; lr: 0.0000120;  29 docs/s;  19125 sec\n",
            "[2021-04-30 23:22:18,852 INFO] Step 27700/50000; xent: 2.67; lr: 0.0000120;  31 docs/s;  19159 sec\n",
            "[2021-04-30 23:22:52,640 INFO] Step 27750/50000; xent: 2.60; lr: 0.0000120;  30 docs/s;  19193 sec\n",
            "[2021-04-30 23:23:26,808 INFO] Step 27800/50000; xent: 2.69; lr: 0.0000120;  31 docs/s;  19227 sec\n",
            "[2021-04-30 23:23:43,029 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.114.bert.pt, number of examples: 2001\n",
            "[2021-04-30 23:24:02,012 INFO] Step 27850/50000; xent: 2.72; lr: 0.0000120;  30 docs/s;  19262 sec\n",
            "[2021-04-30 23:24:35,938 INFO] Step 27900/50000; xent: 2.61; lr: 0.0000120;  31 docs/s;  19296 sec\n",
            "[2021-04-30 23:25:09,704 INFO] Step 27950/50000; xent: 2.60; lr: 0.0000120;  30 docs/s;  19330 sec\n",
            "[2021-04-30 23:25:43,559 INFO] Step 28000/50000; xent: 2.49; lr: 0.0000120;  31 docs/s;  19364 sec\n",
            "[2021-04-30 23:25:43,562 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_28000.pt\n",
            "[2021-04-30 23:26:01,640 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.47.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:26:25,829 INFO] Step 28050/50000; xent: 2.55; lr: 0.0000119;  24 docs/s;  19406 sec\n",
            "[2021-04-30 23:26:59,454 INFO] Step 28100/50000; xent: 2.55; lr: 0.0000119;  31 docs/s;  19440 sec\n",
            "[2021-04-30 23:27:33,285 INFO] Step 28150/50000; xent: 2.61; lr: 0.0000119;  31 docs/s;  19473 sec\n",
            "[2021-04-30 23:28:06,930 INFO] Step 28200/50000; xent: 2.59; lr: 0.0000119;  31 docs/s;  19507 sec\n",
            "[2021-04-30 23:28:13,788 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.24.bert.pt, number of examples: 1999\n",
            "[2021-04-30 23:28:42,646 INFO] Step 28250/50000; xent: 2.65; lr: 0.0000119;  29 docs/s;  19543 sec\n",
            "[2021-04-30 23:29:16,428 INFO] Step 28300/50000; xent: 2.56; lr: 0.0000119;  32 docs/s;  19576 sec\n",
            "[2021-04-30 23:29:50,162 INFO] Step 28350/50000; xent: 2.57; lr: 0.0000119;  31 docs/s;  19610 sec\n",
            "[2021-04-30 23:30:24,838 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.13.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:30:25,618 INFO] Step 28400/50000; xent: 2.64; lr: 0.0000119;  29 docs/s;  19646 sec\n",
            "[2021-04-30 23:30:59,540 INFO] Step 28450/50000; xent: 2.55; lr: 0.0000119;  32 docs/s;  19680 sec\n",
            "[2021-04-30 23:31:33,630 INFO] Step 28500/50000; xent: 2.65; lr: 0.0000118;  30 docs/s;  19714 sec\n",
            "[2021-04-30 23:32:07,435 INFO] Step 28550/50000; xent: 2.54; lr: 0.0000118;  31 docs/s;  19747 sec\n",
            "[2021-04-30 23:32:35,476 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.40.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:32:41,661 INFO] Step 28600/50000; xent: 2.57; lr: 0.0000118;  30 docs/s;  19782 sec\n",
            "[2021-04-30 23:33:15,406 INFO] Step 28650/50000; xent: 2.60; lr: 0.0000118;  31 docs/s;  19815 sec\n",
            "[2021-04-30 23:33:49,652 INFO] Step 28700/50000; xent: 2.61; lr: 0.0000118;  30 docs/s;  19850 sec\n",
            "[2021-04-30 23:34:23,392 INFO] Step 28750/50000; xent: 2.67; lr: 0.0000118;  31 docs/s;  19883 sec\n",
            "[2021-04-30 23:34:46,876 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.69.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:34:58,480 INFO] Step 28800/50000; xent: 2.58; lr: 0.0000118;  30 docs/s;  19919 sec\n",
            "[2021-04-30 23:35:32,275 INFO] Step 28850/50000; xent: 2.75; lr: 0.0000118;  30 docs/s;  19952 sec\n",
            "[2021-04-30 23:36:06,176 INFO] Step 28900/50000; xent: 2.60; lr: 0.0000118;  31 docs/s;  19986 sec\n",
            "[2021-04-30 23:36:40,106 INFO] Step 28950/50000; xent: 2.60; lr: 0.0000118;  31 docs/s;  20020 sec\n",
            "[2021-04-30 23:36:59,110 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.41.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:37:16,160 INFO] Step 29000/50000; xent: 2.61; lr: 0.0000117;  29 docs/s;  20056 sec\n",
            "[2021-04-30 23:37:16,174 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_29000.pt\n",
            "[2021-04-30 23:37:55,857 INFO] Step 29050/50000; xent: 2.60; lr: 0.0000117;  26 docs/s;  20096 sec\n",
            "[2021-04-30 23:38:29,698 INFO] Step 29100/50000; xent: 2.58; lr: 0.0000117;  32 docs/s;  20130 sec\n",
            "[2021-04-30 23:39:04,155 INFO] Step 29150/50000; xent: 2.53; lr: 0.0000117;  29 docs/s;  20164 sec\n",
            "[2021-04-30 23:39:17,356 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.39.bert.pt, number of examples: 2001\n",
            "[2021-04-30 23:39:39,813 INFO] Step 29200/50000; xent: 2.53; lr: 0.0000117;  30 docs/s;  20200 sec\n",
            "[2021-04-30 23:40:13,606 INFO] Step 29250/50000; xent: 2.64; lr: 0.0000117;  31 docs/s;  20234 sec\n",
            "[2021-04-30 23:40:47,376 INFO] Step 29300/50000; xent: 2.60; lr: 0.0000117;  31 docs/s;  20267 sec\n",
            "[2021-04-30 23:41:21,207 INFO] Step 29350/50000; xent: 2.59; lr: 0.0000117;  30 docs/s;  20301 sec\n",
            "[2021-04-30 23:41:27,761 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.77.bert.pt, number of examples: 2001\n",
            "[2021-04-30 23:41:55,799 INFO] Step 29400/50000; xent: 2.57; lr: 0.0000117;  30 docs/s;  20336 sec\n",
            "[2021-04-30 23:42:29,625 INFO] Step 29450/50000; xent: 2.69; lr: 0.0000117;  31 docs/s;  20370 sec\n",
            "[2021-04-30 23:43:03,466 INFO] Step 29500/50000; xent: 2.64; lr: 0.0000116;  31 docs/s;  20404 sec\n",
            "[2021-04-30 23:43:36,973 INFO] Step 29550/50000; xent: 2.58; lr: 0.0000116;  30 docs/s;  20437 sec\n",
            "[2021-04-30 23:43:39,982 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.52.bert.pt, number of examples: 1999\n",
            "[2021-04-30 23:44:12,740 INFO] Step 29600/50000; xent: 2.53; lr: 0.0000116;  30 docs/s;  20473 sec\n",
            "[2021-04-30 23:44:46,567 INFO] Step 29650/50000; xent: 2.48; lr: 0.0000116;  30 docs/s;  20507 sec\n",
            "[2021-04-30 23:45:20,401 INFO] Step 29700/50000; xent: 2.54; lr: 0.0000116;  31 docs/s;  20540 sec\n",
            "[2021-04-30 23:45:50,513 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.31.bert.pt, number of examples: 2001\n",
            "[2021-04-30 23:45:54,685 INFO] Step 29750/50000; xent: 2.53; lr: 0.0000116;  30 docs/s;  20575 sec\n",
            "[2021-04-30 23:46:28,736 INFO] Step 29800/50000; xent: 2.62; lr: 0.0000116;  30 docs/s;  20609 sec\n",
            "[2021-04-30 23:47:02,677 INFO] Step 29850/50000; xent: 2.60; lr: 0.0000116;  31 docs/s;  20643 sec\n",
            "[2021-04-30 23:47:36,477 INFO] Step 29900/50000; xent: 2.62; lr: 0.0000116;  31 docs/s;  20677 sec\n",
            "[2021-04-30 23:48:02,577 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.121.bert.pt, number of examples: 1999\n",
            "[2021-04-30 23:48:12,135 INFO] Step 29950/50000; xent: 2.59; lr: 0.0000116;  29 docs/s;  20712 sec\n",
            "[2021-04-30 23:48:45,991 INFO] Step 30000/50000; xent: 2.49; lr: 0.0000115;  31 docs/s;  20746 sec\n",
            "[2021-04-30 23:48:46,004 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_30000.pt\n",
            "[2021-04-30 23:49:27,201 INFO] Step 30050/50000; xent: 2.51; lr: 0.0000115;  26 docs/s;  20787 sec\n",
            "[2021-04-30 23:50:00,957 INFO] Step 30100/50000; xent: 2.47; lr: 0.0000115;  31 docs/s;  20821 sec\n",
            "[2021-04-30 23:50:20,243 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.48.bert.pt, number of examples: 2000\n",
            "[2021-04-30 23:50:35,269 INFO] Step 30150/50000; xent: 2.60; lr: 0.0000115;  31 docs/s;  20855 sec\n",
            "[2021-04-30 23:51:09,081 INFO] Step 30200/50000; xent: 2.57; lr: 0.0000115;  31 docs/s;  20889 sec\n",
            "[2021-04-30 23:51:43,311 INFO] Step 30250/50000; xent: 2.61; lr: 0.0000115;  30 docs/s;  20923 sec\n",
            "[2021-04-30 23:52:17,143 INFO] Step 30300/50000; xent: 2.58; lr: 0.0000115;  31 docs/s;  20957 sec\n",
            "[2021-04-30 23:52:32,486 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.28.bert.pt, number of examples: 1999\n",
            "[2021-04-30 23:52:52,903 INFO] Step 30350/50000; xent: 2.64; lr: 0.0000115;  28 docs/s;  20993 sec\n",
            "[2021-04-30 23:53:26,659 INFO] Step 30400/50000; xent: 2.60; lr: 0.0000115;  31 docs/s;  21027 sec\n",
            "[2021-04-30 23:54:00,388 INFO] Step 30450/50000; xent: 2.64; lr: 0.0000115;  31 docs/s;  21060 sec\n",
            "[2021-04-30 23:54:34,252 INFO] Step 30500/50000; xent: 2.57; lr: 0.0000115;  31 docs/s;  21094 sec\n",
            "[2021-04-30 23:54:44,072 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.58.bert.pt, number of examples: 2001\n",
            "[2021-04-30 23:55:08,560 INFO] Step 30550/50000; xent: 2.60; lr: 0.0000114;  30 docs/s;  21129 sec\n",
            "[2021-04-30 23:55:42,376 INFO] Step 30600/50000; xent: 2.58; lr: 0.0000114;  32 docs/s;  21162 sec\n",
            "[2021-04-30 23:56:16,207 INFO] Step 30650/50000; xent: 2.60; lr: 0.0000114;  30 docs/s;  21196 sec\n",
            "[2021-04-30 23:56:50,328 INFO] Step 30700/50000; xent: 2.58; lr: 0.0000114;  30 docs/s;  21230 sec\n",
            "[2021-04-30 23:56:56,758 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.62.bert.pt, number of examples: 2001\n",
            "[2021-04-30 23:57:26,588 INFO] Step 30750/50000; xent: 2.63; lr: 0.0000114;  29 docs/s;  21267 sec\n",
            "[2021-04-30 23:58:00,250 INFO] Step 30800/50000; xent: 2.59; lr: 0.0000114;  31 docs/s;  21300 sec\n",
            "[2021-04-30 23:58:34,062 INFO] Step 30850/50000; xent: 2.57; lr: 0.0000114;  30 docs/s;  21334 sec\n",
            "[2021-04-30 23:59:07,814 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.133.bert.pt, number of examples: 1999\n",
            "[2021-04-30 23:59:08,596 INFO] Step 30900/50000; xent: 2.56; lr: 0.0000114;  30 docs/s;  21369 sec\n",
            "[2021-04-30 23:59:42,455 INFO] Step 30950/50000; xent: 2.70; lr: 0.0000114;  31 docs/s;  21403 sec\n",
            "[2021-05-01 00:00:16,238 INFO] Step 31000/50000; xent: 2.61; lr: 0.0000114;  31 docs/s;  21436 sec\n",
            "[2021-05-01 00:00:16,254 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_31000.pt\n",
            "[2021-05-01 00:00:56,135 INFO] Step 31050/50000; xent: 2.58; lr: 0.0000114;  26 docs/s;  21476 sec\n",
            "[2021-05-01 00:01:26,495 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.86.bert.pt, number of examples: 1999\n",
            "[2021-05-01 00:01:32,059 INFO] Step 31100/50000; xent: 2.55; lr: 0.0000113;  28 docs/s;  21512 sec\n",
            "[2021-05-01 00:02:06,743 INFO] Step 31150/50000; xent: 2.42; lr: 0.0000113;  30 docs/s;  21547 sec\n",
            "[2021-05-01 00:02:40,562 INFO] Step 31200/50000; xent: 2.57; lr: 0.0000113;  31 docs/s;  21581 sec\n",
            "[2021-05-01 00:03:14,358 INFO] Step 31250/50000; xent: 2.56; lr: 0.0000113;  31 docs/s;  21614 sec\n",
            "[2021-05-01 00:03:38,182 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.3.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:03:48,435 INFO] Step 31300/50000; xent: 2.55; lr: 0.0000113;  31 docs/s;  21648 sec\n",
            "[2021-05-01 00:04:22,468 INFO] Step 31350/50000; xent: 2.63; lr: 0.0000113;  31 docs/s;  21683 sec\n",
            "[2021-05-01 00:04:56,361 INFO] Step 31400/50000; xent: 2.60; lr: 0.0000113;  31 docs/s;  21716 sec\n",
            "[2021-05-01 00:05:30,118 INFO] Step 31450/50000; xent: 2.66; lr: 0.0000113;  30 docs/s;  21750 sec\n",
            "[2021-05-01 00:05:51,001 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.9.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:06:05,968 INFO] Step 31500/50000; xent: 2.55; lr: 0.0000113;  29 docs/s;  21786 sec\n",
            "[2021-05-01 00:06:39,763 INFO] Step 31550/50000; xent: 2.51; lr: 0.0000113;  31 docs/s;  21820 sec\n",
            "[2021-05-01 00:07:13,954 INFO] Step 31600/50000; xent: 2.58; lr: 0.0000113;  31 docs/s;  21854 sec\n",
            "[2021-05-01 00:07:47,709 INFO] Step 31650/50000; xent: 2.56; lr: 0.0000112;  31 docs/s;  21888 sec\n",
            "[2021-05-01 00:08:01,590 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.70.bert.pt, number of examples: 1999\n",
            "[2021-05-01 00:08:21,982 INFO] Step 31700/50000; xent: 2.61; lr: 0.0000112;  30 docs/s;  21922 sec\n",
            "[2021-05-01 00:08:55,801 INFO] Step 31750/50000; xent: 2.56; lr: 0.0000112;  30 docs/s;  21956 sec\n",
            "[2021-05-01 00:09:29,758 INFO] Step 31800/50000; xent: 2.55; lr: 0.0000112;  32 docs/s;  21990 sec\n",
            "[2021-05-01 00:10:03,559 INFO] Step 31850/50000; xent: 2.59; lr: 0.0000112;  30 docs/s;  22024 sec\n",
            "[2021-05-01 00:10:13,722 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.22.bert.pt, number of examples: 2001\n",
            "[2021-05-01 00:10:39,526 INFO] Step 31900/50000; xent: 2.53; lr: 0.0000112;  29 docs/s;  22060 sec\n",
            "[2021-05-01 00:11:13,382 INFO] Step 31950/50000; xent: 2.60; lr: 0.0000112;  31 docs/s;  22093 sec\n",
            "[2021-05-01 00:11:47,221 INFO] Step 32000/50000; xent: 2.67; lr: 0.0000112;  30 docs/s;  22127 sec\n",
            "[2021-05-01 00:11:47,241 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_32000.pt\n",
            "[2021-05-01 00:12:27,674 INFO] Step 32050/50000; xent: 2.57; lr: 0.0000112;  25 docs/s;  22168 sec\n",
            "[2021-05-01 00:12:32,594 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.91.bert.pt, number of examples: 1995\n",
            "[2021-05-01 00:13:02,989 INFO] Step 32100/50000; xent: 2.50; lr: 0.0000112;  29 docs/s;  22203 sec\n",
            "[2021-05-01 00:13:36,762 INFO] Step 32150/50000; xent: 2.56; lr: 0.0000112;  31 docs/s;  22237 sec\n",
            "[2021-05-01 00:14:10,592 INFO] Step 32200/50000; xent: 2.52; lr: 0.0000111;  30 docs/s;  22271 sec\n",
            "[2021-05-01 00:14:44,439 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.95.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:14:46,633 INFO] Step 32250/50000; xent: 2.60; lr: 0.0000111;  28 docs/s;  22307 sec\n",
            "[2021-05-01 00:15:20,490 INFO] Step 32300/50000; xent: 2.55; lr: 0.0000111;  31 docs/s;  22341 sec\n",
            "[2021-05-01 00:15:54,082 INFO] Step 32350/50000; xent: 2.66; lr: 0.0000111;  30 docs/s;  22374 sec\n",
            "[2021-05-01 00:16:27,918 INFO] Step 32400/50000; xent: 2.70; lr: 0.0000111;  31 docs/s;  22408 sec\n",
            "[2021-05-01 00:16:57,119 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.123.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:17:04,081 INFO] Step 32450/50000; xent: 2.49; lr: 0.0000111;  29 docs/s;  22444 sec\n",
            "[2021-05-01 00:17:38,038 INFO] Step 32500/50000; xent: 2.62; lr: 0.0000111;  30 docs/s;  22478 sec\n",
            "[2021-05-01 00:18:11,891 INFO] Step 32550/50000; xent: 2.58; lr: 0.0000111;  32 docs/s;  22512 sec\n",
            "[2021-05-01 00:18:45,720 INFO] Step 32600/50000; xent: 2.59; lr: 0.0000111;  30 docs/s;  22546 sec\n",
            "[2021-05-01 00:19:08,218 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.92.bert.pt, number of examples: 1998\n",
            "[2021-05-01 00:19:21,170 INFO] Step 32650/50000; xent: 2.65; lr: 0.0000111;  30 docs/s;  22581 sec\n",
            "[2021-05-01 00:19:55,155 INFO] Step 32700/50000; xent: 2.57; lr: 0.0000111;  30 docs/s;  22615 sec\n",
            "[2021-05-01 00:20:29,149 INFO] Step 32750/50000; xent: 2.52; lr: 0.0000111;  31 docs/s;  22649 sec\n",
            "[2021-05-01 00:21:02,892 INFO] Step 32800/50000; xent: 2.55; lr: 0.0000110;  31 docs/s;  22683 sec\n",
            "[2021-05-01 00:21:20,718 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.76.bert.pt, number of examples: 2001\n",
            "[2021-05-01 00:21:38,444 INFO] Step 32850/50000; xent: 2.52; lr: 0.0000110;  29 docs/s;  22719 sec\n",
            "[2021-05-01 00:22:12,092 INFO] Step 32900/50000; xent: 2.58; lr: 0.0000110;  30 docs/s;  22752 sec\n",
            "[2021-05-01 00:22:46,308 INFO] Step 32950/50000; xent: 2.43; lr: 0.0000110;  30 docs/s;  22786 sec\n",
            "[2021-05-01 00:23:20,144 INFO] Step 33000/50000; xent: 2.47; lr: 0.0000110;  31 docs/s;  22820 sec\n",
            "[2021-05-01 00:23:20,147 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_33000.pt\n",
            "[2021-05-01 00:23:38,415 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.34.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:24:00,827 INFO] Step 33050/50000; xent: 2.53; lr: 0.0000110;  25 docs/s;  22861 sec\n",
            "[2021-05-01 00:24:34,651 INFO] Step 33100/50000; xent: 2.53; lr: 0.0000110;  32 docs/s;  22895 sec\n",
            "[2021-05-01 00:25:08,947 INFO] Step 33150/50000; xent: 2.54; lr: 0.0000110;  30 docs/s;  22929 sec\n",
            "[2021-05-01 00:25:42,706 INFO] Step 33200/50000; xent: 2.56; lr: 0.0000110;  31 docs/s;  22963 sec\n",
            "[2021-05-01 00:25:49,900 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.75.bert.pt, number of examples: 1999\n",
            "[2021-05-01 00:26:17,047 INFO] Step 33250/50000; xent: 2.56; lr: 0.0000110;  30 docs/s;  22997 sec\n",
            "[2021-05-01 00:26:50,866 INFO] Step 33300/50000; xent: 2.61; lr: 0.0000110;  30 docs/s;  23031 sec\n",
            "[2021-05-01 00:27:24,584 INFO] Step 33350/50000; xent: 2.53; lr: 0.0000110;  31 docs/s;  23065 sec\n",
            "[2021-05-01 00:27:58,725 INFO] Step 33400/50000; xent: 2.64; lr: 0.0000109;  30 docs/s;  23099 sec\n",
            "[2021-05-01 00:28:01,165 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.56.bert.pt, number of examples: 2001\n",
            "[2021-05-01 00:28:32,983 INFO] Step 33450/50000; xent: 2.50; lr: 0.0000109;  30 docs/s;  23133 sec\n",
            "[2021-05-01 00:29:06,788 INFO] Step 33500/50000; xent: 2.39; lr: 0.0000109;  32 docs/s;  23167 sec\n",
            "[2021-05-01 00:29:40,630 INFO] Step 33550/50000; xent: 2.50; lr: 0.0000109;  30 docs/s;  23201 sec\n",
            "[2021-05-01 00:30:12,240 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.60.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:30:15,069 INFO] Step 33600/50000; xent: 2.52; lr: 0.0000109;  30 docs/s;  23235 sec\n",
            "[2021-05-01 00:30:49,274 INFO] Step 33650/50000; xent: 2.58; lr: 0.0000109;  31 docs/s;  23269 sec\n",
            "[2021-05-01 00:31:23,498 INFO] Step 33700/50000; xent: 2.55; lr: 0.0000109;  30 docs/s;  23304 sec\n",
            "[2021-05-01 00:31:57,633 INFO] Step 33750/50000; xent: 2.52; lr: 0.0000109;  30 docs/s;  23338 sec\n",
            "[2021-05-01 00:32:25,181 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.65.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:32:33,582 INFO] Step 33800/50000; xent: 2.63; lr: 0.0000109;  29 docs/s;  23374 sec\n",
            "[2021-05-01 00:33:07,884 INFO] Step 33850/50000; xent: 2.64; lr: 0.0000109;  31 docs/s;  23408 sec\n",
            "[2021-05-01 00:33:42,152 INFO] Step 33900/50000; xent: 2.61; lr: 0.0000109;  31 docs/s;  23442 sec\n",
            "[2021-05-01 00:34:16,294 INFO] Step 33950/50000; xent: 2.58; lr: 0.0000109;  30 docs/s;  23476 sec\n",
            "[2021-05-01 00:34:39,038 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.110.bert.pt, number of examples: 2001\n",
            "[2021-05-01 00:34:52,828 INFO] Step 34000/50000; xent: 2.57; lr: 0.0000108;  28 docs/s;  23513 sec\n",
            "[2021-05-01 00:34:52,846 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_34000.pt\n",
            "[2021-05-01 00:35:36,670 INFO] Step 34050/50000; xent: 2.63; lr: 0.0000108;  23 docs/s;  23557 sec\n",
            "[2021-05-01 00:36:11,046 INFO] Step 34100/50000; xent: 2.64; lr: 0.0000108;  31 docs/s;  23591 sec\n",
            "[2021-05-01 00:36:45,473 INFO] Step 34150/50000; xent: 2.58; lr: 0.0000108;  30 docs/s;  23626 sec\n",
            "[2021-05-01 00:37:01,802 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.108.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:37:20,470 INFO] Step 34200/50000; xent: 2.51; lr: 0.0000108;  30 docs/s;  23661 sec\n",
            "[2021-05-01 00:37:54,820 INFO] Step 34250/50000; xent: 2.54; lr: 0.0000108;  30 docs/s;  23695 sec\n",
            "[2021-05-01 00:38:28,728 INFO] Step 34300/50000; xent: 2.59; lr: 0.0000108;  31 docs/s;  23729 sec\n",
            "[2021-05-01 00:39:02,636 INFO] Step 34350/50000; xent: 2.52; lr: 0.0000108;  31 docs/s;  23763 sec\n",
            "[2021-05-01 00:39:14,392 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.23.bert.pt, number of examples: 2001\n",
            "[2021-05-01 00:39:38,183 INFO] Step 34400/50000; xent: 2.56; lr: 0.0000108;  29 docs/s;  23798 sec\n",
            "[2021-05-01 00:40:12,018 INFO] Step 34450/50000; xent: 2.60; lr: 0.0000108;  31 docs/s;  23832 sec\n",
            "[2021-05-01 00:40:45,801 INFO] Step 34500/50000; xent: 2.64; lr: 0.0000108;  31 docs/s;  23866 sec\n",
            "[2021-05-01 00:41:19,413 INFO] Step 34550/50000; xent: 2.60; lr: 0.0000108;  31 docs/s;  23899 sec\n",
            "[2021-05-01 00:41:25,787 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.115.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:41:54,684 INFO] Step 34600/50000; xent: 2.58; lr: 0.0000108;  29 docs/s;  23935 sec\n",
            "[2021-05-01 00:42:28,464 INFO] Step 34650/50000; xent: 2.63; lr: 0.0000107;  31 docs/s;  23969 sec\n",
            "[2021-05-01 00:43:02,352 INFO] Step 34700/50000; xent: 2.59; lr: 0.0000107;  30 docs/s;  24002 sec\n",
            "[2021-05-01 00:43:36,232 INFO] Step 34750/50000; xent: 2.60; lr: 0.0000107;  31 docs/s;  24036 sec\n",
            "[2021-05-01 00:43:37,870 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.89.bert.pt, number of examples: 2001\n",
            "[2021-05-01 00:44:11,801 INFO] Step 34800/50000; xent: 2.58; lr: 0.0000107;  29 docs/s;  24072 sec\n",
            "[2021-05-01 00:44:45,498 INFO] Step 34850/50000; xent: 2.63; lr: 0.0000107;  30 docs/s;  24106 sec\n",
            "[2021-05-01 00:45:19,258 INFO] Step 34900/50000; xent: 2.51; lr: 0.0000107;  31 docs/s;  24139 sec\n",
            "[2021-05-01 00:45:49,994 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.81.bert.pt, number of examples: 2001\n",
            "[2021-05-01 00:45:54,871 INFO] Step 34950/50000; xent: 2.74; lr: 0.0000107;  30 docs/s;  24175 sec\n",
            "[2021-05-01 00:46:28,609 INFO] Step 35000/50000; xent: 2.61; lr: 0.0000107;  31 docs/s;  24209 sec\n",
            "[2021-05-01 00:46:28,623 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_35000.pt\n",
            "[2021-05-01 00:47:08,777 INFO] Step 35050/50000; xent: 2.72; lr: 0.0000107;  25 docs/s;  24249 sec\n",
            "[2021-05-01 00:47:42,562 INFO] Step 35100/50000; xent: 2.61; lr: 0.0000107;  31 docs/s;  24283 sec\n",
            "[2021-05-01 00:48:07,646 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.5.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:48:17,920 INFO] Step 35150/50000; xent: 2.59; lr: 0.0000107;  30 docs/s;  24318 sec\n",
            "[2021-05-01 00:48:51,736 INFO] Step 35200/50000; xent: 2.62; lr: 0.0000107;  31 docs/s;  24352 sec\n",
            "[2021-05-01 00:49:25,296 INFO] Step 35250/50000; xent: 2.60; lr: 0.0000107;  31 docs/s;  24385 sec\n",
            "[2021-05-01 00:49:59,085 INFO] Step 35300/50000; xent: 2.66; lr: 0.0000106;  30 docs/s;  24419 sec\n",
            "[2021-05-01 00:50:20,260 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.7.bert.pt, number of examples: 2000\n",
            "[2021-05-01 00:50:35,223 INFO] Step 35350/50000; xent: 2.61; lr: 0.0000106;  29 docs/s;  24455 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7NIgvXvp2fX"
      },
      "source": [
        "## lr=2e-3, layer=2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTEdFUgZnPL9",
        "outputId": "3ce51f1b-5304-4d94-a966-89563dbb7816"
      },
      "source": [
        "!python3 train.py -task ext -encoder roberta -mode train -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -ext_dropout 0.1 -model_path ../data/trained_models/roberta_2layers -lr 2e-3 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file ../logs/ext_roberta2_cnndm -use_interval true -warmup_steps 10000 -max_pos 512 -ext_layers 2 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "----TRAIN EXTRACTIVE----\n",
            "[2021-05-02 10:49:33,347 INFO] Device ID 0\n",
            "[2021-05-02 10:49:33,348 INFO] Device cuda\n",
            "[2021-05-02 10:49:34,117 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-02 10:49:34,910 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-02 10:49:35,646 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-02 10:49:58,339 INFO] ExtSummarizer(\n",
            "  (bert): Roberta(\n",
            "    (model): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(514, 768)\n",
            "        (token_type_embeddings): Embedding(1, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ext_layer): ExtTransformerEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2021-05-02 10:49:58,418 INFO] * number of parameters: 135675905\n",
            "[2021-05-02 10:49:58,419 INFO] Start training...\n",
            "[2021-05-02 10:50:03,635 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.123.bert.pt, number of examples: 2000\n",
            "[2021-05-02 10:50:37,452 INFO] Step 50/50000; xent: 3.17; lr: 0.0000001;  30 docs/s;     34 sec\n",
            "[2021-05-02 10:51:11,589 INFO] Step 100/50000; xent: 3.23; lr: 0.0000002;  31 docs/s;     68 sec\n",
            "[2021-05-02 10:51:45,454 INFO] Step 150/50000; xent: 3.26; lr: 0.0000003;  32 docs/s;    102 sec\n",
            "[2021-05-02 10:52:15,474 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.91.bert.pt, number of examples: 1995\n",
            "[2021-05-02 10:52:21,658 INFO] Step 200/50000; xent: 3.23; lr: 0.0000004;  28 docs/s;    138 sec\n",
            "[2021-05-02 10:52:55,611 INFO] Step 250/50000; xent: 3.10; lr: 0.0000005;  30 docs/s;    172 sec\n",
            "[2021-05-02 10:53:29,464 INFO] Step 300/50000; xent: 3.08; lr: 0.0000006;  30 docs/s;    206 sec\n",
            "[2021-05-02 10:54:03,315 INFO] Step 350/50000; xent: 3.10; lr: 0.0000007;  31 docs/s;    240 sec\n",
            "[2021-05-02 10:54:29,798 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.39.bert.pt, number of examples: 2001\n",
            "[2021-05-02 10:54:40,730 INFO] Step 400/50000; xent: 3.07; lr: 0.0000008;  28 docs/s;    277 sec\n",
            "[2021-05-02 10:55:14,453 INFO] Step 450/50000; xent: 3.09; lr: 0.0000009;  30 docs/s;    311 sec\n",
            "[2021-05-02 10:55:48,407 INFO] Step 500/50000; xent: 2.98; lr: 0.0000010;  32 docs/s;    345 sec\n",
            "[2021-05-02 10:56:22,298 INFO] Step 550/50000; xent: 3.01; lr: 0.0000011;  30 docs/s;    379 sec\n",
            "[2021-05-02 10:56:42,285 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.6.bert.pt, number of examples: 2001\n",
            "[2021-05-02 10:56:58,642 INFO] Step 600/50000; xent: 3.04; lr: 0.0000012;  28 docs/s;    415 sec\n",
            "[2021-05-02 10:57:32,607 INFO] Step 650/50000; xent: 3.12; lr: 0.0000013;  30 docs/s;    449 sec\n",
            "[2021-05-02 10:58:06,513 INFO] Step 700/50000; xent: 3.05; lr: 0.0000014;  30 docs/s;    483 sec\n",
            "[2021-05-02 10:58:40,270 INFO] Step 750/50000; xent: 2.96; lr: 0.0000015;  31 docs/s;    517 sec\n",
            "[2021-05-02 10:58:55,451 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.81.bert.pt, number of examples: 2001\n",
            "[2021-05-02 10:59:16,541 INFO] Step 800/50000; xent: 2.90; lr: 0.0000016;  29 docs/s;    553 sec\n",
            "[2021-05-02 10:59:50,472 INFO] Step 850/50000; xent: 2.96; lr: 0.0000017;  31 docs/s;    587 sec\n",
            "[2021-05-02 11:00:24,324 INFO] Step 900/50000; xent: 2.96; lr: 0.0000018;  30 docs/s;    621 sec\n",
            "[2021-05-02 11:00:58,189 INFO] Step 950/50000; xent: 3.02; lr: 0.0000019;  31 docs/s;    655 sec\n",
            "[2021-05-02 11:01:08,888 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.98.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:01:35,436 INFO] Step 1000/50000; xent: 2.85; lr: 0.0000020;  28 docs/s;    692 sec\n",
            "[2021-05-02 11:01:35,450 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_1000.pt\n",
            "[2021-05-02 11:02:15,377 INFO] Step 1050/50000; xent: 2.87; lr: 0.0000021;  26 docs/s;    732 sec\n",
            "[2021-05-02 11:02:49,239 INFO] Step 1100/50000; xent: 2.91; lr: 0.0000022;  32 docs/s;    766 sec\n",
            "[2021-05-02 11:03:22,870 INFO] Step 1150/50000; xent: 2.94; lr: 0.0000023;  30 docs/s;    799 sec\n",
            "[2021-05-02 11:03:27,062 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.93.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:03:58,959 INFO] Step 1200/50000; xent: 2.84; lr: 0.0000024;  29 docs/s;    835 sec\n",
            "[2021-05-02 11:04:32,856 INFO] Step 1250/50000; xent: 2.86; lr: 0.0000025;  30 docs/s;    869 sec\n",
            "[2021-05-02 11:05:06,779 INFO] Step 1300/50000; xent: 2.85; lr: 0.0000026;  30 docs/s;    903 sec\n",
            "[2021-05-02 11:05:40,473 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.63.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:05:42,592 INFO] Step 1350/50000; xent: 2.89; lr: 0.0000027;  28 docs/s;    939 sec\n",
            "[2021-05-02 11:06:16,258 INFO] Step 1400/50000; xent: 2.79; lr: 0.0000028;  31 docs/s;    973 sec\n",
            "[2021-05-02 11:06:50,236 INFO] Step 1450/50000; xent: 2.93; lr: 0.0000029;  30 docs/s;   1007 sec\n",
            "[2021-05-02 11:07:24,179 INFO] Step 1500/50000; xent: 2.83; lr: 0.0000030;  31 docs/s;   1041 sec\n",
            "[2021-05-02 11:07:52,490 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.15.bert.pt, number of examples: 2000\n",
            "[2021-05-02 11:08:00,055 INFO] Step 1550/50000; xent: 2.83; lr: 0.0000031;  29 docs/s;   1076 sec\n",
            "[2021-05-02 11:08:33,949 INFO] Step 1600/50000; xent: 2.92; lr: 0.0000032;  31 docs/s;   1110 sec\n",
            "[2021-05-02 11:09:07,848 INFO] Step 1650/50000; xent: 2.75; lr: 0.0000033;  31 docs/s;   1144 sec\n",
            "[2021-05-02 11:09:41,738 INFO] Step 1700/50000; xent: 2.78; lr: 0.0000034;  30 docs/s;   1178 sec\n",
            "[2021-05-02 11:10:05,827 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.64.bert.pt, number of examples: 1998\n",
            "[2021-05-02 11:10:18,122 INFO] Step 1750/50000; xent: 2.85; lr: 0.0000035;  28 docs/s;   1214 sec\n",
            "[2021-05-02 11:10:51,993 INFO] Step 1800/50000; xent: 2.93; lr: 0.0000036;  30 docs/s;   1248 sec\n",
            "[2021-05-02 11:11:25,895 INFO] Step 1850/50000; xent: 2.71; lr: 0.0000037;  32 docs/s;   1282 sec\n",
            "[2021-05-02 11:11:59,781 INFO] Step 1900/50000; xent: 2.89; lr: 0.0000038;  30 docs/s;   1316 sec\n",
            "[2021-05-02 11:12:18,072 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.28.bert.pt, number of examples: 1999\n",
            "[2021-05-02 11:12:35,533 INFO] Step 1950/50000; xent: 2.76; lr: 0.0000039;  28 docs/s;   1352 sec\n",
            "[2021-05-02 11:13:09,526 INFO] Step 2000/50000; xent: 2.84; lr: 0.0000040;  31 docs/s;   1386 sec\n",
            "[2021-05-02 11:13:09,539 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_2000.pt\n",
            "[2021-05-02 11:13:49,442 INFO] Step 2050/50000; xent: 2.80; lr: 0.0000041;  26 docs/s;   1426 sec\n",
            "[2021-05-02 11:14:23,349 INFO] Step 2100/50000; xent: 2.74; lr: 0.0000042;  30 docs/s;   1460 sec\n",
            "[2021-05-02 11:14:37,557 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.32.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:14:59,352 INFO] Step 2150/50000; xent: 2.75; lr: 0.0000043;  28 docs/s;   1496 sec\n",
            "[2021-05-02 11:15:33,229 INFO] Step 2200/50000; xent: 2.72; lr: 0.0000044;  31 docs/s;   1530 sec\n",
            "[2021-05-02 11:16:07,056 INFO] Step 2250/50000; xent: 2.79; lr: 0.0000045;  32 docs/s;   1563 sec\n",
            "[2021-05-02 11:16:40,726 INFO] Step 2300/50000; xent: 2.71; lr: 0.0000046;  30 docs/s;   1597 sec\n",
            "[2021-05-02 11:16:49,702 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.111.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:17:16,948 INFO] Step 2350/50000; xent: 2.75; lr: 0.0000047;  29 docs/s;   1633 sec\n",
            "[2021-05-02 11:17:50,832 INFO] Step 2400/50000; xent: 2.73; lr: 0.0000048;  31 docs/s;   1667 sec\n",
            "[2021-05-02 11:18:24,737 INFO] Step 2450/50000; xent: 2.76; lr: 0.0000049;  31 docs/s;   1701 sec\n",
            "[2021-05-02 11:18:58,781 INFO] Step 2500/50000; xent: 2.80; lr: 0.0000050;  31 docs/s;   1735 sec\n",
            "[2021-05-02 11:19:01,560 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.49.bert.pt, number of examples: 2000\n",
            "[2021-05-02 11:19:34,679 INFO] Step 2550/50000; xent: 2.69; lr: 0.0000051;  29 docs/s;   1771 sec\n",
            "[2021-05-02 11:20:08,552 INFO] Step 2600/50000; xent: 2.74; lr: 0.0000052;  31 docs/s;   1805 sec\n",
            "[2021-05-02 11:20:42,502 INFO] Step 2650/50000; xent: 2.72; lr: 0.0000053;  31 docs/s;   1839 sec\n",
            "[2021-05-02 11:21:14,313 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.59.bert.pt, number of examples: 2000\n",
            "[2021-05-02 11:21:18,475 INFO] Step 2700/50000; xent: 2.74; lr: 0.0000054;  29 docs/s;   1875 sec\n",
            "[2021-05-02 11:21:52,401 INFO] Step 2750/50000; xent: 2.74; lr: 0.0000055;  30 docs/s;   1909 sec\n",
            "[2021-05-02 11:22:26,293 INFO] Step 2800/50000; xent: 2.75; lr: 0.0000056;  31 docs/s;   1943 sec\n",
            "[2021-05-02 11:23:00,229 INFO] Step 2850/50000; xent: 2.73; lr: 0.0000057;  30 docs/s;   1977 sec\n",
            "[2021-05-02 11:23:26,639 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.84.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:23:36,211 INFO] Step 2900/50000; xent: 2.71; lr: 0.0000058;  29 docs/s;   2013 sec\n",
            "[2021-05-02 11:24:10,173 INFO] Step 2950/50000; xent: 2.76; lr: 0.0000059;  30 docs/s;   2047 sec\n",
            "[2021-05-02 11:24:44,062 INFO] Step 3000/50000; xent: 2.67; lr: 0.0000060;  32 docs/s;   2080 sec\n",
            "[2021-05-02 11:24:44,076 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_3000.pt\n",
            "[2021-05-02 11:25:24,066 INFO] Step 3050/50000; xent: 2.70; lr: 0.0000061;  25 docs/s;   2120 sec\n",
            "[2021-05-02 11:25:45,897 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.137.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:26:00,228 INFO] Step 3100/50000; xent: 2.75; lr: 0.0000062;  29 docs/s;   2157 sec\n",
            "[2021-05-02 11:26:34,159 INFO] Step 3150/50000; xent: 2.74; lr: 0.0000063;  30 docs/s;   2191 sec\n",
            "[2021-05-02 11:27:07,999 INFO] Step 3200/50000; xent: 2.82; lr: 0.0000064;  30 docs/s;   2224 sec\n",
            "[2021-05-02 11:27:41,882 INFO] Step 3250/50000; xent: 2.68; lr: 0.0000065;  31 docs/s;   2258 sec\n",
            "[2021-05-02 11:27:58,752 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.13.bert.pt, number of examples: 2000\n",
            "[2021-05-02 11:28:17,835 INFO] Step 3300/50000; xent: 2.69; lr: 0.0000066;  29 docs/s;   2294 sec\n",
            "[2021-05-02 11:28:51,590 INFO] Step 3350/50000; xent: 2.74; lr: 0.0000067;  30 docs/s;   2328 sec\n",
            "[2021-05-02 11:29:25,551 INFO] Step 3400/50000; xent: 2.71; lr: 0.0000068;  32 docs/s;   2362 sec\n",
            "[2021-05-02 11:29:59,495 INFO] Step 3450/50000; xent: 2.70; lr: 0.0000069;  31 docs/s;   2396 sec\n",
            "[2021-05-02 11:30:10,964 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.135.bert.pt, number of examples: 2000\n",
            "[2021-05-02 11:30:35,487 INFO] Step 3500/50000; xent: 2.72; lr: 0.0000070;  28 docs/s;   2432 sec\n",
            "[2021-05-02 11:31:09,423 INFO] Step 3550/50000; xent: 2.76; lr: 0.0000071;  31 docs/s;   2466 sec\n",
            "[2021-05-02 11:31:43,359 INFO] Step 3600/50000; xent: 2.71; lr: 0.0000072;  31 docs/s;   2500 sec\n",
            "[2021-05-02 11:32:17,262 INFO] Step 3650/50000; xent: 2.72; lr: 0.0000073;  31 docs/s;   2534 sec\n",
            "[2021-05-02 11:32:24,251 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.71.bert.pt, number of examples: 1999\n",
            "[2021-05-02 11:32:53,514 INFO] Step 3700/50000; xent: 2.70; lr: 0.0000074;  28 docs/s;   2570 sec\n",
            "[2021-05-02 11:33:27,405 INFO] Step 3750/50000; xent: 2.69; lr: 0.0000075;  31 docs/s;   2604 sec\n",
            "[2021-05-02 11:34:01,410 INFO] Step 3800/50000; xent: 2.81; lr: 0.0000076;  31 docs/s;   2638 sec\n",
            "[2021-05-02 11:34:36,721 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.9.bert.pt, number of examples: 2000\n",
            "[2021-05-02 11:34:37,487 INFO] Step 3850/50000; xent: 2.68; lr: 0.0000077;  28 docs/s;   2674 sec\n",
            "[2021-05-02 11:35:11,433 INFO] Step 3900/50000; xent: 2.65; lr: 0.0000078;  31 docs/s;   2708 sec\n",
            "[2021-05-02 11:35:45,234 INFO] Step 3950/50000; xent: 2.73; lr: 0.0000079;  31 docs/s;   2742 sec\n",
            "[2021-05-02 11:36:19,163 INFO] Step 4000/50000; xent: 2.63; lr: 0.0000080;  30 docs/s;   2776 sec\n",
            "[2021-05-02 11:36:19,177 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_4000.pt\n",
            "[2021-05-02 11:36:55,945 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.105.bert.pt, number of examples: 2000\n",
            "[2021-05-02 11:37:01,388 INFO] Step 4050/50000; xent: 2.67; lr: 0.0000081;  24 docs/s;   2818 sec\n",
            "[2021-05-02 11:37:35,439 INFO] Step 4100/50000; xent: 2.74; lr: 0.0000082;  30 docs/s;   2852 sec\n",
            "[2021-05-02 11:38:09,470 INFO] Step 4150/50000; xent: 2.84; lr: 0.0000083;  31 docs/s;   2886 sec\n",
            "[2021-05-02 11:38:43,420 INFO] Step 4200/50000; xent: 2.76; lr: 0.0000084;  31 docs/s;   2920 sec\n",
            "[2021-05-02 11:39:09,529 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.50.bert.pt, number of examples: 1999\n",
            "[2021-05-02 11:39:19,806 INFO] Step 4250/50000; xent: 2.71; lr: 0.0000085;  28 docs/s;   2956 sec\n",
            "[2021-05-02 11:39:53,768 INFO] Step 4300/50000; xent: 2.73; lr: 0.0000086;  31 docs/s;   2990 sec\n",
            "[2021-05-02 11:40:27,814 INFO] Step 4350/50000; xent: 2.74; lr: 0.0000087;  30 docs/s;   3024 sec\n",
            "[2021-05-02 11:41:01,839 INFO] Step 4400/50000; xent: 2.67; lr: 0.0000088;  30 docs/s;   3058 sec\n",
            "[2021-05-02 11:41:22,768 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.106.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:41:37,794 INFO] Step 4450/50000; xent: 2.65; lr: 0.0000089;  29 docs/s;   3094 sec\n",
            "[2021-05-02 11:42:11,787 INFO] Step 4500/50000; xent: 2.70; lr: 0.0000090;  32 docs/s;   3128 sec\n",
            "[2021-05-02 11:42:45,608 INFO] Step 4550/50000; xent: 2.76; lr: 0.0000091;  30 docs/s;   3162 sec\n",
            "[2021-05-02 11:43:19,234 INFO] Step 4600/50000; xent: 2.65; lr: 0.0000092;  30 docs/s;   3196 sec\n",
            "[2021-05-02 11:43:33,741 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.38.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:43:54,169 INFO] Step 4650/50000; xent: 2.62; lr: 0.0000093;  30 docs/s;   3231 sec\n",
            "[2021-05-02 11:44:27,929 INFO] Step 4700/50000; xent: 2.65; lr: 0.0000094;  30 docs/s;   3264 sec\n",
            "[2021-05-02 11:45:01,832 INFO] Step 4750/50000; xent: 2.70; lr: 0.0000095;  31 docs/s;   3298 sec\n",
            "[2021-05-02 11:45:35,685 INFO] Step 4800/50000; xent: 2.71; lr: 0.0000096;  30 docs/s;   3332 sec\n",
            "[2021-05-02 11:45:46,654 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.24.bert.pt, number of examples: 1999\n",
            "[2021-05-02 11:46:11,856 INFO] Step 4850/50000; xent: 2.65; lr: 0.0000097;  29 docs/s;   3368 sec\n",
            "[2021-05-02 11:46:45,627 INFO] Step 4900/50000; xent: 2.73; lr: 0.0000098;  31 docs/s;   3402 sec\n",
            "[2021-05-02 11:47:19,543 INFO] Step 4950/50000; xent: 2.71; lr: 0.0000099;  30 docs/s;   3436 sec\n",
            "[2021-05-02 11:47:53,315 INFO] Step 5000/50000; xent: 2.67; lr: 0.0000100;  31 docs/s;   3470 sec\n",
            "[2021-05-02 11:47:53,317 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_5000.pt\n",
            "[2021-05-02 11:48:05,979 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.143.bert.pt, number of examples: 1084\n",
            "[2021-05-02 11:48:36,666 INFO] Step 5050/50000; xent: 2.67; lr: 0.0000101;  25 docs/s;   3513 sec\n",
            "[2021-05-02 11:49:10,346 INFO] Step 5100/50000; xent: 2.67; lr: 0.0000102;  30 docs/s;   3547 sec\n",
            "[2021-05-02 11:49:18,905 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.94.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:49:46,819 INFO] Step 5150/50000; xent: 2.67; lr: 0.0000103;  28 docs/s;   3583 sec\n",
            "[2021-05-02 11:50:20,651 INFO] Step 5200/50000; xent: 2.68; lr: 0.0000104;  30 docs/s;   3617 sec\n",
            "[2021-05-02 11:50:54,364 INFO] Step 5250/50000; xent: 2.73; lr: 0.0000105;  31 docs/s;   3651 sec\n",
            "[2021-05-02 11:51:27,999 INFO] Step 5300/50000; xent: 2.58; lr: 0.0000106;  31 docs/s;   3684 sec\n",
            "[2021-05-02 11:51:31,442 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.62.bert.pt, number of examples: 2001\n",
            "[2021-05-02 11:52:04,083 INFO] Step 5350/50000; xent: 2.74; lr: 0.0000107;  29 docs/s;   3720 sec\n",
            "[2021-05-02 11:52:37,913 INFO] Step 5400/50000; xent: 2.71; lr: 0.0000108;  31 docs/s;   3754 sec\n",
            "[2021-05-02 11:53:11,801 INFO] Step 5450/50000; xent: 2.62; lr: 0.0000109;  31 docs/s;   3788 sec\n",
            "[2021-05-02 11:53:43,778 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.139.bert.pt, number of examples: 2000\n",
            "[2021-05-02 11:53:47,919 INFO] Step 5500/50000; xent: 2.67; lr: 0.0000110;  28 docs/s;   3824 sec\n",
            "[2021-05-02 11:54:21,814 INFO] Step 5550/50000; xent: 2.65; lr: 0.0000111;  30 docs/s;   3858 sec\n",
            "[2021-05-02 11:54:55,422 INFO] Step 5600/50000; xent: 2.64; lr: 0.0000112;  31 docs/s;   3892 sec\n",
            "[2021-05-02 11:55:29,363 INFO] Step 5650/50000; xent: 2.66; lr: 0.0000113;  31 docs/s;   3926 sec\n",
            "[2021-05-02 11:55:56,610 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.88.bert.pt, number of examples: 2000\n",
            "[2021-05-02 11:56:05,496 INFO] Step 5700/50000; xent: 2.71; lr: 0.0000114;  29 docs/s;   3962 sec\n",
            "[2021-05-02 11:56:39,274 INFO] Step 5750/50000; xent: 2.63; lr: 0.0000115;  30 docs/s;   3996 sec\n",
            "[2021-05-02 11:57:13,149 INFO] Step 5800/50000; xent: 2.66; lr: 0.0000116;  31 docs/s;   4030 sec\n",
            "[2021-05-02 11:57:47,101 INFO] Step 5850/50000; xent: 2.74; lr: 0.0000117;  31 docs/s;   4063 sec\n",
            "[2021-05-02 11:58:09,472 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.92.bert.pt, number of examples: 1998\n",
            "[2021-05-02 11:58:23,139 INFO] Step 5900/50000; xent: 2.76; lr: 0.0000118;  28 docs/s;   4100 sec\n",
            "[2021-05-02 11:58:57,116 INFO] Step 5950/50000; xent: 2.66; lr: 0.0000119;  31 docs/s;   4133 sec\n",
            "[2021-05-02 11:59:30,859 INFO] Step 6000/50000; xent: 2.65; lr: 0.0000120;  30 docs/s;   4167 sec\n",
            "[2021-05-02 11:59:30,873 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_6000.pt\n",
            "[2021-05-02 12:00:10,693 INFO] Step 6050/50000; xent: 2.57; lr: 0.0000121;  27 docs/s;   4207 sec\n",
            "[2021-05-02 12:00:27,610 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.68.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:00:46,655 INFO] Step 6100/50000; xent: 2.61; lr: 0.0000122;  28 docs/s;   4243 sec\n",
            "[2021-05-02 12:01:20,561 INFO] Step 6150/50000; xent: 2.61; lr: 0.0000123;  31 docs/s;   4277 sec\n",
            "[2021-05-02 12:01:54,261 INFO] Step 6200/50000; xent: 2.77; lr: 0.0000124;  31 docs/s;   4311 sec\n",
            "[2021-05-02 12:02:28,152 INFO] Step 6250/50000; xent: 2.63; lr: 0.0000125;  31 docs/s;   4345 sec\n",
            "[2021-05-02 12:02:40,374 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.0.bert.pt, number of examples: 2000\n",
            "[2021-05-02 12:03:04,150 INFO] Step 6300/50000; xent: 2.64; lr: 0.0000126;  29 docs/s;   4381 sec\n",
            "[2021-05-02 12:03:38,063 INFO] Step 6350/50000; xent: 2.63; lr: 0.0000127;  31 docs/s;   4414 sec\n",
            "[2021-05-02 12:04:11,964 INFO] Step 6400/50000; xent: 2.69; lr: 0.0000128;  30 docs/s;   4448 sec\n",
            "[2021-05-02 12:04:45,602 INFO] Step 6450/50000; xent: 2.67; lr: 0.0000129;  31 docs/s;   4482 sec\n",
            "[2021-05-02 12:04:52,988 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.83.bert.pt, number of examples: 1999\n",
            "[2021-05-02 12:05:21,571 INFO] Step 6500/50000; xent: 2.68; lr: 0.0000130;  29 docs/s;   4518 sec\n",
            "[2021-05-02 12:05:55,169 INFO] Step 6550/50000; xent: 2.63; lr: 0.0000131;  31 docs/s;   4552 sec\n",
            "[2021-05-02 12:06:29,128 INFO] Step 6600/50000; xent: 2.62; lr: 0.0000132;  31 docs/s;   4585 sec\n",
            "[2021-05-02 12:07:02,829 INFO] Step 6650/50000; xent: 2.62; lr: 0.0000133;  30 docs/s;   4619 sec\n",
            "[2021-05-02 12:07:04,980 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.138.bert.pt, number of examples: 2000\n",
            "[2021-05-02 12:07:39,012 INFO] Step 6700/50000; xent: 2.65; lr: 0.0000134;  29 docs/s;   4655 sec\n",
            "[2021-05-02 12:08:12,942 INFO] Step 6750/50000; xent: 2.69; lr: 0.0000135;  32 docs/s;   4689 sec\n",
            "[2021-05-02 12:08:46,834 INFO] Step 6800/50000; xent: 2.73; lr: 0.0000136;  30 docs/s;   4723 sec\n",
            "[2021-05-02 12:09:20,095 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.72.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:09:25,603 INFO] Step 6850/50000; xent: 2.61; lr: 0.0000137;  27 docs/s;   4762 sec\n",
            "[2021-05-02 12:09:59,978 INFO] Step 6900/50000; xent: 2.65; lr: 0.0000138;  31 docs/s;   4796 sec\n",
            "[2021-05-02 12:10:34,834 INFO] Step 6950/50000; xent: 2.74; lr: 0.0000139;  31 docs/s;   4831 sec\n",
            "[2021-05-02 12:11:08,709 INFO] Step 7000/50000; xent: 2.59; lr: 0.0000140;  31 docs/s;   4865 sec\n",
            "[2021-05-02 12:11:08,723 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_7000.pt\n",
            "[2021-05-02 12:11:41,834 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.89.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:11:52,096 INFO] Step 7050/50000; xent: 2.58; lr: 0.0000141;  24 docs/s;   4908 sec\n",
            "[2021-05-02 12:12:25,968 INFO] Step 7100/50000; xent: 2.60; lr: 0.0000142;  31 docs/s;   4942 sec\n",
            "[2021-05-02 12:12:59,667 INFO] Step 7150/50000; xent: 2.70; lr: 0.0000143;  31 docs/s;   4976 sec\n",
            "[2021-05-02 12:13:33,533 INFO] Step 7200/50000; xent: 2.67; lr: 0.0000144;  30 docs/s;   5010 sec\n",
            "[2021-05-02 12:13:54,441 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.51.bert.pt, number of examples: 1999\n",
            "[2021-05-02 12:14:09,412 INFO] Step 7250/50000; xent: 2.63; lr: 0.0000145;  29 docs/s;   5046 sec\n",
            "[2021-05-02 12:14:43,324 INFO] Step 7300/50000; xent: 2.68; lr: 0.0000146;  31 docs/s;   5080 sec\n",
            "[2021-05-02 12:15:16,931 INFO] Step 7350/50000; xent: 2.65; lr: 0.0000147;  30 docs/s;   5113 sec\n",
            "[2021-05-02 12:15:50,828 INFO] Step 7400/50000; xent: 2.55; lr: 0.0000148;  31 docs/s;   5147 sec\n",
            "[2021-05-02 12:16:08,878 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.35.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:16:27,963 INFO] Step 7450/50000; xent: 2.61; lr: 0.0000149;  28 docs/s;   5184 sec\n",
            "[2021-05-02 12:17:01,960 INFO] Step 7500/50000; xent: 2.74; lr: 0.0000150;  31 docs/s;   5218 sec\n",
            "[2021-05-02 12:17:35,837 INFO] Step 7550/50000; xent: 2.67; lr: 0.0000151;  31 docs/s;   5252 sec\n",
            "[2021-05-02 12:18:09,829 INFO] Step 7600/50000; xent: 2.70; lr: 0.0000152;  31 docs/s;   5286 sec\n",
            "[2021-05-02 12:18:21,476 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.37.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:18:45,823 INFO] Step 7650/50000; xent: 2.68; lr: 0.0000153;  28 docs/s;   5322 sec\n",
            "[2021-05-02 12:19:19,758 INFO] Step 7700/50000; xent: 2.62; lr: 0.0000154;  31 docs/s;   5356 sec\n",
            "[2021-05-02 12:19:53,753 INFO] Step 7750/50000; xent: 2.64; lr: 0.0000155;  31 docs/s;   5390 sec\n",
            "[2021-05-02 12:20:27,675 INFO] Step 7800/50000; xent: 2.63; lr: 0.0000156;  31 docs/s;   5424 sec\n",
            "[2021-05-02 12:20:33,878 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.80.bert.pt, number of examples: 2000\n",
            "[2021-05-02 12:21:03,823 INFO] Step 7850/50000; xent: 2.66; lr: 0.0000157;  29 docs/s;   5460 sec\n",
            "[2021-05-02 12:21:37,758 INFO] Step 7900/50000; xent: 2.67; lr: 0.0000158;  30 docs/s;   5494 sec\n",
            "[2021-05-02 12:22:11,725 INFO] Step 7950/50000; xent: 2.70; lr: 0.0000159;  31 docs/s;   5528 sec\n",
            "[2021-05-02 12:22:46,762 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.52.bert.pt, number of examples: 1999\n",
            "[2021-05-02 12:22:47,530 INFO] Step 8000/50000; xent: 2.64; lr: 0.0000160;  29 docs/s;   5564 sec\n",
            "[2021-05-02 12:22:47,544 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_8000.pt\n",
            "[2021-05-02 12:23:27,127 INFO] Step 8050/50000; xent: 2.58; lr: 0.0000161;  27 docs/s;   5603 sec\n",
            "[2021-05-02 12:24:01,093 INFO] Step 8100/50000; xent: 2.61; lr: 0.0000162;  31 docs/s;   5637 sec\n",
            "[2021-05-02 12:24:35,116 INFO] Step 8150/50000; xent: 2.64; lr: 0.0000163;  30 docs/s;   5671 sec\n",
            "[2021-05-02 12:25:05,020 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.12.bert.pt, number of examples: 1998\n",
            "[2021-05-02 12:25:11,217 INFO] Step 8200/50000; xent: 2.74; lr: 0.0000164;  29 docs/s;   5708 sec\n",
            "[2021-05-02 12:25:45,105 INFO] Step 8250/50000; xent: 2.66; lr: 0.0000165;  31 docs/s;   5741 sec\n",
            "[2021-05-02 12:26:19,125 INFO] Step 8300/50000; xent: 2.68; lr: 0.0000166;  31 docs/s;   5775 sec\n",
            "[2021-05-02 12:26:53,623 INFO] Step 8350/50000; xent: 2.67; lr: 0.0000167;  30 docs/s;   5810 sec\n",
            "[2021-05-02 12:27:17,967 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.114.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:27:29,594 INFO] Step 8400/50000; xent: 2.61; lr: 0.0000168;  29 docs/s;   5846 sec\n",
            "[2021-05-02 12:28:03,586 INFO] Step 8450/50000; xent: 2.64; lr: 0.0000169;  30 docs/s;   5880 sec\n",
            "[2021-05-02 12:28:37,261 INFO] Step 8500/50000; xent: 2.64; lr: 0.0000170;  31 docs/s;   5914 sec\n",
            "[2021-05-02 12:29:11,226 INFO] Step 8550/50000; xent: 2.74; lr: 0.0000171;  30 docs/s;   5948 sec\n",
            "[2021-05-02 12:29:30,814 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.86.bert.pt, number of examples: 1999\n",
            "[2021-05-02 12:29:47,221 INFO] Step 8600/50000; xent: 2.69; lr: 0.0000172;  28 docs/s;   5984 sec\n",
            "[2021-05-02 12:30:21,169 INFO] Step 8650/50000; xent: 2.68; lr: 0.0000173;  30 docs/s;   6018 sec\n",
            "[2021-05-02 12:30:54,884 INFO] Step 8700/50000; xent: 2.68; lr: 0.0000174;  32 docs/s;   6051 sec\n",
            "[2021-05-02 12:31:28,895 INFO] Step 8750/50000; xent: 2.56; lr: 0.0000175;  31 docs/s;   6085 sec\n",
            "[2021-05-02 12:31:43,253 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.113.bert.pt, number of examples: 2000\n",
            "[2021-05-02 12:32:04,897 INFO] Step 8800/50000; xent: 2.69; lr: 0.0000176;  29 docs/s;   6121 sec\n",
            "[2021-05-02 12:32:38,863 INFO] Step 8850/50000; xent: 2.62; lr: 0.0000177;  31 docs/s;   6155 sec\n",
            "[2021-05-02 12:33:12,857 INFO] Step 8900/50000; xent: 2.71; lr: 0.0000178;  30 docs/s;   6189 sec\n",
            "[2021-05-02 12:33:46,676 INFO] Step 8950/50000; xent: 2.67; lr: 0.0000179;  31 docs/s;   6223 sec\n",
            "[2021-05-02 12:33:55,568 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.96.bert.pt, number of examples: 1999\n",
            "[2021-05-02 12:34:22,177 INFO] Step 9000/50000; xent: 2.68; lr: 0.0000180;  30 docs/s;   6259 sec\n",
            "[2021-05-02 12:34:22,193 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_9000.pt\n",
            "[2021-05-02 12:35:03,060 INFO] Step 9050/50000; xent: 2.68; lr: 0.0000181;  26 docs/s;   6299 sec\n",
            "[2021-05-02 12:35:37,037 INFO] Step 9100/50000; xent: 2.63; lr: 0.0000182;  30 docs/s;   6333 sec\n",
            "[2021-05-02 12:36:10,904 INFO] Step 9150/50000; xent: 2.66; lr: 0.0000183;  31 docs/s;   6367 sec\n",
            "[2021-05-02 12:36:15,171 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.131.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:36:47,000 INFO] Step 9200/50000; xent: 2.63; lr: 0.0000184;  29 docs/s;   6403 sec\n",
            "[2021-05-02 12:37:20,897 INFO] Step 9250/50000; xent: 2.73; lr: 0.0000185;  31 docs/s;   6437 sec\n",
            "[2021-05-02 12:37:54,764 INFO] Step 9300/50000; xent: 2.67; lr: 0.0000186;  31 docs/s;   6471 sec\n",
            "[2021-05-02 12:38:27,442 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.97.bert.pt, number of examples: 2000\n",
            "[2021-05-02 12:38:30,913 INFO] Step 9350/50000; xent: 2.72; lr: 0.0000187;  29 docs/s;   6507 sec\n",
            "[2021-05-02 12:39:04,784 INFO] Step 9400/50000; xent: 2.64; lr: 0.0000188;  31 docs/s;   6541 sec\n",
            "[2021-05-02 12:39:38,675 INFO] Step 9450/50000; xent: 2.63; lr: 0.0000189;  31 docs/s;   6575 sec\n",
            "[2021-05-02 12:40:12,429 INFO] Step 9500/50000; xent: 2.71; lr: 0.0000190;  30 docs/s;   6609 sec\n",
            "[2021-05-02 12:40:41,017 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.55.bert.pt, number of examples: 1999\n",
            "[2021-05-02 12:40:48,540 INFO] Step 9550/50000; xent: 2.71; lr: 0.0000191;  28 docs/s;   6645 sec\n",
            "[2021-05-02 12:41:22,439 INFO] Step 9600/50000; xent: 2.63; lr: 0.0000192;  31 docs/s;   6679 sec\n",
            "[2021-05-02 12:41:56,306 INFO] Step 9650/50000; xent: 2.65; lr: 0.0000193;  31 docs/s;   6713 sec\n",
            "[2021-05-02 12:42:30,176 INFO] Step 9700/50000; xent: 2.61; lr: 0.0000194;  31 docs/s;   6747 sec\n",
            "[2021-05-02 12:42:52,802 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.128.bert.pt, number of examples: 2000\n",
            "[2021-05-02 12:43:06,424 INFO] Step 9750/50000; xent: 2.65; lr: 0.0000195;  28 docs/s;   6783 sec\n",
            "[2021-05-02 12:43:40,348 INFO] Step 9800/50000; xent: 2.64; lr: 0.0000196;  31 docs/s;   6817 sec\n",
            "[2021-05-02 12:44:14,035 INFO] Step 9850/50000; xent: 2.69; lr: 0.0000197;  31 docs/s;   6850 sec\n",
            "[2021-05-02 12:44:47,927 INFO] Step 9900/50000; xent: 2.58; lr: 0.0000198;  31 docs/s;   6884 sec\n",
            "[2021-05-02 12:45:04,689 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.104.bert.pt, number of examples: 2000\n",
            "[2021-05-02 12:45:23,557 INFO] Step 9950/50000; xent: 2.58; lr: 0.0000199;  29 docs/s;   6920 sec\n",
            "[2021-05-02 12:45:57,458 INFO] Step 10000/50000; xent: 2.66; lr: 0.0000200;  30 docs/s;   6954 sec\n",
            "[2021-05-02 12:45:57,473 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_10000.pt\n",
            "[2021-05-02 12:46:38,051 INFO] Step 10050/50000; xent: 2.62; lr: 0.0000200;  27 docs/s;   6994 sec\n",
            "[2021-05-02 12:47:11,846 INFO] Step 10100/50000; xent: 2.64; lr: 0.0000199;  30 docs/s;   7028 sec\n",
            "[2021-05-02 12:47:23,407 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.118.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:47:47,940 INFO] Step 10150/50000; xent: 2.67; lr: 0.0000199;  29 docs/s;   7064 sec\n",
            "[2021-05-02 12:48:21,688 INFO] Step 10200/50000; xent: 2.56; lr: 0.0000198;  31 docs/s;   7098 sec\n",
            "[2021-05-02 12:48:55,428 INFO] Step 10250/50000; xent: 2.69; lr: 0.0000198;  31 docs/s;   7132 sec\n",
            "[2021-05-02 12:49:29,385 INFO] Step 10300/50000; xent: 2.49; lr: 0.0000197;  31 docs/s;   7166 sec\n",
            "[2021-05-02 12:49:35,466 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.47.bert.pt, number of examples: 2000\n",
            "[2021-05-02 12:50:05,350 INFO] Step 10350/50000; xent: 2.66; lr: 0.0000197;  29 docs/s;   7202 sec\n",
            "[2021-05-02 12:50:39,242 INFO] Step 10400/50000; xent: 2.65; lr: 0.0000196;  30 docs/s;   7236 sec\n",
            "[2021-05-02 12:51:13,058 INFO] Step 10450/50000; xent: 2.66; lr: 0.0000196;  31 docs/s;   7269 sec\n",
            "[2021-05-02 12:51:47,785 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.8.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:51:49,223 INFO] Step 10500/50000; xent: 2.70; lr: 0.0000195;  29 docs/s;   7306 sec\n",
            "[2021-05-02 12:52:23,131 INFO] Step 10550/50000; xent: 2.66; lr: 0.0000195;  31 docs/s;   7339 sec\n",
            "[2021-05-02 12:52:56,805 INFO] Step 10600/50000; xent: 2.64; lr: 0.0000194;  31 docs/s;   7373 sec\n",
            "[2021-05-02 12:53:30,710 INFO] Step 10650/50000; xent: 2.61; lr: 0.0000194;  31 docs/s;   7407 sec\n",
            "[2021-05-02 12:53:59,476 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.11.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:54:06,362 INFO] Step 10700/50000; xent: 2.61; lr: 0.0000193;  29 docs/s;   7443 sec\n",
            "[2021-05-02 12:54:40,196 INFO] Step 10750/50000; xent: 2.67; lr: 0.0000193;  31 docs/s;   7477 sec\n",
            "[2021-05-02 12:55:14,066 INFO] Step 10800/50000; xent: 2.57; lr: 0.0000192;  31 docs/s;   7510 sec\n",
            "[2021-05-02 12:55:47,889 INFO] Step 10850/50000; xent: 2.53; lr: 0.0000192;  31 docs/s;   7544 sec\n",
            "[2021-05-02 12:56:12,046 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.66.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:56:23,662 INFO] Step 10900/50000; xent: 2.66; lr: 0.0000192;  29 docs/s;   7580 sec\n",
            "[2021-05-02 12:56:57,546 INFO] Step 10950/50000; xent: 2.63; lr: 0.0000191;  31 docs/s;   7614 sec\n",
            "[2021-05-02 12:57:31,430 INFO] Step 11000/50000; xent: 2.65; lr: 0.0000191;  31 docs/s;   7648 sec\n",
            "[2021-05-02 12:57:31,445 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_11000.pt\n",
            "[2021-05-02 12:58:11,634 INFO] Step 11050/50000; xent: 2.73; lr: 0.0000190;  26 docs/s;   7688 sec\n",
            "[2021-05-02 12:58:30,560 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.36.bert.pt, number of examples: 2001\n",
            "[2021-05-02 12:58:47,540 INFO] Step 11100/50000; xent: 2.56; lr: 0.0000190;  29 docs/s;   7724 sec\n",
            "[2021-05-02 12:59:21,386 INFO] Step 11150/50000; xent: 2.58; lr: 0.0000189;  31 docs/s;   7758 sec\n",
            "[2021-05-02 12:59:55,264 INFO] Step 11200/50000; xent: 2.67; lr: 0.0000189;  31 docs/s;   7792 sec\n",
            "[2021-05-02 13:00:28,996 INFO] Step 11250/50000; xent: 2.86; lr: 0.0000189;  30 docs/s;   7825 sec\n",
            "[2021-05-02 13:00:43,580 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.73.bert.pt, number of examples: 2001\n",
            "[2021-05-02 13:01:05,391 INFO] Step 11300/50000; xent: 2.95; lr: 0.0000188;  28 docs/s;   7862 sec\n",
            "[2021-05-02 13:01:39,244 INFO] Step 11350/50000; xent: 2.65; lr: 0.0000188;  31 docs/s;   7896 sec\n",
            "[2021-05-02 13:02:12,929 INFO] Step 11400/50000; xent: 2.65; lr: 0.0000187;  31 docs/s;   7929 sec\n",
            "[2021-05-02 13:02:46,838 INFO] Step 11450/50000; xent: 2.64; lr: 0.0000187;  30 docs/s;   7963 sec\n",
            "[2021-05-02 13:02:56,253 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.33.bert.pt, number of examples: 1997\n",
            "[2021-05-02 13:03:22,626 INFO] Step 11500/50000; xent: 2.66; lr: 0.0000187;  29 docs/s;   7999 sec\n",
            "[2021-05-02 13:03:56,457 INFO] Step 11550/50000; xent: 2.71; lr: 0.0000186;  30 docs/s;   8033 sec\n",
            "[2021-05-02 13:04:30,346 INFO] Step 11600/50000; xent: 2.63; lr: 0.0000186;  31 docs/s;   8067 sec\n",
            "[2021-05-02 13:05:04,054 INFO] Step 11650/50000; xent: 2.61; lr: 0.0000185;  31 docs/s;   8100 sec\n",
            "[2021-05-02 13:05:08,238 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.121.bert.pt, number of examples: 1999\n",
            "[2021-05-02 13:05:40,170 INFO] Step 11700/50000; xent: 2.71; lr: 0.0000185;  29 docs/s;   8137 sec\n",
            "[2021-05-02 13:06:13,988 INFO] Step 11750/50000; xent: 2.60; lr: 0.0000185;  30 docs/s;   8170 sec\n",
            "[2021-05-02 13:06:47,743 INFO] Step 11800/50000; xent: 2.63; lr: 0.0000184;  31 docs/s;   8204 sec\n",
            "[2021-05-02 13:07:20,406 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.136.bert.pt, number of examples: 1998\n",
            "[2021-05-02 13:07:23,875 INFO] Step 11850/50000; xent: 2.59; lr: 0.0000184;  29 docs/s;   8240 sec\n",
            "[2021-05-02 13:07:57,781 INFO] Step 11900/50000; xent: 2.64; lr: 0.0000183;  31 docs/s;   8274 sec\n",
            "[2021-05-02 13:08:31,620 INFO] Step 11950/50000; xent: 2.65; lr: 0.0000183;  31 docs/s;   8308 sec\n",
            "[2021-05-02 13:09:05,432 INFO] Step 12000/50000; xent: 2.63; lr: 0.0000183;  31 docs/s;   8342 sec\n",
            "[2021-05-02 13:09:05,447 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_12000.pt\n",
            "[2021-05-02 13:09:38,162 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.20.bert.pt, number of examples: 2000\n",
            "[2021-05-02 13:09:47,060 INFO] Step 12050/50000; xent: 2.61; lr: 0.0000182;  24 docs/s;   8383 sec\n",
            "[2021-05-02 13:10:20,977 INFO] Step 12100/50000; xent: 2.77; lr: 0.0000182;  31 docs/s;   8417 sec\n",
            "[2021-05-02 13:10:54,775 INFO] Step 12150/50000; xent: 2.59; lr: 0.0000181;  31 docs/s;   8451 sec\n",
            "[2021-05-02 13:11:28,380 INFO] Step 12200/50000; xent: 2.62; lr: 0.0000181;  31 docs/s;   8485 sec\n",
            "[2021-05-02 13:11:49,449 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.61.bert.pt, number of examples: 1999\n",
            "[2021-05-02 13:12:03,716 INFO] Step 12250/50000; xent: 2.65; lr: 0.0000181;  29 docs/s;   8520 sec\n",
            "[2021-05-02 13:12:37,552 INFO] Step 12300/50000; xent: 2.66; lr: 0.0000180;  31 docs/s;   8554 sec\n",
            "[2021-05-02 13:13:11,198 INFO] Step 12350/50000; xent: 2.67; lr: 0.0000180;  31 docs/s;   8588 sec\n",
            "[2021-05-02 13:13:45,061 INFO] Step 12400/50000; xent: 2.62; lr: 0.0000180;  31 docs/s;   8621 sec\n",
            "[2021-05-02 13:14:02,025 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.45.bert.pt, number of examples: 2000\n",
            "[2021-05-02 13:14:21,053 INFO] Step 12450/50000; xent: 2.56; lr: 0.0000179;  29 docs/s;   8657 sec\n",
            "[2021-05-02 13:14:54,850 INFO] Step 12500/50000; xent: 2.56; lr: 0.0000179;  31 docs/s;   8691 sec\n",
            "[2021-05-02 13:15:28,651 INFO] Step 12550/50000; xent: 2.59; lr: 0.0000179;  30 docs/s;   8725 sec\n",
            "[2021-05-02 13:16:02,480 INFO] Step 12600/50000; xent: 2.63; lr: 0.0000178;  30 docs/s;   8759 sec\n",
            "[2021-05-02 13:16:14,641 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.134.bert.pt, number of examples: 2000\n",
            "[2021-05-02 13:16:38,375 INFO] Step 12650/50000; xent: 2.60; lr: 0.0000178;  29 docs/s;   8795 sec\n",
            "[2021-05-02 13:17:12,197 INFO] Step 12700/50000; xent: 2.65; lr: 0.0000177;  30 docs/s;   8829 sec\n",
            "[2021-05-02 13:17:46,073 INFO] Step 12750/50000; xent: 2.61; lr: 0.0000177;  31 docs/s;   8862 sec\n",
            "[2021-05-02 13:18:19,961 INFO] Step 12800/50000; xent: 2.65; lr: 0.0000177;  31 docs/s;   8896 sec\n",
            "[2021-05-02 13:18:26,715 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.21.bert.pt, number of examples: 2001\n",
            "[2021-05-02 13:18:55,886 INFO] Step 12850/50000; xent: 2.74; lr: 0.0000176;  29 docs/s;   8932 sec\n",
            "[2021-05-02 13:19:29,475 INFO] Step 12900/50000; xent: 2.67; lr: 0.0000176;  31 docs/s;   8966 sec\n",
            "[2021-05-02 13:20:03,353 INFO] Step 12950/50000; xent: 2.65; lr: 0.0000176;  31 docs/s;   9000 sec\n",
            "[2021-05-02 13:20:36,993 INFO] Step 13000/50000; xent: 2.59; lr: 0.0000175;  30 docs/s;   9033 sec\n",
            "[2021-05-02 13:20:36,996 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_13000.pt\n",
            "[2021-05-02 13:20:44,559 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.43.bert.pt, number of examples: 2001\n",
            "[2021-05-02 13:21:18,676 INFO] Step 13050/50000; xent: 2.71; lr: 0.0000175;  26 docs/s;   9075 sec\n",
            "[2021-05-02 13:21:52,356 INFO] Step 13100/50000; xent: 2.66; lr: 0.0000175;  31 docs/s;   9109 sec\n",
            "[2021-05-02 13:22:26,181 INFO] Step 13150/50000; xent: 2.63; lr: 0.0000174;  31 docs/s;   9143 sec\n",
            "[2021-05-02 13:22:56,933 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.141.bert.pt, number of examples: 1998\n",
            "[2021-05-02 13:23:02,428 INFO] Step 13200/50000; xent: 2.58; lr: 0.0000174;  28 docs/s;   9179 sec\n",
            "[2021-05-02 13:23:36,310 INFO] Step 13250/50000; xent: 2.64; lr: 0.0000174;  30 docs/s;   9213 sec\n",
            "[2021-05-02 13:24:10,007 INFO] Step 13300/50000; xent: 2.66; lr: 0.0000173;  31 docs/s;   9246 sec\n",
            "[2021-05-02 13:24:43,899 INFO] Step 13350/50000; xent: 2.60; lr: 0.0000173;  31 docs/s;   9280 sec\n",
            "[2021-05-02 13:25:10,266 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.16.bert.pt, number of examples: 2001\n",
            "[2021-05-02 13:25:21,195 INFO] Step 13400/50000; xent: 2.59; lr: 0.0000173;  28 docs/s;   9318 sec\n",
            "[2021-05-02 13:25:55,031 INFO] Step 13450/50000; xent: 2.58; lr: 0.0000172;  31 docs/s;   9351 sec\n",
            "[2021-05-02 13:26:28,696 INFO] Step 13500/50000; xent: 2.63; lr: 0.0000172;  31 docs/s;   9385 sec\n",
            "[2021-05-02 13:27:02,549 INFO] Step 13550/50000; xent: 2.67; lr: 0.0000172;  31 docs/s;   9419 sec\n",
            "[2021-05-02 13:27:22,749 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.116.bert.pt, number of examples: 1997\n",
            "[2021-05-02 13:27:38,382 INFO] Step 13600/50000; xent: 2.90; lr: 0.0000171;  29 docs/s;   9455 sec\n",
            "[2021-05-02 13:28:12,213 INFO] Step 13650/50000; xent: 2.94; lr: 0.0000171;  31 docs/s;   9489 sec\n",
            "[2021-05-02 13:28:46,022 INFO] Step 13700/50000; xent: 3.00; lr: 0.0000171;  31 docs/s;   9522 sec\n",
            "[2021-05-02 13:29:19,855 INFO] Step 13750/50000; xent: 3.05; lr: 0.0000171;  30 docs/s;   9556 sec\n",
            "[2021-05-02 13:29:34,927 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.76.bert.pt, number of examples: 2001\n",
            "[2021-05-02 13:29:55,983 INFO] Step 13800/50000; xent: 2.99; lr: 0.0000170;  29 docs/s;   9592 sec\n",
            "[2021-05-02 13:30:29,911 INFO] Step 13850/50000; xent: 2.92; lr: 0.0000170;  30 docs/s;   9626 sec\n",
            "[2021-05-02 13:31:03,530 INFO] Step 13900/50000; xent: 2.95; lr: 0.0000170;  32 docs/s;   9660 sec\n",
            "[2021-05-02 13:31:37,363 INFO] Step 13950/50000; xent: 2.95; lr: 0.0000169;  30 docs/s;   9694 sec\n",
            "[2021-05-02 13:31:48,214 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.19.bert.pt, number of examples: 1999\n",
            "[2021-05-02 13:32:13,232 INFO] Step 14000/50000; xent: 2.96; lr: 0.0000169;  29 docs/s;   9730 sec\n",
            "[2021-05-02 13:32:13,246 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_14000.pt\n",
            "[2021-05-02 13:32:54,089 INFO] Step 14050/50000; xent: 2.96; lr: 0.0000169;  26 docs/s;   9770 sec\n",
            "[2021-05-02 13:33:27,995 INFO] Step 14100/50000; xent: 3.04; lr: 0.0000168;  31 docs/s;   9804 sec\n",
            "[2021-05-02 13:34:01,687 INFO] Step 14150/50000; xent: 3.03; lr: 0.0000168;  30 docs/s;   9838 sec\n",
            "[2021-05-02 13:34:06,769 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.107.bert.pt, number of examples: 1999\n",
            "[2021-05-02 13:34:37,349 INFO] Step 14200/50000; xent: 2.93; lr: 0.0000168;  29 docs/s;   9874 sec\n",
            "[2021-05-02 13:35:11,253 INFO] Step 14250/50000; xent: 3.00; lr: 0.0000168;  31 docs/s;   9908 sec\n",
            "[2021-05-02 13:35:44,828 INFO] Step 14300/50000; xent: 3.02; lr: 0.0000167;  31 docs/s;   9941 sec\n",
            "[2021-05-02 13:36:19,463 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.125.bert.pt, number of examples: 2000\n",
            "[2021-05-02 13:36:20,902 INFO] Step 14350/50000; xent: 3.00; lr: 0.0000167;  28 docs/s;   9977 sec\n",
            "[2021-05-02 13:36:54,659 INFO] Step 14400/50000; xent: 2.94; lr: 0.0000167;  31 docs/s;  10011 sec\n",
            "[2021-05-02 13:37:28,491 INFO] Step 14450/50000; xent: 2.92; lr: 0.0000166;  32 docs/s;  10045 sec\n",
            "[2021-05-02 13:38:02,315 INFO] Step 14500/50000; xent: 3.04; lr: 0.0000166;  30 docs/s;  10079 sec\n",
            "[2021-05-02 13:38:31,435 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.142.bert.pt, number of examples: 1996\n",
            "[2021-05-02 13:38:38,096 INFO] Step 14550/50000; xent: 2.98; lr: 0.0000166;  29 docs/s;  10114 sec\n",
            "[2021-05-02 13:39:12,037 INFO] Step 14600/50000; xent: 3.02; lr: 0.0000166;  31 docs/s;  10148 sec\n",
            "[2021-05-02 13:39:45,925 INFO] Step 14650/50000; xent: 3.06; lr: 0.0000165;  31 docs/s;  10182 sec\n",
            "[2021-05-02 13:40:19,721 INFO] Step 14700/50000; xent: 3.00; lr: 0.0000165;  30 docs/s;  10216 sec\n",
            "[2021-05-02 13:40:42,121 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.41.bert.pt, number of examples: 2000\n",
            "[2021-05-02 13:40:55,051 INFO] Step 14750/50000; xent: 2.94; lr: 0.0000165;  30 docs/s;  10251 sec\n",
            "[2021-05-02 13:41:28,756 INFO] Step 14800/50000; xent: 2.93; lr: 0.0000164;  31 docs/s;  10285 sec\n",
            "[2021-05-02 13:42:02,581 INFO] Step 14850/50000; xent: 3.00; lr: 0.0000164;  31 docs/s;  10319 sec\n",
            "[2021-05-02 13:42:36,448 INFO] Step 14900/50000; xent: 2.97; lr: 0.0000164;  31 docs/s;  10353 sec\n",
            "[2021-05-02 13:42:55,476 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.44.bert.pt, number of examples: 2000\n",
            "[2021-05-02 13:43:13,872 INFO] Step 14950/50000; xent: 2.93; lr: 0.0000164;  28 docs/s;  10390 sec\n",
            "[2021-05-02 13:43:47,677 INFO] Step 15000/50000; xent: 2.91; lr: 0.0000163;  30 docs/s;  10424 sec\n",
            "[2021-05-02 13:43:47,691 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_15000.pt\n",
            "[2021-05-02 13:44:26,985 INFO] Step 15050/50000; xent: 3.02; lr: 0.0000163;  26 docs/s;  10463 sec\n",
            "[2021-05-02 13:45:00,888 INFO] Step 15100/50000; xent: 2.95; lr: 0.0000163;  31 docs/s;  10497 sec\n",
            "[2021-05-02 13:45:12,918 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.95.bert.pt, number of examples: 2000\n",
            "[2021-05-02 13:45:36,704 INFO] Step 15150/50000; xent: 3.00; lr: 0.0000162;  29 docs/s;  10533 sec\n",
            "[2021-05-02 13:46:10,533 INFO] Step 15200/50000; xent: 2.94; lr: 0.0000162;  31 docs/s;  10567 sec\n",
            "[2021-05-02 13:46:44,361 INFO] Step 15250/50000; xent: 2.94; lr: 0.0000162;  32 docs/s;  10601 sec\n",
            "[2021-05-02 13:47:18,049 INFO] Step 15300/50000; xent: 3.02; lr: 0.0000162;  30 docs/s;  10634 sec\n",
            "[2021-05-02 13:47:25,455 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.79.bert.pt, number of examples: 2001\n",
            "[2021-05-02 13:47:53,951 INFO] Step 15350/50000; xent: 2.96; lr: 0.0000161;  29 docs/s;  10670 sec\n",
            "[2021-05-02 13:48:27,723 INFO] Step 15400/50000; xent: 2.93; lr: 0.0000161;  31 docs/s;  10704 sec\n",
            "[2021-05-02 13:49:01,665 INFO] Step 15450/50000; xent: 3.00; lr: 0.0000161;  31 docs/s;  10738 sec\n",
            "[2021-05-02 13:49:35,440 INFO] Step 15500/50000; xent: 3.03; lr: 0.0000161;  31 docs/s;  10772 sec\n",
            "[2021-05-02 13:49:37,586 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.110.bert.pt, number of examples: 2001\n",
            "[2021-05-02 13:50:11,539 INFO] Step 15550/50000; xent: 2.93; lr: 0.0000160;  29 docs/s;  10808 sec\n",
            "[2021-05-02 13:50:45,219 INFO] Step 15600/50000; xent: 2.97; lr: 0.0000160;  30 docs/s;  10842 sec\n",
            "[2021-05-02 13:51:19,072 INFO] Step 15650/50000; xent: 2.96; lr: 0.0000160;  31 docs/s;  10875 sec\n",
            "[2021-05-02 13:51:49,699 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.23.bert.pt, number of examples: 2001\n",
            "[2021-05-02 13:51:55,198 INFO] Step 15700/50000; xent: 2.97; lr: 0.0000160;  28 docs/s;  10912 sec\n",
            "[2021-05-02 13:52:28,776 INFO] Step 15750/50000; xent: 2.98; lr: 0.0000159;  32 docs/s;  10945 sec\n",
            "[2021-05-02 13:53:02,702 INFO] Step 15800/50000; xent: 2.98; lr: 0.0000159;  31 docs/s;  10979 sec\n",
            "[2021-05-02 13:53:36,585 INFO] Step 15850/50000; xent: 3.00; lr: 0.0000159;  31 docs/s;  11013 sec\n",
            "[2021-05-02 13:54:02,229 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.53.bert.pt, number of examples: 2000\n",
            "[2021-05-02 13:54:12,251 INFO] Step 15900/50000; xent: 2.99; lr: 0.0000159;  29 docs/s;  11049 sec\n",
            "[2021-05-02 13:54:46,147 INFO] Step 15950/50000; xent: 3.00; lr: 0.0000158;  31 docs/s;  11083 sec\n",
            "[2021-05-02 13:55:19,938 INFO] Step 16000/50000; xent: 2.95; lr: 0.0000158;  30 docs/s;  11116 sec\n",
            "[2021-05-02 13:55:19,952 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_16000.pt\n",
            "[2021-05-02 13:55:59,909 INFO] Step 16050/50000; xent: 2.96; lr: 0.0000158;  26 docs/s;  11156 sec\n",
            "[2021-05-02 13:56:19,601 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.27.bert.pt, number of examples: 1999\n",
            "[2021-05-02 13:56:35,318 INFO] Step 16100/50000; xent: 3.05; lr: 0.0000158;  29 docs/s;  11192 sec\n",
            "[2021-05-02 13:57:09,172 INFO] Step 16150/50000; xent: 3.01; lr: 0.0000157;  30 docs/s;  11226 sec\n",
            "[2021-05-02 13:57:43,058 INFO] Step 16200/50000; xent: 2.95; lr: 0.0000157;  31 docs/s;  11259 sec\n",
            "[2021-05-02 13:58:16,872 INFO] Step 16250/50000; xent: 2.99; lr: 0.0000157;  31 docs/s;  11293 sec\n",
            "[2021-05-02 13:58:30,908 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.14.bert.pt, number of examples: 1998\n",
            "[2021-05-02 13:58:52,029 INFO] Step 16300/50000; xent: 2.97; lr: 0.0000157;  29 docs/s;  11328 sec\n",
            "[2021-05-02 13:59:25,876 INFO] Step 16350/50000; xent: 2.99; lr: 0.0000156;  31 docs/s;  11362 sec\n",
            "[2021-05-02 13:59:59,706 INFO] Step 16400/50000; xent: 2.98; lr: 0.0000156;  31 docs/s;  11396 sec\n",
            "[2021-05-02 14:00:33,408 INFO] Step 16450/50000; xent: 2.89; lr: 0.0000156;  31 docs/s;  11430 sec\n",
            "[2021-05-02 14:00:44,717 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.82.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:01:10,556 INFO] Step 16500/50000; xent: 2.84; lr: 0.0000156;  28 docs/s;  11467 sec\n",
            "[2021-05-02 14:01:44,391 INFO] Step 16550/50000; xent: 2.71; lr: 0.0000155;  31 docs/s;  11501 sec\n",
            "[2021-05-02 14:02:18,194 INFO] Step 16600/50000; xent: 2.67; lr: 0.0000155;  30 docs/s;  11535 sec\n",
            "[2021-05-02 14:02:51,928 INFO] Step 16650/50000; xent: 2.71; lr: 0.0000155;  31 docs/s;  11568 sec\n",
            "[2021-05-02 14:02:57,472 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.18.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:03:27,806 INFO] Step 16700/50000; xent: 2.65; lr: 0.0000155;  29 docs/s;  11604 sec\n",
            "[2021-05-02 14:04:01,700 INFO] Step 16750/50000; xent: 2.66; lr: 0.0000155;  31 docs/s;  11638 sec\n",
            "[2021-05-02 14:04:35,528 INFO] Step 16800/50000; xent: 2.63; lr: 0.0000154;  31 docs/s;  11672 sec\n",
            "[2021-05-02 14:05:09,378 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.87.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:05:11,498 INFO] Step 16850/50000; xent: 2.61; lr: 0.0000154;  29 docs/s;  11708 sec\n",
            "[2021-05-02 14:05:45,421 INFO] Step 16900/50000; xent: 2.61; lr: 0.0000154;  30 docs/s;  11742 sec\n",
            "[2021-05-02 14:06:19,241 INFO] Step 16950/50000; xent: 2.62; lr: 0.0000154;  32 docs/s;  11776 sec\n",
            "[2021-05-02 14:06:52,995 INFO] Step 17000/50000; xent: 2.65; lr: 0.0000153;  31 docs/s;  11809 sec\n",
            "[2021-05-02 14:06:53,010 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_17000.pt\n",
            "[2021-05-02 14:07:26,953 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.2.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:07:34,506 INFO] Step 17050/50000; xent: 2.61; lr: 0.0000153;  24 docs/s;  11851 sec\n",
            "[2021-05-02 14:08:08,325 INFO] Step 17100/50000; xent: 2.63; lr: 0.0000153;  31 docs/s;  11885 sec\n",
            "[2021-05-02 14:08:42,141 INFO] Step 17150/50000; xent: 2.68; lr: 0.0000153;  30 docs/s;  11919 sec\n",
            "[2021-05-02 14:09:16,122 INFO] Step 17200/50000; xent: 2.69; lr: 0.0000152;  31 docs/s;  11952 sec\n",
            "[2021-05-02 14:09:40,156 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.69.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:09:52,420 INFO] Step 17250/50000; xent: 2.62; lr: 0.0000152;  29 docs/s;  11989 sec\n",
            "[2021-05-02 14:10:26,298 INFO] Step 17300/50000; xent: 2.71; lr: 0.0000152;  31 docs/s;  12023 sec\n",
            "[2021-05-02 14:11:00,059 INFO] Step 17350/50000; xent: 2.67; lr: 0.0000152;  31 docs/s;  12056 sec\n",
            "[2021-05-02 14:11:33,931 INFO] Step 17400/50000; xent: 2.68; lr: 0.0000152;  31 docs/s;  12090 sec\n",
            "[2021-05-02 14:11:52,243 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.25.bert.pt, number of examples: 1999\n",
            "[2021-05-02 14:12:09,891 INFO] Step 17450/50000; xent: 2.56; lr: 0.0000151;  29 docs/s;  12126 sec\n",
            "[2021-05-02 14:12:43,601 INFO] Step 17500/50000; xent: 2.64; lr: 0.0000151;  31 docs/s;  12160 sec\n",
            "[2021-05-02 14:13:17,438 INFO] Step 17550/50000; xent: 2.62; lr: 0.0000151;  30 docs/s;  12194 sec\n",
            "[2021-05-02 14:13:51,366 INFO] Step 17600/50000; xent: 2.65; lr: 0.0000151;  30 docs/s;  12228 sec\n",
            "[2021-05-02 14:14:04,034 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.22.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:14:27,203 INFO] Step 17650/50000; xent: 2.66; lr: 0.0000151;  29 docs/s;  12264 sec\n",
            "[2021-05-02 14:15:01,156 INFO] Step 17700/50000; xent: 2.73; lr: 0.0000150;  30 docs/s;  12298 sec\n",
            "[2021-05-02 14:15:34,977 INFO] Step 17750/50000; xent: 2.60; lr: 0.0000150;  31 docs/s;  12331 sec\n",
            "[2021-05-02 14:16:08,789 INFO] Step 17800/50000; xent: 2.53; lr: 0.0000150;  31 docs/s;  12365 sec\n",
            "[2021-05-02 14:16:16,737 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.127.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:16:44,689 INFO] Step 17850/50000; xent: 2.61; lr: 0.0000150;  28 docs/s;  12401 sec\n",
            "[2021-05-02 14:17:18,587 INFO] Step 17900/50000; xent: 2.58; lr: 0.0000149;  31 docs/s;  12435 sec\n",
            "[2021-05-02 14:17:52,185 INFO] Step 17950/50000; xent: 2.59; lr: 0.0000149;  30 docs/s;  12469 sec\n",
            "[2021-05-02 14:18:26,147 INFO] Step 18000/50000; xent: 2.60; lr: 0.0000149;  32 docs/s;  12503 sec\n",
            "[2021-05-02 14:18:26,150 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_18000.pt\n",
            "[2021-05-02 14:18:33,866 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.57.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:19:07,887 INFO] Step 18050/50000; xent: 2.54; lr: 0.0000149;  25 docs/s;  12544 sec\n",
            "[2021-05-02 14:19:41,790 INFO] Step 18100/50000; xent: 2.67; lr: 0.0000149;  31 docs/s;  12578 sec\n",
            "[2021-05-02 14:20:15,682 INFO] Step 18150/50000; xent: 2.61; lr: 0.0000148;  31 docs/s;  12612 sec\n",
            "[2021-05-02 14:20:46,074 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.99.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:20:51,607 INFO] Step 18200/50000; xent: 2.59; lr: 0.0000148;  29 docs/s;  12648 sec\n",
            "[2021-05-02 14:21:25,482 INFO] Step 18250/50000; xent: 2.56; lr: 0.0000148;  31 docs/s;  12682 sec\n",
            "[2021-05-02 14:21:59,287 INFO] Step 18300/50000; xent: 2.58; lr: 0.0000148;  31 docs/s;  12716 sec\n",
            "[2021-05-02 14:22:33,235 INFO] Step 18350/50000; xent: 2.67; lr: 0.0000148;  30 docs/s;  12750 sec\n",
            "[2021-05-02 14:22:58,615 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.65.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:23:09,563 INFO] Step 18400/50000; xent: 2.65; lr: 0.0000147;  28 docs/s;  12786 sec\n",
            "[2021-05-02 14:23:43,421 INFO] Step 18450/50000; xent: 2.66; lr: 0.0000147;  31 docs/s;  12820 sec\n",
            "[2021-05-02 14:24:17,356 INFO] Step 18500/50000; xent: 2.64; lr: 0.0000147;  31 docs/s;  12854 sec\n",
            "[2021-05-02 14:24:51,162 INFO] Step 18550/50000; xent: 2.58; lr: 0.0000147;  31 docs/s;  12888 sec\n",
            "[2021-05-02 14:25:10,037 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.119.bert.pt, number of examples: 1998\n",
            "[2021-05-02 14:25:27,047 INFO] Step 18600/50000; xent: 2.72; lr: 0.0000147;  29 docs/s;  12923 sec\n",
            "[2021-05-02 14:26:00,737 INFO] Step 18650/50000; xent: 2.65; lr: 0.0000146;  31 docs/s;  12957 sec\n",
            "[2021-05-02 14:26:34,602 INFO] Step 18700/50000; xent: 2.59; lr: 0.0000146;  31 docs/s;  12991 sec\n",
            "[2021-05-02 14:27:08,497 INFO] Step 18750/50000; xent: 2.66; lr: 0.0000146;  30 docs/s;  13025 sec\n",
            "[2021-05-02 14:27:22,070 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.70.bert.pt, number of examples: 1999\n",
            "[2021-05-02 14:27:44,554 INFO] Step 18800/50000; xent: 2.70; lr: 0.0000146;  29 docs/s;  13061 sec\n",
            "[2021-05-02 14:28:18,356 INFO] Step 18850/50000; xent: 2.53; lr: 0.0000146;  31 docs/s;  13095 sec\n",
            "[2021-05-02 14:28:52,261 INFO] Step 18900/50000; xent: 2.57; lr: 0.0000145;  31 docs/s;  13129 sec\n",
            "[2021-05-02 14:29:25,866 INFO] Step 18950/50000; xent: 2.59; lr: 0.0000145;  31 docs/s;  13162 sec\n",
            "[2021-05-02 14:29:34,476 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.54.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:30:02,339 INFO] Step 19000/50000; xent: 2.61; lr: 0.0000145;  29 docs/s;  13199 sec\n",
            "[2021-05-02 14:30:02,354 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_19000.pt\n",
            "[2021-05-02 14:30:41,721 INFO] Step 19050/50000; xent: 2.65; lr: 0.0000145;  27 docs/s;  13238 sec\n",
            "[2021-05-02 14:31:15,568 INFO] Step 19100/50000; xent: 2.55; lr: 0.0000145;  31 docs/s;  13272 sec\n",
            "[2021-05-02 14:31:49,115 INFO] Step 19150/50000; xent: 2.63; lr: 0.0000145;  30 docs/s;  13305 sec\n",
            "[2021-05-02 14:31:51,404 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.103.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:32:24,654 INFO] Step 19200/50000; xent: 2.63; lr: 0.0000144;  29 docs/s;  13341 sec\n",
            "[2021-05-02 14:32:58,501 INFO] Step 19250/50000; xent: 2.55; lr: 0.0000144;  31 docs/s;  13375 sec\n",
            "[2021-05-02 14:33:32,098 INFO] Step 19300/50000; xent: 2.63; lr: 0.0000144;  30 docs/s;  13408 sec\n",
            "[2021-05-02 14:34:04,164 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.1.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:34:08,300 INFO] Step 19350/50000; xent: 2.69; lr: 0.0000144;  29 docs/s;  13445 sec\n",
            "[2021-05-02 14:34:42,066 INFO] Step 19400/50000; xent: 2.63; lr: 0.0000144;  31 docs/s;  13478 sec\n",
            "[2021-05-02 14:35:15,983 INFO] Step 19450/50000; xent: 2.61; lr: 0.0000143;  31 docs/s;  13512 sec\n",
            "[2021-05-02 14:35:49,808 INFO] Step 19500/50000; xent: 2.59; lr: 0.0000143;  30 docs/s;  13546 sec\n",
            "[2021-05-02 14:36:16,072 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.3.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:36:25,661 INFO] Step 19550/50000; xent: 2.64; lr: 0.0000143;  30 docs/s;  13582 sec\n",
            "[2021-05-02 14:36:59,231 INFO] Step 19600/50000; xent: 2.63; lr: 0.0000143;  31 docs/s;  13616 sec\n",
            "[2021-05-02 14:37:33,131 INFO] Step 19650/50000; xent: 2.59; lr: 0.0000143;  31 docs/s;  13649 sec\n",
            "[2021-05-02 14:38:06,971 INFO] Step 19700/50000; xent: 2.64; lr: 0.0000142;  30 docs/s;  13683 sec\n",
            "[2021-05-02 14:38:28,058 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.10.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:38:42,346 INFO] Step 19750/50000; xent: 2.66; lr: 0.0000142;  29 docs/s;  13719 sec\n",
            "[2021-05-02 14:39:16,175 INFO] Step 19800/50000; xent: 2.58; lr: 0.0000142;  31 docs/s;  13753 sec\n",
            "[2021-05-02 14:39:49,971 INFO] Step 19850/50000; xent: 2.63; lr: 0.0000142;  31 docs/s;  13786 sec\n",
            "[2021-05-02 14:40:23,610 INFO] Step 19900/50000; xent: 2.66; lr: 0.0000142;  31 docs/s;  13820 sec\n",
            "[2021-05-02 14:40:40,710 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.78.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:40:59,753 INFO] Step 19950/50000; xent: 2.66; lr: 0.0000142;  28 docs/s;  13856 sec\n",
            "[2021-05-02 14:41:33,565 INFO] Step 20000/50000; xent: 2.62; lr: 0.0000141;  31 docs/s;  13890 sec\n",
            "[2021-05-02 14:41:33,580 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_20000.pt\n",
            "[2021-05-02 14:42:13,336 INFO] Step 20050/50000; xent: 2.59; lr: 0.0000141;  25 docs/s;  13930 sec\n",
            "[2021-05-02 14:42:47,239 INFO] Step 20100/50000; xent: 2.55; lr: 0.0000141;  31 docs/s;  13964 sec\n",
            "[2021-05-02 14:42:59,422 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.112.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:43:23,184 INFO] Step 20150/50000; xent: 2.62; lr: 0.0000141;  29 docs/s;  14000 sec\n",
            "[2021-05-02 14:43:56,962 INFO] Step 20200/50000; xent: 2.53; lr: 0.0000141;  31 docs/s;  14033 sec\n",
            "[2021-05-02 14:44:30,675 INFO] Step 20250/50000; xent: 2.65; lr: 0.0000141;  30 docs/s;  14067 sec\n",
            "[2021-05-02 14:45:04,616 INFO] Step 20300/50000; xent: 2.57; lr: 0.0000140;  31 docs/s;  14101 sec\n",
            "[2021-05-02 14:45:11,458 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.102.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:45:40,682 INFO] Step 20350/50000; xent: 2.64; lr: 0.0000140;  29 docs/s;  14137 sec\n",
            "[2021-05-02 14:46:14,569 INFO] Step 20400/50000; xent: 2.60; lr: 0.0000140;  31 docs/s;  14171 sec\n",
            "[2021-05-02 14:46:48,378 INFO] Step 20450/50000; xent: 2.58; lr: 0.0000140;  30 docs/s;  14205 sec\n",
            "[2021-05-02 14:47:23,318 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.40.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:47:24,083 INFO] Step 20500/50000; xent: 2.56; lr: 0.0000140;  29 docs/s;  14240 sec\n",
            "[2021-05-02 14:47:57,918 INFO] Step 20550/50000; xent: 2.59; lr: 0.0000140;  31 docs/s;  14274 sec\n",
            "[2021-05-02 14:48:31,582 INFO] Step 20600/50000; xent: 2.66; lr: 0.0000139;  30 docs/s;  14308 sec\n",
            "[2021-05-02 14:49:05,403 INFO] Step 20650/50000; xent: 2.60; lr: 0.0000139;  31 docs/s;  14342 sec\n",
            "[2021-05-02 14:49:35,094 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.122.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:49:41,075 INFO] Step 20700/50000; xent: 2.58; lr: 0.0000139;  28 docs/s;  14377 sec\n",
            "[2021-05-02 14:50:14,889 INFO] Step 20750/50000; xent: 2.57; lr: 0.0000139;  30 docs/s;  14411 sec\n",
            "[2021-05-02 14:50:48,733 INFO] Step 20800/50000; xent: 2.61; lr: 0.0000139;  31 docs/s;  14445 sec\n",
            "[2021-05-02 14:51:22,572 INFO] Step 20850/50000; xent: 2.56; lr: 0.0000139;  31 docs/s;  14479 sec\n",
            "[2021-05-02 14:51:47,982 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.133.bert.pt, number of examples: 1999\n",
            "[2021-05-02 14:51:58,910 INFO] Step 20900/50000; xent: 2.61; lr: 0.0000138;  29 docs/s;  14515 sec\n",
            "[2021-05-02 14:52:32,794 INFO] Step 20950/50000; xent: 2.54; lr: 0.0000138;  31 docs/s;  14549 sec\n",
            "[2021-05-02 14:53:06,620 INFO] Step 21000/50000; xent: 2.68; lr: 0.0000138;  30 docs/s;  14583 sec\n",
            "[2021-05-02 14:53:06,635 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_21000.pt\n",
            "[2021-05-02 14:53:48,368 INFO] Step 21050/50000; xent: 2.62; lr: 0.0000138;  25 docs/s;  14625 sec\n",
            "[2021-05-02 14:54:09,187 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.67.bert.pt, number of examples: 2001\n",
            "[2021-05-02 14:54:24,238 INFO] Step 21100/50000; xent: 2.57; lr: 0.0000138;  29 docs/s;  14661 sec\n",
            "[2021-05-02 14:54:58,050 INFO] Step 21150/50000; xent: 2.63; lr: 0.0000138;  31 docs/s;  14694 sec\n",
            "[2021-05-02 14:55:31,873 INFO] Step 21200/50000; xent: 2.59; lr: 0.0000137;  31 docs/s;  14728 sec\n",
            "[2021-05-02 14:56:05,464 INFO] Step 21250/50000; xent: 2.58; lr: 0.0000137;  30 docs/s;  14762 sec\n",
            "[2021-05-02 14:56:21,663 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.108.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:56:41,354 INFO] Step 21300/50000; xent: 2.57; lr: 0.0000137;  29 docs/s;  14798 sec\n",
            "[2021-05-02 14:57:15,219 INFO] Step 21350/50000; xent: 2.50; lr: 0.0000137;  31 docs/s;  14832 sec\n",
            "[2021-05-02 14:57:49,046 INFO] Step 21400/50000; xent: 2.60; lr: 0.0000137;  30 docs/s;  14865 sec\n",
            "[2021-05-02 14:58:22,826 INFO] Step 21450/50000; xent: 2.57; lr: 0.0000137;  31 docs/s;  14899 sec\n",
            "[2021-05-02 14:58:33,607 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.60.bert.pt, number of examples: 2000\n",
            "[2021-05-02 14:58:58,749 INFO] Step 21500/50000; xent: 2.54; lr: 0.0000136;  29 docs/s;  14935 sec\n",
            "[2021-05-02 14:59:32,548 INFO] Step 21550/50000; xent: 2.51; lr: 0.0000136;  31 docs/s;  14969 sec\n",
            "[2021-05-02 15:00:06,414 INFO] Step 21600/50000; xent: 2.59; lr: 0.0000136;  30 docs/s;  15003 sec\n",
            "[2021-05-02 15:00:40,175 INFO] Step 21650/50000; xent: 2.60; lr: 0.0000136;  31 docs/s;  15037 sec\n",
            "[2021-05-02 15:00:46,428 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.29.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:01:16,113 INFO] Step 21700/50000; xent: 2.55; lr: 0.0000136;  28 docs/s;  15072 sec\n",
            "[2021-05-02 15:01:49,948 INFO] Step 21750/50000; xent: 2.61; lr: 0.0000136;  32 docs/s;  15106 sec\n",
            "[2021-05-02 15:02:23,804 INFO] Step 21800/50000; xent: 2.62; lr: 0.0000135;  31 docs/s;  15140 sec\n",
            "[2021-05-02 15:02:58,397 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.90.bert.pt, number of examples: 2000\n",
            "[2021-05-02 15:02:59,869 INFO] Step 21850/50000; xent: 2.60; lr: 0.0000135;  28 docs/s;  15176 sec\n",
            "[2021-05-02 15:03:33,740 INFO] Step 21900/50000; xent: 2.60; lr: 0.0000135;  30 docs/s;  15210 sec\n",
            "[2021-05-02 15:04:07,558 INFO] Step 21950/50000; xent: 2.56; lr: 0.0000135;  30 docs/s;  15244 sec\n",
            "[2021-05-02 15:04:41,174 INFO] Step 22000/50000; xent: 2.65; lr: 0.0000135;  32 docs/s;  15278 sec\n",
            "[2021-05-02 15:04:41,189 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_22000.pt\n",
            "[2021-05-02 15:05:16,810 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.5.bert.pt, number of examples: 2000\n",
            "[2021-05-02 15:05:23,015 INFO] Step 22050/50000; xent: 2.63; lr: 0.0000135;  25 docs/s;  15319 sec\n",
            "[2021-05-02 15:05:56,926 INFO] Step 22100/50000; xent: 2.59; lr: 0.0000135;  31 docs/s;  15353 sec\n",
            "[2021-05-02 15:06:30,792 INFO] Step 22150/50000; xent: 2.65; lr: 0.0000134;  31 docs/s;  15387 sec\n",
            "[2021-05-02 15:07:04,609 INFO] Step 22200/50000; xent: 2.65; lr: 0.0000134;  30 docs/s;  15421 sec\n",
            "[2021-05-02 15:07:29,489 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.140.bert.pt, number of examples: 1999\n",
            "[2021-05-02 15:07:40,399 INFO] Step 22250/50000; xent: 2.52; lr: 0.0000134;  29 docs/s;  15457 sec\n",
            "[2021-05-02 15:08:14,174 INFO] Step 22300/50000; xent: 2.66; lr: 0.0000134;  30 docs/s;  15491 sec\n",
            "[2021-05-02 15:08:48,130 INFO] Step 22350/50000; xent: 2.57; lr: 0.0000134;  31 docs/s;  15524 sec\n",
            "[2021-05-02 15:09:21,930 INFO] Step 22400/50000; xent: 2.58; lr: 0.0000134;  31 docs/s;  15558 sec\n",
            "[2021-05-02 15:09:41,703 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.17.bert.pt, number of examples: 1999\n",
            "[2021-05-02 15:09:57,906 INFO] Step 22450/50000; xent: 2.50; lr: 0.0000133;  29 docs/s;  15594 sec\n",
            "[2021-05-02 15:10:31,803 INFO] Step 22500/50000; xent: 2.64; lr: 0.0000133;  32 docs/s;  15628 sec\n",
            "[2021-05-02 15:11:05,607 INFO] Step 22550/50000; xent: 2.69; lr: 0.0000133;  31 docs/s;  15662 sec\n",
            "[2021-05-02 15:11:39,227 INFO] Step 22600/50000; xent: 2.71; lr: 0.0000133;  30 docs/s;  15696 sec\n",
            "[2021-05-02 15:11:54,276 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.31.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:12:15,319 INFO] Step 22650/50000; xent: 2.65; lr: 0.0000133;  29 docs/s;  15732 sec\n",
            "[2021-05-02 15:12:49,158 INFO] Step 22700/50000; xent: 2.57; lr: 0.0000133;  32 docs/s;  15766 sec\n",
            "[2021-05-02 15:13:22,953 INFO] Step 22750/50000; xent: 2.59; lr: 0.0000133;  31 docs/s;  15799 sec\n",
            "[2021-05-02 15:13:56,573 INFO] Step 22800/50000; xent: 2.63; lr: 0.0000132;  30 docs/s;  15833 sec\n",
            "[2021-05-02 15:14:05,652 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.4.bert.pt, number of examples: 2000\n",
            "[2021-05-02 15:14:32,042 INFO] Step 22850/50000; xent: 2.62; lr: 0.0000132;  29 docs/s;  15868 sec\n",
            "[2021-05-02 15:15:05,903 INFO] Step 22900/50000; xent: 2.56; lr: 0.0000132;  31 docs/s;  15902 sec\n",
            "[2021-05-02 15:15:39,730 INFO] Step 22950/50000; xent: 2.59; lr: 0.0000132;  31 docs/s;  15936 sec\n",
            "[2021-05-02 15:16:13,447 INFO] Step 23000/50000; xent: 2.60; lr: 0.0000132;  30 docs/s;  15970 sec\n",
            "[2021-05-02 15:16:13,449 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_23000.pt\n",
            "[2021-05-02 15:16:25,371 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.42.bert.pt, number of examples: 2000\n",
            "[2021-05-02 15:16:56,706 INFO] Step 23050/50000; xent: 2.57; lr: 0.0000132;  24 docs/s;  16013 sec\n",
            "[2021-05-02 15:17:30,412 INFO] Step 23100/50000; xent: 2.53; lr: 0.0000132;  31 docs/s;  16047 sec\n",
            "[2021-05-02 15:18:04,196 INFO] Step 23150/50000; xent: 2.52; lr: 0.0000131;  31 docs/s;  16081 sec\n",
            "[2021-05-02 15:18:38,009 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.75.bert.pt, number of examples: 1999\n",
            "[2021-05-02 15:18:40,125 INFO] Step 23200/50000; xent: 2.68; lr: 0.0000131;  29 docs/s;  16116 sec\n",
            "[2021-05-02 15:19:13,976 INFO] Step 23250/50000; xent: 2.56; lr: 0.0000131;  31 docs/s;  16150 sec\n",
            "[2021-05-02 15:19:47,834 INFO] Step 23300/50000; xent: 2.66; lr: 0.0000131;  30 docs/s;  16184 sec\n",
            "[2021-05-02 15:20:21,545 INFO] Step 23350/50000; xent: 2.55; lr: 0.0000131;  30 docs/s;  16218 sec\n",
            "[2021-05-02 15:20:51,340 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.129.bert.pt, number of examples: 1999\n",
            "[2021-05-02 15:20:57,507 INFO] Step 23400/50000; xent: 2.65; lr: 0.0000131;  29 docs/s;  16254 sec\n",
            "[2021-05-02 15:21:31,417 INFO] Step 23450/50000; xent: 2.65; lr: 0.0000131;  31 docs/s;  16288 sec\n",
            "[2021-05-02 15:22:05,270 INFO] Step 23500/50000; xent: 2.65; lr: 0.0000130;  31 docs/s;  16322 sec\n",
            "[2021-05-02 15:22:39,040 INFO] Step 23550/50000; xent: 2.62; lr: 0.0000130;  30 docs/s;  16355 sec\n",
            "[2021-05-02 15:23:03,267 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.117.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:23:14,822 INFO] Step 23600/50000; xent: 2.51; lr: 0.0000130;  29 docs/s;  16391 sec\n",
            "[2021-05-02 15:23:48,743 INFO] Step 23650/50000; xent: 2.53; lr: 0.0000130;  31 docs/s;  16425 sec\n",
            "[2021-05-02 15:24:22,394 INFO] Step 23700/50000; xent: 2.61; lr: 0.0000130;  30 docs/s;  16459 sec\n",
            "[2021-05-02 15:24:56,213 INFO] Step 23750/50000; xent: 2.63; lr: 0.0000130;  31 docs/s;  16493 sec\n",
            "[2021-05-02 15:25:15,755 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.115.bert.pt, number of examples: 2000\n",
            "[2021-05-02 15:25:32,068 INFO] Step 23800/50000; xent: 2.60; lr: 0.0000130;  29 docs/s;  16528 sec\n",
            "[2021-05-02 15:26:05,840 INFO] Step 23850/50000; xent: 2.54; lr: 0.0000130;  31 docs/s;  16562 sec\n",
            "[2021-05-02 15:26:39,789 INFO] Step 23900/50000; xent: 2.65; lr: 0.0000129;  30 docs/s;  16596 sec\n",
            "[2021-05-02 15:27:13,618 INFO] Step 23950/50000; xent: 2.59; lr: 0.0000129;  31 docs/s;  16630 sec\n",
            "[2021-05-02 15:27:28,629 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.48.bert.pt, number of examples: 2000\n",
            "[2021-05-02 15:27:49,779 INFO] Step 24000/50000; xent: 2.60; lr: 0.0000129;  28 docs/s;  16666 sec\n",
            "[2021-05-02 15:27:49,794 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_24000.pt\n",
            "[2021-05-02 15:28:29,229 INFO] Step 24050/50000; xent: 2.52; lr: 0.0000129;  27 docs/s;  16706 sec\n",
            "[2021-05-02 15:29:03,142 INFO] Step 24100/50000; xent: 2.64; lr: 0.0000129;  30 docs/s;  16740 sec\n",
            "[2021-05-02 15:29:36,951 INFO] Step 24150/50000; xent: 2.61; lr: 0.0000129;  31 docs/s;  16773 sec\n",
            "[2021-05-02 15:29:47,056 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.132.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:30:12,923 INFO] Step 24200/50000; xent: 2.62; lr: 0.0000129;  28 docs/s;  16809 sec\n",
            "[2021-05-02 15:30:46,782 INFO] Step 24250/50000; xent: 2.55; lr: 0.0000128;  31 docs/s;  16843 sec\n",
            "[2021-05-02 15:31:20,619 INFO] Step 24300/50000; xent: 2.60; lr: 0.0000128;  31 docs/s;  16877 sec\n",
            "[2021-05-02 15:31:54,512 INFO] Step 24350/50000; xent: 2.56; lr: 0.0000128;  30 docs/s;  16911 sec\n",
            "[2021-05-02 15:32:00,019 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.120.bert.pt, number of examples: 2000\n",
            "[2021-05-02 15:32:30,684 INFO] Step 24400/50000; xent: 2.54; lr: 0.0000128;  29 docs/s;  16947 sec\n",
            "[2021-05-02 15:33:04,559 INFO] Step 24450/50000; xent: 2.54; lr: 0.0000128;  30 docs/s;  16981 sec\n",
            "[2021-05-02 15:33:38,182 INFO] Step 24500/50000; xent: 2.61; lr: 0.0000128;  31 docs/s;  17015 sec\n",
            "[2021-05-02 15:34:11,831 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.30.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:34:13,953 INFO] Step 24550/50000; xent: 2.62; lr: 0.0000128;  29 docs/s;  17050 sec\n",
            "[2021-05-02 15:34:47,549 INFO] Step 24600/50000; xent: 2.62; lr: 0.0000128;  30 docs/s;  17084 sec\n",
            "[2021-05-02 15:35:21,476 INFO] Step 24650/50000; xent: 2.55; lr: 0.0000127;  31 docs/s;  17118 sec\n",
            "[2021-05-02 15:35:55,292 INFO] Step 24700/50000; xent: 2.57; lr: 0.0000127;  31 docs/s;  17152 sec\n",
            "[2021-05-02 15:36:28,806 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.124.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:36:35,011 INFO] Step 24750/50000; xent: 2.55; lr: 0.0000127;  26 docs/s;  17191 sec\n",
            "[2021-05-02 15:37:08,917 INFO] Step 24800/50000; xent: 2.58; lr: 0.0000127;  31 docs/s;  17225 sec\n",
            "[2021-05-02 15:37:42,847 INFO] Step 24850/50000; xent: 2.62; lr: 0.0000127;  31 docs/s;  17259 sec\n",
            "[2021-05-02 15:38:16,748 INFO] Step 24900/50000; xent: 2.66; lr: 0.0000127;  30 docs/s;  17293 sec\n",
            "[2021-05-02 15:38:43,009 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.101.bert.pt, number of examples: 1998\n",
            "[2021-05-02 15:38:54,625 INFO] Step 24950/50000; xent: 2.57; lr: 0.0000127;  27 docs/s;  17331 sec\n",
            "[2021-05-02 15:39:29,062 INFO] Step 25000/50000; xent: 2.68; lr: 0.0000126;  31 docs/s;  17365 sec\n",
            "[2021-05-02 15:39:29,077 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_25000.pt\n",
            "[2021-05-02 15:40:10,762 INFO] Step 25050/50000; xent: 2.62; lr: 0.0000126;  25 docs/s;  17407 sec\n",
            "[2021-05-02 15:40:44,671 INFO] Step 25100/50000; xent: 2.62; lr: 0.0000126;  31 docs/s;  17441 sec\n",
            "[2021-05-02 15:41:04,178 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.26.bert.pt, number of examples: 1998\n",
            "[2021-05-02 15:41:20,541 INFO] Step 25150/50000; xent: 2.57; lr: 0.0000126;  29 docs/s;  17477 sec\n",
            "[2021-05-02 15:41:54,370 INFO] Step 25200/50000; xent: 2.61; lr: 0.0000126;  31 docs/s;  17511 sec\n",
            "[2021-05-02 15:42:28,293 INFO] Step 25250/50000; xent: 2.59; lr: 0.0000126;  31 docs/s;  17545 sec\n",
            "[2021-05-02 15:43:01,950 INFO] Step 25300/50000; xent: 2.60; lr: 0.0000126;  30 docs/s;  17578 sec\n",
            "[2021-05-02 15:43:16,207 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.77.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:43:37,770 INFO] Step 25350/50000; xent: 2.60; lr: 0.0000126;  29 docs/s;  17614 sec\n",
            "[2021-05-02 15:44:11,680 INFO] Step 25400/50000; xent: 2.58; lr: 0.0000125;  31 docs/s;  17648 sec\n",
            "[2021-05-02 15:44:45,428 INFO] Step 25450/50000; xent: 2.60; lr: 0.0000125;  31 docs/s;  17682 sec\n",
            "[2021-05-02 15:45:19,286 INFO] Step 25500/50000; xent: 2.67; lr: 0.0000125;  31 docs/s;  17716 sec\n",
            "[2021-05-02 15:45:28,489 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.58.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:45:55,050 INFO] Step 25550/50000; xent: 2.51; lr: 0.0000125;  30 docs/s;  17751 sec\n",
            "[2021-05-02 15:46:28,920 INFO] Step 25600/50000; xent: 2.61; lr: 0.0000125;  31 docs/s;  17785 sec\n",
            "[2021-05-02 15:47:02,776 INFO] Step 25650/50000; xent: 2.59; lr: 0.0000125;  30 docs/s;  17819 sec\n",
            "[2021-05-02 15:47:36,557 INFO] Step 25700/50000; xent: 2.57; lr: 0.0000125;  31 docs/s;  17853 sec\n",
            "[2021-05-02 15:47:41,443 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.130.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:48:13,411 INFO] Step 25750/50000; xent: 2.57; lr: 0.0000125;  29 docs/s;  17890 sec\n",
            "[2021-05-02 15:48:47,153 INFO] Step 25800/50000; xent: 2.60; lr: 0.0000125;  31 docs/s;  17924 sec\n",
            "[2021-05-02 15:49:21,034 INFO] Step 25850/50000; xent: 2.63; lr: 0.0000124;  30 docs/s;  17957 sec\n",
            "[2021-05-02 15:49:53,969 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.109.bert.pt, number of examples: 1999\n",
            "[2021-05-02 15:49:56,765 INFO] Step 25900/50000; xent: 2.57; lr: 0.0000124;  29 docs/s;  17993 sec\n",
            "[2021-05-02 15:50:30,693 INFO] Step 25950/50000; xent: 2.60; lr: 0.0000124;  31 docs/s;  18027 sec\n",
            "[2021-05-02 15:51:04,594 INFO] Step 26000/50000; xent: 2.54; lr: 0.0000124;  30 docs/s;  18061 sec\n",
            "[2021-05-02 15:51:04,609 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_26000.pt\n",
            "[2021-05-02 15:51:44,021 INFO] Step 26050/50000; xent: 2.60; lr: 0.0000124;  26 docs/s;  18100 sec\n",
            "[2021-05-02 15:52:12,477 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.126.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:52:20,046 INFO] Step 26100/50000; xent: 2.60; lr: 0.0000124;  28 docs/s;  18136 sec\n",
            "[2021-05-02 15:52:53,763 INFO] Step 26150/50000; xent: 2.64; lr: 0.0000124;  30 docs/s;  18170 sec\n",
            "[2021-05-02 15:53:27,677 INFO] Step 26200/50000; xent: 2.54; lr: 0.0000124;  31 docs/s;  18204 sec\n",
            "[2021-05-02 15:54:01,492 INFO] Step 26250/50000; xent: 2.59; lr: 0.0000123;  31 docs/s;  18238 sec\n",
            "[2021-05-02 15:54:25,167 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.46.bert.pt, number of examples: 2001\n",
            "[2021-05-02 15:54:37,477 INFO] Step 26300/50000; xent: 2.55; lr: 0.0000123;  29 docs/s;  18274 sec\n",
            "[2021-05-02 15:55:11,371 INFO] Step 26350/50000; xent: 2.60; lr: 0.0000123;  30 docs/s;  18308 sec\n",
            "[2021-05-02 15:55:45,239 INFO] Step 26400/50000; xent: 2.56; lr: 0.0000123;  30 docs/s;  18342 sec\n",
            "[2021-05-02 15:56:19,213 INFO] Step 26450/50000; xent: 2.56; lr: 0.0000123;  32 docs/s;  18376 sec\n",
            "[2021-05-02 15:56:37,293 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.100.bert.pt, number of examples: 2000\n",
            "[2021-05-02 15:56:54,277 INFO] Step 26500/50000; xent: 2.55; lr: 0.0000123;  29 docs/s;  18411 sec\n",
            "[2021-05-02 15:57:28,260 INFO] Step 26550/50000; xent: 2.61; lr: 0.0000123;  31 docs/s;  18445 sec\n",
            "[2021-05-02 15:58:02,152 INFO] Step 26600/50000; xent: 2.63; lr: 0.0000123;  31 docs/s;  18479 sec\n",
            "[2021-05-02 15:58:36,300 INFO] Step 26650/50000; xent: 2.55; lr: 0.0000123;  31 docs/s;  18513 sec\n",
            "[2021-05-02 15:58:49,070 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.85.bert.pt, number of examples: 1998\n",
            "[2021-05-02 15:59:12,303 INFO] Step 26700/50000; xent: 2.61; lr: 0.0000122;  29 docs/s;  18549 sec\n",
            "[2021-05-02 15:59:46,234 INFO] Step 26750/50000; xent: 2.54; lr: 0.0000122;  31 docs/s;  18583 sec\n",
            "[2021-05-02 16:00:20,138 INFO] Step 26800/50000; xent: 2.57; lr: 0.0000122;  31 docs/s;  18617 sec\n",
            "[2021-05-02 16:00:54,059 INFO] Step 26850/50000; xent: 2.60; lr: 0.0000122;  30 docs/s;  18650 sec\n",
            "[2021-05-02 16:01:01,852 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.34.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:01:30,461 INFO] Step 26900/50000; xent: 2.63; lr: 0.0000122;  29 docs/s;  18687 sec\n",
            "[2021-05-02 16:02:04,437 INFO] Step 26950/50000; xent: 2.54; lr: 0.0000122;  31 docs/s;  18721 sec\n",
            "[2021-05-02 16:02:38,469 INFO] Step 27000/50000; xent: 2.60; lr: 0.0000122;  30 docs/s;  18755 sec\n",
            "[2021-05-02 16:02:38,485 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_27000.pt\n",
            "[2021-05-02 16:03:18,335 INFO] Step 27050/50000; xent: 2.63; lr: 0.0000122;  26 docs/s;  18795 sec\n",
            "[2021-05-02 16:03:20,422 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.7.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:03:54,282 INFO] Step 27100/50000; xent: 2.55; lr: 0.0000121;  28 docs/s;  18831 sec\n",
            "[2021-05-02 16:04:28,263 INFO] Step 27150/50000; xent: 2.59; lr: 0.0000121;  31 docs/s;  18865 sec\n",
            "[2021-05-02 16:05:02,150 INFO] Step 27200/50000; xent: 2.52; lr: 0.0000121;  31 docs/s;  18899 sec\n",
            "[2021-05-02 16:05:33,135 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.56.bert.pt, number of examples: 2001\n",
            "[2021-05-02 16:05:38,029 INFO] Step 27250/50000; xent: 2.60; lr: 0.0000121;  28 docs/s;  18934 sec\n",
            "[2021-05-02 16:06:12,031 INFO] Step 27300/50000; xent: 2.57; lr: 0.0000121;  31 docs/s;  18968 sec\n",
            "[2021-05-02 16:06:45,891 INFO] Step 27350/50000; xent: 2.52; lr: 0.0000121;  30 docs/s;  19002 sec\n",
            "[2021-05-02 16:07:19,776 INFO] Step 27400/50000; xent: 2.53; lr: 0.0000121;  31 docs/s;  19036 sec\n",
            "[2021-05-02 16:07:45,521 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.74.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:07:55,113 INFO] Step 27450/50000; xent: 2.60; lr: 0.0000121;  29 docs/s;  19071 sec\n",
            "[2021-05-02 16:08:29,030 INFO] Step 27500/50000; xent: 2.52; lr: 0.0000121;  30 docs/s;  19105 sec\n",
            "[2021-05-02 16:09:02,968 INFO] Step 27550/50000; xent: 2.64; lr: 0.0000120;  30 docs/s;  19139 sec\n",
            "[2021-05-02 16:09:36,628 INFO] Step 27600/50000; xent: 2.54; lr: 0.0000120;  31 docs/s;  19173 sec\n",
            "[2021-05-02 16:09:58,340 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.105.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:10:12,656 INFO] Step 27650/50000; xent: 2.64; lr: 0.0000120;  29 docs/s;  19209 sec\n",
            "[2021-05-02 16:10:46,334 INFO] Step 27700/50000; xent: 2.62; lr: 0.0000120;  31 docs/s;  19243 sec\n",
            "[2021-05-02 16:11:20,200 INFO] Step 27750/50000; xent: 2.54; lr: 0.0000120;  30 docs/s;  19277 sec\n",
            "[2021-05-02 16:11:54,232 INFO] Step 27800/50000; xent: 2.66; lr: 0.0000120;  31 docs/s;  19311 sec\n",
            "[2021-05-02 16:12:11,147 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.114.bert.pt, number of examples: 2001\n",
            "[2021-05-02 16:12:30,165 INFO] Step 27850/50000; xent: 2.66; lr: 0.0000120;  29 docs/s;  19347 sec\n",
            "[2021-05-02 16:13:04,196 INFO] Step 27900/50000; xent: 2.55; lr: 0.0000120;  31 docs/s;  19381 sec\n",
            "[2021-05-02 16:13:38,029 INFO] Step 27950/50000; xent: 2.55; lr: 0.0000120;  30 docs/s;  19414 sec\n",
            "[2021-05-02 16:14:11,914 INFO] Step 28000/50000; xent: 2.47; lr: 0.0000120;  31 docs/s;  19448 sec\n",
            "[2021-05-02 16:14:11,917 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_28000.pt\n",
            "[2021-05-02 16:14:30,575 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.47.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:14:54,419 INFO] Step 28050/50000; xent: 2.50; lr: 0.0000119;  24 docs/s;  19491 sec\n",
            "[2021-05-02 16:15:28,104 INFO] Step 28100/50000; xent: 2.49; lr: 0.0000119;  31 docs/s;  19524 sec\n",
            "[2021-05-02 16:16:01,996 INFO] Step 28150/50000; xent: 2.57; lr: 0.0000119;  31 docs/s;  19558 sec\n",
            "[2021-05-02 16:16:35,701 INFO] Step 28200/50000; xent: 2.58; lr: 0.0000119;  31 docs/s;  19592 sec\n",
            "[2021-05-02 16:16:43,056 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.24.bert.pt, number of examples: 1999\n",
            "[2021-05-02 16:17:11,691 INFO] Step 28250/50000; xent: 2.62; lr: 0.0000119;  29 docs/s;  19628 sec\n",
            "[2021-05-02 16:17:45,616 INFO] Step 28300/50000; xent: 2.53; lr: 0.0000119;  31 docs/s;  19662 sec\n",
            "[2021-05-02 16:18:19,488 INFO] Step 28350/50000; xent: 2.51; lr: 0.0000119;  31 docs/s;  19696 sec\n",
            "[2021-05-02 16:18:54,944 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.13.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:18:55,708 INFO] Step 28400/50000; xent: 2.62; lr: 0.0000119;  28 docs/s;  19732 sec\n",
            "[2021-05-02 16:19:29,559 INFO] Step 28450/50000; xent: 2.53; lr: 0.0000119;  32 docs/s;  19766 sec\n",
            "[2021-05-02 16:20:03,573 INFO] Step 28500/50000; xent: 2.62; lr: 0.0000118;  30 docs/s;  19800 sec\n",
            "[2021-05-02 16:20:37,519 INFO] Step 28550/50000; xent: 2.52; lr: 0.0000118;  30 docs/s;  19834 sec\n",
            "[2021-05-02 16:21:05,639 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.40.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:21:11,828 INFO] Step 28600/50000; xent: 2.55; lr: 0.0000118;  30 docs/s;  19868 sec\n",
            "[2021-05-02 16:21:45,710 INFO] Step 28650/50000; xent: 2.46; lr: 0.0000118;  31 docs/s;  19902 sec\n",
            "[2021-05-02 16:22:19,700 INFO] Step 28700/50000; xent: 2.50; lr: 0.0000118;  30 docs/s;  19936 sec\n",
            "[2021-05-02 16:22:53,594 INFO] Step 28750/50000; xent: 2.58; lr: 0.0000118;  31 docs/s;  19970 sec\n",
            "[2021-05-02 16:23:16,141 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.69.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:23:27,776 INFO] Step 28800/50000; xent: 2.44; lr: 0.0000118;  30 docs/s;  20004 sec\n",
            "[2021-05-02 16:24:01,735 INFO] Step 28850/50000; xent: 2.64; lr: 0.0000118;  30 docs/s;  20038 sec\n",
            "[2021-05-02 16:24:35,678 INFO] Step 28900/50000; xent: 2.48; lr: 0.0000118;  31 docs/s;  20072 sec\n",
            "[2021-05-02 16:25:09,585 INFO] Step 28950/50000; xent: 2.47; lr: 0.0000118;  31 docs/s;  20106 sec\n",
            "[2021-05-02 16:25:29,930 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.41.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:25:47,050 INFO] Step 29000/50000; xent: 2.55; lr: 0.0000117;  28 docs/s;  20143 sec\n",
            "[2021-05-02 16:25:47,064 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_29000.pt\n",
            "[2021-05-02 16:26:28,350 INFO] Step 29050/50000; xent: 2.56; lr: 0.0000117;  25 docs/s;  20185 sec\n",
            "[2021-05-02 16:27:02,352 INFO] Step 29100/50000; xent: 2.54; lr: 0.0000117;  32 docs/s;  20219 sec\n",
            "[2021-05-02 16:27:36,287 INFO] Step 29150/50000; xent: 2.50; lr: 0.0000117;  30 docs/s;  20253 sec\n",
            "[2021-05-02 16:27:49,868 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.39.bert.pt, number of examples: 2001\n",
            "[2021-05-02 16:28:12,402 INFO] Step 29200/50000; xent: 2.51; lr: 0.0000117;  30 docs/s;  20289 sec\n",
            "[2021-05-02 16:28:46,350 INFO] Step 29250/50000; xent: 2.61; lr: 0.0000117;  31 docs/s;  20323 sec\n",
            "[2021-05-02 16:29:20,271 INFO] Step 29300/50000; xent: 2.58; lr: 0.0000117;  31 docs/s;  20357 sec\n",
            "[2021-05-02 16:29:54,141 INFO] Step 29350/50000; xent: 2.55; lr: 0.0000117;  30 docs/s;  20391 sec\n",
            "[2021-05-02 16:30:00,547 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.77.bert.pt, number of examples: 2001\n",
            "[2021-05-02 16:30:28,496 INFO] Step 29400/50000; xent: 2.48; lr: 0.0000117;  31 docs/s;  20425 sec\n",
            "[2021-05-02 16:31:02,455 INFO] Step 29450/50000; xent: 2.58; lr: 0.0000117;  31 docs/s;  20459 sec\n",
            "[2021-05-02 16:31:36,431 INFO] Step 29500/50000; xent: 2.51; lr: 0.0000116;  31 docs/s;  20493 sec\n",
            "[2021-05-02 16:32:10,072 INFO] Step 29550/50000; xent: 2.48; lr: 0.0000116;  30 docs/s;  20526 sec\n",
            "[2021-05-02 16:32:13,477 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.52.bert.pt, number of examples: 1999\n",
            "[2021-05-02 16:32:46,009 INFO] Step 29600/50000; xent: 2.51; lr: 0.0000116;  30 docs/s;  20562 sec\n",
            "[2021-05-02 16:33:19,971 INFO] Step 29650/50000; xent: 2.49; lr: 0.0000116;  30 docs/s;  20596 sec\n",
            "[2021-05-02 16:33:53,945 INFO] Step 29700/50000; xent: 2.51; lr: 0.0000116;  31 docs/s;  20630 sec\n",
            "[2021-05-02 16:34:24,122 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.31.bert.pt, number of examples: 2001\n",
            "[2021-05-02 16:34:28,293 INFO] Step 29750/50000; xent: 2.50; lr: 0.0000116;  30 docs/s;  20665 sec\n",
            "[2021-05-02 16:35:02,285 INFO] Step 29800/50000; xent: 2.51; lr: 0.0000116;  31 docs/s;  20699 sec\n",
            "[2021-05-02 16:35:36,211 INFO] Step 29850/50000; xent: 2.49; lr: 0.0000116;  31 docs/s;  20733 sec\n",
            "[2021-05-02 16:36:10,156 INFO] Step 29900/50000; xent: 2.52; lr: 0.0000116;  31 docs/s;  20767 sec\n",
            "[2021-05-02 16:36:36,668 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.121.bert.pt, number of examples: 1999\n",
            "[2021-05-02 16:36:46,257 INFO] Step 29950/50000; xent: 2.50; lr: 0.0000116;  29 docs/s;  20803 sec\n",
            "[2021-05-02 16:37:20,223 INFO] Step 30000/50000; xent: 2.47; lr: 0.0000115;  31 docs/s;  20837 sec\n",
            "[2021-05-02 16:37:20,238 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_30000.pt\n",
            "[2021-05-02 16:38:00,302 INFO] Step 30050/50000; xent: 2.52; lr: 0.0000115;  26 docs/s;  20877 sec\n",
            "[2021-05-02 16:38:34,237 INFO] Step 30100/50000; xent: 2.49; lr: 0.0000115;  31 docs/s;  20911 sec\n",
            "[2021-05-02 16:38:53,553 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.48.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:39:08,649 INFO] Step 30150/50000; xent: 2.53; lr: 0.0000115;  31 docs/s;  20945 sec\n",
            "[2021-05-02 16:39:42,602 INFO] Step 30200/50000; xent: 2.48; lr: 0.0000115;  31 docs/s;  20979 sec\n",
            "[2021-05-02 16:40:16,549 INFO] Step 30250/50000; xent: 2.50; lr: 0.0000115;  30 docs/s;  21013 sec\n",
            "[2021-05-02 16:40:50,549 INFO] Step 30300/50000; xent: 2.48; lr: 0.0000115;  31 docs/s;  21047 sec\n",
            "[2021-05-02 16:41:06,385 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.28.bert.pt, number of examples: 1999\n",
            "[2021-05-02 16:41:26,886 INFO] Step 30350/50000; xent: 2.58; lr: 0.0000115;  28 docs/s;  21083 sec\n",
            "[2021-05-02 16:42:00,815 INFO] Step 30400/50000; xent: 2.59; lr: 0.0000115;  30 docs/s;  21117 sec\n",
            "[2021-05-02 16:42:34,596 INFO] Step 30450/50000; xent: 2.61; lr: 0.0000115;  30 docs/s;  21151 sec\n",
            "[2021-05-02 16:43:08,451 INFO] Step 30500/50000; xent: 2.56; lr: 0.0000115;  31 docs/s;  21185 sec\n",
            "[2021-05-02 16:43:18,258 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.58.bert.pt, number of examples: 2001\n",
            "[2021-05-02 16:43:42,848 INFO] Step 30550/50000; xent: 2.50; lr: 0.0000114;  30 docs/s;  21219 sec\n",
            "[2021-05-02 16:44:16,819 INFO] Step 30600/50000; xent: 2.44; lr: 0.0000114;  32 docs/s;  21253 sec\n",
            "[2021-05-02 16:44:50,819 INFO] Step 30650/50000; xent: 2.47; lr: 0.0000114;  30 docs/s;  21287 sec\n",
            "[2021-05-02 16:45:24,740 INFO] Step 30700/50000; xent: 2.43; lr: 0.0000114;  30 docs/s;  21321 sec\n",
            "[2021-05-02 16:45:30,845 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.62.bert.pt, number of examples: 2001\n",
            "[2021-05-02 16:46:00,821 INFO] Step 30750/50000; xent: 2.61; lr: 0.0000114;  29 docs/s;  21357 sec\n",
            "[2021-05-02 16:46:34,643 INFO] Step 30800/50000; xent: 2.56; lr: 0.0000114;  31 docs/s;  21391 sec\n",
            "[2021-05-02 16:47:08,648 INFO] Step 30850/50000; xent: 2.57; lr: 0.0000114;  30 docs/s;  21425 sec\n",
            "[2021-05-02 16:47:42,380 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.133.bert.pt, number of examples: 1999\n",
            "[2021-05-02 16:47:43,154 INFO] Step 30900/50000; xent: 2.53; lr: 0.0000114;  30 docs/s;  21460 sec\n",
            "[2021-05-02 16:48:17,110 INFO] Step 30950/50000; xent: 2.59; lr: 0.0000114;  31 docs/s;  21493 sec\n",
            "[2021-05-02 16:48:51,085 INFO] Step 31000/50000; xent: 2.51; lr: 0.0000114;  31 docs/s;  21527 sec\n",
            "[2021-05-02 16:48:51,099 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_31000.pt\n",
            "[2021-05-02 16:49:30,956 INFO] Step 31050/50000; xent: 2.50; lr: 0.0000114;  26 docs/s;  21567 sec\n",
            "[2021-05-02 16:50:01,394 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.86.bert.pt, number of examples: 1999\n",
            "[2021-05-02 16:50:06,934 INFO] Step 31100/50000; xent: 2.44; lr: 0.0000113;  28 docs/s;  21603 sec\n",
            "[2021-05-02 16:50:40,846 INFO] Step 31150/50000; xent: 2.43; lr: 0.0000113;  31 docs/s;  21637 sec\n",
            "[2021-05-02 16:51:14,834 INFO] Step 31200/50000; xent: 2.55; lr: 0.0000113;  30 docs/s;  21671 sec\n",
            "[2021-05-02 16:51:48,794 INFO] Step 31250/50000; xent: 2.54; lr: 0.0000113;  31 docs/s;  21705 sec\n",
            "[2021-05-02 16:52:12,683 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.3.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:52:22,965 INFO] Step 31300/50000; xent: 2.49; lr: 0.0000113;  30 docs/s;  21739 sec\n",
            "[2021-05-02 16:52:56,938 INFO] Step 31350/50000; xent: 2.53; lr: 0.0000113;  31 docs/s;  21773 sec\n",
            "[2021-05-02 16:53:30,930 INFO] Step 31400/50000; xent: 2.51; lr: 0.0000113;  31 docs/s;  21807 sec\n",
            "[2021-05-02 16:54:04,852 INFO] Step 31450/50000; xent: 2.55; lr: 0.0000113;  30 docs/s;  21841 sec\n",
            "[2021-05-02 16:54:26,009 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.9.bert.pt, number of examples: 2000\n",
            "[2021-05-02 16:54:41,035 INFO] Step 31500/50000; xent: 2.50; lr: 0.0000113;  29 docs/s;  21877 sec\n",
            "[2021-05-02 16:55:14,933 INFO] Step 31550/50000; xent: 2.49; lr: 0.0000113;  31 docs/s;  21911 sec\n",
            "[2021-05-02 16:55:48,952 INFO] Step 31600/50000; xent: 2.57; lr: 0.0000113;  31 docs/s;  21945 sec\n",
            "[2021-05-02 16:56:22,875 INFO] Step 31650/50000; xent: 2.53; lr: 0.0000112;  31 docs/s;  21979 sec\n",
            "[2021-05-02 16:56:36,803 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.70.bert.pt, number of examples: 1999\n",
            "[2021-05-02 16:56:57,284 INFO] Step 31700/50000; xent: 2.54; lr: 0.0000112;  30 docs/s;  22014 sec\n",
            "[2021-05-02 16:57:31,278 INFO] Step 31750/50000; xent: 2.47; lr: 0.0000112;  30 docs/s;  22048 sec\n",
            "[2021-05-02 16:58:05,214 INFO] Step 31800/50000; xent: 2.45; lr: 0.0000112;  32 docs/s;  22082 sec\n",
            "[2021-05-02 16:58:39,051 INFO] Step 31850/50000; xent: 2.47; lr: 0.0000112;  30 docs/s;  22115 sec\n",
            "[2021-05-02 16:58:49,194 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.22.bert.pt, number of examples: 2001\n",
            "[2021-05-02 16:59:15,082 INFO] Step 31900/50000; xent: 2.45; lr: 0.0000112;  29 docs/s;  22151 sec\n",
            "[2021-05-02 16:59:49,120 INFO] Step 31950/50000; xent: 2.52; lr: 0.0000112;  31 docs/s;  22185 sec\n",
            "[2021-05-02 17:00:23,116 INFO] Step 32000/50000; xent: 2.57; lr: 0.0000112;  30 docs/s;  22219 sec\n",
            "[2021-05-02 17:00:23,130 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_32000.pt\n",
            "[2021-05-02 17:01:02,447 INFO] Step 32050/50000; xent: 2.47; lr: 0.0000112;  26 docs/s;  22259 sec\n",
            "[2021-05-02 17:01:07,891 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.91.bert.pt, number of examples: 1995\n",
            "[2021-05-02 17:01:38,402 INFO] Step 32100/50000; xent: 2.50; lr: 0.0000112;  29 docs/s;  22295 sec\n",
            "[2021-05-02 17:02:12,346 INFO] Step 32150/50000; xent: 2.54; lr: 0.0000112;  31 docs/s;  22329 sec\n",
            "[2021-05-02 17:02:46,343 INFO] Step 32200/50000; xent: 2.50; lr: 0.0000111;  30 docs/s;  22363 sec\n",
            "[2021-05-02 17:03:20,298 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.95.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:03:22,425 INFO] Step 32250/50000; xent: 2.58; lr: 0.0000111;  28 docs/s;  22399 sec\n",
            "[2021-05-02 17:03:56,347 INFO] Step 32300/50000; xent: 2.53; lr: 0.0000111;  31 docs/s;  22433 sec\n",
            "[2021-05-02 17:04:30,115 INFO] Step 32350/50000; xent: 2.63; lr: 0.0000111;  30 docs/s;  22466 sec\n",
            "[2021-05-02 17:05:04,093 INFO] Step 32400/50000; xent: 2.70; lr: 0.0000111;  31 docs/s;  22500 sec\n",
            "[2021-05-02 17:05:33,388 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.123.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:05:40,257 INFO] Step 32450/50000; xent: 2.46; lr: 0.0000111;  29 docs/s;  22537 sec\n",
            "[2021-05-02 17:06:14,167 INFO] Step 32500/50000; xent: 2.60; lr: 0.0000111;  30 docs/s;  22571 sec\n",
            "[2021-05-02 17:06:48,150 INFO] Step 32550/50000; xent: 2.57; lr: 0.0000111;  31 docs/s;  22605 sec\n",
            "[2021-05-02 17:07:22,078 INFO] Step 32600/50000; xent: 2.57; lr: 0.0000111;  30 docs/s;  22638 sec\n",
            "[2021-05-02 17:07:44,457 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.92.bert.pt, number of examples: 1998\n",
            "[2021-05-02 17:07:57,461 INFO] Step 32650/50000; xent: 2.62; lr: 0.0000111;  30 docs/s;  22674 sec\n",
            "[2021-05-02 17:08:31,280 INFO] Step 32700/50000; xent: 2.56; lr: 0.0000111;  30 docs/s;  22708 sec\n",
            "[2021-05-02 17:09:05,288 INFO] Step 32750/50000; xent: 2.50; lr: 0.0000111;  31 docs/s;  22742 sec\n",
            "[2021-05-02 17:09:39,196 INFO] Step 32800/50000; xent: 2.53; lr: 0.0000110;  31 docs/s;  22776 sec\n",
            "[2021-05-02 17:09:57,287 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.76.bert.pt, number of examples: 2001\n",
            "[2021-05-02 17:10:15,079 INFO] Step 32850/50000; xent: 2.54; lr: 0.0000110;  28 docs/s;  22811 sec\n",
            "[2021-05-02 17:10:48,838 INFO] Step 32900/50000; xent: 2.64; lr: 0.0000110;  30 docs/s;  22845 sec\n",
            "[2021-05-02 17:11:22,878 INFO] Step 32950/50000; xent: 2.51; lr: 0.0000110;  30 docs/s;  22879 sec\n",
            "[2021-05-02 17:11:56,848 INFO] Step 33000/50000; xent: 2.56; lr: 0.0000110;  31 docs/s;  22913 sec\n",
            "[2021-05-02 17:11:56,851 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_33000.pt\n",
            "[2021-05-02 17:12:16,878 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.34.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:12:39,416 INFO] Step 33050/50000; xent: 2.55; lr: 0.0000110;  24 docs/s;  22956 sec\n",
            "[2021-05-02 17:13:13,443 INFO] Step 33100/50000; xent: 2.49; lr: 0.0000110;  31 docs/s;  22990 sec\n",
            "[2021-05-02 17:13:47,289 INFO] Step 33150/50000; xent: 2.49; lr: 0.0000110;  30 docs/s;  23024 sec\n",
            "[2021-05-02 17:14:20,995 INFO] Step 33200/50000; xent: 2.49; lr: 0.0000110;  31 docs/s;  23057 sec\n",
            "[2021-05-02 17:14:28,198 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.75.bert.pt, number of examples: 1999\n",
            "[2021-05-02 17:14:55,445 INFO] Step 33250/50000; xent: 2.46; lr: 0.0000110;  30 docs/s;  23092 sec\n",
            "[2021-05-02 17:15:29,421 INFO] Step 33300/50000; xent: 2.54; lr: 0.0000110;  30 docs/s;  23126 sec\n",
            "[2021-05-02 17:16:03,204 INFO] Step 33350/50000; xent: 2.45; lr: 0.0000110;  31 docs/s;  23160 sec\n",
            "[2021-05-02 17:16:37,192 INFO] Step 33400/50000; xent: 2.54; lr: 0.0000109;  30 docs/s;  23194 sec\n",
            "[2021-05-02 17:16:39,610 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.56.bert.pt, number of examples: 2001\n",
            "[2021-05-02 17:17:11,527 INFO] Step 33450/50000; xent: 2.46; lr: 0.0000109;  30 docs/s;  23228 sec\n",
            "[2021-05-02 17:17:45,489 INFO] Step 33500/50000; xent: 2.37; lr: 0.0000109;  32 docs/s;  23262 sec\n",
            "[2021-05-02 17:18:19,438 INFO] Step 33550/50000; xent: 2.45; lr: 0.0000109;  30 docs/s;  23296 sec\n",
            "[2021-05-02 17:18:50,912 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.60.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:18:53,730 INFO] Step 33600/50000; xent: 2.49; lr: 0.0000109;  30 docs/s;  23330 sec\n",
            "[2021-05-02 17:19:27,580 INFO] Step 33650/50000; xent: 2.48; lr: 0.0000109;  31 docs/s;  23364 sec\n",
            "[2021-05-02 17:20:01,623 INFO] Step 33700/50000; xent: 2.45; lr: 0.0000109;  30 docs/s;  23398 sec\n",
            "[2021-05-02 17:20:35,542 INFO] Step 33750/50000; xent: 2.42; lr: 0.0000109;  31 docs/s;  23432 sec\n",
            "[2021-05-02 17:21:03,727 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.65.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:21:11,979 INFO] Step 33800/50000; xent: 2.52; lr: 0.0000109;  28 docs/s;  23468 sec\n",
            "[2021-05-02 17:21:45,998 INFO] Step 33850/50000; xent: 2.54; lr: 0.0000109;  31 docs/s;  23502 sec\n",
            "[2021-05-02 17:22:19,977 INFO] Step 33900/50000; xent: 2.51; lr: 0.0000109;  31 docs/s;  23536 sec\n",
            "[2021-05-02 17:22:53,694 INFO] Step 33950/50000; xent: 2.50; lr: 0.0000109;  30 docs/s;  23570 sec\n",
            "[2021-05-02 17:23:16,116 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.110.bert.pt, number of examples: 2001\n",
            "[2021-05-02 17:23:29,753 INFO] Step 34000/50000; xent: 2.50; lr: 0.0000108;  29 docs/s;  23606 sec\n",
            "[2021-05-02 17:23:29,767 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_34000.pt\n",
            "[2021-05-02 17:24:09,671 INFO] Step 34050/50000; xent: 2.63; lr: 0.0000108;  26 docs/s;  23646 sec\n",
            "[2021-05-02 17:24:43,784 INFO] Step 34100/50000; xent: 2.62; lr: 0.0000108;  32 docs/s;  23680 sec\n",
            "[2021-05-02 17:25:17,716 INFO] Step 34150/50000; xent: 2.58; lr: 0.0000108;  30 docs/s;  23714 sec\n",
            "[2021-05-02 17:25:33,529 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.108.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:25:51,974 INFO] Step 34200/50000; xent: 2.44; lr: 0.0000108;  31 docs/s;  23748 sec\n",
            "[2021-05-02 17:26:25,908 INFO] Step 34250/50000; xent: 2.42; lr: 0.0000108;  31 docs/s;  23782 sec\n",
            "[2021-05-02 17:26:59,600 INFO] Step 34300/50000; xent: 2.50; lr: 0.0000108;  31 docs/s;  23816 sec\n",
            "[2021-05-02 17:27:33,639 INFO] Step 34350/50000; xent: 2.40; lr: 0.0000108;  30 docs/s;  23850 sec\n",
            "[2021-05-02 17:27:45,722 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.23.bert.pt, number of examples: 2001\n",
            "[2021-05-02 17:28:09,608 INFO] Step 34400/50000; xent: 2.54; lr: 0.0000108;  29 docs/s;  23886 sec\n",
            "[2021-05-02 17:28:43,583 INFO] Step 34450/50000; xent: 2.58; lr: 0.0000108;  30 docs/s;  23920 sec\n",
            "[2021-05-02 17:29:17,524 INFO] Step 34500/50000; xent: 2.62; lr: 0.0000108;  31 docs/s;  23954 sec\n",
            "[2021-05-02 17:29:51,297 INFO] Step 34550/50000; xent: 2.60; lr: 0.0000108;  31 docs/s;  23988 sec\n",
            "[2021-05-02 17:29:56,428 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.115.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:30:25,444 INFO] Step 34600/50000; xent: 2.49; lr: 0.0000108;  30 docs/s;  24022 sec\n",
            "[2021-05-02 17:30:59,355 INFO] Step 34650/50000; xent: 2.54; lr: 0.0000107;  31 docs/s;  24056 sec\n",
            "[2021-05-02 17:31:33,275 INFO] Step 34700/50000; xent: 2.50; lr: 0.0000107;  30 docs/s;  24090 sec\n",
            "[2021-05-02 17:32:07,192 INFO] Step 34750/50000; xent: 2.50; lr: 0.0000107;  31 docs/s;  24124 sec\n",
            "[2021-05-02 17:32:09,185 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.89.bert.pt, number of examples: 2001\n",
            "[2021-05-02 17:32:43,146 INFO] Step 34800/50000; xent: 2.54; lr: 0.0000107;  29 docs/s;  24160 sec\n",
            "[2021-05-02 17:33:16,896 INFO] Step 34850/50000; xent: 2.65; lr: 0.0000107;  30 docs/s;  24193 sec\n",
            "[2021-05-02 17:33:50,709 INFO] Step 34900/50000; xent: 2.49; lr: 0.0000107;  31 docs/s;  24227 sec\n",
            "[2021-05-02 17:34:21,840 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.81.bert.pt, number of examples: 2001\n",
            "[2021-05-02 17:34:26,698 INFO] Step 34950/50000; xent: 2.53; lr: 0.0000107;  29 docs/s;  24263 sec\n",
            "[2021-05-02 17:35:00,489 INFO] Step 35000/50000; xent: 2.47; lr: 0.0000107;  31 docs/s;  24297 sec\n",
            "[2021-05-02 17:35:00,504 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_35000.pt\n",
            "[2021-05-02 17:35:41,555 INFO] Step 35050/50000; xent: 2.63; lr: 0.0000107;  25 docs/s;  24338 sec\n",
            "[2021-05-02 17:36:15,370 INFO] Step 35100/50000; xent: 2.58; lr: 0.0000107;  31 docs/s;  24372 sec\n",
            "[2021-05-02 17:36:41,196 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.5.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:36:51,450 INFO] Step 35150/50000; xent: 2.52; lr: 0.0000107;  29 docs/s;  24408 sec\n",
            "[2021-05-02 17:37:25,312 INFO] Step 35200/50000; xent: 2.54; lr: 0.0000107;  31 docs/s;  24442 sec\n",
            "[2021-05-02 17:37:58,912 INFO] Step 35250/50000; xent: 2.50; lr: 0.0000107;  31 docs/s;  24475 sec\n",
            "[2021-05-02 17:38:32,749 INFO] Step 35300/50000; xent: 2.59; lr: 0.0000106;  30 docs/s;  24509 sec\n",
            "[2021-05-02 17:38:51,915 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.7.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:39:06,874 INFO] Step 35350/50000; xent: 2.55; lr: 0.0000106;  30 docs/s;  24543 sec\n",
            "[2021-05-02 17:39:40,649 INFO] Step 35400/50000; xent: 2.50; lr: 0.0000106;  30 docs/s;  24577 sec\n",
            "[2021-05-02 17:40:14,458 INFO] Step 35450/50000; xent: 2.49; lr: 0.0000106;  31 docs/s;  24611 sec\n",
            "[2021-05-02 17:40:48,346 INFO] Step 35500/50000; xent: 2.44; lr: 0.0000106;  32 docs/s;  24645 sec\n",
            "[2021-05-02 17:41:03,812 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.116.bert.pt, number of examples: 1997\n",
            "[2021-05-02 17:41:24,144 INFO] Step 35550/50000; xent: 2.50; lr: 0.0000106;  29 docs/s;  24681 sec\n",
            "[2021-05-02 17:41:57,964 INFO] Step 35600/50000; xent: 2.54; lr: 0.0000106;  31 docs/s;  24714 sec\n",
            "[2021-05-02 17:42:31,809 INFO] Step 35650/50000; xent: 2.60; lr: 0.0000106;  31 docs/s;  24748 sec\n",
            "[2021-05-02 17:43:05,702 INFO] Step 35700/50000; xent: 2.63; lr: 0.0000106;  30 docs/s;  24782 sec\n",
            "[2021-05-02 17:43:14,809 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.132.bert.pt, number of examples: 2001\n",
            "[2021-05-02 17:43:39,889 INFO] Step 35750/50000; xent: 2.47; lr: 0.0000106;  31 docs/s;  24816 sec\n",
            "[2021-05-02 17:44:13,724 INFO] Step 35800/50000; xent: 2.50; lr: 0.0000106;  30 docs/s;  24850 sec\n",
            "[2021-05-02 17:44:47,627 INFO] Step 35850/50000; xent: 2.51; lr: 0.0000106;  30 docs/s;  24884 sec\n",
            "[2021-05-02 17:45:21,076 INFO] Step 35900/50000; xent: 2.50; lr: 0.0000106;  31 docs/s;  24917 sec\n",
            "[2021-05-02 17:45:27,167 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.71.bert.pt, number of examples: 1999\n",
            "[2021-05-02 17:45:56,977 INFO] Step 35950/50000; xent: 2.60; lr: 0.0000105;  29 docs/s;  24953 sec\n",
            "[2021-05-02 17:46:30,818 INFO] Step 36000/50000; xent: 2.57; lr: 0.0000105;  31 docs/s;  24987 sec\n",
            "[2021-05-02 17:46:30,833 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_36000.pt\n",
            "[2021-05-02 17:47:10,612 INFO] Step 36050/50000; xent: 2.60; lr: 0.0000105;  26 docs/s;  25027 sec\n",
            "[2021-05-02 17:47:45,076 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.73.bert.pt, number of examples: 2001\n",
            "[2021-05-02 17:47:46,520 INFO] Step 36100/50000; xent: 2.58; lr: 0.0000105;  29 docs/s;  25063 sec\n",
            "[2021-05-02 17:48:20,337 INFO] Step 36150/50000; xent: 2.61; lr: 0.0000105;  31 docs/s;  25097 sec\n",
            "[2021-05-02 17:48:54,207 INFO] Step 36200/50000; xent: 2.52; lr: 0.0000105;  31 docs/s;  25131 sec\n",
            "[2021-05-02 17:49:28,183 INFO] Step 36250/50000; xent: 2.45; lr: 0.0000105;  30 docs/s;  25165 sec\n",
            "[2021-05-02 17:49:58,429 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.137.bert.pt, number of examples: 2001\n",
            "[2021-05-02 17:50:03,982 INFO] Step 36300/50000; xent: 2.55; lr: 0.0000105;  28 docs/s;  25200 sec\n",
            "[2021-05-02 17:50:37,822 INFO] Step 36350/50000; xent: 2.61; lr: 0.0000105;  31 docs/s;  25234 sec\n",
            "[2021-05-02 17:51:11,605 INFO] Step 36400/50000; xent: 2.53; lr: 0.0000105;  31 docs/s;  25268 sec\n",
            "[2021-05-02 17:51:45,459 INFO] Step 36450/50000; xent: 2.58; lr: 0.0000105;  31 docs/s;  25302 sec\n",
            "[2021-05-02 17:52:11,160 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.45.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:52:21,451 INFO] Step 36500/50000; xent: 2.60; lr: 0.0000105;  29 docs/s;  25338 sec\n",
            "[2021-05-02 17:52:55,212 INFO] Step 36550/50000; xent: 2.49; lr: 0.0000105;  31 docs/s;  25372 sec\n",
            "[2021-05-02 17:53:29,030 INFO] Step 36600/50000; xent: 2.52; lr: 0.0000105;  30 docs/s;  25405 sec\n",
            "[2021-05-02 17:54:02,883 INFO] Step 36650/50000; xent: 2.42; lr: 0.0000104;  31 docs/s;  25439 sec\n",
            "[2021-05-02 17:54:23,374 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.136.bert.pt, number of examples: 1998\n",
            "[2021-05-02 17:54:38,367 INFO] Step 36700/50000; xent: 2.43; lr: 0.0000104;  30 docs/s;  25475 sec\n",
            "[2021-05-02 17:55:12,234 INFO] Step 36750/50000; xent: 2.50; lr: 0.0000104;  31 docs/s;  25509 sec\n",
            "[2021-05-02 17:55:46,142 INFO] Step 36800/50000; xent: 2.53; lr: 0.0000104;  31 docs/s;  25543 sec\n",
            "[2021-05-02 17:56:19,989 INFO] Step 36850/50000; xent: 2.47; lr: 0.0000104;  30 docs/s;  25576 sec\n",
            "[2021-05-02 17:56:34,865 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.19.bert.pt, number of examples: 1999\n",
            "[2021-05-02 17:56:55,304 INFO] Step 36900/50000; xent: 2.55; lr: 0.0000104;  29 docs/s;  25612 sec\n",
            "[2021-05-02 17:57:29,160 INFO] Step 36950/50000; xent: 2.56; lr: 0.0000104;  31 docs/s;  25646 sec\n",
            "[2021-05-02 17:58:03,055 INFO] Step 37000/50000; xent: 2.57; lr: 0.0000104;  30 docs/s;  25679 sec\n",
            "[2021-05-02 17:58:03,069 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_37000.pt\n",
            "[2021-05-02 17:58:42,363 INFO] Step 37050/50000; xent: 2.61; lr: 0.0000104;  27 docs/s;  25719 sec\n",
            "[2021-05-02 17:58:53,265 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.44.bert.pt, number of examples: 2000\n",
            "[2021-05-02 17:59:18,394 INFO] Step 37100/50000; xent: 2.52; lr: 0.0000104;  29 docs/s;  25755 sec\n",
            "[2021-05-02 17:59:52,137 INFO] Step 37150/50000; xent: 2.54; lr: 0.0000104;  31 docs/s;  25789 sec\n",
            "[2021-05-02 18:00:26,002 INFO] Step 37200/50000; xent: 2.53; lr: 0.0000104;  31 docs/s;  25822 sec\n",
            "[2021-05-02 18:00:59,996 INFO] Step 37250/50000; xent: 2.59; lr: 0.0000104;  31 docs/s;  25856 sec\n",
            "[2021-05-02 18:01:05,291 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.140.bert.pt, number of examples: 1999\n",
            "[2021-05-02 18:01:35,811 INFO] Step 37300/50000; xent: 2.47; lr: 0.0000104;  29 docs/s;  25892 sec\n",
            "[2021-05-02 18:02:09,752 INFO] Step 37350/50000; xent: 2.50; lr: 0.0000103;  31 docs/s;  25926 sec\n",
            "[2021-05-02 18:02:43,579 INFO] Step 37400/50000; xent: 2.47; lr: 0.0000103;  30 docs/s;  25960 sec\n",
            "[2021-05-02 18:03:18,356 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.103.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:03:19,812 INFO] Step 37450/50000; xent: 2.52; lr: 0.0000103;  28 docs/s;  25996 sec\n",
            "[2021-05-02 18:03:53,678 INFO] Step 37500/50000; xent: 2.56; lr: 0.0000103;  31 docs/s;  26030 sec\n",
            "[2021-05-02 18:04:27,249 INFO] Step 37550/50000; xent: 2.43; lr: 0.0000103;  31 docs/s;  26064 sec\n",
            "[2021-05-02 18:05:01,091 INFO] Step 37600/50000; xent: 2.51; lr: 0.0000103;  31 docs/s;  26097 sec\n",
            "[2021-05-02 18:05:31,261 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.15.bert.pt, number of examples: 2000\n",
            "[2021-05-02 18:05:37,447 INFO] Step 37650/50000; xent: 2.55; lr: 0.0000103;  28 docs/s;  26134 sec\n",
            "[2021-05-02 18:06:11,307 INFO] Step 37700/50000; xent: 2.53; lr: 0.0000103;  31 docs/s;  26168 sec\n",
            "[2021-05-02 18:06:45,175 INFO] Step 37750/50000; xent: 2.51; lr: 0.0000103;  31 docs/s;  26202 sec\n",
            "[2021-05-02 18:07:18,932 INFO] Step 37800/50000; xent: 2.51; lr: 0.0000103;  31 docs/s;  26235 sec\n",
            "[2021-05-02 18:07:44,096 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.84.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:07:54,948 INFO] Step 37850/50000; xent: 2.60; lr: 0.0000103;  29 docs/s;  26271 sec\n",
            "[2021-05-02 18:08:28,767 INFO] Step 37900/50000; xent: 2.55; lr: 0.0000103;  31 docs/s;  26305 sec\n",
            "[2021-05-02 18:09:02,676 INFO] Step 37950/50000; xent: 2.61; lr: 0.0000103;  31 docs/s;  26339 sec\n",
            "[2021-05-02 18:09:36,469 INFO] Step 38000/50000; xent: 2.52; lr: 0.0000103;  30 docs/s;  26373 sec\n",
            "[2021-05-02 18:09:36,483 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_38000.pt\n",
            "[2021-05-02 18:10:02,731 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.66.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:10:18,475 INFO] Step 38050/50000; xent: 2.50; lr: 0.0000103;  25 docs/s;  26415 sec\n",
            "[2021-05-02 18:10:52,318 INFO] Step 38100/50000; xent: 2.47; lr: 0.0000102;  30 docs/s;  26449 sec\n",
            "[2021-05-02 18:11:26,049 INFO] Step 38150/50000; xent: 2.50; lr: 0.0000102;  31 docs/s;  26482 sec\n",
            "[2021-05-02 18:11:59,968 INFO] Step 38200/50000; xent: 2.60; lr: 0.0000102;  31 docs/s;  26516 sec\n",
            "[2021-05-02 18:12:15,270 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.32.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:12:35,709 INFO] Step 38250/50000; xent: 2.61; lr: 0.0000102;  29 docs/s;  26552 sec\n",
            "[2021-05-02 18:13:09,574 INFO] Step 38300/50000; xent: 2.56; lr: 0.0000102;  31 docs/s;  26586 sec\n",
            "[2021-05-02 18:13:43,293 INFO] Step 38350/50000; xent: 2.60; lr: 0.0000102;  31 docs/s;  26620 sec\n",
            "[2021-05-02 18:14:16,900 INFO] Step 38400/50000; xent: 2.43; lr: 0.0000102;  31 docs/s;  26653 sec\n",
            "[2021-05-02 18:14:25,421 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.109.bert.pt, number of examples: 1999\n",
            "[2021-05-02 18:14:51,227 INFO] Step 38450/50000; xent: 2.46; lr: 0.0000102;  30 docs/s;  26688 sec\n",
            "[2021-05-02 18:15:25,141 INFO] Step 38500/50000; xent: 2.54; lr: 0.0000102;  31 docs/s;  26722 sec\n",
            "[2021-05-02 18:15:59,005 INFO] Step 38550/50000; xent: 2.46; lr: 0.0000102;  30 docs/s;  26755 sec\n",
            "[2021-05-02 18:16:32,615 INFO] Step 38600/50000; xent: 2.50; lr: 0.0000102;  31 docs/s;  26789 sec\n",
            "[2021-05-02 18:16:38,421 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.37.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:17:08,960 INFO] Step 38650/50000; xent: 2.51; lr: 0.0000102;  28 docs/s;  26825 sec\n",
            "[2021-05-02 18:17:42,928 INFO] Step 38700/50000; xent: 2.48; lr: 0.0000102;  31 docs/s;  26859 sec\n",
            "[2021-05-02 18:18:16,827 INFO] Step 38750/50000; xent: 2.54; lr: 0.0000102;  31 docs/s;  26893 sec\n",
            "[2021-05-02 18:18:50,432 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.118.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:18:52,551 INFO] Step 38800/50000; xent: 2.48; lr: 0.0000102;  29 docs/s;  26929 sec\n",
            "[2021-05-02 18:19:26,409 INFO] Step 38850/50000; xent: 2.43; lr: 0.0000101;  30 docs/s;  26963 sec\n",
            "[2021-05-02 18:20:00,303 INFO] Step 38900/50000; xent: 2.46; lr: 0.0000101;  31 docs/s;  26997 sec\n",
            "[2021-05-02 18:20:33,930 INFO] Step 38950/50000; xent: 2.38; lr: 0.0000101;  32 docs/s;  27030 sec\n",
            "[2021-05-02 18:21:03,203 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.98.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:21:10,769 INFO] Step 39000/50000; xent: 2.55; lr: 0.0000101;  28 docs/s;  27067 sec\n",
            "[2021-05-02 18:21:10,783 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_39000.pt\n",
            "[2021-05-02 18:21:50,167 INFO] Step 39050/50000; xent: 2.58; lr: 0.0000101;  27 docs/s;  27107 sec\n",
            "[2021-05-02 18:22:23,981 INFO] Step 39100/50000; xent: 2.64; lr: 0.0000101;  31 docs/s;  27140 sec\n",
            "[2021-05-02 18:22:57,580 INFO] Step 39150/50000; xent: 2.47; lr: 0.0000101;  31 docs/s;  27174 sec\n",
            "[2021-05-02 18:23:21,169 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.117.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:23:33,443 INFO] Step 39200/50000; xent: 2.52; lr: 0.0000101;  29 docs/s;  27210 sec\n",
            "[2021-05-02 18:24:07,240 INFO] Step 39250/50000; xent: 2.51; lr: 0.0000101;  31 docs/s;  27244 sec\n",
            "[2021-05-02 18:24:40,950 INFO] Step 39300/50000; xent: 2.52; lr: 0.0000101;  31 docs/s;  27277 sec\n",
            "[2021-05-02 18:25:14,803 INFO] Step 39350/50000; xent: 2.49; lr: 0.0000101;  31 docs/s;  27311 sec\n",
            "[2021-05-02 18:25:33,508 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.38.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:25:50,508 INFO] Step 39400/50000; xent: 2.53; lr: 0.0000101;  29 docs/s;  27347 sec\n",
            "[2021-05-02 18:26:24,380 INFO] Step 39450/50000; xent: 2.41; lr: 0.0000101;  32 docs/s;  27381 sec\n",
            "[2021-05-02 18:26:58,019 INFO] Step 39500/50000; xent: 2.59; lr: 0.0000101;  30 docs/s;  27414 sec\n",
            "[2021-05-02 18:27:31,940 INFO] Step 39550/50000; xent: 2.48; lr: 0.0000101;  30 docs/s;  27448 sec\n",
            "[2021-05-02 18:27:43,714 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.100.bert.pt, number of examples: 2000\n",
            "[2021-05-02 18:28:06,188 INFO] Step 39600/50000; xent: 2.52; lr: 0.0000101;  30 docs/s;  27483 sec\n",
            "[2021-05-02 18:28:40,107 INFO] Step 39650/50000; xent: 2.55; lr: 0.0000100;  32 docs/s;  27516 sec\n",
            "[2021-05-02 18:29:13,960 INFO] Step 39700/50000; xent: 2.46; lr: 0.0000100;  31 docs/s;  27550 sec\n",
            "[2021-05-02 18:29:47,566 INFO] Step 39750/50000; xent: 2.51; lr: 0.0000100;  30 docs/s;  27584 sec\n",
            "[2021-05-02 18:29:55,051 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.87.bert.pt, number of examples: 2000\n",
            "[2021-05-02 18:30:22,930 INFO] Step 39800/50000; xent: 2.50; lr: 0.0000100;  30 docs/s;  27619 sec\n",
            "[2021-05-02 18:30:56,785 INFO] Step 39850/50000; xent: 2.46; lr: 0.0000100;  31 docs/s;  27653 sec\n",
            "[2021-05-02 18:31:30,393 INFO] Step 39900/50000; xent: 2.45; lr: 0.0000100;  30 docs/s;  27687 sec\n",
            "[2021-05-02 18:32:04,275 INFO] Step 39950/50000; xent: 2.54; lr: 0.0000100;  30 docs/s;  27721 sec\n",
            "[2021-05-02 18:32:06,978 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.125.bert.pt, number of examples: 2000\n",
            "[2021-05-02 18:32:40,012 INFO] Step 40000/50000; xent: 2.57; lr: 0.0000100;  29 docs/s;  27756 sec\n",
            "[2021-05-02 18:32:40,028 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_40000.pt\n",
            "[2021-05-02 18:33:21,106 INFO] Step 40050/50000; xent: 2.54; lr: 0.0000100;  26 docs/s;  27797 sec\n",
            "[2021-05-02 18:33:54,976 INFO] Step 40100/50000; xent: 2.55; lr: 0.0000100;  31 docs/s;  27831 sec\n",
            "[2021-05-02 18:34:25,610 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.53.bert.pt, number of examples: 2000\n",
            "[2021-05-02 18:34:30,444 INFO] Step 40150/50000; xent: 2.52; lr: 0.0000100;  29 docs/s;  27867 sec\n",
            "[2021-05-02 18:35:04,101 INFO] Step 40200/50000; xent: 2.53; lr: 0.0000100;  31 docs/s;  27900 sec\n",
            "[2021-05-02 18:35:37,976 INFO] Step 40250/50000; xent: 2.53; lr: 0.0000100;  31 docs/s;  27934 sec\n",
            "[2021-05-02 18:36:11,796 INFO] Step 40300/50000; xent: 2.58; lr: 0.0000100;  31 docs/s;  27968 sec\n",
            "[2021-05-02 18:36:37,364 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.96.bert.pt, number of examples: 1999\n",
            "[2021-05-02 18:36:47,596 INFO] Step 40350/50000; xent: 2.57; lr: 0.0000100;  29 docs/s;  28004 sec\n",
            "[2021-05-02 18:37:21,408 INFO] Step 40400/50000; xent: 2.52; lr: 0.0000100;  30 docs/s;  28038 sec\n",
            "[2021-05-02 18:37:55,194 INFO] Step 40450/50000; xent: 2.46; lr: 0.0000099;  31 docs/s;  28072 sec\n",
            "[2021-05-02 18:38:28,910 INFO] Step 40500/50000; xent: 2.54; lr: 0.0000099;  32 docs/s;  28105 sec\n",
            "[2021-05-02 18:38:49,005 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.72.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:39:04,647 INFO] Step 40550/50000; xent: 2.50; lr: 0.0000099;  29 docs/s;  28141 sec\n",
            "[2021-05-02 18:39:38,387 INFO] Step 40600/50000; xent: 2.47; lr: 0.0000099;  31 docs/s;  28175 sec\n",
            "[2021-05-02 18:40:12,239 INFO] Step 40650/50000; xent: 2.56; lr: 0.0000099;  31 docs/s;  28209 sec\n",
            "[2021-05-02 18:40:46,104 INFO] Step 40700/50000; xent: 2.46; lr: 0.0000099;  31 docs/s;  28242 sec\n",
            "[2021-05-02 18:41:01,037 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.26.bert.pt, number of examples: 1998\n",
            "[2021-05-02 18:41:21,822 INFO] Step 40750/50000; xent: 2.54; lr: 0.0000099;  29 docs/s;  28278 sec\n",
            "[2021-05-02 18:41:55,679 INFO] Step 40800/50000; xent: 2.51; lr: 0.0000099;  31 docs/s;  28312 sec\n",
            "[2021-05-02 18:42:29,536 INFO] Step 40850/50000; xent: 2.54; lr: 0.0000099;  30 docs/s;  28346 sec\n",
            "[2021-05-02 18:43:03,337 INFO] Step 40900/50000; xent: 2.43; lr: 0.0000099;  31 docs/s;  28380 sec\n",
            "[2021-05-02 18:43:13,343 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.129.bert.pt, number of examples: 1999\n",
            "[2021-05-02 18:43:39,147 INFO] Step 40950/50000; xent: 2.48; lr: 0.0000099;  29 docs/s;  28416 sec\n",
            "[2021-05-02 18:44:13,020 INFO] Step 41000/50000; xent: 2.47; lr: 0.0000099;  31 docs/s;  28449 sec\n",
            "[2021-05-02 18:44:13,035 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_41000.pt\n",
            "[2021-05-02 18:44:52,997 INFO] Step 41050/50000; xent: 2.47; lr: 0.0000099;  26 docs/s;  28489 sec\n",
            "[2021-05-02 18:45:26,857 INFO] Step 41100/50000; xent: 2.58; lr: 0.0000099;  30 docs/s;  28523 sec\n",
            "[2021-05-02 18:45:31,629 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.10.bert.pt, number of examples: 2000\n",
            "[2021-05-02 18:46:02,591 INFO] Step 41150/50000; xent: 2.53; lr: 0.0000099;  29 docs/s;  28559 sec\n",
            "[2021-05-02 18:46:36,490 INFO] Step 41200/50000; xent: 2.58; lr: 0.0000099;  31 docs/s;  28593 sec\n",
            "[2021-05-02 18:47:10,371 INFO] Step 41250/50000; xent: 2.47; lr: 0.0000098;  30 docs/s;  28627 sec\n",
            "[2021-05-02 18:47:43,580 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.54.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:47:46,345 INFO] Step 41300/50000; xent: 2.48; lr: 0.0000098;  30 docs/s;  28663 sec\n",
            "[2021-05-02 18:48:20,222 INFO] Step 41350/50000; xent: 2.48; lr: 0.0000098;  31 docs/s;  28697 sec\n",
            "[2021-05-02 18:48:54,061 INFO] Step 41400/50000; xent: 2.53; lr: 0.0000098;  31 docs/s;  28730 sec\n",
            "[2021-05-02 18:49:27,949 INFO] Step 41450/50000; xent: 2.47; lr: 0.0000098;  31 docs/s;  28764 sec\n",
            "[2021-05-02 18:49:55,502 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.80.bert.pt, number of examples: 2000\n",
            "[2021-05-02 18:50:03,716 INFO] Step 41500/50000; xent: 2.52; lr: 0.0000098;  28 docs/s;  28800 sec\n",
            "[2021-05-02 18:50:37,313 INFO] Step 41550/50000; xent: 2.57; lr: 0.0000098;  30 docs/s;  28834 sec\n",
            "[2021-05-02 18:51:11,139 INFO] Step 41600/50000; xent: 2.49; lr: 0.0000098;  30 docs/s;  28868 sec\n",
            "[2021-05-02 18:51:45,014 INFO] Step 41650/50000; xent: 2.53; lr: 0.0000098;  32 docs/s;  28901 sec\n",
            "[2021-05-02 18:52:07,257 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.25.bert.pt, number of examples: 1999\n",
            "[2021-05-02 18:52:20,221 INFO] Step 41700/50000; xent: 2.47; lr: 0.0000098;  29 docs/s;  28937 sec\n",
            "[2021-05-02 18:52:54,042 INFO] Step 41750/50000; xent: 2.57; lr: 0.0000098;  32 docs/s;  28970 sec\n",
            "[2021-05-02 18:53:27,815 INFO] Step 41800/50000; xent: 2.50; lr: 0.0000098;  31 docs/s;  29004 sec\n",
            "[2021-05-02 18:54:01,706 INFO] Step 41850/50000; xent: 2.53; lr: 0.0000098;  30 docs/s;  29038 sec\n",
            "[2021-05-02 18:54:20,287 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.83.bert.pt, number of examples: 1999\n",
            "[2021-05-02 18:54:38,748 INFO] Step 41900/50000; xent: 2.49; lr: 0.0000098;  28 docs/s;  29075 sec\n",
            "[2021-05-02 18:55:12,448 INFO] Step 41950/50000; xent: 2.54; lr: 0.0000098;  31 docs/s;  29109 sec\n",
            "[2021-05-02 18:55:46,247 INFO] Step 42000/50000; xent: 2.48; lr: 0.0000098;  30 docs/s;  29143 sec\n",
            "[2021-05-02 18:55:46,262 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_42000.pt\n",
            "[2021-05-02 18:56:25,726 INFO] Step 42050/50000; xent: 2.49; lr: 0.0000098;  26 docs/s;  29182 sec\n",
            "[2021-05-02 18:56:38,334 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.43.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:57:02,067 INFO] Step 42100/50000; xent: 2.60; lr: 0.0000097;  29 docs/s;  29218 sec\n",
            "[2021-05-02 18:57:35,927 INFO] Step 42150/50000; xent: 2.51; lr: 0.0000097;  31 docs/s;  29252 sec\n",
            "[2021-05-02 18:58:09,779 INFO] Step 42200/50000; xent: 2.54; lr: 0.0000097;  31 docs/s;  29286 sec\n",
            "[2021-05-02 18:58:43,553 INFO] Step 42250/50000; xent: 2.50; lr: 0.0000097;  30 docs/s;  29320 sec\n",
            "[2021-05-02 18:58:49,688 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.68.bert.pt, number of examples: 2001\n",
            "[2021-05-02 18:59:19,550 INFO] Step 42300/50000; xent: 2.49; lr: 0.0000097;  29 docs/s;  29356 sec\n",
            "[2021-05-02 18:59:53,186 INFO] Step 42350/50000; xent: 2.55; lr: 0.0000097;  30 docs/s;  29390 sec\n",
            "[2021-05-02 19:00:27,001 INFO] Step 42400/50000; xent: 2.57; lr: 0.0000097;  31 docs/s;  29423 sec\n",
            "[2021-05-02 19:01:00,688 INFO] Step 42450/50000; xent: 2.46; lr: 0.0000097;  31 docs/s;  29457 sec\n",
            "[2021-05-02 19:01:02,731 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.141.bert.pt, number of examples: 1998\n",
            "[2021-05-02 19:01:36,456 INFO] Step 42500/50000; xent: 2.51; lr: 0.0000097;  29 docs/s;  29493 sec\n",
            "[2021-05-02 19:02:10,340 INFO] Step 42550/50000; xent: 2.53; lr: 0.0000097;  31 docs/s;  29527 sec\n",
            "[2021-05-02 19:02:44,168 INFO] Step 42600/50000; xent: 2.56; lr: 0.0000097;  30 docs/s;  29561 sec\n",
            "[2021-05-02 19:03:14,430 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.50.bert.pt, number of examples: 1999\n",
            "[2021-05-02 19:03:19,928 INFO] Step 42650/50000; xent: 2.49; lr: 0.0000097;  29 docs/s;  29596 sec\n",
            "[2021-05-02 19:03:53,585 INFO] Step 42700/50000; xent: 2.61; lr: 0.0000097;  31 docs/s;  29630 sec\n",
            "[2021-05-02 19:04:27,485 INFO] Step 42750/50000; xent: 2.62; lr: 0.0000097;  30 docs/s;  29664 sec\n",
            "[2021-05-02 19:05:01,283 INFO] Step 42800/50000; xent: 2.50; lr: 0.0000097;  31 docs/s;  29698 sec\n",
            "[2021-05-02 19:05:27,077 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.59.bert.pt, number of examples: 2000\n",
            "[2021-05-02 19:05:37,352 INFO] Step 42850/50000; xent: 2.51; lr: 0.0000097;  29 docs/s;  29734 sec\n",
            "[2021-05-02 19:06:11,238 INFO] Step 42900/50000; xent: 2.55; lr: 0.0000097;  31 docs/s;  29768 sec\n",
            "[2021-05-02 19:06:45,083 INFO] Step 42950/50000; xent: 2.53; lr: 0.0000097;  31 docs/s;  29801 sec\n",
            "[2021-05-02 19:07:18,836 INFO] Step 43000/50000; xent: 2.51; lr: 0.0000096;  30 docs/s;  29835 sec\n",
            "[2021-05-02 19:07:18,851 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_43000.pt\n",
            "[2021-05-02 19:07:45,236 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.4.bert.pt, number of examples: 2000\n",
            "[2021-05-02 19:08:00,278 INFO] Step 43050/50000; xent: 2.54; lr: 0.0000096;  25 docs/s;  29877 sec\n",
            "[2021-05-02 19:08:34,123 INFO] Step 43100/50000; xent: 2.54; lr: 0.0000096;  31 docs/s;  29910 sec\n",
            "[2021-05-02 19:09:07,979 INFO] Step 43150/50000; xent: 2.46; lr: 0.0000096;  30 docs/s;  29944 sec\n",
            "[2021-05-02 19:09:41,841 INFO] Step 43200/50000; xent: 2.50; lr: 0.0000096;  31 docs/s;  29978 sec\n",
            "[2021-05-02 19:09:57,975 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.90.bert.pt, number of examples: 2000\n",
            "[2021-05-02 19:10:17,676 INFO] Step 43250/50000; xent: 2.44; lr: 0.0000096;  29 docs/s;  30014 sec\n",
            "[2021-05-02 19:10:51,530 INFO] Step 43300/50000; xent: 2.46; lr: 0.0000096;  31 docs/s;  30048 sec\n",
            "[2021-05-02 19:11:25,190 INFO] Step 43350/50000; xent: 2.55; lr: 0.0000096;  30 docs/s;  30082 sec\n",
            "[2021-05-02 19:11:58,868 INFO] Step 43400/50000; xent: 2.48; lr: 0.0000096;  31 docs/s;  30115 sec\n",
            "[2021-05-02 19:12:10,764 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.97.bert.pt, number of examples: 2000\n",
            "[2021-05-02 19:12:35,224 INFO] Step 43450/50000; xent: 2.54; lr: 0.0000096;  28 docs/s;  30152 sec\n",
            "[2021-05-02 19:13:09,084 INFO] Step 43500/50000; xent: 2.50; lr: 0.0000096;  31 docs/s;  30185 sec\n",
            "[2021-05-02 19:13:42,851 INFO] Step 43550/50000; xent: 2.52; lr: 0.0000096;  30 docs/s;  30219 sec\n",
            "[2021-05-02 19:14:16,724 INFO] Step 43600/50000; xent: 2.48; lr: 0.0000096;  31 docs/s;  30253 sec\n",
            "[2021-05-02 19:14:23,568 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.131.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:14:52,794 INFO] Step 43650/50000; xent: 2.54; lr: 0.0000096;  29 docs/s;  30289 sec\n",
            "[2021-05-02 19:15:26,574 INFO] Step 43700/50000; xent: 2.51; lr: 0.0000096;  31 docs/s;  30323 sec\n",
            "[2021-05-02 19:16:00,463 INFO] Step 43750/50000; xent: 2.62; lr: 0.0000096;  31 docs/s;  30357 sec\n",
            "[2021-05-02 19:16:35,411 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.85.bert.pt, number of examples: 1998\n",
            "[2021-05-02 19:16:36,183 INFO] Step 43800/50000; xent: 2.52; lr: 0.0000096;  29 docs/s;  30393 sec\n",
            "[2021-05-02 19:17:10,079 INFO] Step 43850/50000; xent: 2.41; lr: 0.0000096;  31 docs/s;  30426 sec\n",
            "[2021-05-02 19:17:43,836 INFO] Step 43900/50000; xent: 2.47; lr: 0.0000095;  30 docs/s;  30460 sec\n",
            "[2021-05-02 19:18:17,641 INFO] Step 43950/50000; xent: 2.50; lr: 0.0000095;  31 docs/s;  30494 sec\n",
            "[2021-05-02 19:18:48,901 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.106.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:18:54,384 INFO] Step 44000/50000; xent: 2.58; lr: 0.0000095;  28 docs/s;  30531 sec\n",
            "[2021-05-02 19:18:54,399 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_44000.pt\n",
            "[2021-05-02 19:19:33,685 INFO] Step 44050/50000; xent: 2.54; lr: 0.0000095;  26 docs/s;  30570 sec\n",
            "[2021-05-02 19:20:07,553 INFO] Step 44100/50000; xent: 2.56; lr: 0.0000095;  31 docs/s;  30604 sec\n",
            "[2021-05-02 19:20:41,388 INFO] Step 44150/50000; xent: 2.54; lr: 0.0000095;  31 docs/s;  30638 sec\n",
            "[2021-05-02 19:21:06,271 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.94.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:21:17,178 INFO] Step 44200/50000; xent: 2.59; lr: 0.0000095;  29 docs/s;  30674 sec\n",
            "[2021-05-02 19:21:51,025 INFO] Step 44250/50000; xent: 2.58; lr: 0.0000095;  30 docs/s;  30707 sec\n",
            "[2021-05-02 19:22:24,787 INFO] Step 44300/50000; xent: 2.48; lr: 0.0000095;  31 docs/s;  30741 sec\n",
            "[2021-05-02 19:22:58,663 INFO] Step 44350/50000; xent: 2.54; lr: 0.0000095;  31 docs/s;  30775 sec\n",
            "[2021-05-02 19:23:18,194 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.79.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:23:34,505 INFO] Step 44400/50000; xent: 2.50; lr: 0.0000095;  29 docs/s;  30811 sec\n",
            "[2021-05-02 19:24:08,120 INFO] Step 44450/50000; xent: 2.59; lr: 0.0000095;  30 docs/s;  30844 sec\n",
            "[2021-05-02 19:24:41,930 INFO] Step 44500/50000; xent: 2.55; lr: 0.0000095;  31 docs/s;  30878 sec\n",
            "[2021-05-02 19:25:15,826 INFO] Step 44550/50000; xent: 2.57; lr: 0.0000095;  31 docs/s;  30912 sec\n",
            "[2021-05-02 19:25:30,583 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.0.bert.pt, number of examples: 2000\n",
            "[2021-05-02 19:25:51,660 INFO] Step 44600/50000; xent: 2.59; lr: 0.0000095;  29 docs/s;  30948 sec\n",
            "[2021-05-02 19:26:25,293 INFO] Step 44650/50000; xent: 2.54; lr: 0.0000095;  31 docs/s;  30982 sec\n",
            "[2021-05-02 19:26:59,161 INFO] Step 44700/50000; xent: 2.54; lr: 0.0000095;  31 docs/s;  31016 sec\n",
            "[2021-05-02 19:27:32,937 INFO] Step 44750/50000; xent: 2.52; lr: 0.0000095;  31 docs/s;  31049 sec\n",
            "[2021-05-02 19:27:42,806 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.111.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:28:08,609 INFO] Step 44800/50000; xent: 2.49; lr: 0.0000094;  30 docs/s;  31085 sec\n",
            "[2021-05-02 19:28:42,433 INFO] Step 44850/50000; xent: 2.61; lr: 0.0000094;  30 docs/s;  31119 sec\n",
            "[2021-05-02 19:29:16,298 INFO] Step 44900/50000; xent: 2.61; lr: 0.0000094;  31 docs/s;  31153 sec\n",
            "[2021-05-02 19:29:49,879 INFO] Step 44950/50000; xent: 2.52; lr: 0.0000094;  31 docs/s;  31186 sec\n",
            "[2021-05-02 19:29:56,322 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.64.bert.pt, number of examples: 1998\n",
            "[2021-05-02 19:30:27,369 INFO] Step 45000/50000; xent: 2.62; lr: 0.0000094;  28 docs/s;  31224 sec\n",
            "[2021-05-02 19:30:27,384 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_45000.pt\n",
            "[2021-05-02 19:31:07,389 INFO] Step 45050/50000; xent: 2.53; lr: 0.0000094;  26 docs/s;  31264 sec\n",
            "[2021-05-02 19:31:41,258 INFO] Step 45100/50000; xent: 2.47; lr: 0.0000094;  31 docs/s;  31298 sec\n",
            "[2021-05-02 19:32:14,413 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.130.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:32:17,211 INFO] Step 45150/50000; xent: 2.61; lr: 0.0000094;  28 docs/s;  31334 sec\n",
            "[2021-05-02 19:32:50,903 INFO] Step 45200/50000; xent: 2.49; lr: 0.0000094;  31 docs/s;  31367 sec\n",
            "[2021-05-02 19:33:24,693 INFO] Step 45250/50000; xent: 2.52; lr: 0.0000094;  31 docs/s;  31401 sec\n",
            "[2021-05-02 19:33:58,571 INFO] Step 45300/50000; xent: 2.53; lr: 0.0000094;  30 docs/s;  31435 sec\n",
            "[2021-05-02 19:34:26,357 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.61.bert.pt, number of examples: 1999\n",
            "[2021-05-02 19:34:33,873 INFO] Step 45350/50000; xent: 2.47; lr: 0.0000094;  30 docs/s;  31470 sec\n",
            "[2021-05-02 19:35:07,726 INFO] Step 45400/50000; xent: 2.49; lr: 0.0000094;  31 docs/s;  31504 sec\n",
            "[2021-05-02 19:35:41,527 INFO] Step 45450/50000; xent: 2.53; lr: 0.0000094;  31 docs/s;  31538 sec\n",
            "[2021-05-02 19:36:15,246 INFO] Step 45500/50000; xent: 2.51; lr: 0.0000094;  31 docs/s;  31572 sec\n",
            "[2021-05-02 19:36:38,266 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.55.bert.pt, number of examples: 1999\n",
            "[2021-05-02 19:36:51,264 INFO] Step 45550/50000; xent: 2.53; lr: 0.0000094;  29 docs/s;  31608 sec\n",
            "[2021-05-02 19:37:24,878 INFO] Step 45600/50000; xent: 2.57; lr: 0.0000094;  30 docs/s;  31641 sec\n",
            "[2021-05-02 19:37:58,663 INFO] Step 45650/50000; xent: 2.50; lr: 0.0000094;  31 docs/s;  31675 sec\n",
            "[2021-05-02 19:38:32,529 INFO] Step 45700/50000; xent: 2.43; lr: 0.0000094;  31 docs/s;  31709 sec\n",
            "[2021-05-02 19:38:49,980 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.2.bert.pt, number of examples: 2000\n",
            "[2021-05-02 19:39:08,226 INFO] Step 45750/50000; xent: 2.51; lr: 0.0000094;  29 docs/s;  31745 sec\n",
            "[2021-05-02 19:39:42,010 INFO] Step 45800/50000; xent: 2.48; lr: 0.0000093;  31 docs/s;  31778 sec\n",
            "[2021-05-02 19:40:15,911 INFO] Step 45850/50000; xent: 2.51; lr: 0.0000093;  30 docs/s;  31812 sec\n",
            "[2021-05-02 19:40:49,580 INFO] Step 45900/50000; xent: 2.48; lr: 0.0000093;  30 docs/s;  31846 sec\n",
            "[2021-05-02 19:41:02,475 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.51.bert.pt, number of examples: 1999\n",
            "[2021-05-02 19:41:25,590 INFO] Step 45950/50000; xent: 2.48; lr: 0.0000093;  29 docs/s;  31882 sec\n",
            "[2021-05-02 19:41:59,469 INFO] Step 46000/50000; xent: 2.50; lr: 0.0000093;  31 docs/s;  31916 sec\n",
            "[2021-05-02 19:41:59,484 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_46000.pt\n",
            "[2021-05-02 19:42:38,915 INFO] Step 46050/50000; xent: 2.49; lr: 0.0000093;  26 docs/s;  31955 sec\n",
            "[2021-05-02 19:43:12,645 INFO] Step 46100/50000; xent: 2.46; lr: 0.0000093;  30 docs/s;  31989 sec\n",
            "[2021-05-02 19:43:20,453 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.101.bert.pt, number of examples: 1998\n",
            "[2021-05-02 19:43:48,262 INFO] Step 46150/50000; xent: 2.60; lr: 0.0000093;  29 docs/s;  32025 sec\n",
            "[2021-05-02 19:44:22,120 INFO] Step 46200/50000; xent: 2.49; lr: 0.0000093;  31 docs/s;  32058 sec\n",
            "[2021-05-02 19:44:55,886 INFO] Step 46250/50000; xent: 2.46; lr: 0.0000093;  31 docs/s;  32092 sec\n",
            "[2021-05-02 19:45:29,644 INFO] Step 46300/50000; xent: 2.53; lr: 0.0000093;  30 docs/s;  32126 sec\n",
            "[2021-05-02 19:45:32,289 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.30.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:46:05,515 INFO] Step 46350/50000; xent: 2.46; lr: 0.0000093;  29 docs/s;  32162 sec\n",
            "[2021-05-02 19:46:39,222 INFO] Step 46400/50000; xent: 2.52; lr: 0.0000093;  30 docs/s;  32196 sec\n",
            "[2021-05-02 19:47:13,066 INFO] Step 46450/50000; xent: 2.45; lr: 0.0000093;  31 docs/s;  32229 sec\n",
            "[2021-05-02 19:47:44,804 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.112.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:47:48,930 INFO] Step 46500/50000; xent: 2.46; lr: 0.0000093;  29 docs/s;  32265 sec\n",
            "[2021-05-02 19:48:22,647 INFO] Step 46550/50000; xent: 2.49; lr: 0.0000093;  31 docs/s;  32299 sec\n",
            "[2021-05-02 19:48:56,473 INFO] Step 46600/50000; xent: 2.52; lr: 0.0000093;  31 docs/s;  32333 sec\n",
            "[2021-05-02 19:49:30,311 INFO] Step 46650/50000; xent: 2.51; lr: 0.0000093;  30 docs/s;  32367 sec\n",
            "[2021-05-02 19:49:56,672 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.67.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:50:06,241 INFO] Step 46700/50000; xent: 2.47; lr: 0.0000093;  29 docs/s;  32403 sec\n",
            "[2021-05-02 19:50:40,076 INFO] Step 46750/50000; xent: 2.42; lr: 0.0000092;  31 docs/s;  32436 sec\n",
            "[2021-05-02 19:51:13,933 INFO] Step 46800/50000; xent: 2.46; lr: 0.0000092;  31 docs/s;  32470 sec\n",
            "[2021-05-02 19:51:47,770 INFO] Step 46850/50000; xent: 2.48; lr: 0.0000092;  30 docs/s;  32504 sec\n",
            "[2021-05-02 19:52:09,436 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.29.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:52:23,742 INFO] Step 46900/50000; xent: 2.52; lr: 0.0000092;  29 docs/s;  32540 sec\n",
            "[2021-05-02 19:52:57,577 INFO] Step 46950/50000; xent: 2.45; lr: 0.0000092;  32 docs/s;  32574 sec\n",
            "[2021-05-02 19:53:31,372 INFO] Step 47000/50000; xent: 2.48; lr: 0.0000092;  31 docs/s;  32608 sec\n",
            "[2021-05-02 19:53:31,386 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_47000.pt\n",
            "[2021-05-02 19:54:10,354 INFO] Step 47050/50000; xent: 2.51; lr: 0.0000092;  26 docs/s;  32647 sec\n",
            "[2021-05-02 19:54:26,668 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.107.bert.pt, number of examples: 1999\n",
            "[2021-05-02 19:54:46,387 INFO] Step 47100/50000; xent: 2.57; lr: 0.0000092;  29 docs/s;  32683 sec\n",
            "[2021-05-02 19:55:20,190 INFO] Step 47150/50000; xent: 2.57; lr: 0.0000092;  31 docs/s;  32717 sec\n",
            "[2021-05-02 19:55:54,046 INFO] Step 47200/50000; xent: 2.55; lr: 0.0000092;  31 docs/s;  32750 sec\n",
            "[2021-05-02 19:56:27,801 INFO] Step 47250/50000; xent: 2.54; lr: 0.0000092;  30 docs/s;  32784 sec\n",
            "[2021-05-02 19:56:39,378 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.1.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:57:03,822 INFO] Step 47300/50000; xent: 2.51; lr: 0.0000092;  29 docs/s;  32820 sec\n",
            "[2021-05-02 19:57:37,707 INFO] Step 47350/50000; xent: 2.56; lr: 0.0000092;  31 docs/s;  32854 sec\n",
            "[2021-05-02 19:58:11,610 INFO] Step 47400/50000; xent: 2.43; lr: 0.0000092;  31 docs/s;  32888 sec\n",
            "[2021-05-02 19:58:45,392 INFO] Step 47450/50000; xent: 2.47; lr: 0.0000092;  31 docs/s;  32922 sec\n",
            "[2021-05-02 19:58:50,812 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.46.bert.pt, number of examples: 2001\n",
            "[2021-05-02 19:59:21,350 INFO] Step 47500/50000; xent: 2.46; lr: 0.0000092;  29 docs/s;  32958 sec\n",
            "[2021-05-02 19:59:55,197 INFO] Step 47550/50000; xent: 2.47; lr: 0.0000092;  31 docs/s;  32992 sec\n",
            "[2021-05-02 20:00:29,034 INFO] Step 47600/50000; xent: 2.49; lr: 0.0000092;  31 docs/s;  33025 sec\n",
            "[2021-05-02 20:01:03,043 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.102.bert.pt, number of examples: 2000\n",
            "[2021-05-02 20:01:04,484 INFO] Step 47650/50000; xent: 2.47; lr: 0.0000092;  29 docs/s;  33061 sec\n",
            "[2021-05-02 20:01:38,271 INFO] Step 47700/50000; xent: 2.52; lr: 0.0000092;  31 docs/s;  33095 sec\n",
            "[2021-05-02 20:02:12,090 INFO] Step 47750/50000; xent: 2.52; lr: 0.0000092;  31 docs/s;  33128 sec\n",
            "[2021-05-02 20:02:45,729 INFO] Step 47800/50000; xent: 2.42; lr: 0.0000091;  31 docs/s;  33162 sec\n",
            "[2021-05-02 20:03:14,783 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.33.bert.pt, number of examples: 1997\n",
            "[2021-05-02 20:03:21,633 INFO] Step 47850/50000; xent: 2.47; lr: 0.0000091;  29 docs/s;  33198 sec\n",
            "[2021-05-02 20:03:55,475 INFO] Step 47900/50000; xent: 2.52; lr: 0.0000091;  31 docs/s;  33232 sec\n",
            "[2021-05-02 20:04:29,171 INFO] Step 47950/50000; xent: 2.52; lr: 0.0000091;  31 docs/s;  33266 sec\n",
            "[2021-05-02 20:05:03,074 INFO] Step 48000/50000; xent: 2.50; lr: 0.0000091;  31 docs/s;  33299 sec\n",
            "[2021-05-02 20:05:03,089 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_48000.pt\n",
            "[2021-05-02 20:05:31,970 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.127.bert.pt, number of examples: 2000\n",
            "[2021-05-02 20:05:44,983 INFO] Step 48050/50000; xent: 2.46; lr: 0.0000091;  25 docs/s;  33341 sec\n",
            "[2021-05-02 20:06:18,835 INFO] Step 48100/50000; xent: 2.53; lr: 0.0000091;  31 docs/s;  33375 sec\n",
            "[2021-05-02 20:06:52,746 INFO] Step 48150/50000; xent: 2.42; lr: 0.0000091;  31 docs/s;  33409 sec\n",
            "[2021-05-02 20:07:26,563 INFO] Step 48200/50000; xent: 2.44; lr: 0.0000091;  30 docs/s;  33443 sec\n",
            "[2021-05-02 20:07:44,053 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.104.bert.pt, number of examples: 2000\n",
            "[2021-05-02 20:08:02,319 INFO] Step 48250/50000; xent: 2.43; lr: 0.0000091;  30 docs/s;  33479 sec\n",
            "[2021-05-02 20:08:36,145 INFO] Step 48300/50000; xent: 2.52; lr: 0.0000091;  31 docs/s;  33513 sec\n",
            "[2021-05-02 20:09:10,001 INFO] Step 48350/50000; xent: 2.55; lr: 0.0000091;  30 docs/s;  33546 sec\n",
            "[2021-05-02 20:09:43,767 INFO] Step 48400/50000; xent: 2.48; lr: 0.0000091;  31 docs/s;  33580 sec\n",
            "[2021-05-02 20:09:55,268 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.16.bert.pt, number of examples: 2001\n",
            "[2021-05-02 20:10:19,561 INFO] Step 48450/50000; xent: 2.49; lr: 0.0000091;  29 docs/s;  33616 sec\n",
            "[2021-05-02 20:10:53,351 INFO] Step 48500/50000; xent: 2.55; lr: 0.0000091;  31 docs/s;  33650 sec\n",
            "[2021-05-02 20:11:27,210 INFO] Step 48550/50000; xent: 2.56; lr: 0.0000091;  31 docs/s;  33684 sec\n",
            "[2021-05-02 20:12:01,084 INFO] Step 48600/50000; xent: 2.54; lr: 0.0000091;  31 docs/s;  33717 sec\n",
            "[2021-05-02 20:12:07,897 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.120.bert.pt, number of examples: 2000\n",
            "[2021-05-02 20:12:36,919 INFO] Step 48650/50000; xent: 2.48; lr: 0.0000091;  29 docs/s;  33753 sec\n",
            "[2021-05-02 20:13:10,721 INFO] Step 48700/50000; xent: 2.48; lr: 0.0000091;  31 docs/s;  33787 sec\n",
            "[2021-05-02 20:13:44,523 INFO] Step 48750/50000; xent: 2.41; lr: 0.0000091;  31 docs/s;  33821 sec\n",
            "[2021-05-02 20:14:18,133 INFO] Step 48800/50000; xent: 2.53; lr: 0.0000091;  31 docs/s;  33854 sec\n",
            "[2021-05-02 20:14:20,176 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.99.bert.pt, number of examples: 2001\n",
            "[2021-05-02 20:14:53,981 INFO] Step 48850/50000; xent: 2.49; lr: 0.0000090;  29 docs/s;  33890 sec\n",
            "[2021-05-02 20:15:27,815 INFO] Step 48900/50000; xent: 2.51; lr: 0.0000090;  31 docs/s;  33924 sec\n",
            "[2021-05-02 20:16:01,647 INFO] Step 48950/50000; xent: 2.48; lr: 0.0000090;  31 docs/s;  33958 sec\n",
            "[2021-05-02 20:16:32,515 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.49.bert.pt, number of examples: 2000\n",
            "[2021-05-02 20:16:38,017 INFO] Step 49000/50000; xent: 2.41; lr: 0.0000090;  29 docs/s;  33994 sec\n",
            "[2021-05-02 20:16:38,032 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_49000.pt\n",
            "[2021-05-02 20:17:17,041 INFO] Step 49050/50000; xent: 2.52; lr: 0.0000090;  27 docs/s;  34033 sec\n",
            "[2021-05-02 20:17:50,667 INFO] Step 49100/50000; xent: 2.50; lr: 0.0000090;  30 docs/s;  34067 sec\n",
            "[2021-05-02 20:18:24,439 INFO] Step 49150/50000; xent: 2.51; lr: 0.0000090;  31 docs/s;  34101 sec\n",
            "[2021-05-02 20:18:49,452 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.126.bert.pt, number of examples: 2001\n",
            "[2021-05-02 20:19:00,363 INFO] Step 49200/50000; xent: 2.55; lr: 0.0000090;  29 docs/s;  34137 sec\n",
            "[2021-05-02 20:19:34,171 INFO] Step 49250/50000; xent: 2.48; lr: 0.0000090;  31 docs/s;  34171 sec\n",
            "[2021-05-02 20:20:07,798 INFO] Step 49300/50000; xent: 2.53; lr: 0.0000090;  31 docs/s;  34204 sec\n",
            "[2021-05-02 20:20:41,601 INFO] Step 49350/50000; xent: 2.41; lr: 0.0000090;  30 docs/s;  34238 sec\n",
            "[2021-05-02 20:21:02,722 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.128.bert.pt, number of examples: 2000\n",
            "[2021-05-02 20:21:17,672 INFO] Step 49400/50000; xent: 2.44; lr: 0.0000090;  29 docs/s;  34274 sec\n",
            "[2021-05-02 20:21:51,496 INFO] Step 49450/50000; xent: 2.48; lr: 0.0000090;  30 docs/s;  34308 sec\n",
            "[2021-05-02 20:22:25,331 INFO] Step 49500/50000; xent: 2.48; lr: 0.0000090;  31 docs/s;  34342 sec\n",
            "[2021-05-02 20:22:58,977 INFO] Step 49550/50000; xent: 2.41; lr: 0.0000090;  31 docs/s;  34375 sec\n",
            "[2021-05-02 20:23:13,673 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.27.bert.pt, number of examples: 1999\n",
            "[2021-05-02 20:23:34,088 INFO] Step 49600/50000; xent: 2.60; lr: 0.0000090;  30 docs/s;  34410 sec\n",
            "[2021-05-02 20:24:07,869 INFO] Step 49650/50000; xent: 2.50; lr: 0.0000090;  31 docs/s;  34444 sec\n",
            "[2021-05-02 20:24:41,433 INFO] Step 49700/50000; xent: 2.59; lr: 0.0000090;  31 docs/s;  34478 sec\n",
            "[2021-05-02 20:25:15,105 INFO] Step 49750/50000; xent: 2.53; lr: 0.0000090;  31 docs/s;  34511 sec\n",
            "[2021-05-02 20:25:26,754 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.82.bert.pt, number of examples: 2001\n",
            "[2021-05-02 20:25:52,597 INFO] Step 49800/50000; xent: 2.62; lr: 0.0000090;  28 docs/s;  34549 sec\n",
            "[2021-05-02 20:26:26,441 INFO] Step 49850/50000; xent: 2.45; lr: 0.0000090;  31 docs/s;  34583 sec\n",
            "[2021-05-02 20:27:00,096 INFO] Step 49900/50000; xent: 2.48; lr: 0.0000090;  30 docs/s;  34616 sec\n",
            "[2021-05-02 20:27:34,021 INFO] Step 49950/50000; xent: 2.46; lr: 0.0000089;  31 docs/s;  34650 sec\n",
            "[2021-05-02 20:27:39,327 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.63.bert.pt, number of examples: 2001\n",
            "[2021-05-02 20:28:09,828 INFO] Step 50000/50000; xent: 2.59; lr: 0.0000089;  28 docs/s;  34686 sec\n",
            "[2021-05-02 20:28:09,843 INFO] Saving checkpoint ../data/trained_models/roberta_2layers/model_step_50000.pt\n",
            "[2021-05-02 20:28:17,975 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.78.bert.pt, number of examples: 2001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzJtejfOpvRg"
      },
      "source": [
        "## lr=1e-5 layer=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFs4lXqrSGff",
        "outputId": "7701346a-d68d-4a50-8911-1110b401353d"
      },
      "source": [
        "!python3 train.py -task ext -encoder roberta -mode train -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -ext_dropout 0.1 -model_path ../data/trained_models/reberta_e5 -lr 1e-5 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 5000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file ../logs/ext_roberta_cnndm -use_interval true -warmup_steps 10000 -max_pos 512 -ext_layers 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l04frLlhtIXg"
      },
      "source": [
        "!python3 train.py -task ext -encoder roberta -mode train -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -ext_dropout 0.1 -model_path ../data/trained_models/reberta_2layers -lr 2e-3 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 50000 -accum_count 2 -log_file ../logs/ext_roberta2_cnndm -use_interval true -warmup_steps 10000 -max_pos 512 -ext_layers 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wki4fzhdh5qR",
        "outputId": "d8e32f7b-4d04-4f61-b0d1-cef37f408fb8"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta.log -model_path ../data/trained_models/reberta_default -sep_optim true -use_interval true -visible_gpus 1 -max_pos 514 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta_ext_bert_cnndm -test_from ../data/trained_models/reberta_default/model_step_50000.pt "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-04-30 16:25:03,406 INFO] Loading checkpoint from ../data/trained_models/reberta_default/model_step_50000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=514, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/reberta_default', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta_ext_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/reberta_default/model_step_50000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-04-30 16:25:06,563 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-04-30 16:25:06,564 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-04-30 16:25:07,315 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-04-30 16:25:17,339 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-04-30 16:25:17,346 INFO] * number of parameters: 135678209\n",
            "[2021-04-30 16:26:13,642 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-04-30 16:27:10,017 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-04-30 16:28:06,440 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-04-30 16:29:03,396 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-04-30 16:29:59,838 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-04-30 16:32:47,325 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-04-30 16:32:47,325 INFO] Writing summaries.\n",
            "2021-04-30 16:32:47,331 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmp5vvtt_rm/system and model files to ../temp/tmp5vvtt_rm/model.\n",
            "[2021-04-30 16:32:47,331 INFO] Processing summaries. Saving system files to ../temp/tmp5vvtt_rm/system and model files to ../temp/tmp5vvtt_rm/model.\n",
            "2021-04-30 16:32:47,331 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-04-30-16-30-40/candidate/.\n",
            "[2021-04-30 16:32:47,331 INFO] Processing files in ../temp/rouge-tmp-2021-04-30-16-30-40/candidate/.\n",
            "2021-04-30 16:34:31,695 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp5vvtt_rm/system.\n",
            "[2021-04-30 16:34:31,695 INFO] Saved processed files to ../temp/tmp5vvtt_rm/system.\n",
            "2021-04-30 16:34:31,696 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-04-30-16-30-40/reference/.\n",
            "[2021-04-30 16:34:31,696 INFO] Processing files in ../temp/rouge-tmp-2021-04-30-16-30-40/reference/.\n",
            "2021-04-30 16:36:16,690 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp5vvtt_rm/model.\n",
            "[2021-04-30 16:36:16,690 INFO] Saved processed files to ../temp/tmp5vvtt_rm/model.\n",
            "2021-04-30 16:36:16,938 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmp15eggwqg/rouge_conf.xml\n",
            "[2021-04-30 16:36:16,938 INFO] Written ROUGE configuration to ../temp/tmp15eggwqg/rouge_conf.xml\n",
            "2021-04-30 16:36:16,939 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp15eggwqg/rouge_conf.xml\n",
            "[2021-04-30 16:36:16,939 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp15eggwqg/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.50625 (95%-conf.int. 0.50320 - 0.50912)\n",
            "1 ROUGE-1 Average_P: 0.34690 (95%-conf.int. 0.34460 - 0.34937)\n",
            "1 ROUGE-1 Average_F: 0.39696 (95%-conf.int. 0.39484 - 0.39926)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.22063 (95%-conf.int. 0.21780 - 0.22326)\n",
            "1 ROUGE-2 Average_P: 0.15072 (95%-conf.int. 0.14871 - 0.15278)\n",
            "1 ROUGE-2 Average_F: 0.17251 (95%-conf.int. 0.17034 - 0.17464)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.45973 (95%-conf.int. 0.45679 - 0.46253)\n",
            "1 ROUGE-L Average_P: 0.31559 (95%-conf.int. 0.31338 - 0.31790)\n",
            "1 ROUGE-L Average_F: 0.36084 (95%-conf.int. 0.35879 - 0.36306)\n",
            "\n",
            "[2021-04-30 16:40:42,153 INFO] Rouges at step 50000 \n",
            ">> ROUGE-F(1/2/3/l): 39.70/17.25/36.08\n",
            "ROUGE-R(1/2/3/l): 50.62/22.06/45.97\n",
            "\n",
            "[2021-04-30 16:40:42,154 INFO] Validation xent: 5.93173 at step 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGZa9j9Vsz0R",
        "outputId": "64ac2082-80a0-4732-9289-8af4a922fa3e"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta.log -model_path ../data/trained_models/reberta_default -sep_optim true -use_interval true -visible_gpus 1 -max_pos 514 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta_ext_bert_cnndm -test_from ../data/trained_models/reberta_default/model_step_30000.pt "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-04-30 16:54:53,049 INFO] Loading checkpoint from ../data/trained_models/reberta_default/model_step_30000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=514, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/reberta_default', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta_ext_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/reberta_default/model_step_30000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-04-30 16:55:11,291 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-04-30 16:55:11,293 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-04-30 16:55:12,056 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-04-30 16:55:20,679 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-04-30 16:55:20,722 INFO] * number of parameters: 135678209\n",
            "[2021-04-30 16:56:15,841 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-04-30 16:57:11,011 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-04-30 16:58:06,276 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-04-30 16:59:01,415 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-04-30 16:59:56,715 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-04-30 17:03:56,420 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-04-30 17:03:56,420 INFO] Writing summaries.\n",
            "2021-04-30 17:03:56,445 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmptfk84c61/system and model files to ../temp/tmptfk84c61/model.\n",
            "[2021-04-30 17:03:56,445 INFO] Processing summaries. Saving system files to ../temp/tmptfk84c61/system and model files to ../temp/tmptfk84c61/model.\n",
            "2021-04-30 17:03:56,446 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-04-30-17-00-37/candidate/.\n",
            "[2021-04-30 17:03:56,446 INFO] Processing files in ../temp/rouge-tmp-2021-04-30-17-00-37/candidate/.\n",
            "2021-04-30 17:05:43,971 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmptfk84c61/system.\n",
            "[2021-04-30 17:05:43,971 INFO] Saved processed files to ../temp/tmptfk84c61/system.\n",
            "2021-04-30 17:05:43,972 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-04-30-17-00-37/reference/.\n",
            "[2021-04-30 17:05:43,972 INFO] Processing files in ../temp/rouge-tmp-2021-04-30-17-00-37/reference/.\n",
            "2021-04-30 17:07:31,583 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmptfk84c61/model.\n",
            "[2021-04-30 17:07:31,583 INFO] Saved processed files to ../temp/tmptfk84c61/model.\n",
            "2021-04-30 17:07:31,825 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpbwf6f7c7/rouge_conf.xml\n",
            "[2021-04-30 17:07:31,825 INFO] Written ROUGE configuration to ../temp/tmpbwf6f7c7/rouge_conf.xml\n",
            "2021-04-30 17:07:31,826 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpbwf6f7c7/rouge_conf.xml\n",
            "[2021-04-30 17:07:31,826 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpbwf6f7c7/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.50169 (95%-conf.int. 0.49883 - 0.50452)\n",
            "1 ROUGE-1 Average_P: 0.34722 (95%-conf.int. 0.34489 - 0.34978)\n",
            "1 ROUGE-1 Average_F: 0.39556 (95%-conf.int. 0.39339 - 0.39781)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.21865 (95%-conf.int. 0.21581 - 0.22128)\n",
            "1 ROUGE-2 Average_P: 0.15105 (95%-conf.int. 0.14899 - 0.15313)\n",
            "1 ROUGE-2 Average_F: 0.17200 (95%-conf.int. 0.16988 - 0.17415)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.45575 (95%-conf.int. 0.45296 - 0.45849)\n",
            "1 ROUGE-L Average_P: 0.31602 (95%-conf.int. 0.31372 - 0.31841)\n",
            "1 ROUGE-L Average_F: 0.35971 (95%-conf.int. 0.35756 - 0.36195)\n",
            "\n",
            "[2021-04-30 17:14:24,419 INFO] Rouges at step 30000 \n",
            ">> ROUGE-F(1/2/3/l): 39.56/17.20/35.97\n",
            "ROUGE-R(1/2/3/l): 50.17/21.87/45.57\n",
            "\n",
            "[2021-04-30 17:14:24,420 INFO] Validation xent: 5.9109 at step 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk5HLJiD7J_B",
        "outputId": "03d1b5f0-7249-4a1c-b99b-94bdfd794f0b"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta_smaller.log -model_path ../data/trained_models/reberta_smaller -sep_optim true -use_interval false -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta_ext_bert_cnndm -test_from ../data/trained_models/reberta_smaller/model_step_35000.pt -ext_layers 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-05-01 03:23:33,009 INFO] Loading checkpoint from ../data/trained_models/reberta_smaller/model_step_35000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=1, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta_smaller.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/reberta_smaller', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta_ext_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/reberta_smaller/model_step_35000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-05-01 03:23:35,809 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-01 03:23:36,447 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-01 03:23:36,819 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-01 03:23:52,409 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-05-01 03:23:52,414 INFO] * number of parameters: 130161921\n",
            "[2021-05-01 03:24:25,342 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-05-01 03:24:57,456 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-05-01 03:25:30,377 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-05-01 03:26:02,726 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-05-01 03:26:34,847 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-05-01 03:28:44,654 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-05-01 03:28:44,654 INFO] Writing summaries.\n",
            "2021-05-01 03:28:44,677 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmpuvpp8_0b/system and model files to ../temp/tmpuvpp8_0b/model.\n",
            "[2021-05-01 03:28:44,677 INFO] Processing summaries. Saving system files to ../temp/tmpuvpp8_0b/system and model files to ../temp/tmpuvpp8_0b/model.\n",
            "2021-05-01 03:28:44,678 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-01-03-26-57/candidate/.\n",
            "[2021-05-01 03:28:44,678 INFO] Processing files in ../temp/rouge-tmp-2021-05-01-03-26-57/candidate/.\n",
            "2021-05-01 03:30:19,914 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpuvpp8_0b/system.\n",
            "[2021-05-01 03:30:19,914 INFO] Saved processed files to ../temp/tmpuvpp8_0b/system.\n",
            "2021-05-01 03:30:19,915 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-01-03-26-57/reference/.\n",
            "[2021-05-01 03:30:19,915 INFO] Processing files in ../temp/rouge-tmp-2021-05-01-03-26-57/reference/.\n",
            "2021-05-01 03:31:55,100 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpuvpp8_0b/model.\n",
            "[2021-05-01 03:31:55,100 INFO] Saved processed files to ../temp/tmpuvpp8_0b/model.\n",
            "2021-05-01 03:31:55,305 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpsqk6ipkw/rouge_conf.xml\n",
            "[2021-05-01 03:31:55,305 INFO] Written ROUGE configuration to ../temp/tmpsqk6ipkw/rouge_conf.xml\n",
            "2021-05-01 03:31:55,305 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpsqk6ipkw/rouge_conf.xml\n",
            "[2021-05-01 03:31:55,305 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpsqk6ipkw/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.50922 (95%-conf.int. 0.50657 - 0.51198)\n",
            "1 ROUGE-1 Average_P: 0.37482 (95%-conf.int. 0.37231 - 0.37736)\n",
            "1 ROUGE-1 Average_F: 0.41676 (95%-conf.int. 0.41469 - 0.41894)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.22945 (95%-conf.int. 0.22691 - 0.23194)\n",
            "1 ROUGE-2 Average_P: 0.16961 (95%-conf.int. 0.16752 - 0.17174)\n",
            "1 ROUGE-2 Average_F: 0.18796 (95%-conf.int. 0.18585 - 0.19010)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.46524 (95%-conf.int. 0.46268 - 0.46787)\n",
            "1 ROUGE-L Average_P: 0.34316 (95%-conf.int. 0.34077 - 0.34572)\n",
            "1 ROUGE-L Average_F: 0.38122 (95%-conf.int. 0.37924 - 0.38347)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 157, in <module>\n",
            "    test_ext(args, device_id, cp, step)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/train_extractive.py\", line 198, in test_ext\n",
            "    trainer.test(test_iter, step)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/models/trainer_ext.py\", line 290, in test\n",
            "    rouges = test_rouge(self.args.temp_dir, can_path, gold_path)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/others/utils.py\", line 94, in test_rouge\n",
            "    shutil.rmtree(tmp_dir)\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 494, in rmtree\n",
            "    _rmtree_safe_fd(fd, path, onerror)\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 436, in _rmtree_safe_fd\n",
            "    onerror(os.rmdir, fullname, sys.exc_info())\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 434, in _rmtree_safe_fd\n",
            "    os.rmdir(entry.name, dir_fd=topfd)\n",
            "OSError: [Errno 39] Directory not empty: 'reference'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bX0t90LeLST"
      },
      "source": [
        "## Tested on Step 49000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvPMoQk7U9Rk",
        "outputId": "bada905e-9d92-4762-a828-3e4077cae0f1"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta_smaller.log -model_path ../data/trained_models/reberta_smaller -sep_optim true -use_interval false -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta_ext_bert_cnndm -test_from ../data/trained_models/reberta_smaller/model_step_49000.pt -ext_layers 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-05-01 14:28:16,264 INFO] Loading checkpoint from ../data/trained_models/reberta_smaller/model_step_49000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=1, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta_smaller.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/reberta_smaller', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta_ext_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/reberta_smaller/model_step_49000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-05-01 14:28:46,019 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-01 14:28:46,258 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-01 14:28:46,355 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-01 14:29:08,016 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-05-01 14:29:08,027 INFO] * number of parameters: 130161921\n",
            "[2021-05-01 14:30:00,278 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-05-01 14:30:53,735 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-05-01 14:31:44,752 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-05-01 14:32:34,851 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-05-01 14:33:25,035 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-05-01 14:36:09,761 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-05-01 14:36:09,761 INFO] Writing summaries.\n",
            "2021-05-01 14:36:09,769 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmpt8_wyu8j/system and model files to ../temp/tmpt8_wyu8j/model.\n",
            "[2021-05-01 14:36:09,769 INFO] Processing summaries. Saving system files to ../temp/tmpt8_wyu8j/system and model files to ../temp/tmpt8_wyu8j/model.\n",
            "2021-05-01 14:36:09,769 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-01-14-34-01/candidate/.\n",
            "[2021-05-01 14:36:09,769 INFO] Processing files in ../temp/rouge-tmp-2021-05-01-14-34-01/candidate/.\n",
            "2021-05-01 14:37:57,752 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpt8_wyu8j/system.\n",
            "[2021-05-01 14:37:57,752 INFO] Saved processed files to ../temp/tmpt8_wyu8j/system.\n",
            "2021-05-01 14:37:57,753 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-01-14-34-01/reference/.\n",
            "[2021-05-01 14:37:57,753 INFO] Processing files in ../temp/rouge-tmp-2021-05-01-14-34-01/reference/.\n",
            "2021-05-01 14:39:46,718 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpt8_wyu8j/model.\n",
            "[2021-05-01 14:39:46,718 INFO] Saved processed files to ../temp/tmpt8_wyu8j/model.\n",
            "2021-05-01 14:39:46,941 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmp465eyv82/rouge_conf.xml\n",
            "[2021-05-01 14:39:46,941 INFO] Written ROUGE configuration to ../temp/tmp465eyv82/rouge_conf.xml\n",
            "2021-05-01 14:39:46,941 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp465eyv82/rouge_conf.xml\n",
            "[2021-05-01 14:39:46,941 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp465eyv82/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.53242 (95%-conf.int. 0.52980 - 0.53503)\n",
            "1 ROUGE-1 Average_P: 0.38322 (95%-conf.int. 0.38063 - 0.38557)\n",
            "1 ROUGE-1 Average_F: 0.43066 (95%-conf.int. 0.42854 - 0.43281)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.25009 (95%-conf.int. 0.24729 - 0.25286)\n",
            "1 ROUGE-2 Average_P: 0.18071 (95%-conf.int. 0.17832 - 0.18299)\n",
            "1 ROUGE-2 Average_F: 0.20242 (95%-conf.int. 0.20003 - 0.20471)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.48759 (95%-conf.int. 0.48500 - 0.49032)\n",
            "1 ROUGE-L Average_P: 0.35162 (95%-conf.int. 0.34904 - 0.35400)\n",
            "1 ROUGE-L Average_F: 0.39483 (95%-conf.int. 0.39261 - 0.39691)\n",
            "\n",
            "[2021-05-01 14:44:10,677 INFO] Rouges at step 49000 \n",
            ">> ROUGE-F(1/2/3/l): 43.07/20.24/39.48\n",
            "ROUGE-R(1/2/3/l): 53.24/25.01/48.76\n",
            "\n",
            "[2021-05-01 14:44:10,677 INFO] Validation xent: 5.16984 at step 49000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGo9zDnMWeCz"
      },
      "source": [
        "## Testing on Step 51000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9rEZFAqWIDd",
        "outputId": "8b6a9fed-cc6a-409b-dcb2-d6dcea691b98"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta_smaller.log -model_path ../data/trained_models/reberta_smaller -sep_optim true -use_interval false -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta_ext_bert_cnndm -test_from ../data/trained_models/reberta_smaller/model_step_51000.pt -ext_layers 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-05-02 04:31:49,679 INFO] Loading checkpoint from ../data/trained_models/reberta_smaller/model_step_51000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=1, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta_smaller.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/reberta_smaller', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta_ext_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/reberta_smaller/model_step_51000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-05-02 04:32:00,726 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-02 04:32:00,727 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-02 04:32:00,840 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-02 04:32:09,466 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-05-02 04:32:09,473 INFO] * number of parameters: 130161921\n",
            "[2021-05-02 04:32:59,512 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:33:50,406 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:34:40,265 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:35:29,992 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:36:21,388 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-05-02 04:40:24,104 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-05-02 04:40:24,104 INFO] Writing summaries.\n",
            "2021-05-02 04:40:24,111 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmptyxlrumt/system and model files to ../temp/tmptyxlrumt/model.\n",
            "[2021-05-02 04:40:24,111 INFO] Processing summaries. Saving system files to ../temp/tmptyxlrumt/system and model files to ../temp/tmptyxlrumt/model.\n",
            "2021-05-02 04:40:24,112 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-02-04-36-58/candidate/.\n",
            "[2021-05-02 04:40:24,112 INFO] Processing files in ../temp/rouge-tmp-2021-05-02-04-36-58/candidate/.\n",
            "2021-05-02 04:42:17,694 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmptyxlrumt/system.\n",
            "[2021-05-02 04:42:17,694 INFO] Saved processed files to ../temp/tmptyxlrumt/system.\n",
            "2021-05-02 04:42:17,696 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-02-04-36-58/reference/.\n",
            "[2021-05-02 04:42:17,696 INFO] Processing files in ../temp/rouge-tmp-2021-05-02-04-36-58/reference/.\n",
            "2021-05-02 04:44:12,924 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmptyxlrumt/model.\n",
            "[2021-05-02 04:44:12,924 INFO] Saved processed files to ../temp/tmptyxlrumt/model.\n",
            "2021-05-02 04:44:13,162 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpbvj2a0xg/rouge_conf.xml\n",
            "[2021-05-02 04:44:13,162 INFO] Written ROUGE configuration to ../temp/tmpbvj2a0xg/rouge_conf.xml\n",
            "2021-05-02 04:44:13,162 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpbvj2a0xg/rouge_conf.xml\n",
            "[2021-05-02 04:44:13,162 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpbvj2a0xg/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.53270 (95%-conf.int. 0.53008 - 0.53539)\n",
            "1 ROUGE-1 Average_P: 0.38390 (95%-conf.int. 0.38133 - 0.38636)\n",
            "1 ROUGE-1 Average_F: 0.43097 (95%-conf.int. 0.42875 - 0.43307)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.25018 (95%-conf.int. 0.24747 - 0.25290)\n",
            "1 ROUGE-2 Average_P: 0.18117 (95%-conf.int. 0.17879 - 0.18340)\n",
            "1 ROUGE-2 Average_F: 0.20265 (95%-conf.int. 0.20039 - 0.20498)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.48791 (95%-conf.int. 0.48532 - 0.49043)\n",
            "1 ROUGE-L Average_P: 0.35228 (95%-conf.int. 0.34987 - 0.35464)\n",
            "1 ROUGE-L Average_F: 0.39517 (95%-conf.int. 0.39305 - 0.39729)\n",
            "\n",
            "[2021-05-02 04:51:24,989 INFO] Rouges at step 51000 \n",
            ">> ROUGE-F(1/2/3/l): 43.10/20.27/39.52\n",
            "ROUGE-R(1/2/3/l): 53.27/25.02/48.79\n",
            "\n",
            "[2021-05-02 04:51:24,989 INFO] Validation xent: 5.18566 at step 51000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLvZHigRWsJ1"
      },
      "source": [
        "## Testing on Step 52000 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUuFjF9XWH52",
        "outputId": "c1f56d75-ac31-4ec8-ddc8-864c04bb467c"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta_smaller.log -model_path ../data/trained_models/reberta_smaller -sep_optim true -use_interval false -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta_ext_bert_cnndm -test_from ../data/trained_models/reberta_smaller/model_step_52000.pt -ext_layers 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-05-02 04:51:27,822 INFO] Loading checkpoint from ../data/trained_models/reberta_smaller/model_step_52000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=1, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta_smaller.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/reberta_smaller', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta_ext_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/reberta_smaller/model_step_52000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-05-02 04:51:49,648 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-02 04:51:49,650 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-02 04:51:49,781 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-02 04:51:57,993 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-05-02 04:51:58,000 INFO] * number of parameters: 130161921\n",
            "[2021-05-02 04:52:47,713 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:53:39,253 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:54:29,128 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:55:18,974 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:56:09,436 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-05-02 05:00:15,337 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-05-02 05:00:15,337 INFO] Writing summaries.\n",
            "2021-05-02 05:00:15,345 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmp6xe_sic7/system and model files to ../temp/tmp6xe_sic7/model.\n",
            "[2021-05-02 05:00:15,345 INFO] Processing summaries. Saving system files to ../temp/tmp6xe_sic7/system and model files to ../temp/tmp6xe_sic7/model.\n",
            "2021-05-02 05:00:15,346 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-02-04-56-46/candidate/.\n",
            "[2021-05-02 05:00:15,346 INFO] Processing files in ../temp/rouge-tmp-2021-05-02-04-56-46/candidate/.\n",
            "2021-05-02 05:02:08,879 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp6xe_sic7/system.\n",
            "[2021-05-02 05:02:08,879 INFO] Saved processed files to ../temp/tmp6xe_sic7/system.\n",
            "2021-05-02 05:02:08,880 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-02-04-56-46/reference/.\n",
            "[2021-05-02 05:02:08,880 INFO] Processing files in ../temp/rouge-tmp-2021-05-02-04-56-46/reference/.\n",
            "2021-05-02 05:04:05,197 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp6xe_sic7/model.\n",
            "[2021-05-02 05:04:05,197 INFO] Saved processed files to ../temp/tmp6xe_sic7/model.\n",
            "2021-05-02 05:04:05,448 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmp1civaj7c/rouge_conf.xml\n",
            "[2021-05-02 05:04:05,448 INFO] Written ROUGE configuration to ../temp/tmp1civaj7c/rouge_conf.xml\n",
            "2021-05-02 05:04:05,449 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp1civaj7c/rouge_conf.xml\n",
            "[2021-05-02 05:04:05,449 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp1civaj7c/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.53274 (95%-conf.int. 0.53011 - 0.53521)\n",
            "1 ROUGE-1 Average_P: 0.38388 (95%-conf.int. 0.38123 - 0.38636)\n",
            "1 ROUGE-1 Average_F: 0.43097 (95%-conf.int. 0.42867 - 0.43314)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.25009 (95%-conf.int. 0.24737 - 0.25287)\n",
            "1 ROUGE-2 Average_P: 0.18113 (95%-conf.int. 0.17869 - 0.18354)\n",
            "1 ROUGE-2 Average_F: 0.20260 (95%-conf.int. 0.20031 - 0.20486)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.48821 (95%-conf.int. 0.48567 - 0.49079)\n",
            "1 ROUGE-L Average_P: 0.35253 (95%-conf.int. 0.34999 - 0.35498)\n",
            "1 ROUGE-L Average_F: 0.39544 (95%-conf.int. 0.39318 - 0.39761)\n",
            "\n",
            "[2021-05-02 05:11:25,945 INFO] Rouges at step 52000 \n",
            ">> ROUGE-F(1/2/3/l): 43.10/20.26/39.54\n",
            "ROUGE-R(1/2/3/l): 53.27/25.01/48.82\n",
            "\n",
            "[2021-05-02 05:11:25,946 INFO] Validation xent: 5.17571 at step 52000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C93FjYlsWtR1"
      },
      "source": [
        "## Testing on Step 53000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbd2MXimWK2p",
        "outputId": "a6a1f3b2-81d9-4477-893b-8a3ec38970fe"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta_smaller.log -model_path ../data/trained_models/reberta_smaller -sep_optim true -use_interval false -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta_ext_bert_cnndm -test_from ../data/trained_models/reberta_smaller/model_step_53000.pt -ext_layers 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-05-02 05:11:28,820 INFO] Loading checkpoint from ../data/trained_models/reberta_smaller/model_step_53000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=1, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta_smaller.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/reberta_smaller', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta_ext_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/reberta_smaller/model_step_53000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-05-02 05:11:39,214 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-02 05:11:39,216 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-02 05:11:39,330 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-02 05:11:50,172 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-05-02 05:11:50,179 INFO] * number of parameters: 130161921\n",
            "[2021-05-02 05:12:40,343 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-05-02 05:13:30,039 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-05-02 05:14:19,778 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-05-02 05:15:09,965 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-05-02 05:15:59,757 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-05-02 05:20:04,896 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-05-02 05:20:04,896 INFO] Writing summaries.\n",
            "2021-05-02 05:20:04,902 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmp4y7v7t3d/system and model files to ../temp/tmp4y7v7t3d/model.\n",
            "[2021-05-02 05:20:04,902 INFO] Processing summaries. Saving system files to ../temp/tmp4y7v7t3d/system and model files to ../temp/tmp4y7v7t3d/model.\n",
            "2021-05-02 05:20:04,903 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-02-05-16-36/candidate/.\n",
            "[2021-05-02 05:20:04,903 INFO] Processing files in ../temp/rouge-tmp-2021-05-02-05-16-36/candidate/.\n",
            "2021-05-02 05:21:56,926 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp4y7v7t3d/system.\n",
            "[2021-05-02 05:21:56,926 INFO] Saved processed files to ../temp/tmp4y7v7t3d/system.\n",
            "2021-05-02 05:21:56,928 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-02-05-16-36/reference/.\n",
            "[2021-05-02 05:21:56,928 INFO] Processing files in ../temp/rouge-tmp-2021-05-02-05-16-36/reference/.\n",
            "2021-05-02 05:23:51,574 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp4y7v7t3d/model.\n",
            "[2021-05-02 05:23:51,574 INFO] Saved processed files to ../temp/tmp4y7v7t3d/model.\n",
            "2021-05-02 05:23:51,810 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmp_lu7zac1/rouge_conf.xml\n",
            "[2021-05-02 05:23:51,810 INFO] Written ROUGE configuration to ../temp/tmp_lu7zac1/rouge_conf.xml\n",
            "2021-05-02 05:23:51,810 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp_lu7zac1/rouge_conf.xml\n",
            "[2021-05-02 05:23:51,810 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp_lu7zac1/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.53143 (95%-conf.int. 0.52890 - 0.53402)\n",
            "1 ROUGE-1 Average_P: 0.38254 (95%-conf.int. 0.37996 - 0.38502)\n",
            "1 ROUGE-1 Average_F: 0.42971 (95%-conf.int. 0.42757 - 0.43180)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.24956 (95%-conf.int. 0.24676 - 0.25241)\n",
            "1 ROUGE-2 Average_P: 0.18037 (95%-conf.int. 0.17810 - 0.18272)\n",
            "1 ROUGE-2 Average_F: 0.20196 (95%-conf.int. 0.19957 - 0.20430)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.48685 (95%-conf.int. 0.48427 - 0.48939)\n",
            "1 ROUGE-L Average_P: 0.35109 (95%-conf.int. 0.34861 - 0.35349)\n",
            "1 ROUGE-L Average_F: 0.39409 (95%-conf.int. 0.39194 - 0.39624)\n",
            "\n",
            "[2021-05-02 05:31:04,320 INFO] Rouges at step 53000 \n",
            ">> ROUGE-F(1/2/3/l): 42.97/20.20/39.41\n",
            "ROUGE-R(1/2/3/l): 53.14/24.96/48.69\n",
            "\n",
            "[2021-05-02 05:31:04,320 INFO] Validation xent: 5.34993 at step 53000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD4AZmCxPtl_"
      },
      "source": [
        "## (Tested on Step 55000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLrV8a4cPYbA",
        "outputId": "183b822b-4046-4e6d-d6f8-e0fa98049600"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta_smaller.log -model_path ../data/trained_models/reberta_smaller -sep_optim true -use_interval false -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta_ext_bert_cnndm -test_from ../data/trained_models/reberta_smaller/model_step_55000.pt -ext_layers 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-05-02 04:03:01,893 INFO] Loading checkpoint from ../data/trained_models/reberta_smaller/model_step_55000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=1, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta_smaller.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/reberta_smaller', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta_ext_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/reberta_smaller/model_step_55000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-05-02 04:03:23,979 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-02 04:03:23,982 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-02 04:03:24,112 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-02 04:03:39,304 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-05-02 04:03:39,311 INFO] * number of parameters: 130161921\n",
            "[2021-05-02 04:04:29,966 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:05:20,231 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:06:10,510 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:07:01,265 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-05-02 04:07:51,509 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-05-02 04:10:38,357 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-05-02 04:10:38,357 INFO] Writing summaries.\n",
            "2021-05-02 04:10:38,363 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmpwfmua531/system and model files to ../temp/tmpwfmua531/model.\n",
            "[2021-05-02 04:10:38,363 INFO] Processing summaries. Saving system files to ../temp/tmpwfmua531/system and model files to ../temp/tmpwfmua531/model.\n",
            "2021-05-02 04:10:38,363 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-02-04-08-28/candidate/.\n",
            "[2021-05-02 04:10:38,363 INFO] Processing files in ../temp/rouge-tmp-2021-05-02-04-08-28/candidate/.\n",
            "2021-05-02 04:12:29,530 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpwfmua531/system.\n",
            "[2021-05-02 04:12:29,530 INFO] Saved processed files to ../temp/tmpwfmua531/system.\n",
            "2021-05-02 04:12:29,531 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-02-04-08-28/reference/.\n",
            "[2021-05-02 04:12:29,531 INFO] Processing files in ../temp/rouge-tmp-2021-05-02-04-08-28/reference/.\n",
            "2021-05-02 04:14:20,433 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpwfmua531/model.\n",
            "[2021-05-02 04:14:20,433 INFO] Saved processed files to ../temp/tmpwfmua531/model.\n",
            "2021-05-02 04:14:20,687 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpiaft8gzk/rouge_conf.xml\n",
            "[2021-05-02 04:14:20,687 INFO] Written ROUGE configuration to ../temp/tmpiaft8gzk/rouge_conf.xml\n",
            "2021-05-02 04:14:20,688 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpiaft8gzk/rouge_conf.xml\n",
            "[2021-05-02 04:14:20,688 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpiaft8gzk/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.53208 (95%-conf.int. 0.52953 - 0.53458)\n",
            "1 ROUGE-1 Average_P: 0.38135 (95%-conf.int. 0.37860 - 0.38397)\n",
            "1 ROUGE-1 Average_F: 0.42901 (95%-conf.int. 0.42688 - 0.43115)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.24845 (95%-conf.int. 0.24581 - 0.25125)\n",
            "1 ROUGE-2 Average_P: 0.17901 (95%-conf.int. 0.17658 - 0.18129)\n",
            "1 ROUGE-2 Average_F: 0.20062 (95%-conf.int. 0.19832 - 0.20283)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.48669 (95%-conf.int. 0.48416 - 0.48926)\n",
            "1 ROUGE-L Average_P: 0.34952 (95%-conf.int. 0.34690 - 0.35204)\n",
            "1 ROUGE-L Average_F: 0.39289 (95%-conf.int. 0.39069 - 0.39505)\n",
            "\n",
            "[2021-05-02 04:18:51,956 INFO] Rouges at step 55000 \n",
            ">> ROUGE-F(1/2/3/l): 42.90/20.06/39.29\n",
            "ROUGE-R(1/2/3/l): 53.21/24.84/48.67\n",
            "\n",
            "[2021-05-02 04:18:51,957 INFO] Validation xent: 5.37828 at step 55000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMO_w6JIAHNu"
      },
      "source": [
        "## 60000 steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzWApDY8eOdz",
        "outputId": "a5291db8-ba67-4ff0-dbd6-67c111484278"
      },
      "source": [
        "!python3 train.py -task ext -encoder roberta -mode train -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -ext_dropout 0.1 -model_path ../data/trained_models/reberta_smaller -lr 2e-3 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 60000 -accum_count 2 -log_file ../logs/ext_roberta_cnndm -use_interval true -warmup_steps 10000 -max_pos 512 -ext_layers 1 -train_from ../data/trained_models/reberta_smaller/model_step_49000.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "----TRAIN EXTRACTIVE----\n",
            "[2021-05-01 15:08:45,603 INFO] Device ID 0\n",
            "[2021-05-01 15:08:45,777 INFO] Device cuda\n",
            "[2021-05-01 15:08:45,778 INFO] Loading checkpoint from ../data/trained_models/reberta_smaller/model_step_49000.pt\n",
            "---TRAINING FROM:  ../data/trained_models/reberta_smaller/model_step_49000.pt\n",
            "[2021-05-01 15:08:48,160 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-01 15:08:48,162 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-01 15:08:48,340 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-01 15:08:57,119 INFO] ExtSummarizer(\n",
            "  (bert): Roberta(\n",
            "    (model): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(514, 768)\n",
            "        (token_type_embeddings): Embedding(1, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ext_layer): ExtTransformerEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2021-05-01 15:08:57,220 INFO] * number of parameters: 130161921\n",
            "[2021-05-01 15:08:57,220 INFO] Start training...\n",
            "[2021-05-01 15:08:58,035 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.123.bert.pt, number of examples: 2000\n",
            "[2021-05-01 15:09:31,921 INFO] Step 49050/60000; xent: 2.44; lr: 0.0000090;  30 docs/s;     34 sec\n",
            "[2021-05-01 15:10:05,777 INFO] Step 49100/60000; xent: 2.49; lr: 0.0000090;  31 docs/s;     68 sec\n",
            "[2021-05-01 15:10:40,071 INFO] Step 49150/60000; xent: 2.57; lr: 0.0000090;  31 docs/s;    102 sec\n",
            "[2021-05-01 15:11:08,713 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.91.bert.pt, number of examples: 1995\n",
            "[2021-05-01 15:11:14,920 INFO] Step 49200/60000; xent: 2.61; lr: 0.0000090;  29 docs/s;    137 sec\n",
            "[2021-05-01 15:11:48,842 INFO] Step 49250/60000; xent: 2.38; lr: 0.0000090;  30 docs/s;    171 sec\n",
            "[2021-05-01 15:12:22,664 INFO] Step 49300/60000; xent: 2.45; lr: 0.0000090;  31 docs/s;    205 sec\n",
            "[2021-05-01 15:12:56,519 INFO] Step 49350/60000; xent: 2.48; lr: 0.0000090;  31 docs/s;    238 sec\n",
            "[2021-05-01 15:13:20,168 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.39.bert.pt, number of examples: 2001\n",
            "[2021-05-01 15:13:31,114 INFO] Step 49400/60000; xent: 2.50; lr: 0.0000090;  30 docs/s;    273 sec\n",
            "[2021-05-01 15:14:04,843 INFO] Step 49450/60000; xent: 2.54; lr: 0.0000090;  30 docs/s;    307 sec\n",
            "[2021-05-01 15:14:38,795 INFO] Step 49500/60000; xent: 2.41; lr: 0.0000090;  32 docs/s;    341 sec\n",
            "[2021-05-01 15:15:12,691 INFO] Step 49550/60000; xent: 2.50; lr: 0.0000090;  30 docs/s;    375 sec\n",
            "[2021-05-01 15:15:31,551 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.6.bert.pt, number of examples: 2001\n",
            "[2021-05-01 15:15:47,911 INFO] Step 49600/60000; xent: 2.53; lr: 0.0000090;  29 docs/s;    410 sec\n",
            "[2021-05-01 15:16:21,900 INFO] Step 49650/60000; xent: 2.63; lr: 0.0000090;  30 docs/s;    444 sec\n",
            "[2021-05-01 15:16:55,843 INFO] Step 49700/60000; xent: 2.63; lr: 0.0000090;  30 docs/s;    478 sec\n",
            "[2021-05-01 15:17:29,596 INFO] Step 49750/60000; xent: 2.53; lr: 0.0000090;  31 docs/s;    512 sec\n",
            "[2021-05-01 15:17:43,356 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.81.bert.pt, number of examples: 2001\n",
            "[2021-05-01 15:18:04,433 INFO] Step 49800/60000; xent: 2.47; lr: 0.0000090;  30 docs/s;    546 sec\n",
            "[2021-05-01 15:18:38,366 INFO] Step 49850/60000; xent: 2.56; lr: 0.0000090;  31 docs/s;    580 sec\n",
            "[2021-05-01 15:19:12,290 INFO] Step 49900/60000; xent: 2.54; lr: 0.0000090;  30 docs/s;    614 sec\n",
            "[2021-05-01 15:19:46,218 INFO] Step 49950/60000; xent: 2.64; lr: 0.0000089;  31 docs/s;    648 sec\n",
            "[2021-05-01 15:19:54,478 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.98.bert.pt, number of examples: 2001\n",
            "[2021-05-01 15:20:21,029 INFO] Step 50000/60000; xent: 2.46; lr: 0.0000089;  30 docs/s;    683 sec\n",
            "[2021-05-01 15:20:21,043 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_50000.pt\n",
            "[2021-05-01 15:21:00,980 INFO] Step 50050/60000; xent: 2.47; lr: 0.0000089;  26 docs/s;    723 sec\n",
            "[2021-05-01 15:21:34,854 INFO] Step 50100/60000; xent: 2.54; lr: 0.0000089;  32 docs/s;    757 sec\n",
            "[2021-05-01 15:22:08,532 INFO] Step 50150/60000; xent: 2.59; lr: 0.0000089;  30 docs/s;    790 sec\n",
            "[2021-05-01 15:22:11,921 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.93.bert.pt, number of examples: 2001\n",
            "[2021-05-01 15:22:43,967 INFO] Step 50200/60000; xent: 2.50; lr: 0.0000089;  30 docs/s;    826 sec\n",
            "[2021-05-01 15:23:17,861 INFO] Step 50250/60000; xent: 2.49; lr: 0.0000089;  30 docs/s;    860 sec\n",
            "[2021-05-01 15:23:51,810 INFO] Step 50300/60000; xent: 2.45; lr: 0.0000089;  30 docs/s;    894 sec\n",
            "[2021-05-01 15:24:24,963 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.63.bert.pt, number of examples: 2001\n",
            "[2021-05-01 15:24:27,103 INFO] Step 50350/60000; xent: 2.58; lr: 0.0000089;  29 docs/s;    929 sec\n",
            "[2021-05-01 15:25:00,765 INFO] Step 50400/60000; xent: 2.47; lr: 0.0000089;  31 docs/s;    963 sec\n",
            "[2021-05-01 15:25:34,786 INFO] Step 50450/60000; xent: 2.57; lr: 0.0000089;  30 docs/s;    997 sec\n",
            "[2021-05-01 15:26:08,719 INFO] Step 50500/60000; xent: 2.52; lr: 0.0000089;  31 docs/s;   1031 sec\n",
            "[2021-05-01 15:26:35,864 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.15.bert.pt, number of examples: 2000\n",
            "[2021-05-01 15:26:43,466 INFO] Step 50550/60000; xent: 2.54; lr: 0.0000089;  30 docs/s;   1065 sec\n",
            "[2021-05-01 15:27:17,394 INFO] Step 50600/60000; xent: 2.56; lr: 0.0000089;  31 docs/s;   1099 sec\n",
            "[2021-05-01 15:27:51,354 INFO] Step 50650/60000; xent: 2.42; lr: 0.0000089;  31 docs/s;   1133 sec\n",
            "[2021-05-01 15:28:25,311 INFO] Step 50700/60000; xent: 2.51; lr: 0.0000089;  30 docs/s;   1167 sec\n",
            "[2021-05-01 15:28:47,901 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.64.bert.pt, number of examples: 1998\n",
            "[2021-05-01 15:29:00,259 INFO] Step 50750/60000; xent: 2.51; lr: 0.0000089;  29 docs/s;   1202 sec\n",
            "[2021-05-01 15:29:34,192 INFO] Step 50800/60000; xent: 2.62; lr: 0.0000089;  30 docs/s;   1236 sec\n",
            "[2021-05-01 15:30:08,165 INFO] Step 50850/60000; xent: 2.40; lr: 0.0000089;  32 docs/s;   1270 sec\n",
            "[2021-05-01 15:30:42,132 INFO] Step 50900/60000; xent: 2.61; lr: 0.0000089;  30 docs/s;   1304 sec\n",
            "[2021-05-01 15:30:59,394 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.28.bert.pt, number of examples: 1999\n",
            "[2021-05-01 15:31:16,949 INFO] Step 50950/60000; xent: 2.46; lr: 0.0000089;  29 docs/s;   1339 sec\n",
            "[2021-05-01 15:31:50,963 INFO] Step 51000/60000; xent: 2.51; lr: 0.0000089;  31 docs/s;   1373 sec\n",
            "[2021-05-01 15:31:50,977 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_51000.pt\n",
            "[2021-05-01 15:32:31,147 INFO] Step 51050/60000; xent: 2.42; lr: 0.0000089;  26 docs/s;   1413 sec\n",
            "[2021-05-01 15:33:05,064 INFO] Step 51100/60000; xent: 2.40; lr: 0.0000088;  30 docs/s;   1447 sec\n",
            "[2021-05-01 15:33:17,997 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.32.bert.pt, number of examples: 2001\n",
            "[2021-05-01 15:33:39,872 INFO] Step 51150/60000; xent: 2.43; lr: 0.0000088;  29 docs/s;   1482 sec\n",
            "[2021-05-01 15:34:13,866 INFO] Step 51200/60000; xent: 2.41; lr: 0.0000088;  30 docs/s;   1516 sec\n",
            "[2021-05-01 15:34:47,848 INFO] Step 51250/60000; xent: 2.51; lr: 0.0000088;  32 docs/s;   1550 sec\n",
            "[2021-05-01 15:35:21,645 INFO] Step 51300/60000; xent: 2.48; lr: 0.0000088;  30 docs/s;   1584 sec\n",
            "[2021-05-01 15:35:29,657 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.111.bert.pt, number of examples: 2001\n",
            "[2021-05-01 15:35:57,047 INFO] Step 51350/60000; xent: 2.53; lr: 0.0000088;  30 docs/s;   1619 sec\n",
            "[2021-05-01 15:36:31,098 INFO] Step 51400/60000; xent: 2.49; lr: 0.0000088;  30 docs/s;   1653 sec\n",
            "[2021-05-01 15:37:05,146 INFO] Step 51450/60000; xent: 2.51; lr: 0.0000088;  31 docs/s;   1687 sec\n",
            "[2021-05-01 15:37:39,279 INFO] Step 51500/60000; xent: 2.58; lr: 0.0000088;  30 docs/s;   1721 sec\n",
            "[2021-05-01 15:37:40,871 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.49.bert.pt, number of examples: 2000\n",
            "[2021-05-01 15:38:14,125 INFO] Step 51550/60000; xent: 2.49; lr: 0.0000088;  30 docs/s;   1756 sec\n",
            "[2021-05-01 15:38:48,150 INFO] Step 51600/60000; xent: 2.48; lr: 0.0000088;  31 docs/s;   1790 sec\n",
            "[2021-05-01 15:39:22,208 INFO] Step 51650/60000; xent: 2.47; lr: 0.0000088;  30 docs/s;   1824 sec\n",
            "[2021-05-01 15:39:52,846 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.59.bert.pt, number of examples: 2000\n",
            "[2021-05-01 15:39:57,051 INFO] Step 51700/60000; xent: 2.48; lr: 0.0000088;  30 docs/s;   1859 sec\n",
            "[2021-05-01 15:40:31,112 INFO] Step 51750/60000; xent: 2.48; lr: 0.0000088;  30 docs/s;   1893 sec\n",
            "[2021-05-01 15:41:05,103 INFO] Step 51800/60000; xent: 2.51; lr: 0.0000088;  31 docs/s;   1927 sec\n",
            "[2021-05-01 15:41:39,197 INFO] Step 51850/60000; xent: 2.48; lr: 0.0000088;  30 docs/s;   1961 sec\n",
            "[2021-05-01 15:42:04,483 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.84.bert.pt, number of examples: 2001\n",
            "[2021-05-01 15:42:14,139 INFO] Step 51900/60000; xent: 2.48; lr: 0.0000088;  29 docs/s;   1996 sec\n",
            "[2021-05-01 15:42:48,252 INFO] Step 51950/60000; xent: 2.57; lr: 0.0000088;  30 docs/s;   2030 sec\n",
            "[2021-05-01 15:43:22,317 INFO] Step 52000/60000; xent: 2.48; lr: 0.0000088;  31 docs/s;   2064 sec\n",
            "[2021-05-01 15:43:22,333 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_52000.pt\n",
            "[2021-05-01 15:44:02,975 INFO] Step 52050/60000; xent: 2.45; lr: 0.0000088;  25 docs/s;   2105 sec\n",
            "[2021-05-01 15:44:23,608 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.137.bert.pt, number of examples: 2001\n",
            "[2021-05-01 15:44:38,038 INFO] Step 52100/60000; xent: 2.48; lr: 0.0000088;  30 docs/s;   2140 sec\n",
            "[2021-05-01 15:45:12,125 INFO] Step 52150/60000; xent: 2.49; lr: 0.0000088;  30 docs/s;   2174 sec\n",
            "[2021-05-01 15:45:46,105 INFO] Step 52200/60000; xent: 2.59; lr: 0.0000088;  30 docs/s;   2208 sec\n",
            "[2021-05-01 15:46:20,135 INFO] Step 52250/60000; xent: 2.46; lr: 0.0000087;  31 docs/s;   2242 sec\n",
            "[2021-05-01 15:46:35,802 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.13.bert.pt, number of examples: 2000\n",
            "[2021-05-01 15:46:54,948 INFO] Step 52300/60000; xent: 2.40; lr: 0.0000087;  30 docs/s;   2277 sec\n",
            "[2021-05-01 15:47:28,797 INFO] Step 52350/60000; xent: 2.41; lr: 0.0000087;  30 docs/s;   2311 sec\n",
            "[2021-05-01 15:48:02,948 INFO] Step 52400/60000; xent: 2.44; lr: 0.0000087;  31 docs/s;   2345 sec\n",
            "[2021-05-01 15:48:37,025 INFO] Step 52450/60000; xent: 2.39; lr: 0.0000087;  31 docs/s;   2379 sec\n",
            "[2021-05-01 15:48:47,132 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.135.bert.pt, number of examples: 2000\n",
            "[2021-05-01 15:49:11,753 INFO] Step 52500/60000; xent: 2.50; lr: 0.0000087;  29 docs/s;   2414 sec\n",
            "[2021-05-01 15:49:45,817 INFO] Step 52550/60000; xent: 2.50; lr: 0.0000087;  31 docs/s;   2448 sec\n",
            "[2021-05-01 15:50:19,883 INFO] Step 52600/60000; xent: 2.47; lr: 0.0000087;  30 docs/s;   2482 sec\n",
            "[2021-05-01 15:50:53,915 INFO] Step 52650/60000; xent: 2.50; lr: 0.0000087;  31 docs/s;   2516 sec\n",
            "[2021-05-01 15:50:59,480 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.71.bert.pt, number of examples: 1999\n",
            "[2021-05-01 15:51:28,911 INFO] Step 52700/60000; xent: 2.46; lr: 0.0000087;  29 docs/s;   2551 sec\n",
            "[2021-05-01 15:52:02,934 INFO] Step 52750/60000; xent: 2.49; lr: 0.0000087;  31 docs/s;   2585 sec\n",
            "[2021-05-01 15:52:37,063 INFO] Step 52800/60000; xent: 2.61; lr: 0.0000087;  31 docs/s;   2619 sec\n",
            "[2021-05-01 15:53:11,115 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.9.bert.pt, number of examples: 2000\n",
            "[2021-05-01 15:53:11,907 INFO] Step 52850/60000; xent: 2.46; lr: 0.0000087;  30 docs/s;   2654 sec\n",
            "[2021-05-01 15:53:45,944 INFO] Step 52900/60000; xent: 2.33; lr: 0.0000087;  31 docs/s;   2688 sec\n",
            "[2021-05-01 15:54:19,831 INFO] Step 52950/60000; xent: 2.38; lr: 0.0000087;  31 docs/s;   2722 sec\n",
            "[2021-05-01 15:54:53,848 INFO] Step 53000/60000; xent: 2.29; lr: 0.0000087;  30 docs/s;   2756 sec\n",
            "[2021-05-01 15:54:53,864 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_53000.pt\n",
            "[2021-05-01 15:55:29,869 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.105.bert.pt, number of examples: 2000\n",
            "[2021-05-01 15:55:35,343 INFO] Step 53050/60000; xent: 2.32; lr: 0.0000087;  25 docs/s;   2797 sec\n",
            "[2021-05-01 15:56:09,447 INFO] Step 53100/60000; xent: 2.38; lr: 0.0000087;  30 docs/s;   2831 sec\n",
            "[2021-05-01 15:56:43,570 INFO] Step 53150/60000; xent: 2.49; lr: 0.0000087;  31 docs/s;   2866 sec\n",
            "[2021-05-01 15:57:17,604 INFO] Step 53200/60000; xent: 2.43; lr: 0.0000087;  30 docs/s;   2900 sec\n",
            "[2021-05-01 15:57:42,489 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.50.bert.pt, number of examples: 1999\n",
            "[2021-05-01 15:57:52,801 INFO] Step 53250/60000; xent: 2.37; lr: 0.0000087;  29 docs/s;   2935 sec\n",
            "[2021-05-01 15:58:26,847 INFO] Step 53300/60000; xent: 2.46; lr: 0.0000087;  31 docs/s;   2969 sec\n",
            "[2021-05-01 15:59:00,981 INFO] Step 53350/60000; xent: 2.50; lr: 0.0000087;  30 docs/s;   3003 sec\n",
            "[2021-05-01 15:59:35,041 INFO] Step 53400/60000; xent: 2.46; lr: 0.0000087;  30 docs/s;   3037 sec\n",
            "[2021-05-01 15:59:54,836 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.106.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:00:09,946 INFO] Step 53450/60000; xent: 2.44; lr: 0.0000087;  30 docs/s;   3072 sec\n",
            "[2021-05-01 16:00:44,090 INFO] Step 53500/60000; xent: 2.47; lr: 0.0000086;  32 docs/s;   3106 sec\n",
            "[2021-05-01 16:01:18,075 INFO] Step 53550/60000; xent: 2.48; lr: 0.0000086;  30 docs/s;   3140 sec\n",
            "[2021-05-01 16:01:51,888 INFO] Step 53600/60000; xent: 2.43; lr: 0.0000086;  30 docs/s;   3174 sec\n",
            "[2021-05-01 16:02:06,418 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.38.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:02:26,967 INFO] Step 53650/60000; xent: 2.41; lr: 0.0000086;  30 docs/s;   3209 sec\n",
            "[2021-05-01 16:03:00,885 INFO] Step 53700/60000; xent: 2.44; lr: 0.0000086;  30 docs/s;   3243 sec\n",
            "[2021-05-01 16:03:34,948 INFO] Step 53750/60000; xent: 2.47; lr: 0.0000086;  31 docs/s;   3277 sec\n",
            "[2021-05-01 16:04:08,987 INFO] Step 53800/60000; xent: 2.48; lr: 0.0000086;  30 docs/s;   3311 sec\n",
            "[2021-05-01 16:04:18,639 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.24.bert.pt, number of examples: 1999\n",
            "[2021-05-01 16:04:43,980 INFO] Step 53850/60000; xent: 2.34; lr: 0.0000086;  30 docs/s;   3346 sec\n",
            "[2021-05-01 16:05:17,930 INFO] Step 53900/60000; xent: 2.40; lr: 0.0000086;  31 docs/s;   3380 sec\n",
            "[2021-05-01 16:05:52,014 INFO] Step 53950/60000; xent: 2.37; lr: 0.0000086;  30 docs/s;   3414 sec\n",
            "[2021-05-01 16:06:25,972 INFO] Step 54000/60000; xent: 2.30; lr: 0.0000086;  31 docs/s;   3448 sec\n",
            "[2021-05-01 16:06:25,975 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_54000.pt\n",
            "[2021-05-01 16:06:36,908 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.143.bert.pt, number of examples: 1084\n",
            "[2021-05-01 16:07:07,685 INFO] Step 54050/60000; xent: 2.43; lr: 0.0000086;  26 docs/s;   3490 sec\n",
            "[2021-05-01 16:07:41,541 INFO] Step 54100/60000; xent: 2.47; lr: 0.0000086;  30 docs/s;   3524 sec\n",
            "[2021-05-01 16:07:48,610 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.94.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:08:16,691 INFO] Step 54150/60000; xent: 2.40; lr: 0.0000086;  29 docs/s;   3559 sec\n",
            "[2021-05-01 16:08:50,732 INFO] Step 54200/60000; xent: 2.40; lr: 0.0000086;  30 docs/s;   3593 sec\n",
            "[2021-05-01 16:09:24,607 INFO] Step 54250/60000; xent: 2.51; lr: 0.0000086;  31 docs/s;   3627 sec\n",
            "[2021-05-01 16:09:58,434 INFO] Step 54300/60000; xent: 2.33; lr: 0.0000086;  31 docs/s;   3660 sec\n",
            "[2021-05-01 16:10:00,682 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.62.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:10:33,507 INFO] Step 54350/60000; xent: 2.38; lr: 0.0000086;  30 docs/s;   3695 sec\n",
            "[2021-05-01 16:11:07,522 INFO] Step 54400/60000; xent: 2.37; lr: 0.0000086;  31 docs/s;   3729 sec\n",
            "[2021-05-01 16:11:41,602 INFO] Step 54450/60000; xent: 2.28; lr: 0.0000086;  31 docs/s;   3764 sec\n",
            "[2021-05-01 16:12:12,487 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.139.bert.pt, number of examples: 2000\n",
            "[2021-05-01 16:12:16,679 INFO] Step 54500/60000; xent: 2.35; lr: 0.0000086;  29 docs/s;   3799 sec\n",
            "[2021-05-01 16:12:50,753 INFO] Step 54550/60000; xent: 2.42; lr: 0.0000086;  30 docs/s;   3833 sec\n",
            "[2021-05-01 16:13:24,524 INFO] Step 54600/60000; xent: 2.36; lr: 0.0000086;  31 docs/s;   3866 sec\n",
            "[2021-05-01 16:13:58,643 INFO] Step 54650/60000; xent: 2.44; lr: 0.0000086;  31 docs/s;   3901 sec\n",
            "[2021-05-01 16:14:24,758 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.88.bert.pt, number of examples: 2000\n",
            "[2021-05-01 16:14:33,702 INFO] Step 54700/60000; xent: 2.44; lr: 0.0000086;  30 docs/s;   3936 sec\n",
            "[2021-05-01 16:15:07,635 INFO] Step 54750/60000; xent: 2.38; lr: 0.0000085;  30 docs/s;   3970 sec\n",
            "[2021-05-01 16:15:41,687 INFO] Step 54800/60000; xent: 2.42; lr: 0.0000085;  31 docs/s;   4004 sec\n",
            "[2021-05-01 16:16:15,812 INFO] Step 54850/60000; xent: 2.45; lr: 0.0000085;  31 docs/s;   4038 sec\n",
            "[2021-05-01 16:16:37,043 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.92.bert.pt, number of examples: 1998\n",
            "[2021-05-01 16:16:50,820 INFO] Step 54900/60000; xent: 2.41; lr: 0.0000085;  29 docs/s;   4073 sec\n",
            "[2021-05-01 16:17:24,985 INFO] Step 54950/60000; xent: 2.31; lr: 0.0000085;  30 docs/s;   4107 sec\n",
            "[2021-05-01 16:17:58,912 INFO] Step 55000/60000; xent: 2.26; lr: 0.0000085;  30 docs/s;   4141 sec\n",
            "[2021-05-01 16:17:58,927 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_55000.pt\n",
            "[2021-05-01 16:18:39,833 INFO] Step 55050/60000; xent: 2.17; lr: 0.0000085;  27 docs/s;   4182 sec\n",
            "[2021-05-01 16:18:55,676 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.68.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:19:14,853 INFO] Step 55100/60000; xent: 2.27; lr: 0.0000085;  29 docs/s;   4217 sec\n",
            "[2021-05-01 16:19:48,950 INFO] Step 55150/60000; xent: 2.38; lr: 0.0000085;  30 docs/s;   4251 sec\n",
            "[2021-05-01 16:20:22,833 INFO] Step 55200/60000; xent: 2.48; lr: 0.0000085;  31 docs/s;   4285 sec\n",
            "[2021-05-01 16:20:56,900 INFO] Step 55250/60000; xent: 2.39; lr: 0.0000085;  30 docs/s;   4319 sec\n",
            "[2021-05-01 16:21:07,866 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.0.bert.pt, number of examples: 2000\n",
            "[2021-05-01 16:21:31,781 INFO] Step 55300/60000; xent: 2.38; lr: 0.0000085;  29 docs/s;   4354 sec\n",
            "[2021-05-01 16:22:05,878 INFO] Step 55350/60000; xent: 2.39; lr: 0.0000085;  31 docs/s;   4388 sec\n",
            "[2021-05-01 16:22:39,981 INFO] Step 55400/60000; xent: 2.45; lr: 0.0000085;  30 docs/s;   4422 sec\n",
            "[2021-05-01 16:23:13,784 INFO] Step 55450/60000; xent: 2.38; lr: 0.0000085;  31 docs/s;   4456 sec\n",
            "[2021-05-01 16:23:19,886 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.83.bert.pt, number of examples: 1999\n",
            "[2021-05-01 16:23:48,665 INFO] Step 55500/60000; xent: 2.40; lr: 0.0000085;  30 docs/s;   4491 sec\n",
            "[2021-05-01 16:24:22,437 INFO] Step 55550/60000; xent: 2.39; lr: 0.0000085;  31 docs/s;   4524 sec\n",
            "[2021-05-01 16:24:56,561 INFO] Step 55600/60000; xent: 2.34; lr: 0.0000085;  31 docs/s;   4559 sec\n",
            "[2021-05-01 16:25:30,426 INFO] Step 55650/60000; xent: 2.29; lr: 0.0000085;  30 docs/s;   4592 sec\n",
            "[2021-05-01 16:25:31,297 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.138.bert.pt, number of examples: 2000\n",
            "[2021-05-01 16:26:05,472 INFO] Step 55700/60000; xent: 2.34; lr: 0.0000085;  29 docs/s;   4627 sec\n",
            "[2021-05-01 16:26:39,522 INFO] Step 55750/60000; xent: 2.43; lr: 0.0000085;  32 docs/s;   4661 sec\n",
            "[2021-05-01 16:27:13,503 INFO] Step 55800/60000; xent: 2.46; lr: 0.0000085;  30 docs/s;   4695 sec\n",
            "[2021-05-01 16:27:42,645 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.72.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:27:48,169 INFO] Step 55850/60000; xent: 2.34; lr: 0.0000085;  30 docs/s;   4730 sec\n",
            "[2021-05-01 16:28:21,944 INFO] Step 55900/60000; xent: 2.36; lr: 0.0000085;  31 docs/s;   4764 sec\n",
            "[2021-05-01 16:28:55,912 INFO] Step 55950/60000; xent: 2.41; lr: 0.0000085;  31 docs/s;   4798 sec\n",
            "[2021-05-01 16:29:29,850 INFO] Step 56000/60000; xent: 2.30; lr: 0.0000085;  31 docs/s;   4832 sec\n",
            "[2021-05-01 16:29:29,865 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_56000.pt\n",
            "[2021-05-01 16:30:01,002 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.89.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:30:11,269 INFO] Step 56050/60000; xent: 2.26; lr: 0.0000084;  25 docs/s;   4873 sec\n",
            "[2021-05-01 16:30:45,208 INFO] Step 56100/60000; xent: 2.20; lr: 0.0000084;  31 docs/s;   4907 sec\n",
            "[2021-05-01 16:31:18,975 INFO] Step 56150/60000; xent: 2.30; lr: 0.0000084;  31 docs/s;   4941 sec\n",
            "[2021-05-01 16:31:52,930 INFO] Step 56200/60000; xent: 2.30; lr: 0.0000084;  30 docs/s;   4975 sec\n",
            "[2021-05-01 16:32:12,700 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.51.bert.pt, number of examples: 1999\n",
            "[2021-05-01 16:32:27,730 INFO] Step 56250/60000; xent: 2.29; lr: 0.0000084;  30 docs/s;   5010 sec\n",
            "[2021-05-01 16:33:01,776 INFO] Step 56300/60000; xent: 2.35; lr: 0.0000084;  31 docs/s;   5044 sec\n",
            "[2021-05-01 16:33:35,548 INFO] Step 56350/60000; xent: 2.31; lr: 0.0000084;  30 docs/s;   5078 sec\n",
            "[2021-05-01 16:34:09,605 INFO] Step 56400/60000; xent: 2.23; lr: 0.0000084;  31 docs/s;   5112 sec\n",
            "[2021-05-01 16:34:25,920 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.35.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:34:45,059 INFO] Step 56450/60000; xent: 2.28; lr: 0.0000084;  29 docs/s;   5147 sec\n",
            "[2021-05-01 16:35:19,400 INFO] Step 56500/60000; xent: 2.42; lr: 0.0000084;  31 docs/s;   5181 sec\n",
            "[2021-05-01 16:35:54,779 INFO] Step 56550/60000; xent: 2.35; lr: 0.0000084;  30 docs/s;   5217 sec\n",
            "[2021-05-01 16:36:30,472 INFO] Step 56600/60000; xent: 2.38; lr: 0.0000084;  29 docs/s;   5252 sec\n",
            "[2021-05-01 16:36:41,167 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.37.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:37:05,584 INFO] Step 56650/60000; xent: 2.33; lr: 0.0000084;  29 docs/s;   5288 sec\n",
            "[2021-05-01 16:37:39,465 INFO] Step 56700/60000; xent: 2.31; lr: 0.0000084;  31 docs/s;   5321 sec\n",
            "[2021-05-01 16:38:13,396 INFO] Step 56750/60000; xent: 2.38; lr: 0.0000084;  31 docs/s;   5355 sec\n",
            "[2021-05-01 16:38:47,299 INFO] Step 56800/60000; xent: 2.32; lr: 0.0000084;  31 docs/s;   5389 sec\n",
            "[2021-05-01 16:38:52,177 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.80.bert.pt, number of examples: 2000\n",
            "[2021-05-01 16:39:22,130 INFO] Step 56850/60000; xent: 2.30; lr: 0.0000084;  30 docs/s;   5424 sec\n",
            "[2021-05-01 16:39:56,112 INFO] Step 56900/60000; xent: 2.32; lr: 0.0000084;  30 docs/s;   5458 sec\n",
            "[2021-05-01 16:40:30,046 INFO] Step 56950/60000; xent: 2.41; lr: 0.0000084;  31 docs/s;   5492 sec\n",
            "[2021-05-01 16:41:03,876 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.52.bert.pt, number of examples: 1999\n",
            "[2021-05-01 16:41:04,663 INFO] Step 57000/60000; xent: 2.32; lr: 0.0000084;  30 docs/s;   5527 sec\n",
            "[2021-05-01 16:41:04,677 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_57000.pt\n",
            "[2021-05-01 16:41:44,957 INFO] Step 57050/60000; xent: 2.04; lr: 0.0000084;  26 docs/s;   5567 sec\n",
            "[2021-05-01 16:42:18,801 INFO] Step 57100/60000; xent: 2.17; lr: 0.0000084;  31 docs/s;   5601 sec\n",
            "[2021-05-01 16:42:52,762 INFO] Step 57150/60000; xent: 2.22; lr: 0.0000084;  30 docs/s;   5635 sec\n",
            "[2021-05-01 16:43:21,450 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.12.bert.pt, number of examples: 1998\n",
            "[2021-05-01 16:43:27,676 INFO] Step 57200/60000; xent: 2.21; lr: 0.0000084;  30 docs/s;   5670 sec\n",
            "[2021-05-01 16:44:01,525 INFO] Step 57250/60000; xent: 2.34; lr: 0.0000084;  31 docs/s;   5703 sec\n",
            "[2021-05-01 16:44:35,452 INFO] Step 57300/60000; xent: 2.33; lr: 0.0000084;  31 docs/s;   5737 sec\n",
            "[2021-05-01 16:45:09,370 INFO] Step 57350/60000; xent: 2.29; lr: 0.0000084;  30 docs/s;   5771 sec\n",
            "[2021-05-01 16:45:32,330 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.114.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:45:43,965 INFO] Step 57400/60000; xent: 2.26; lr: 0.0000083;  30 docs/s;   5806 sec\n",
            "[2021-05-01 16:46:17,852 INFO] Step 57450/60000; xent: 2.16; lr: 0.0000083;  31 docs/s;   5840 sec\n",
            "[2021-05-01 16:46:51,567 INFO] Step 57500/60000; xent: 2.21; lr: 0.0000083;  31 docs/s;   5874 sec\n",
            "[2021-05-01 16:47:25,541 INFO] Step 57550/60000; xent: 2.29; lr: 0.0000083;  30 docs/s;   5908 sec\n",
            "[2021-05-01 16:47:43,989 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.86.bert.pt, number of examples: 1999\n",
            "[2021-05-01 16:48:00,402 INFO] Step 57600/60000; xent: 2.22; lr: 0.0000083;  29 docs/s;   5942 sec\n",
            "[2021-05-01 16:48:34,262 INFO] Step 57650/60000; xent: 2.22; lr: 0.0000083;  30 docs/s;   5976 sec\n",
            "[2021-05-01 16:49:07,901 INFO] Step 57700/60000; xent: 2.15; lr: 0.0000083;  32 docs/s;   6010 sec\n",
            "[2021-05-01 16:49:41,845 INFO] Step 57750/60000; xent: 2.06; lr: 0.0000083;  31 docs/s;   6044 sec\n",
            "[2021-05-01 16:49:54,871 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.113.bert.pt, number of examples: 2000\n",
            "[2021-05-01 16:50:16,467 INFO] Step 57800/60000; xent: 2.27; lr: 0.0000083;  30 docs/s;   6078 sec\n",
            "[2021-05-01 16:50:50,371 INFO] Step 57850/60000; xent: 2.31; lr: 0.0000083;  31 docs/s;   6112 sec\n",
            "[2021-05-01 16:51:24,283 INFO] Step 57900/60000; xent: 2.43; lr: 0.0000083;  30 docs/s;   6146 sec\n",
            "[2021-05-01 16:51:58,040 INFO] Step 57950/60000; xent: 2.31; lr: 0.0000083;  31 docs/s;   6180 sec\n",
            "[2021-05-01 16:52:06,336 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.96.bert.pt, number of examples: 1999\n",
            "[2021-05-01 16:52:32,905 INFO] Step 58000/60000; xent: 2.31; lr: 0.0000083;  30 docs/s;   6215 sec\n",
            "[2021-05-01 16:52:32,921 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_58000.pt\n",
            "[2021-05-01 16:53:13,079 INFO] Step 58050/60000; xent: 2.32; lr: 0.0000083;  26 docs/s;   6255 sec\n",
            "[2021-05-01 16:53:46,951 INFO] Step 58100/60000; xent: 2.25; lr: 0.0000083;  30 docs/s;   6289 sec\n",
            "[2021-05-01 16:54:20,729 INFO] Step 58150/60000; xent: 2.25; lr: 0.0000083;  31 docs/s;   6323 sec\n",
            "[2021-05-01 16:54:23,638 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.131.bert.pt, number of examples: 2001\n",
            "[2021-05-01 16:54:55,463 INFO] Step 58200/60000; xent: 2.24; lr: 0.0000083;  30 docs/s;   6357 sec\n",
            "[2021-05-01 16:55:29,343 INFO] Step 58250/60000; xent: 2.35; lr: 0.0000083;  31 docs/s;   6391 sec\n",
            "[2021-05-01 16:56:03,211 INFO] Step 58300/60000; xent: 2.33; lr: 0.0000083;  31 docs/s;   6425 sec\n",
            "[2021-05-01 16:56:34,479 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.97.bert.pt, number of examples: 2000\n",
            "[2021-05-01 16:56:37,972 INFO] Step 58350/60000; xent: 2.34; lr: 0.0000083;  30 docs/s;   6460 sec\n",
            "[2021-05-01 16:57:11,813 INFO] Step 58400/60000; xent: 2.30; lr: 0.0000083;  31 docs/s;   6494 sec\n",
            "[2021-05-01 16:57:45,701 INFO] Step 58450/60000; xent: 2.28; lr: 0.0000083;  31 docs/s;   6528 sec\n",
            "[2021-05-01 16:58:19,451 INFO] Step 58500/60000; xent: 2.31; lr: 0.0000083;  30 docs/s;   6561 sec\n",
            "[2021-05-01 16:58:46,551 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.55.bert.pt, number of examples: 1999\n",
            "[2021-05-01 16:58:54,092 INFO] Step 58550/60000; xent: 2.35; lr: 0.0000083;  30 docs/s;   6596 sec\n",
            "[2021-05-01 16:59:27,980 INFO] Step 58600/60000; xent: 2.24; lr: 0.0000083;  31 docs/s;   6630 sec\n",
            "[2021-05-01 17:00:01,830 INFO] Step 58650/60000; xent: 2.34; lr: 0.0000083;  31 docs/s;   6664 sec\n",
            "[2021-05-01 17:00:35,708 INFO] Step 58700/60000; xent: 2.23; lr: 0.0000083;  31 docs/s;   6698 sec\n",
            "[2021-05-01 17:00:56,925 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.128.bert.pt, number of examples: 2000\n",
            "[2021-05-01 17:01:10,553 INFO] Step 58750/60000; xent: 2.23; lr: 0.0000083;  30 docs/s;   6733 sec\n",
            "[2021-05-01 17:01:44,462 INFO] Step 58800/60000; xent: 2.29; lr: 0.0000082;  31 docs/s;   6766 sec\n",
            "[2021-05-01 17:02:18,121 INFO] Step 58850/60000; xent: 2.33; lr: 0.0000082;  31 docs/s;   6800 sec\n",
            "[2021-05-01 17:02:51,987 INFO] Step 58900/60000; xent: 2.13; lr: 0.0000082;  31 docs/s;   6834 sec\n",
            "[2021-05-01 17:03:07,444 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.104.bert.pt, number of examples: 2000\n",
            "[2021-05-01 17:03:26,319 INFO] Step 58950/60000; xent: 2.16; lr: 0.0000082;  30 docs/s;   6868 sec\n",
            "[2021-05-01 17:04:00,204 INFO] Step 59000/60000; xent: 2.30; lr: 0.0000082;  30 docs/s;   6902 sec\n",
            "[2021-05-01 17:04:00,220 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_59000.pt\n",
            "[2021-05-01 17:04:40,680 INFO] Step 59050/60000; xent: 2.26; lr: 0.0000082;  27 docs/s;   6943 sec\n",
            "[2021-05-01 17:05:14,491 INFO] Step 59100/60000; xent: 2.23; lr: 0.0000082;  30 docs/s;   6976 sec\n",
            "[2021-05-01 17:05:24,948 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.118.bert.pt, number of examples: 2001\n",
            "[2021-05-01 17:05:49,531 INFO] Step 59150/60000; xent: 2.21; lr: 0.0000082;  30 docs/s;   7011 sec\n",
            "[2021-05-01 17:06:23,322 INFO] Step 59200/60000; xent: 2.13; lr: 0.0000082;  31 docs/s;   7045 sec\n",
            "[2021-05-01 17:06:57,104 INFO] Step 59250/60000; xent: 2.25; lr: 0.0000082;  31 docs/s;   7079 sec\n",
            "[2021-05-01 17:07:31,080 INFO] Step 59300/60000; xent: 2.02; lr: 0.0000082;  31 docs/s;   7113 sec\n",
            "[2021-05-01 17:07:35,833 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.47.bert.pt, number of examples: 2000\n",
            "[2021-05-01 17:08:05,740 INFO] Step 59350/60000; xent: 2.12; lr: 0.0000082;  30 docs/s;   7148 sec\n",
            "[2021-05-01 17:08:39,651 INFO] Step 59400/60000; xent: 2.05; lr: 0.0000082;  30 docs/s;   7182 sec\n",
            "[2021-05-01 17:09:13,504 INFO] Step 59450/60000; xent: 2.11; lr: 0.0000082;  31 docs/s;   7215 sec\n",
            "[2021-05-01 17:09:46,918 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.8.bert.pt, number of examples: 2001\n",
            "[2021-05-01 17:09:48,379 INFO] Step 59500/60000; xent: 2.10; lr: 0.0000082;  30 docs/s;   7250 sec\n",
            "[2021-05-01 17:10:22,288 INFO] Step 59550/60000; xent: 2.18; lr: 0.0000082;  31 docs/s;   7284 sec\n",
            "[2021-05-01 17:10:55,976 INFO] Step 59600/60000; xent: 2.17; lr: 0.0000082;  31 docs/s;   7318 sec\n",
            "[2021-05-01 17:11:29,907 INFO] Step 59650/60000; xent: 2.18; lr: 0.0000082;  31 docs/s;   7352 sec\n",
            "[2021-05-01 17:11:57,768 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.11.bert.pt, number of examples: 2001\n",
            "[2021-05-01 17:12:04,689 INFO] Step 59700/60000; xent: 2.16; lr: 0.0000082;  30 docs/s;   7387 sec\n",
            "[2021-05-01 17:12:38,896 INFO] Step 59750/60000; xent: 2.20; lr: 0.0000082;  31 docs/s;   7421 sec\n",
            "[2021-05-01 17:13:12,802 INFO] Step 59800/60000; xent: 2.19; lr: 0.0000082;  31 docs/s;   7455 sec\n",
            "[2021-05-01 17:13:46,646 INFO] Step 59850/60000; xent: 2.12; lr: 0.0000082;  31 docs/s;   7489 sec\n",
            "[2021-05-01 17:14:09,497 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.66.bert.pt, number of examples: 2001\n",
            "[2021-05-01 17:14:21,150 INFO] Step 59900/60000; xent: 2.25; lr: 0.0000082;  30 docs/s;   7523 sec\n",
            "[2021-05-01 17:14:55,063 INFO] Step 59950/60000; xent: 2.25; lr: 0.0000082;  31 docs/s;   7557 sec\n",
            "[2021-05-01 17:15:28,969 INFO] Step 60000/60000; xent: 2.22; lr: 0.0000082;  31 docs/s;   7591 sec\n",
            "[2021-05-01 17:15:28,984 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_60000.pt\n",
            "[2021-05-01 17:15:36,206 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.38.bert.pt, number of examples: 2001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdwiOpTWAOhh"
      },
      "source": [
        "## 80000 steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSaATBFKANoT",
        "outputId": "bdcdc6e2-3b31-489f-b467-2289172648c6"
      },
      "source": [
        "!python3 train.py -task ext -encoder roberta -mode train -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -ext_dropout 0.1 -model_path ../data/trained_models/reberta_smaller -lr 2e-3 -visible_gpus 0 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -train_steps 80000 -accum_count 2 -log_file ../logs/ext_roberta_cnndm -use_interval true -warmup_steps 10000 -max_pos 512 -ext_layers 1 -train_from ../data/trained_models/reberta_smaller/model_step_60000.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "----TRAIN EXTRACTIVE----\n",
            "[2021-05-01 17:37:32,935 INFO] Device ID 0\n",
            "[2021-05-01 17:37:32,936 INFO] Device cuda\n",
            "[2021-05-01 17:37:32,937 INFO] Loading checkpoint from ../data/trained_models/reberta_smaller/model_step_60000.pt\n",
            "---TRAINING FROM:  ../data/trained_models/reberta_smaller/model_step_60000.pt\n",
            "[2021-05-01 17:37:35,268 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-01 17:37:35,270 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-01 17:37:35,347 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-01 17:37:50,436 INFO] ExtSummarizer(\n",
            "  (bert): Roberta(\n",
            "    (model): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(514, 768)\n",
            "        (token_type_embeddings): Embedding(1, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ext_layer): ExtTransformerEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2021-05-01 17:37:50,482 INFO] * number of parameters: 130161921\n",
            "[2021-05-01 17:37:50,483 INFO] Start training...\n",
            "[2021-05-01 17:37:50,749 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.123.bert.pt, number of examples: 2000\n",
            "[2021-05-01 17:38:24,693 INFO] Step 60050/80000; xent: 2.18; lr: 0.0000082;  30 docs/s;     34 sec\n",
            "[2021-05-01 17:38:58,597 INFO] Step 60100/80000; xent: 2.28; lr: 0.0000082;  31 docs/s;     68 sec\n",
            "[2021-05-01 17:39:32,955 INFO] Step 60150/80000; xent: 2.34; lr: 0.0000082;  31 docs/s;    102 sec\n",
            "[2021-05-01 17:40:01,188 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.91.bert.pt, number of examples: 1995\n",
            "[2021-05-01 17:40:07,404 INFO] Step 60200/80000; xent: 2.38; lr: 0.0000082;  30 docs/s;    137 sec\n",
            "[2021-05-01 17:40:41,401 INFO] Step 60250/80000; xent: 2.11; lr: 0.0000081;  30 docs/s;    171 sec\n",
            "[2021-05-01 17:41:15,281 INFO] Step 60300/80000; xent: 2.18; lr: 0.0000081;  30 docs/s;    205 sec\n",
            "[2021-05-01 17:41:49,228 INFO] Step 60350/80000; xent: 2.20; lr: 0.0000081;  31 docs/s;    238 sec\n",
            "[2021-05-01 17:42:12,508 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.39.bert.pt, number of examples: 2001\n",
            "[2021-05-01 17:42:23,476 INFO] Step 60400/80000; xent: 2.23; lr: 0.0000081;  30 docs/s;    273 sec\n",
            "[2021-05-01 17:42:57,250 INFO] Step 60450/80000; xent: 2.27; lr: 0.0000081;  30 docs/s;    307 sec\n",
            "[2021-05-01 17:43:31,245 INFO] Step 60500/80000; xent: 2.10; lr: 0.0000081;  32 docs/s;    340 sec\n",
            "[2021-05-01 17:44:05,163 INFO] Step 60550/80000; xent: 2.19; lr: 0.0000081;  30 docs/s;    374 sec\n",
            "[2021-05-01 17:44:23,251 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.6.bert.pt, number of examples: 2001\n",
            "[2021-05-01 17:44:39,653 INFO] Step 60600/80000; xent: 2.18; lr: 0.0000081;  30 docs/s;    409 sec\n",
            "[2021-05-01 17:45:13,621 INFO] Step 60650/80000; xent: 2.34; lr: 0.0000081;  30 docs/s;    443 sec\n",
            "[2021-05-01 17:45:47,565 INFO] Step 60700/80000; xent: 2.36; lr: 0.0000081;  30 docs/s;    477 sec\n",
            "[2021-05-01 17:46:21,357 INFO] Step 60750/80000; xent: 2.22; lr: 0.0000081;  31 docs/s;    511 sec\n",
            "[2021-05-01 17:46:34,429 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.81.bert.pt, number of examples: 2001\n",
            "[2021-05-01 17:46:55,525 INFO] Step 60800/80000; xent: 2.19; lr: 0.0000081;  31 docs/s;    545 sec\n",
            "[2021-05-01 17:47:29,452 INFO] Step 60850/80000; xent: 2.30; lr: 0.0000081;  31 docs/s;    579 sec\n",
            "[2021-05-01 17:48:03,337 INFO] Step 60900/80000; xent: 2.27; lr: 0.0000081;  30 docs/s;    613 sec\n",
            "[2021-05-01 17:48:37,234 INFO] Step 60950/80000; xent: 2.39; lr: 0.0000081;  31 docs/s;    646 sec\n",
            "[2021-05-01 17:48:45,111 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.98.bert.pt, number of examples: 2001\n",
            "[2021-05-01 17:49:11,636 INFO] Step 61000/80000; xent: 2.19; lr: 0.0000081;  30 docs/s;    681 sec\n",
            "[2021-05-01 17:49:11,649 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_61000.pt\n",
            "[2021-05-01 17:49:52,067 INFO] Step 61050/80000; xent: 2.18; lr: 0.0000081;  25 docs/s;    721 sec\n",
            "[2021-05-01 17:50:26,011 INFO] Step 61100/80000; xent: 2.24; lr: 0.0000081;  32 docs/s;    755 sec\n",
            "[2021-05-01 17:50:59,660 INFO] Step 61150/80000; xent: 2.34; lr: 0.0000081;  30 docs/s;    789 sec\n",
            "[2021-05-01 17:51:02,053 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.93.bert.pt, number of examples: 2001\n",
            "[2021-05-01 17:51:33,984 INFO] Step 61200/80000; xent: 2.24; lr: 0.0000081;  31 docs/s;    823 sec\n",
            "[2021-05-01 17:52:07,905 INFO] Step 61250/80000; xent: 2.16; lr: 0.0000081;  30 docs/s;    857 sec\n",
            "[2021-05-01 17:52:41,816 INFO] Step 61300/80000; xent: 2.10; lr: 0.0000081;  30 docs/s;    891 sec\n",
            "[2021-05-01 17:53:13,801 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.63.bert.pt, number of examples: 2001\n",
            "[2021-05-01 17:53:15,935 INFO] Step 61350/80000; xent: 2.28; lr: 0.0000081;  30 docs/s;    925 sec\n",
            "[2021-05-01 17:53:49,619 INFO] Step 61400/80000; xent: 2.14; lr: 0.0000081;  31 docs/s;    959 sec\n",
            "[2021-05-01 17:54:23,571 INFO] Step 61450/80000; xent: 2.22; lr: 0.0000081;  30 docs/s;    993 sec\n",
            "[2021-05-01 17:54:57,517 INFO] Step 61500/80000; xent: 2.19; lr: 0.0000081;  31 docs/s;   1027 sec\n",
            "[2021-05-01 17:55:24,149 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.15.bert.pt, number of examples: 2000\n",
            "[2021-05-01 17:55:31,739 INFO] Step 61550/80000; xent: 2.23; lr: 0.0000081;  31 docs/s;   1061 sec\n",
            "[2021-05-01 17:56:05,632 INFO] Step 61600/80000; xent: 2.25; lr: 0.0000081;  31 docs/s;   1095 sec\n",
            "[2021-05-01 17:56:39,572 INFO] Step 61650/80000; xent: 2.10; lr: 0.0000081;  31 docs/s;   1129 sec\n",
            "[2021-05-01 17:57:13,512 INFO] Step 61700/80000; xent: 2.20; lr: 0.0000081;  30 docs/s;   1163 sec\n",
            "[2021-05-01 17:57:35,535 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.64.bert.pt, number of examples: 1998\n",
            "[2021-05-01 17:57:47,860 INFO] Step 61750/80000; xent: 2.14; lr: 0.0000080;  30 docs/s;   1197 sec\n",
            "[2021-05-01 17:58:21,709 INFO] Step 61800/80000; xent: 2.26; lr: 0.0000080;  30 docs/s;   1231 sec\n",
            "[2021-05-01 17:58:55,582 INFO] Step 61850/80000; xent: 2.06; lr: 0.0000080;  32 docs/s;   1265 sec\n",
            "[2021-05-01 17:59:29,491 INFO] Step 61900/80000; xent: 2.26; lr: 0.0000080;  30 docs/s;   1299 sec\n",
            "[2021-05-01 17:59:46,034 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.28.bert.pt, number of examples: 1999\n",
            "[2021-05-01 18:00:03,529 INFO] Step 61950/80000; xent: 2.07; lr: 0.0000080;  30 docs/s;   1333 sec\n",
            "[2021-05-01 18:00:37,516 INFO] Step 62000/80000; xent: 2.05; lr: 0.0000080;  31 docs/s;   1367 sec\n",
            "[2021-05-01 18:00:37,529 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_62000.pt\n",
            "[2021-05-01 18:01:17,783 INFO] Step 62050/80000; xent: 1.92; lr: 0.0000080;  26 docs/s;   1407 sec\n",
            "[2021-05-01 18:01:51,791 INFO] Step 62100/80000; xent: 1.86; lr: 0.0000080;  30 docs/s;   1441 sec\n",
            "[2021-05-01 18:02:04,243 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.32.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:02:26,072 INFO] Step 62150/80000; xent: 1.92; lr: 0.0000080;  30 docs/s;   1475 sec\n",
            "[2021-05-01 18:02:59,969 INFO] Step 62200/80000; xent: 1.94; lr: 0.0000080;  31 docs/s;   1509 sec\n",
            "[2021-05-01 18:03:33,828 INFO] Step 62250/80000; xent: 2.12; lr: 0.0000080;  32 docs/s;   1543 sec\n",
            "[2021-05-01 18:04:07,543 INFO] Step 62300/80000; xent: 2.12; lr: 0.0000080;  30 docs/s;   1577 sec\n",
            "[2021-05-01 18:04:14,727 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.111.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:04:42,007 INFO] Step 62350/80000; xent: 2.23; lr: 0.0000080;  31 docs/s;   1611 sec\n",
            "[2021-05-01 18:05:15,880 INFO] Step 62400/80000; xent: 2.12; lr: 0.0000080;  31 docs/s;   1645 sec\n",
            "[2021-05-01 18:05:49,801 INFO] Step 62450/80000; xent: 2.13; lr: 0.0000080;  31 docs/s;   1679 sec\n",
            "[2021-05-01 18:06:23,900 INFO] Step 62500/80000; xent: 2.24; lr: 0.0000080;  31 docs/s;   1713 sec\n",
            "[2021-05-01 18:06:24,993 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.49.bert.pt, number of examples: 2000\n",
            "[2021-05-01 18:06:58,114 INFO] Step 62550/80000; xent: 2.10; lr: 0.0000080;  30 docs/s;   1747 sec\n",
            "[2021-05-01 18:07:31,988 INFO] Step 62600/80000; xent: 2.09; lr: 0.0000080;  31 docs/s;   1781 sec\n",
            "[2021-05-01 18:08:05,901 INFO] Step 62650/80000; xent: 2.11; lr: 0.0000080;  31 docs/s;   1815 sec\n",
            "[2021-05-01 18:08:35,992 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.59.bert.pt, number of examples: 2000\n",
            "[2021-05-01 18:08:40,171 INFO] Step 62700/80000; xent: 2.03; lr: 0.0000080;  30 docs/s;   1849 sec\n",
            "[2021-05-01 18:09:14,074 INFO] Step 62750/80000; xent: 2.06; lr: 0.0000080;  30 docs/s;   1883 sec\n",
            "[2021-05-01 18:09:47,913 INFO] Step 62800/80000; xent: 2.12; lr: 0.0000080;  31 docs/s;   1917 sec\n",
            "[2021-05-01 18:10:21,856 INFO] Step 62850/80000; xent: 2.09; lr: 0.0000080;  30 docs/s;   1951 sec\n",
            "[2021-05-01 18:10:46,597 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.84.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:10:56,196 INFO] Step 62900/80000; xent: 2.10; lr: 0.0000080;  30 docs/s;   1985 sec\n",
            "[2021-05-01 18:11:30,150 INFO] Step 62950/80000; xent: 2.28; lr: 0.0000080;  30 docs/s;   2019 sec\n",
            "[2021-05-01 18:12:04,051 INFO] Step 63000/80000; xent: 2.10; lr: 0.0000080;  32 docs/s;   2053 sec\n",
            "[2021-05-01 18:12:04,066 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_63000.pt\n",
            "[2021-05-01 18:12:44,506 INFO] Step 63050/80000; xent: 2.08; lr: 0.0000080;  25 docs/s;   2094 sec\n",
            "[2021-05-01 18:13:05,070 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.137.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:13:19,408 INFO] Step 63100/80000; xent: 2.07; lr: 0.0000080;  30 docs/s;   2129 sec\n",
            "[2021-05-01 18:13:53,365 INFO] Step 63150/80000; xent: 2.04; lr: 0.0000080;  30 docs/s;   2163 sec\n",
            "[2021-05-01 18:14:27,201 INFO] Step 63200/80000; xent: 2.24; lr: 0.0000080;  30 docs/s;   2196 sec\n",
            "[2021-05-01 18:15:01,098 INFO] Step 63250/80000; xent: 2.08; lr: 0.0000080;  31 docs/s;   2230 sec\n",
            "[2021-05-01 18:15:16,735 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.13.bert.pt, number of examples: 2000\n",
            "[2021-05-01 18:15:35,826 INFO] Step 63300/80000; xent: 1.98; lr: 0.0000079;  30 docs/s;   2265 sec\n",
            "[2021-05-01 18:16:09,531 INFO] Step 63350/80000; xent: 1.95; lr: 0.0000079;  30 docs/s;   2299 sec\n",
            "[2021-05-01 18:16:43,495 INFO] Step 63400/80000; xent: 2.00; lr: 0.0000079;  32 docs/s;   2333 sec\n",
            "[2021-05-01 18:17:17,425 INFO] Step 63450/80000; xent: 1.89; lr: 0.0000079;  31 docs/s;   2367 sec\n",
            "[2021-05-01 18:17:27,589 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.135.bert.pt, number of examples: 2000\n",
            "[2021-05-01 18:17:52,104 INFO] Step 63500/80000; xent: 2.00; lr: 0.0000079;  29 docs/s;   2401 sec\n",
            "[2021-05-01 18:18:26,002 INFO] Step 63550/80000; xent: 2.06; lr: 0.0000079;  31 docs/s;   2435 sec\n",
            "[2021-05-01 18:18:59,911 INFO] Step 63600/80000; xent: 2.02; lr: 0.0000079;  31 docs/s;   2469 sec\n",
            "[2021-05-01 18:19:33,773 INFO] Step 63650/80000; xent: 2.06; lr: 0.0000079;  31 docs/s;   2503 sec\n",
            "[2021-05-01 18:19:39,376 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.71.bert.pt, number of examples: 1999\n",
            "[2021-05-01 18:20:08,621 INFO] Step 63700/80000; xent: 2.05; lr: 0.0000079;  30 docs/s;   2538 sec\n",
            "[2021-05-01 18:20:42,492 INFO] Step 63750/80000; xent: 2.12; lr: 0.0000079;  31 docs/s;   2572 sec\n",
            "[2021-05-01 18:21:16,449 INFO] Step 63800/80000; xent: 2.22; lr: 0.0000079;  31 docs/s;   2606 sec\n",
            "[2021-05-01 18:21:50,234 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.9.bert.pt, number of examples: 2000\n",
            "[2021-05-01 18:21:51,019 INFO] Step 63850/80000; xent: 2.07; lr: 0.0000079;  30 docs/s;   2640 sec\n",
            "[2021-05-01 18:22:24,889 INFO] Step 63900/80000; xent: 1.80; lr: 0.0000079;  31 docs/s;   2674 sec\n",
            "[2021-05-01 18:22:58,598 INFO] Step 63950/80000; xent: 1.76; lr: 0.0000079;  31 docs/s;   2708 sec\n",
            "[2021-05-01 18:23:32,467 INFO] Step 64000/80000; xent: 1.70; lr: 0.0000079;  31 docs/s;   2742 sec\n",
            "[2021-05-01 18:23:32,482 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_64000.pt\n",
            "[2021-05-01 18:24:08,373 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.105.bert.pt, number of examples: 2000\n",
            "[2021-05-01 18:24:13,919 INFO] Step 64050/80000; xent: 1.71; lr: 0.0000079;  25 docs/s;   2783 sec\n",
            "[2021-05-01 18:24:47,907 INFO] Step 64100/80000; xent: 1.69; lr: 0.0000079;  31 docs/s;   2817 sec\n",
            "[2021-05-01 18:25:21,883 INFO] Step 64150/80000; xent: 1.84; lr: 0.0000079;  31 docs/s;   2851 sec\n",
            "[2021-05-01 18:25:55,758 INFO] Step 64200/80000; xent: 1.80; lr: 0.0000079;  31 docs/s;   2885 sec\n",
            "[2021-05-01 18:26:20,324 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.50.bert.pt, number of examples: 1999\n",
            "[2021-05-01 18:26:30,597 INFO] Step 64250/80000; xent: 1.74; lr: 0.0000079;  29 docs/s;   2920 sec\n",
            "[2021-05-01 18:27:04,500 INFO] Step 64300/80000; xent: 1.95; lr: 0.0000079;  31 docs/s;   2954 sec\n",
            "[2021-05-01 18:27:38,468 INFO] Step 64350/80000; xent: 2.00; lr: 0.0000079;  31 docs/s;   2988 sec\n",
            "[2021-05-01 18:28:12,414 INFO] Step 64400/80000; xent: 2.01; lr: 0.0000079;  30 docs/s;   3022 sec\n",
            "[2021-05-01 18:28:32,055 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.106.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:28:47,108 INFO] Step 64450/80000; xent: 2.00; lr: 0.0000079;  30 docs/s;   3056 sec\n",
            "[2021-05-01 18:29:21,075 INFO] Step 64500/80000; xent: 2.05; lr: 0.0000079;  32 docs/s;   3090 sec\n",
            "[2021-05-01 18:29:54,883 INFO] Step 64550/80000; xent: 2.06; lr: 0.0000079;  30 docs/s;   3124 sec\n",
            "[2021-05-01 18:30:28,491 INFO] Step 64600/80000; xent: 1.96; lr: 0.0000079;  30 docs/s;   3158 sec\n",
            "[2021-05-01 18:30:42,454 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.38.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:31:02,892 INFO] Step 64650/80000; xent: 2.05; lr: 0.0000079;  30 docs/s;   3192 sec\n",
            "[2021-05-01 18:31:36,642 INFO] Step 64700/80000; xent: 2.01; lr: 0.0000079;  30 docs/s;   3226 sec\n",
            "[2021-05-01 18:32:10,570 INFO] Step 64750/80000; xent: 2.01; lr: 0.0000079;  31 docs/s;   3260 sec\n",
            "[2021-05-01 18:32:44,433 INFO] Step 64800/80000; xent: 2.04; lr: 0.0000079;  30 docs/s;   3294 sec\n",
            "[2021-05-01 18:32:54,088 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.24.bert.pt, number of examples: 1999\n",
            "[2021-05-01 18:33:19,309 INFO] Step 64850/80000; xent: 1.87; lr: 0.0000079;  30 docs/s;   3329 sec\n",
            "[2021-05-01 18:33:53,088 INFO] Step 64900/80000; xent: 1.89; lr: 0.0000079;  31 docs/s;   3362 sec\n",
            "[2021-05-01 18:34:27,024 INFO] Step 64950/80000; xent: 1.82; lr: 0.0000078;  30 docs/s;   3396 sec\n",
            "[2021-05-01 18:35:00,794 INFO] Step 65000/80000; xent: 1.65; lr: 0.0000078;  31 docs/s;   3430 sec\n",
            "[2021-05-01 18:35:00,796 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_65000.pt\n",
            "[2021-05-01 18:35:11,470 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.143.bert.pt, number of examples: 1084\n",
            "[2021-05-01 18:35:42,523 INFO] Step 65050/80000; xent: 1.91; lr: 0.0000078;  26 docs/s;   3472 sec\n",
            "[2021-05-01 18:36:16,331 INFO] Step 65100/80000; xent: 2.04; lr: 0.0000078;  30 docs/s;   3506 sec\n",
            "[2021-05-01 18:36:23,238 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.94.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:36:51,184 INFO] Step 65150/80000; xent: 1.91; lr: 0.0000078;  30 docs/s;   3540 sec\n",
            "[2021-05-01 18:37:24,998 INFO] Step 65200/80000; xent: 1.84; lr: 0.0000078;  30 docs/s;   3574 sec\n",
            "[2021-05-01 18:37:58,702 INFO] Step 65250/80000; xent: 2.03; lr: 0.0000078;  31 docs/s;   3608 sec\n",
            "[2021-05-01 18:38:32,348 INFO] Step 65300/80000; xent: 1.85; lr: 0.0000078;  31 docs/s;   3642 sec\n",
            "[2021-05-01 18:38:34,586 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.62.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:39:07,228 INFO] Step 65350/80000; xent: 1.81; lr: 0.0000078;  30 docs/s;   3676 sec\n",
            "[2021-05-01 18:39:41,038 INFO] Step 65400/80000; xent: 1.75; lr: 0.0000078;  31 docs/s;   3710 sec\n",
            "[2021-05-01 18:40:14,933 INFO] Step 65450/80000; xent: 1.63; lr: 0.0000078;  31 docs/s;   3744 sec\n",
            "[2021-05-01 18:40:45,428 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.139.bert.pt, number of examples: 2000\n",
            "[2021-05-01 18:40:49,587 INFO] Step 65500/80000; xent: 1.68; lr: 0.0000078;  29 docs/s;   3779 sec\n",
            "[2021-05-01 18:41:23,460 INFO] Step 65550/80000; xent: 1.96; lr: 0.0000078;  30 docs/s;   3813 sec\n",
            "[2021-05-01 18:41:57,053 INFO] Step 65600/80000; xent: 1.86; lr: 0.0000078;  31 docs/s;   3846 sec\n",
            "[2021-05-01 18:42:30,998 INFO] Step 65650/80000; xent: 2.00; lr: 0.0000078;  31 docs/s;   3880 sec\n",
            "[2021-05-01 18:42:56,946 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.88.bert.pt, number of examples: 2000\n",
            "[2021-05-01 18:43:05,849 INFO] Step 65700/80000; xent: 1.97; lr: 0.0000078;  30 docs/s;   3915 sec\n",
            "[2021-05-01 18:43:39,596 INFO] Step 65750/80000; xent: 1.85; lr: 0.0000078;  30 docs/s;   3949 sec\n",
            "[2021-05-01 18:44:13,460 INFO] Step 65800/80000; xent: 1.94; lr: 0.0000078;  31 docs/s;   3983 sec\n",
            "[2021-05-01 18:44:47,407 INFO] Step 65850/80000; xent: 1.92; lr: 0.0000078;  31 docs/s;   4017 sec\n",
            "[2021-05-01 18:45:08,379 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.92.bert.pt, number of examples: 1998\n",
            "[2021-05-01 18:45:22,053 INFO] Step 65900/80000; xent: 1.74; lr: 0.0000078;  29 docs/s;   4051 sec\n",
            "[2021-05-01 18:45:56,047 INFO] Step 65950/80000; xent: 1.65; lr: 0.0000078;  31 docs/s;   4085 sec\n",
            "[2021-05-01 18:46:29,905 INFO] Step 66000/80000; xent: 1.48; lr: 0.0000078;  30 docs/s;   4119 sec\n",
            "[2021-05-01 18:46:29,919 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_66000.pt\n",
            "[2021-05-01 18:47:10,468 INFO] Step 66050/80000; xent: 1.45; lr: 0.0000078;  27 docs/s;   4160 sec\n",
            "[2021-05-01 18:47:26,200 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.68.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:47:45,287 INFO] Step 66100/80000; xent: 1.55; lr: 0.0000078;  29 docs/s;   4195 sec\n",
            "[2021-05-01 18:48:19,251 INFO] Step 66150/80000; xent: 1.80; lr: 0.0000078;  31 docs/s;   4229 sec\n",
            "[2021-05-01 18:48:53,004 INFO] Step 66200/80000; xent: 1.95; lr: 0.0000078;  31 docs/s;   4262 sec\n",
            "[2021-05-01 18:49:26,946 INFO] Step 66250/80000; xent: 1.87; lr: 0.0000078;  31 docs/s;   4296 sec\n",
            "[2021-05-01 18:49:37,826 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.0.bert.pt, number of examples: 2000\n",
            "[2021-05-01 18:50:01,662 INFO] Step 66300/80000; xent: 1.86; lr: 0.0000078;  30 docs/s;   4331 sec\n",
            "[2021-05-01 18:50:35,661 INFO] Step 66350/80000; xent: 1.88; lr: 0.0000078;  31 docs/s;   4365 sec\n",
            "[2021-05-01 18:51:09,605 INFO] Step 66400/80000; xent: 1.96; lr: 0.0000078;  30 docs/s;   4399 sec\n",
            "[2021-05-01 18:51:43,316 INFO] Step 66450/80000; xent: 1.79; lr: 0.0000078;  31 docs/s;   4433 sec\n",
            "[2021-05-01 18:51:49,360 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.83.bert.pt, number of examples: 1999\n",
            "[2021-05-01 18:52:18,013 INFO] Step 66500/80000; xent: 1.82; lr: 0.0000078;  30 docs/s;   4467 sec\n",
            "[2021-05-01 18:52:51,679 INFO] Step 66550/80000; xent: 1.78; lr: 0.0000078;  31 docs/s;   4501 sec\n",
            "[2021-05-01 18:53:25,710 INFO] Step 66600/80000; xent: 1.81; lr: 0.0000077;  31 docs/s;   4535 sec\n",
            "[2021-05-01 18:53:59,478 INFO] Step 66650/80000; xent: 1.63; lr: 0.0000077;  30 docs/s;   4569 sec\n",
            "[2021-05-01 18:54:00,271 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.138.bert.pt, number of examples: 2000\n",
            "[2021-05-01 18:54:34,458 INFO] Step 66700/80000; xent: 1.70; lr: 0.0000077;  30 docs/s;   4604 sec\n",
            "[2021-05-01 18:55:08,441 INFO] Step 66750/80000; xent: 1.83; lr: 0.0000077;  32 docs/s;   4638 sec\n",
            "[2021-05-01 18:55:42,355 INFO] Step 66800/80000; xent: 1.86; lr: 0.0000077;  30 docs/s;   4672 sec\n",
            "[2021-05-01 18:56:11,412 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.72.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:56:16,934 INFO] Step 66850/80000; xent: 1.78; lr: 0.0000077;  30 docs/s;   4706 sec\n",
            "[2021-05-01 18:56:50,717 INFO] Step 66900/80000; xent: 1.72; lr: 0.0000077;  31 docs/s;   4740 sec\n",
            "[2021-05-01 18:57:24,693 INFO] Step 66950/80000; xent: 1.75; lr: 0.0000077;  31 docs/s;   4774 sec\n",
            "[2021-05-01 18:57:58,646 INFO] Step 67000/80000; xent: 1.68; lr: 0.0000077;  31 docs/s;   4808 sec\n",
            "[2021-05-01 18:57:58,661 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_67000.pt\n",
            "[2021-05-01 18:58:29,659 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.89.bert.pt, number of examples: 2001\n",
            "[2021-05-01 18:58:40,078 INFO] Step 67050/80000; xent: 1.70; lr: 0.0000077;  25 docs/s;   4849 sec\n",
            "[2021-05-01 18:59:14,041 INFO] Step 67100/80000; xent: 1.52; lr: 0.0000077;  31 docs/s;   4883 sec\n",
            "[2021-05-01 18:59:47,805 INFO] Step 67150/80000; xent: 1.65; lr: 0.0000077;  31 docs/s;   4917 sec\n",
            "[2021-05-01 19:00:21,771 INFO] Step 67200/80000; xent: 1.65; lr: 0.0000077;  30 docs/s;   4951 sec\n",
            "[2021-05-01 19:00:41,441 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.51.bert.pt, number of examples: 1999\n",
            "[2021-05-01 19:00:56,466 INFO] Step 67250/80000; xent: 1.68; lr: 0.0000077;  30 docs/s;   4986 sec\n",
            "[2021-05-01 19:01:30,469 INFO] Step 67300/80000; xent: 1.66; lr: 0.0000077;  31 docs/s;   5020 sec\n",
            "[2021-05-01 19:02:04,192 INFO] Step 67350/80000; xent: 1.64; lr: 0.0000077;  30 docs/s;   5053 sec\n",
            "[2021-05-01 19:02:38,188 INFO] Step 67400/80000; xent: 1.59; lr: 0.0000077;  31 docs/s;   5087 sec\n",
            "[2021-05-01 19:02:54,125 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.35.bert.pt, number of examples: 2001\n",
            "[2021-05-01 19:03:13,226 INFO] Step 67450/80000; xent: 1.66; lr: 0.0000077;  29 docs/s;   5122 sec\n",
            "[2021-05-01 19:03:47,136 INFO] Step 67500/80000; xent: 1.80; lr: 0.0000077;  31 docs/s;   5156 sec\n",
            "[2021-05-01 19:04:21,111 INFO] Step 67550/80000; xent: 1.79; lr: 0.0000077;  31 docs/s;   5190 sec\n",
            "[2021-05-01 19:04:55,254 INFO] Step 67600/80000; xent: 1.83; lr: 0.0000077;  31 docs/s;   5225 sec\n",
            "[2021-05-01 19:05:05,307 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.37.bert.pt, number of examples: 2001\n",
            "[2021-05-01 19:05:29,712 INFO] Step 67650/80000; xent: 1.68; lr: 0.0000077;  30 docs/s;   5259 sec\n",
            "[2021-05-01 19:06:03,654 INFO] Step 67700/80000; xent: 1.71; lr: 0.0000077;  31 docs/s;   5293 sec\n",
            "[2021-05-01 19:06:37,671 INFO] Step 67750/80000; xent: 1.79; lr: 0.0000077;  31 docs/s;   5327 sec\n",
            "[2021-05-01 19:07:11,631 INFO] Step 67800/80000; xent: 1.72; lr: 0.0000077;  31 docs/s;   5361 sec\n",
            "[2021-05-01 19:07:16,121 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.80.bert.pt, number of examples: 2000\n",
            "[2021-05-01 19:07:46,162 INFO] Step 67850/80000; xent: 1.70; lr: 0.0000077;  30 docs/s;   5395 sec\n",
            "[2021-05-01 19:08:20,134 INFO] Step 67900/80000; xent: 1.56; lr: 0.0000077;  30 docs/s;   5429 sec\n",
            "[2021-05-01 19:08:54,128 INFO] Step 67950/80000; xent: 1.70; lr: 0.0000077;  31 docs/s;   5463 sec\n",
            "[2021-05-01 19:09:27,461 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.52.bert.pt, number of examples: 1999\n",
            "[2021-05-01 19:09:28,250 INFO] Step 68000/80000; xent: 1.73; lr: 0.0000077;  31 docs/s;   5497 sec\n",
            "[2021-05-01 19:09:28,265 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_68000.pt\n",
            "[2021-05-01 19:10:09,333 INFO] Step 68050/80000; xent: 1.25; lr: 0.0000077;  26 docs/s;   5539 sec\n",
            "[2021-05-01 19:10:43,258 INFO] Step 68100/80000; xent: 1.39; lr: 0.0000077;  31 docs/s;   5573 sec\n",
            "[2021-05-01 19:11:17,305 INFO] Step 68150/80000; xent: 1.50; lr: 0.0000077;  30 docs/s;   5607 sec\n",
            "[2021-05-01 19:11:45,577 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.12.bert.pt, number of examples: 1998\n",
            "[2021-05-01 19:11:51,829 INFO] Step 68200/80000; xent: 1.35; lr: 0.0000077;  30 docs/s;   5641 sec\n",
            "[2021-05-01 19:12:26,063 INFO] Step 68250/80000; xent: 1.61; lr: 0.0000077;  31 docs/s;   5675 sec\n",
            "[2021-05-01 19:13:00,264 INFO] Step 68300/80000; xent: 1.63; lr: 0.0000077;  31 docs/s;   5710 sec\n",
            "[2021-05-01 19:13:34,314 INFO] Step 68350/80000; xent: 1.51; lr: 0.0000076;  30 docs/s;   5744 sec\n",
            "[2021-05-01 19:13:57,010 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.114.bert.pt, number of examples: 2001\n",
            "[2021-05-01 19:14:08,705 INFO] Step 68400/80000; xent: 1.65; lr: 0.0000076;  30 docs/s;   5778 sec\n",
            "[2021-05-01 19:14:43,031 INFO] Step 68450/80000; xent: 1.34; lr: 0.0000076;  30 docs/s;   5812 sec\n",
            "[2021-05-01 19:15:16,920 INFO] Step 68500/80000; xent: 1.37; lr: 0.0000076;  31 docs/s;   5846 sec\n",
            "[2021-05-01 19:15:50,970 INFO] Step 68550/80000; xent: 1.51; lr: 0.0000076;  30 docs/s;   5880 sec\n",
            "[2021-05-01 19:16:08,870 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.86.bert.pt, number of examples: 1999\n",
            "[2021-05-01 19:16:25,302 INFO] Step 68600/80000; xent: 1.40; lr: 0.0000076;  30 docs/s;   5915 sec\n",
            "[2021-05-01 19:16:59,493 INFO] Step 68650/80000; xent: 1.41; lr: 0.0000076;  30 docs/s;   5949 sec\n",
            "[2021-05-01 19:17:33,562 INFO] Step 68700/80000; xent: 1.30; lr: 0.0000076;  31 docs/s;   5983 sec\n",
            "[2021-05-01 19:18:07,692 INFO] Step 68750/80000; xent: 1.26; lr: 0.0000076;  30 docs/s;   6017 sec\n",
            "[2021-05-01 19:18:20,374 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.113.bert.pt, number of examples: 2000\n",
            "[2021-05-01 19:18:42,147 INFO] Step 68800/80000; xent: 1.46; lr: 0.0000076;  30 docs/s;   6051 sec\n",
            "[2021-05-01 19:19:16,610 INFO] Step 68850/80000; xent: 1.73; lr: 0.0000076;  31 docs/s;   6086 sec\n",
            "[2021-05-01 19:19:51,019 INFO] Step 68900/80000; xent: 1.84; lr: 0.0000076;  30 docs/s;   6120 sec\n",
            "[2021-05-01 19:20:25,083 INFO] Step 68950/80000; xent: 1.67; lr: 0.0000076;  30 docs/s;   6154 sec\n",
            "[2021-05-01 19:20:33,043 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.96.bert.pt, number of examples: 1999\n",
            "[2021-05-01 19:20:59,847 INFO] Step 69000/80000; xent: 1.67; lr: 0.0000076;  30 docs/s;   6189 sec\n",
            "[2021-05-01 19:20:59,862 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_69000.pt\n",
            "[2021-05-01 19:21:40,728 INFO] Step 69050/80000; xent: 1.69; lr: 0.0000076;  26 docs/s;   6230 sec\n",
            "[2021-05-01 19:22:15,246 INFO] Step 69100/80000; xent: 1.54; lr: 0.0000076;  30 docs/s;   6264 sec\n",
            "[2021-05-01 19:22:49,280 INFO] Step 69150/80000; xent: 1.50; lr: 0.0000076;  31 docs/s;   6299 sec\n",
            "[2021-05-01 19:22:51,763 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.131.bert.pt, number of examples: 2001\n",
            "[2021-05-01 19:23:23,849 INFO] Step 69200/80000; xent: 1.49; lr: 0.0000076;  30 docs/s;   6333 sec\n",
            "[2021-05-01 19:23:58,192 INFO] Step 69250/80000; xent: 1.68; lr: 0.0000076;  30 docs/s;   6367 sec\n",
            "[2021-05-01 19:24:32,477 INFO] Step 69300/80000; xent: 1.65; lr: 0.0000076;  30 docs/s;   6402 sec\n",
            "[2021-05-01 19:25:03,516 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.97.bert.pt, number of examples: 2000\n",
            "[2021-05-01 19:25:07,042 INFO] Step 69350/80000; xent: 1.64; lr: 0.0000076;  30 docs/s;   6436 sec\n",
            "[2021-05-01 19:25:41,160 INFO] Step 69400/80000; xent: 1.63; lr: 0.0000076;  30 docs/s;   6470 sec\n",
            "[2021-05-01 19:26:15,533 INFO] Step 69450/80000; xent: 1.71; lr: 0.0000076;  31 docs/s;   6505 sec\n",
            "[2021-05-01 19:26:49,867 INFO] Step 69500/80000; xent: 1.63; lr: 0.0000076;  30 docs/s;   6539 sec\n",
            "[2021-05-01 19:27:16,754 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.55.bert.pt, number of examples: 1999\n",
            "[2021-05-01 19:27:24,358 INFO] Step 69550/80000; xent: 1.65; lr: 0.0000076;  30 docs/s;   6574 sec\n",
            "[2021-05-01 19:27:58,531 INFO] Step 69600/80000; xent: 1.66; lr: 0.0000076;  31 docs/s;   6608 sec\n",
            "[2021-05-01 19:28:32,725 INFO] Step 69650/80000; xent: 1.70; lr: 0.0000076;  31 docs/s;   6642 sec\n",
            "[2021-05-01 19:29:07,184 INFO] Step 69700/80000; xent: 1.62; lr: 0.0000076;  30 docs/s;   6676 sec\n",
            "[2021-05-01 19:29:28,102 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.128.bert.pt, number of examples: 2000\n",
            "[2021-05-01 19:29:41,854 INFO] Step 69750/80000; xent: 1.53; lr: 0.0000076;  30 docs/s;   6711 sec\n",
            "[2021-05-01 19:30:16,028 INFO] Step 69800/80000; xent: 1.61; lr: 0.0000076;  31 docs/s;   6745 sec\n",
            "[2021-05-01 19:30:49,978 INFO] Step 69850/80000; xent: 1.69; lr: 0.0000076;  30 docs/s;   6779 sec\n",
            "[2021-05-01 19:31:24,542 INFO] Step 69900/80000; xent: 1.39; lr: 0.0000076;  30 docs/s;   6814 sec\n",
            "[2021-05-01 19:31:39,740 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.104.bert.pt, number of examples: 2000\n",
            "[2021-05-01 19:31:58,751 INFO] Step 69950/80000; xent: 1.45; lr: 0.0000076;  30 docs/s;   6848 sec\n",
            "[2021-05-01 19:32:32,908 INFO] Step 70000/80000; xent: 1.61; lr: 0.0000076;  30 docs/s;   6882 sec\n",
            "[2021-05-01 19:32:32,925 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_70000.pt\n",
            "[2021-05-01 19:33:13,535 INFO] Step 70050/80000; xent: 1.66; lr: 0.0000076;  26 docs/s;   6923 sec\n",
            "[2021-05-01 19:33:48,506 INFO] Step 70100/80000; xent: 1.58; lr: 0.0000076;  29 docs/s;   6958 sec\n",
            "[2021-05-01 19:33:58,463 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.118.bert.pt, number of examples: 2001\n",
            "[2021-05-01 19:34:23,213 INFO] Step 70150/80000; xent: 1.46; lr: 0.0000076;  30 docs/s;   6992 sec\n",
            "[2021-05-01 19:34:57,274 INFO] Step 70200/80000; xent: 1.46; lr: 0.0000075;  31 docs/s;   7027 sec\n",
            "[2021-05-01 19:35:31,325 INFO] Step 70250/80000; xent: 1.51; lr: 0.0000075;  31 docs/s;   7061 sec\n",
            "[2021-05-01 19:36:05,953 INFO] Step 70300/80000; xent: 1.30; lr: 0.0000075;  30 docs/s;   7095 sec\n",
            "[2021-05-01 19:36:10,353 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.47.bert.pt, number of examples: 2000\n",
            "[2021-05-01 19:36:40,503 INFO] Step 70350/80000; xent: 1.38; lr: 0.0000075;  30 docs/s;   7130 sec\n",
            "[2021-05-01 19:37:14,632 INFO] Step 70400/80000; xent: 1.25; lr: 0.0000075;  30 docs/s;   7164 sec\n",
            "[2021-05-01 19:37:48,736 INFO] Step 70450/80000; xent: 1.30; lr: 0.0000075;  31 docs/s;   7198 sec\n",
            "[2021-05-01 19:38:22,418 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.8.bert.pt, number of examples: 2001\n",
            "[2021-05-01 19:38:23,893 INFO] Step 70500/80000; xent: 1.29; lr: 0.0000075;  30 docs/s;   7233 sec\n",
            "[2021-05-01 19:38:58,053 INFO] Step 70550/80000; xent: 1.39; lr: 0.0000075;  31 docs/s;   7267 sec\n",
            "[2021-05-01 19:39:32,023 INFO] Step 70600/80000; xent: 1.36; lr: 0.0000075;  30 docs/s;   7301 sec\n",
            "[2021-05-01 19:40:06,210 INFO] Step 70650/80000; xent: 1.46; lr: 0.0000075;  30 docs/s;   7335 sec\n",
            "[2021-05-01 19:40:34,241 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.11.bert.pt, number of examples: 2001\n",
            "[2021-05-01 19:40:41,355 INFO] Step 70700/80000; xent: 1.45; lr: 0.0000075;  29 docs/s;   7371 sec\n",
            "[2021-05-01 19:41:15,472 INFO] Step 70750/80000; xent: 1.46; lr: 0.0000075;  30 docs/s;   7405 sec\n",
            "[2021-05-01 19:41:49,622 INFO] Step 70800/80000; xent: 1.53; lr: 0.0000075;  31 docs/s;   7439 sec\n",
            "[2021-05-01 19:42:23,723 INFO] Step 70850/80000; xent: 1.39; lr: 0.0000075;  31 docs/s;   7473 sec\n",
            "[2021-05-01 19:42:46,421 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.66.bert.pt, number of examples: 2001\n",
            "[2021-05-01 19:42:58,417 INFO] Step 70900/80000; xent: 1.54; lr: 0.0000075;  30 docs/s;   7508 sec\n",
            "[2021-05-01 19:43:32,567 INFO] Step 70950/80000; xent: 1.59; lr: 0.0000075;  31 docs/s;   7542 sec\n",
            "[2021-05-01 19:44:06,728 INFO] Step 71000/80000; xent: 1.69; lr: 0.0000075;  30 docs/s;   7576 sec\n",
            "[2021-05-01 19:44:06,745 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_71000.pt\n",
            "[2021-05-01 19:44:46,940 INFO] Step 71050/80000; xent: 2.44; lr: 0.0000075;  26 docs/s;   7616 sec\n",
            "[2021-05-01 19:45:05,252 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.36.bert.pt, number of examples: 2001\n",
            "[2021-05-01 19:45:22,870 INFO] Step 71100/80000; xent: 2.19; lr: 0.0000075;  29 docs/s;   7652 sec\n",
            "[2021-05-01 19:45:57,201 INFO] Step 71150/80000; xent: 2.22; lr: 0.0000075;  31 docs/s;   7686 sec\n",
            "[2021-05-01 19:46:31,338 INFO] Step 71200/80000; xent: 2.22; lr: 0.0000075;  31 docs/s;   7721 sec\n",
            "[2021-05-01 19:47:05,341 INFO] Step 71250/80000; xent: 2.30; lr: 0.0000075;  30 docs/s;   7755 sec\n",
            "[2021-05-01 19:47:18,711 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.73.bert.pt, number of examples: 2001\n",
            "[2021-05-01 19:47:40,735 INFO] Step 71300/80000; xent: 2.32; lr: 0.0000075;  29 docs/s;   7790 sec\n",
            "[2021-05-01 19:48:15,255 INFO] Step 71350/80000; xent: 2.23; lr: 0.0000075;  30 docs/s;   7825 sec\n",
            "[2021-05-01 19:48:49,232 INFO] Step 71400/80000; xent: 2.37; lr: 0.0000075;  30 docs/s;   7858 sec\n",
            "[2021-05-01 19:49:23,402 INFO] Step 71450/80000; xent: 2.26; lr: 0.0000075;  30 docs/s;   7893 sec\n",
            "[2021-05-01 19:49:31,493 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.33.bert.pt, number of examples: 1997\n",
            "[2021-05-01 19:49:58,119 INFO] Step 71500/80000; xent: 2.25; lr: 0.0000075;  30 docs/s;   7927 sec\n",
            "[2021-05-01 19:50:32,672 INFO] Step 71550/80000; xent: 2.35; lr: 0.0000075;  30 docs/s;   7962 sec\n",
            "[2021-05-01 19:51:06,811 INFO] Step 71600/80000; xent: 2.22; lr: 0.0000075;  31 docs/s;   7996 sec\n",
            "[2021-05-01 19:51:40,823 INFO] Step 71650/80000; xent: 2.24; lr: 0.0000075;  31 docs/s;   8030 sec\n",
            "[2021-05-01 19:51:44,171 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.121.bert.pt, number of examples: 1999\n",
            "[2021-05-01 19:52:16,376 INFO] Step 71700/80000; xent: 2.23; lr: 0.0000075;  30 docs/s;   8066 sec\n",
            "[2021-05-01 19:52:50,904 INFO] Step 71750/80000; xent: 2.05; lr: 0.0000075;  30 docs/s;   8100 sec\n",
            "[2021-05-01 19:53:24,937 INFO] Step 71800/80000; xent: 2.05; lr: 0.0000075;  31 docs/s;   8134 sec\n",
            "[2021-05-01 19:53:58,262 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.136.bert.pt, number of examples: 1998\n",
            "[2021-05-01 19:54:01,795 INFO] Step 71850/80000; xent: 2.10; lr: 0.0000075;  28 docs/s;   8171 sec\n",
            "[2021-05-01 19:54:36,023 INFO] Step 71900/80000; xent: 2.28; lr: 0.0000075;  31 docs/s;   8205 sec\n",
            "[2021-05-01 19:55:10,555 INFO] Step 71950/80000; xent: 2.25; lr: 0.0000075;  30 docs/s;   8240 sec\n",
            "[2021-05-01 19:55:44,662 INFO] Step 72000/80000; xent: 2.26; lr: 0.0000075;  31 docs/s;   8274 sec\n",
            "[2021-05-01 19:55:44,678 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_72000.pt\n",
            "[2021-05-01 19:56:17,058 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.20.bert.pt, number of examples: 2000\n",
            "[2021-05-01 19:56:26,045 INFO] Step 72050/80000; xent: 2.16; lr: 0.0000075;  25 docs/s;   8315 sec\n",
            "[2021-05-01 19:57:00,248 INFO] Step 72100/80000; xent: 2.42; lr: 0.0000074;  30 docs/s;   8349 sec\n",
            "[2021-05-01 19:57:35,249 INFO] Step 72150/80000; xent: 2.17; lr: 0.0000074;  30 docs/s;   8384 sec\n",
            "[2021-05-01 19:58:09,223 INFO] Step 72200/80000; xent: 2.20; lr: 0.0000074;  31 docs/s;   8418 sec\n",
            "[2021-05-01 19:58:29,922 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.61.bert.pt, number of examples: 1999\n",
            "[2021-05-01 19:58:44,321 INFO] Step 72250/80000; xent: 2.28; lr: 0.0000074;  29 docs/s;   8454 sec\n",
            "[2021-05-01 19:59:18,460 INFO] Step 72300/80000; xent: 2.31; lr: 0.0000074;  30 docs/s;   8488 sec\n",
            "[2021-05-01 19:59:52,808 INFO] Step 72350/80000; xent: 2.31; lr: 0.0000074;  30 docs/s;   8522 sec\n",
            "[2021-05-01 20:00:26,960 INFO] Step 72400/80000; xent: 2.22; lr: 0.0000074;  31 docs/s;   8556 sec\n",
            "[2021-05-01 20:00:42,674 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.45.bert.pt, number of examples: 2000\n",
            "[2021-05-01 20:01:01,905 INFO] Step 72450/80000; xent: 2.17; lr: 0.0000074;  30 docs/s;   8591 sec\n",
            "[2021-05-01 20:01:35,997 INFO] Step 72500/80000; xent: 2.13; lr: 0.0000074;  31 docs/s;   8625 sec\n",
            "[2021-05-01 20:02:10,408 INFO] Step 72550/80000; xent: 2.20; lr: 0.0000074;  30 docs/s;   8660 sec\n",
            "[2021-05-01 20:02:44,605 INFO] Step 72600/80000; xent: 2.25; lr: 0.0000074;  30 docs/s;   8694 sec\n",
            "[2021-05-01 20:02:55,621 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.134.bert.pt, number of examples: 2000\n",
            "[2021-05-01 20:03:19,562 INFO] Step 72650/80000; xent: 2.16; lr: 0.0000074;  29 docs/s;   8729 sec\n",
            "[2021-05-01 20:03:53,678 INFO] Step 72700/80000; xent: 2.25; lr: 0.0000074;  30 docs/s;   8763 sec\n",
            "[2021-05-01 20:04:28,113 INFO] Step 72750/80000; xent: 2.20; lr: 0.0000074;  31 docs/s;   8797 sec\n",
            "[2021-05-01 20:05:02,424 INFO] Step 72800/80000; xent: 2.23; lr: 0.0000074;  31 docs/s;   8832 sec\n",
            "[2021-05-01 20:05:08,298 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.21.bert.pt, number of examples: 2001\n",
            "[2021-05-01 20:05:37,739 INFO] Step 72850/80000; xent: 2.38; lr: 0.0000074;  29 docs/s;   8867 sec\n",
            "[2021-05-01 20:06:11,613 INFO] Step 72900/80000; xent: 2.23; lr: 0.0000074;  31 docs/s;   8901 sec\n",
            "[2021-05-01 20:06:46,160 INFO] Step 72950/80000; xent: 2.23; lr: 0.0000074;  30 docs/s;   8935 sec\n",
            "[2021-05-01 20:07:20,244 INFO] Step 73000/80000; xent: 2.19; lr: 0.0000074;  30 docs/s;   8969 sec\n",
            "[2021-05-01 20:07:20,248 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_73000.pt\n",
            "[2021-05-01 20:07:27,271 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.43.bert.pt, number of examples: 2001\n",
            "[2021-05-01 20:08:01,592 INFO] Step 73050/80000; xent: 2.25; lr: 0.0000074;  26 docs/s;   9011 sec\n",
            "[2021-05-01 20:08:35,558 INFO] Step 73100/80000; xent: 2.28; lr: 0.0000074;  31 docs/s;   9045 sec\n",
            "[2021-05-01 20:09:10,084 INFO] Step 73150/80000; xent: 2.23; lr: 0.0000074;  30 docs/s;   9079 sec\n",
            "[2021-05-01 20:09:40,215 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.141.bert.pt, number of examples: 1998\n",
            "[2021-05-01 20:09:45,789 INFO] Step 73200/80000; xent: 2.21; lr: 0.0000074;  29 docs/s;   9115 sec\n",
            "[2021-05-01 20:10:19,939 INFO] Step 73250/80000; xent: 2.28; lr: 0.0000074;  30 docs/s;   9149 sec\n",
            "[2021-05-01 20:10:53,944 INFO] Step 73300/80000; xent: 2.30; lr: 0.0000074;  31 docs/s;   9183 sec\n",
            "[2021-05-01 20:11:28,185 INFO] Step 73350/80000; xent: 2.25; lr: 0.0000074;  31 docs/s;   9217 sec\n",
            "[2021-05-01 20:11:52,735 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.16.bert.pt, number of examples: 2001\n",
            "[2021-05-01 20:12:03,762 INFO] Step 73400/80000; xent: 2.24; lr: 0.0000074;  29 docs/s;   9253 sec\n",
            "[2021-05-01 20:12:37,892 INFO] Step 73450/80000; xent: 2.22; lr: 0.0000074;  31 docs/s;   9287 sec\n",
            "[2021-05-01 20:13:11,891 INFO] Step 73500/80000; xent: 2.24; lr: 0.0000074;  31 docs/s;   9321 sec\n",
            "[2021-05-01 20:13:46,075 INFO] Step 73550/80000; xent: 2.29; lr: 0.0000074;  30 docs/s;   9355 sec\n",
            "[2021-05-01 20:14:05,748 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.116.bert.pt, number of examples: 1997\n",
            "[2021-05-01 20:14:21,553 INFO] Step 73600/80000; xent: 2.38; lr: 0.0000074;  29 docs/s;   9391 sec\n",
            "[2021-05-01 20:14:55,683 INFO] Step 73650/80000; xent: 2.16; lr: 0.0000074;  30 docs/s;   9425 sec\n",
            "[2021-05-01 20:15:29,796 INFO] Step 73700/80000; xent: 2.24; lr: 0.0000074;  31 docs/s;   9459 sec\n",
            "[2021-05-01 20:16:03,949 INFO] Step 73750/80000; xent: 2.21; lr: 0.0000074;  30 docs/s;   9493 sec\n",
            "[2021-05-01 20:16:18,256 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.76.bert.pt, number of examples: 2001\n",
            "[2021-05-01 20:16:39,695 INFO] Step 73800/80000; xent: 2.14; lr: 0.0000074;  29 docs/s;   9529 sec\n",
            "[2021-05-01 20:17:13,948 INFO] Step 73850/80000; xent: 1.95; lr: 0.0000074;  30 docs/s;   9563 sec\n",
            "[2021-05-01 20:17:47,908 INFO] Step 73900/80000; xent: 1.95; lr: 0.0000074;  31 docs/s;   9597 sec\n",
            "[2021-05-01 20:18:22,073 INFO] Step 73950/80000; xent: 1.95; lr: 0.0000074;  30 docs/s;   9631 sec\n",
            "[2021-05-01 20:18:31,957 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.19.bert.pt, number of examples: 1999\n",
            "[2021-05-01 20:18:57,569 INFO] Step 74000/80000; xent: 2.27; lr: 0.0000074;  30 docs/s;   9667 sec\n",
            "[2021-05-01 20:18:57,586 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_74000.pt\n",
            "[2021-05-01 20:19:37,909 INFO] Step 74050/80000; xent: 2.56; lr: 0.0000073;  26 docs/s;   9707 sec\n",
            "[2021-05-01 20:20:12,098 INFO] Step 74100/80000; xent: 2.64; lr: 0.0000073;  30 docs/s;   9741 sec\n",
            "[2021-05-01 20:20:46,078 INFO] Step 74150/80000; xent: 2.68; lr: 0.0000073;  30 docs/s;   9775 sec\n",
            "[2021-05-01 20:20:50,924 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.107.bert.pt, number of examples: 1999\n",
            "[2021-05-01 20:21:22,765 INFO] Step 74200/80000; xent: 2.61; lr: 0.0000073;  28 docs/s;   9812 sec\n",
            "[2021-05-01 20:21:57,013 INFO] Step 74250/80000; xent: 2.59; lr: 0.0000073;  31 docs/s;   9846 sec\n",
            "[2021-05-01 20:22:30,882 INFO] Step 74300/80000; xent: 2.58; lr: 0.0000073;  31 docs/s;   9880 sec\n",
            "[2021-05-01 20:23:04,428 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.125.bert.pt, number of examples: 2000\n",
            "[2021-05-01 20:23:05,905 INFO] Step 74350/80000; xent: 2.64; lr: 0.0000073;  29 docs/s;   9915 sec\n",
            "[2021-05-01 20:23:40,415 INFO] Step 74400/80000; xent: 2.53; lr: 0.0000073;  30 docs/s;   9950 sec\n",
            "[2021-05-01 20:24:14,539 INFO] Step 74450/80000; xent: 2.52; lr: 0.0000073;  31 docs/s;   9984 sec\n",
            "[2021-05-01 20:24:48,688 INFO] Step 74500/80000; xent: 2.62; lr: 0.0000073;  30 docs/s;  10018 sec\n",
            "[2021-05-01 20:25:16,845 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.142.bert.pt, number of examples: 1996\n",
            "[2021-05-01 20:25:23,590 INFO] Step 74550/80000; xent: 2.56; lr: 0.0000073;  29 docs/s;  10053 sec\n",
            "[2021-05-01 20:25:58,182 INFO] Step 74600/80000; xent: 2.58; lr: 0.0000073;  30 docs/s;  10087 sec\n",
            "[2021-05-01 20:26:32,398 INFO] Step 74650/80000; xent: 2.67; lr: 0.0000073;  31 docs/s;  10122 sec\n",
            "[2021-05-01 20:27:06,504 INFO] Step 74700/80000; xent: 2.62; lr: 0.0000073;  30 docs/s;  10156 sec\n",
            "[2021-05-01 20:27:28,732 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.41.bert.pt, number of examples: 2000\n",
            "[2021-05-01 20:27:41,792 INFO] Step 74750/80000; xent: 2.52; lr: 0.0000073;  30 docs/s;  10191 sec\n",
            "[2021-05-01 20:28:16,194 INFO] Step 74800/80000; xent: 2.45; lr: 0.0000073;  30 docs/s;  10225 sec\n",
            "[2021-05-01 20:28:50,329 INFO] Step 74850/80000; xent: 2.56; lr: 0.0000073;  31 docs/s;  10260 sec\n",
            "[2021-05-01 20:29:24,512 INFO] Step 74900/80000; xent: 2.50; lr: 0.0000073;  31 docs/s;  10294 sec\n",
            "[2021-05-01 20:29:41,064 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.44.bert.pt, number of examples: 2000\n",
            "[2021-05-01 20:29:59,656 INFO] Step 74950/80000; xent: 2.51; lr: 0.0000073;  30 docs/s;  10329 sec\n",
            "[2021-05-01 20:30:34,302 INFO] Step 75000/80000; xent: 2.54; lr: 0.0000073;  30 docs/s;  10364 sec\n",
            "[2021-05-01 20:30:34,320 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_75000.pt\n",
            "[2021-05-01 20:31:15,407 INFO] Step 75050/80000; xent: 2.59; lr: 0.0000073;  25 docs/s;  10405 sec\n",
            "[2021-05-01 20:31:49,598 INFO] Step 75100/80000; xent: 2.57; lr: 0.0000073;  31 docs/s;  10439 sec\n",
            "[2021-05-01 20:32:00,392 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.95.bert.pt, number of examples: 2000\n",
            "[2021-05-01 20:32:24,423 INFO] Step 75150/80000; xent: 2.55; lr: 0.0000073;  30 docs/s;  10474 sec\n",
            "[2021-05-01 20:32:59,424 INFO] Step 75200/80000; xent: 2.52; lr: 0.0000073;  30 docs/s;  10509 sec\n",
            "[2021-05-01 20:33:33,662 INFO] Step 75250/80000; xent: 2.50; lr: 0.0000073;  31 docs/s;  10543 sec\n",
            "[2021-05-01 20:34:07,692 INFO] Step 75300/80000; xent: 2.56; lr: 0.0000073;  30 docs/s;  10577 sec\n",
            "[2021-05-01 20:34:13,999 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.79.bert.pt, number of examples: 2001\n",
            "[2021-05-01 20:34:42,790 INFO] Step 75350/80000; xent: 2.55; lr: 0.0000073;  30 docs/s;  10612 sec\n",
            "[2021-05-01 20:35:17,234 INFO] Step 75400/80000; xent: 2.52; lr: 0.0000073;  30 docs/s;  10646 sec\n",
            "[2021-05-01 20:35:51,595 INFO] Step 75450/80000; xent: 2.57; lr: 0.0000073;  31 docs/s;  10681 sec\n",
            "[2021-05-01 20:36:25,716 INFO] Step 75500/80000; xent: 2.64; lr: 0.0000073;  30 docs/s;  10715 sec\n",
            "[2021-05-01 20:36:26,645 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.110.bert.pt, number of examples: 2001\n",
            "[2021-05-01 20:37:00,963 INFO] Step 75550/80000; xent: 2.46; lr: 0.0000073;  30 docs/s;  10750 sec\n",
            "[2021-05-01 20:37:35,214 INFO] Step 75600/80000; xent: 2.51; lr: 0.0000073;  30 docs/s;  10784 sec\n",
            "[2021-05-01 20:38:09,533 INFO] Step 75650/80000; xent: 2.53; lr: 0.0000073;  30 docs/s;  10819 sec\n",
            "[2021-05-01 20:38:39,227 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.23.bert.pt, number of examples: 2001\n",
            "[2021-05-01 20:38:44,810 INFO] Step 75700/80000; xent: 2.54; lr: 0.0000073;  29 docs/s;  10854 sec\n",
            "[2021-05-01 20:39:18,706 INFO] Step 75750/80000; xent: 2.56; lr: 0.0000073;  31 docs/s;  10888 sec\n",
            "[2021-05-01 20:39:53,120 INFO] Step 75800/80000; xent: 2.50; lr: 0.0000073;  30 docs/s;  10922 sec\n",
            "[2021-05-01 20:40:27,466 INFO] Step 75850/80000; xent: 2.55; lr: 0.0000073;  30 docs/s;  10957 sec\n",
            "[2021-05-01 20:40:52,242 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.53.bert.pt, number of examples: 2000\n",
            "[2021-05-01 20:41:02,393 INFO] Step 75900/80000; xent: 2.59; lr: 0.0000073;  29 docs/s;  10992 sec\n",
            "[2021-05-01 20:41:36,610 INFO] Step 75950/80000; xent: 2.57; lr: 0.0000073;  30 docs/s;  11026 sec\n",
            "[2021-05-01 20:42:10,789 INFO] Step 76000/80000; xent: 2.54; lr: 0.0000073;  30 docs/s;  11060 sec\n",
            "[2021-05-01 20:42:10,807 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_76000.pt\n",
            "[2021-05-01 20:42:52,507 INFO] Step 76050/80000; xent: 2.53; lr: 0.0000073;  25 docs/s;  11102 sec\n",
            "[2021-05-01 20:43:12,503 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.27.bert.pt, number of examples: 1999\n",
            "[2021-05-01 20:43:28,372 INFO] Step 76100/80000; xent: 2.63; lr: 0.0000072;  29 docs/s;  11138 sec\n",
            "[2021-05-01 20:44:02,534 INFO] Step 76150/80000; xent: 2.62; lr: 0.0000072;  30 docs/s;  11172 sec\n",
            "[2021-05-01 20:44:36,832 INFO] Step 76200/80000; xent: 2.53; lr: 0.0000072;  30 docs/s;  11206 sec\n",
            "[2021-05-01 20:45:11,174 INFO] Step 76250/80000; xent: 2.61; lr: 0.0000072;  31 docs/s;  11240 sec\n",
            "[2021-05-01 20:45:25,006 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.14.bert.pt, number of examples: 1998\n",
            "[2021-05-01 20:45:46,341 INFO] Step 76300/80000; xent: 2.60; lr: 0.0000072;  29 docs/s;  11276 sec\n",
            "[2021-05-01 20:46:20,471 INFO] Step 76350/80000; xent: 2.62; lr: 0.0000072;  31 docs/s;  11310 sec\n",
            "[2021-05-01 20:46:54,530 INFO] Step 76400/80000; xent: 2.58; lr: 0.0000072;  30 docs/s;  11344 sec\n",
            "[2021-05-01 20:47:28,855 INFO] Step 76450/80000; xent: 2.52; lr: 0.0000072;  30 docs/s;  11378 sec\n",
            "[2021-05-01 20:47:38,030 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.82.bert.pt, number of examples: 2001\n",
            "[2021-05-01 20:48:04,126 INFO] Step 76500/80000; xent: 2.55; lr: 0.0000072;  29 docs/s;  11413 sec\n",
            "[2021-05-01 20:48:38,269 INFO] Step 76550/80000; xent: 2.57; lr: 0.0000072;  31 docs/s;  11448 sec\n",
            "[2021-05-01 20:49:12,372 INFO] Step 76600/80000; xent: 2.54; lr: 0.0000072;  30 docs/s;  11482 sec\n",
            "[2021-05-01 20:49:46,767 INFO] Step 76650/80000; xent: 2.62; lr: 0.0000072;  30 docs/s;  11516 sec\n",
            "[2021-05-01 20:49:51,135 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.18.bert.pt, number of examples: 2001\n",
            "[2021-05-01 20:50:21,760 INFO] Step 76700/80000; xent: 2.57; lr: 0.0000072;  30 docs/s;  11551 sec\n",
            "[2021-05-01 20:50:55,960 INFO] Step 76750/80000; xent: 2.57; lr: 0.0000072;  31 docs/s;  11585 sec\n",
            "[2021-05-01 20:51:30,110 INFO] Step 76800/80000; xent: 2.56; lr: 0.0000072;  31 docs/s;  11619 sec\n",
            "[2021-05-01 20:52:03,517 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.87.bert.pt, number of examples: 2000\n",
            "[2021-05-01 20:52:05,675 INFO] Step 76850/80000; xent: 2.55; lr: 0.0000072;  29 docs/s;  11655 sec\n",
            "[2021-05-01 20:52:39,891 INFO] Step 76900/80000; xent: 2.58; lr: 0.0000072;  30 docs/s;  11689 sec\n",
            "[2021-05-01 20:53:14,020 INFO] Step 76950/80000; xent: 2.53; lr: 0.0000072;  31 docs/s;  11723 sec\n",
            "[2021-05-01 20:53:48,031 INFO] Step 77000/80000; xent: 2.62; lr: 0.0000072;  30 docs/s;  11757 sec\n",
            "[2021-05-01 20:53:48,048 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_77000.pt\n",
            "[2021-05-01 20:54:23,899 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.2.bert.pt, number of examples: 2000\n",
            "[2021-05-01 20:54:31,684 INFO] Step 77050/80000; xent: 2.56; lr: 0.0000072;  23 docs/s;  11801 sec\n",
            "[2021-05-01 20:55:05,803 INFO] Step 77100/80000; xent: 2.57; lr: 0.0000072;  31 docs/s;  11835 sec\n",
            "[2021-05-01 20:55:39,924 INFO] Step 77150/80000; xent: 2.61; lr: 0.0000072;  30 docs/s;  11869 sec\n",
            "[2021-05-01 20:56:14,235 INFO] Step 77200/80000; xent: 2.62; lr: 0.0000072;  31 docs/s;  11903 sec\n",
            "[2021-05-01 20:56:37,325 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.69.bert.pt, number of examples: 2000\n",
            "[2021-05-01 20:56:49,886 INFO] Step 77250/80000; xent: 2.52; lr: 0.0000072;  29 docs/s;  11939 sec\n",
            "[2021-05-01 20:57:24,084 INFO] Step 77300/80000; xent: 2.61; lr: 0.0000072;  30 docs/s;  11973 sec\n",
            "[2021-05-01 20:57:58,160 INFO] Step 77350/80000; xent: 2.54; lr: 0.0000072;  31 docs/s;  12007 sec\n",
            "[2021-05-01 20:58:32,338 INFO] Step 77400/80000; xent: 2.55; lr: 0.0000072;  31 docs/s;  12042 sec\n",
            "[2021-05-01 20:58:49,667 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.25.bert.pt, number of examples: 1999\n",
            "[2021-05-01 20:59:07,920 INFO] Step 77450/80000; xent: 2.49; lr: 0.0000072;  30 docs/s;  12077 sec\n",
            "[2021-05-01 20:59:41,957 INFO] Step 77500/80000; xent: 2.57; lr: 0.0000072;  31 docs/s;  12111 sec\n",
            "[2021-05-01 21:00:16,066 INFO] Step 77550/80000; xent: 2.58; lr: 0.0000072;  30 docs/s;  12145 sec\n",
            "[2021-05-01 21:00:50,283 INFO] Step 77600/80000; xent: 2.60; lr: 0.0000072;  30 docs/s;  12180 sec\n",
            "[2021-05-01 21:01:01,964 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.22.bert.pt, number of examples: 2001\n",
            "[2021-05-01 21:01:25,592 INFO] Step 77650/80000; xent: 2.58; lr: 0.0000072;  29 docs/s;  12215 sec\n",
            "[2021-05-01 21:01:59,939 INFO] Step 77700/80000; xent: 2.63; lr: 0.0000072;  30 docs/s;  12249 sec\n",
            "[2021-05-01 21:02:34,050 INFO] Step 77750/80000; xent: 2.49; lr: 0.0000072;  31 docs/s;  12283 sec\n",
            "[2021-05-01 21:03:08,183 INFO] Step 77800/80000; xent: 2.44; lr: 0.0000072;  31 docs/s;  12317 sec\n",
            "[2021-05-01 21:03:15,001 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.127.bert.pt, number of examples: 2000\n",
            "[2021-05-01 21:03:43,483 INFO] Step 77850/80000; xent: 2.55; lr: 0.0000072;  29 docs/s;  12353 sec\n",
            "[2021-05-01 21:04:17,824 INFO] Step 77900/80000; xent: 2.55; lr: 0.0000072;  31 docs/s;  12387 sec\n",
            "[2021-05-01 21:04:51,707 INFO] Step 77950/80000; xent: 2.55; lr: 0.0000072;  30 docs/s;  12421 sec\n",
            "[2021-05-01 21:05:25,973 INFO] Step 78000/80000; xent: 2.55; lr: 0.0000072;  31 docs/s;  12455 sec\n",
            "[2021-05-01 21:05:25,976 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_78000.pt\n",
            "[2021-05-01 21:05:33,298 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.57.bert.pt, number of examples: 2000\n",
            "[2021-05-01 21:06:08,074 INFO] Step 78050/80000; xent: 2.49; lr: 0.0000072;  25 docs/s;  12497 sec\n",
            "[2021-05-01 21:06:42,631 INFO] Step 78100/80000; xent: 2.62; lr: 0.0000072;  30 docs/s;  12532 sec\n",
            "[2021-05-01 21:07:16,792 INFO] Step 78150/80000; xent: 2.60; lr: 0.0000072;  30 docs/s;  12566 sec\n",
            "[2021-05-01 21:07:46,410 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.99.bert.pt, number of examples: 2001\n",
            "[2021-05-01 21:07:52,009 INFO] Step 78200/80000; xent: 2.56; lr: 0.0000072;  30 docs/s;  12601 sec\n",
            "[2021-05-01 21:08:26,426 INFO] Step 78250/80000; xent: 2.51; lr: 0.0000071;  31 docs/s;  12636 sec\n",
            "[2021-05-01 21:09:00,727 INFO] Step 78300/80000; xent: 2.53; lr: 0.0000071;  30 docs/s;  12670 sec\n",
            "[2021-05-01 21:09:34,957 INFO] Step 78350/80000; xent: 2.62; lr: 0.0000071;  30 docs/s;  12704 sec\n",
            "[2021-05-01 21:09:58,893 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.65.bert.pt, number of examples: 2000\n",
            "[2021-05-01 21:10:09,960 INFO] Step 78400/80000; xent: 2.58; lr: 0.0000071;  29 docs/s;  12739 sec\n",
            "[2021-05-01 21:10:44,318 INFO] Step 78450/80000; xent: 2.55; lr: 0.0000071;  30 docs/s;  12774 sec\n",
            "[2021-05-01 21:11:18,627 INFO] Step 78500/80000; xent: 2.52; lr: 0.0000071;  31 docs/s;  12808 sec\n",
            "[2021-05-01 21:11:52,732 INFO] Step 78550/80000; xent: 2.48; lr: 0.0000071;  30 docs/s;  12842 sec\n",
            "[2021-05-01 21:12:10,532 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.119.bert.pt, number of examples: 1998\n",
            "[2021-05-01 21:12:27,718 INFO] Step 78600/80000; xent: 2.63; lr: 0.0000071;  30 docs/s;  12877 sec\n",
            "[2021-05-01 21:13:02,096 INFO] Step 78650/80000; xent: 2.60; lr: 0.0000071;  31 docs/s;  12911 sec\n",
            "[2021-05-01 21:13:36,344 INFO] Step 78700/80000; xent: 2.54; lr: 0.0000071;  31 docs/s;  12946 sec\n",
            "[2021-05-01 21:14:10,510 INFO] Step 78750/80000; xent: 2.62; lr: 0.0000071;  30 docs/s;  12980 sec\n",
            "[2021-05-01 21:14:22,914 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.70.bert.pt, number of examples: 1999\n",
            "[2021-05-01 21:14:45,617 INFO] Step 78800/80000; xent: 2.61; lr: 0.0000071;  30 docs/s;  13015 sec\n",
            "[2021-05-01 21:15:19,989 INFO] Step 78850/80000; xent: 2.45; lr: 0.0000071;  31 docs/s;  13049 sec\n",
            "[2021-05-01 21:15:54,343 INFO] Step 78900/80000; xent: 2.48; lr: 0.0000071;  30 docs/s;  13084 sec\n",
            "[2021-05-01 21:16:28,259 INFO] Step 78950/80000; xent: 2.48; lr: 0.0000071;  30 docs/s;  13118 sec\n",
            "[2021-05-01 21:16:35,818 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.54.bert.pt, number of examples: 2001\n",
            "[2021-05-01 21:17:03,967 INFO] Step 79000/80000; xent: 2.55; lr: 0.0000071;  30 docs/s;  13153 sec\n",
            "[2021-05-01 21:17:03,985 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_79000.pt\n",
            "[2021-05-01 21:17:44,951 INFO] Step 79050/80000; xent: 2.60; lr: 0.0000071;  25 docs/s;  13194 sec\n",
            "[2021-05-01 21:18:19,656 INFO] Step 79100/80000; xent: 2.49; lr: 0.0000071;  30 docs/s;  13229 sec\n",
            "[2021-05-01 21:18:53,526 INFO] Step 79150/80000; xent: 2.57; lr: 0.0000071;  30 docs/s;  13263 sec\n",
            "[2021-05-01 21:18:55,150 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.103.bert.pt, number of examples: 2001\n",
            "[2021-05-01 21:19:28,692 INFO] Step 79200/80000; xent: 2.60; lr: 0.0000071;  29 docs/s;  13298 sec\n",
            "[2021-05-01 21:20:02,889 INFO] Step 79250/80000; xent: 2.52; lr: 0.0000071;  31 docs/s;  13332 sec\n",
            "[2021-05-01 21:20:37,137 INFO] Step 79300/80000; xent: 2.58; lr: 0.0000071;  30 docs/s;  13366 sec\n",
            "[2021-05-01 21:21:08,105 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.1.bert.pt, number of examples: 2001\n",
            "[2021-05-01 21:21:12,301 INFO] Step 79350/80000; xent: 2.65; lr: 0.0000071;  30 docs/s;  13402 sec\n",
            "[2021-05-01 21:21:46,404 INFO] Step 79400/80000; xent: 2.60; lr: 0.0000071;  31 docs/s;  13436 sec\n",
            "[2021-05-01 21:22:20,617 INFO] Step 79450/80000; xent: 2.58; lr: 0.0000071;  31 docs/s;  13470 sec\n",
            "[2021-05-01 21:22:55,215 INFO] Step 79500/80000; xent: 2.55; lr: 0.0000071;  30 docs/s;  13504 sec\n",
            "[2021-05-01 21:23:20,599 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.3.bert.pt, number of examples: 2000\n",
            "[2021-05-01 21:23:30,303 INFO] Step 79550/80000; xent: 2.59; lr: 0.0000071;  30 docs/s;  13540 sec\n",
            "[2021-05-01 21:24:04,188 INFO] Step 79600/80000; xent: 2.53; lr: 0.0000071;  31 docs/s;  13573 sec\n",
            "[2021-05-01 21:24:38,371 INFO] Step 79650/80000; xent: 2.47; lr: 0.0000071;  31 docs/s;  13608 sec\n",
            "[2021-05-01 21:25:12,959 INFO] Step 79700/80000; xent: 2.54; lr: 0.0000071;  29 docs/s;  13642 sec\n",
            "[2021-05-01 21:25:33,387 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.10.bert.pt, number of examples: 2000\n",
            "[2021-05-01 21:25:47,834 INFO] Step 79750/80000; xent: 2.59; lr: 0.0000071;  29 docs/s;  13677 sec\n",
            "[2021-05-01 21:26:21,965 INFO] Step 79800/80000; xent: 2.53; lr: 0.0000071;  31 docs/s;  13711 sec\n",
            "[2021-05-01 21:26:56,060 INFO] Step 79850/80000; xent: 2.60; lr: 0.0000071;  30 docs/s;  13745 sec\n",
            "[2021-05-01 21:27:30,312 INFO] Step 79900/80000; xent: 2.65; lr: 0.0000071;  30 docs/s;  13780 sec\n",
            "[2021-05-01 21:27:46,319 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.78.bert.pt, number of examples: 2001\n",
            "[2021-05-01 21:28:05,571 INFO] Step 79950/80000; xent: 2.65; lr: 0.0000071;  29 docs/s;  13815 sec\n",
            "[2021-05-01 21:28:39,679 INFO] Step 80000/80000; xent: 2.63; lr: 0.0000071;  30 docs/s;  13849 sec\n",
            "[2021-05-01 21:28:39,697 INFO] Saving checkpoint ../data/trained_models/reberta_smaller/model_step_80000.pt\n",
            "[2021-05-01 21:28:48,391 INFO] Loading train dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.train.17.bert.pt, number of examples: 1999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTqfLWiHM4EA"
      },
      "source": [
        "## Testing with 2 layers (step 50000) 43.28/20.45/39.74\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hRLyqOiAGvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e388066-18b4-4887-fb19-f563b85279a0"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta_2layers.log -model_path ../data/trained_models/roberta_2layers -sep_optim true -use_interval false -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta2_cnndm -test_from ../data/trained_models/roberta_2layers/model_step_50000.pt -ext_layers 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-05-03 03:08:55,908 INFO] Loading checkpoint from ../data/trained_models/roberta_2layers/model_step_50000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta_2layers.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/roberta_2layers', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta2_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/roberta_2layers/model_step_50000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-05-03 03:08:58,420 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-03 03:08:59,007 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-03 03:08:59,761 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-03 03:09:17,287 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-05-03 03:09:17,293 INFO] * number of parameters: 135675905\n",
            "[2021-05-03 03:10:07,171 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:10:56,961 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:11:46,774 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:12:37,128 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:13:27,368 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-05-03 03:15:45,794 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-05-03 03:15:45,794 INFO] Writing summaries.\n",
            "2021-05-03 03:15:45,798 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmp18zmx8wf/system and model files to ../temp/tmp18zmx8wf/model.\n",
            "[2021-05-03 03:15:45,798 INFO] Processing summaries. Saving system files to ../temp/tmp18zmx8wf/system and model files to ../temp/tmp18zmx8wf/model.\n",
            "2021-05-03 03:15:45,799 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-03-03-14-03/candidate/.\n",
            "[2021-05-03 03:15:45,799 INFO] Processing files in ../temp/rouge-tmp-2021-05-03-03-14-03/candidate/.\n",
            "2021-05-03 03:17:14,711 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp18zmx8wf/system.\n",
            "[2021-05-03 03:17:14,711 INFO] Saved processed files to ../temp/tmp18zmx8wf/system.\n",
            "2021-05-03 03:17:14,712 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-03-03-14-03/reference/.\n",
            "[2021-05-03 03:17:14,712 INFO] Processing files in ../temp/rouge-tmp-2021-05-03-03-14-03/reference/.\n",
            "2021-05-03 03:18:44,350 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp18zmx8wf/model.\n",
            "[2021-05-03 03:18:44,350 INFO] Saved processed files to ../temp/tmp18zmx8wf/model.\n",
            "2021-05-03 03:18:44,551 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmp2pbfbw1n/rouge_conf.xml\n",
            "[2021-05-03 03:18:44,551 INFO] Written ROUGE configuration to ../temp/tmp2pbfbw1n/rouge_conf.xml\n",
            "2021-05-03 03:18:44,551 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp2pbfbw1n/rouge_conf.xml\n",
            "[2021-05-03 03:18:44,551 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp2pbfbw1n/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.53073 (95%-conf.int. 0.52799 - 0.53332)\n",
            "1 ROUGE-1 Average_P: 0.38784 (95%-conf.int. 0.38521 - 0.39053)\n",
            "1 ROUGE-1 Average_F: 0.43283 (95%-conf.int. 0.43059 - 0.43507)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.25063 (95%-conf.int. 0.24786 - 0.25352)\n",
            "1 ROUGE-2 Average_P: 0.18387 (95%-conf.int. 0.18149 - 0.18612)\n",
            "1 ROUGE-2 Average_F: 0.20453 (95%-conf.int. 0.20212 - 0.20694)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.48674 (95%-conf.int. 0.48407 - 0.48927)\n",
            "1 ROUGE-L Average_P: 0.35640 (95%-conf.int. 0.35373 - 0.35895)\n",
            "1 ROUGE-L Average_F: 0.39742 (95%-conf.int. 0.39513 - 0.39970)\n",
            "\n",
            "[2021-05-03 03:22:13,087 INFO] Rouges at step 50000 \n",
            ">> ROUGE-F(1/2/3/l): 43.28/20.45/39.74\n",
            "ROUGE-R(1/2/3/l): 53.07/25.06/48.67\n",
            "\n",
            "[2021-05-03 03:22:13,088 INFO] Validation xent: 5.13815 at step 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8udqH3yTWRc1"
      },
      "source": [
        "## Testing with 2 layers (step 49000) 43.39/20.52/39.82"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37BlWNO7SMca",
        "outputId": "6add3000-77b6-4fed-972c-2cdb67a84f01"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta_2layers.log -model_path ../data/trained_models/roberta_2layers -sep_optim true -use_interval false -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta2_cnndm -test_from ../data/trained_models/roberta_2layers/model_step_49000.pt -ext_layers 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-05-03 03:32:34,353 INFO] Loading checkpoint from ../data/trained_models/roberta_2layers/model_step_49000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta_2layers.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/roberta_2layers', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta2_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/roberta_2layers/model_step_49000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-05-03 03:32:37,004 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-03 03:32:37,006 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-03 03:32:37,763 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-03 03:32:44,539 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-05-03 03:32:44,544 INFO] * number of parameters: 135675905\n",
            "[2021-05-03 03:33:33,246 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:34:22,009 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:35:10,838 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:35:59,619 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:36:48,508 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-05-03 03:40:13,081 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-05-03 03:40:13,081 INFO] Writing summaries.\n",
            "2021-05-03 03:40:13,085 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmpdn89ke_4/system and model files to ../temp/tmpdn89ke_4/model.\n",
            "[2021-05-03 03:40:13,085 INFO] Processing summaries. Saving system files to ../temp/tmpdn89ke_4/system and model files to ../temp/tmpdn89ke_4/model.\n",
            "2021-05-03 03:40:13,085 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-03-03-37-24/candidate/.\n",
            "[2021-05-03 03:40:13,085 INFO] Processing files in ../temp/rouge-tmp-2021-05-03-03-37-24/candidate/.\n",
            "2021-05-03 03:41:43,412 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpdn89ke_4/system.\n",
            "[2021-05-03 03:41:43,412 INFO] Saved processed files to ../temp/tmpdn89ke_4/system.\n",
            "2021-05-03 03:41:43,413 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-03-03-37-24/reference/.\n",
            "[2021-05-03 03:41:43,413 INFO] Processing files in ../temp/rouge-tmp-2021-05-03-03-37-24/reference/.\n",
            "2021-05-03 03:43:14,046 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpdn89ke_4/model.\n",
            "[2021-05-03 03:43:14,046 INFO] Saved processed files to ../temp/tmpdn89ke_4/model.\n",
            "2021-05-03 03:43:14,247 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpaje3y2va/rouge_conf.xml\n",
            "[2021-05-03 03:43:14,247 INFO] Written ROUGE configuration to ../temp/tmpaje3y2va/rouge_conf.xml\n",
            "2021-05-03 03:43:14,247 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpaje3y2va/rouge_conf.xml\n",
            "[2021-05-03 03:43:14,247 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpaje3y2va/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.53566 (95%-conf.int. 0.53307 - 0.53830)\n",
            "1 ROUGE-1 Average_P: 0.38651 (95%-conf.int. 0.38382 - 0.38907)\n",
            "1 ROUGE-1 Average_F: 0.43390 (95%-conf.int. 0.43157 - 0.43604)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.25316 (95%-conf.int. 0.25031 - 0.25607)\n",
            "1 ROUGE-2 Average_P: 0.18330 (95%-conf.int. 0.18084 - 0.18568)\n",
            "1 ROUGE-2 Average_F: 0.20518 (95%-conf.int. 0.20271 - 0.20755)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.49105 (95%-conf.int. 0.48841 - 0.49365)\n",
            "1 ROUGE-L Average_P: 0.35498 (95%-conf.int. 0.35239 - 0.35751)\n",
            "1 ROUGE-L Average_F: 0.39821 (95%-conf.int. 0.39591 - 0.40035)\n",
            "\n",
            "[2021-05-03 03:48:51,450 INFO] Rouges at step 49000 \n",
            ">> ROUGE-F(1/2/3/l): 43.39/20.52/39.82\n",
            "ROUGE-R(1/2/3/l): 53.57/25.32/49.10\n",
            "\n",
            "[2021-05-03 03:48:51,450 INFO] Validation xent: 5.12755 at step 49000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZScGsnkVyOj",
        "outputId": "f216ae1a-ab27-425d-bcab-5f24682da0f0"
      },
      "source": [
        "!python3 train.py -task ext -mode test -batch_size 3000 -test_batch_size 500 -bert_data_path ../data/preprocessed_data/roberta_cnndm/tokenized -log_file ../logs/test_my_roberta_2layers.log -model_path ../data/trained_models/roberta_2layers -sep_optim true -use_interval false -visible_gpus 1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/my_roberta2_cnndm -test_from ../data/trained_models/roberta_2layers/model_step_48000.pt -ext_layers 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  0\n",
            "Testing...\n",
            "device:  cuda\n",
            "[2021-05-03 03:48:55,184 INFO] Loading checkpoint from ../data/trained_models/roberta_2layers/model_step_48000.pt\n",
            "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../data/preprocessed_data/roberta_cnndm/tokenized', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='roberta', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/test_my_roberta_2layers.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../data/trained_models/roberta_2layers', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/my_roberta2_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../data/trained_models/roberta_2layers/model_step_48000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
            "[2021-05-03 03:49:18,566 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at ../temp/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n",
            "[2021-05-03 03:49:18,567 INFO] Model config {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[2021-05-03 03:49:19,306 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at ../temp/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
            "[2021-05-03 03:49:26,119 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.0.bert.pt, number of examples: 2001\n",
            "gpu_rank 0\n",
            "[2021-05-03 03:49:26,124 INFO] * number of parameters: 135675905\n",
            "[2021-05-03 03:50:14,848 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.1.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:51:03,658 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.2.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:51:52,511 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.3.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:52:41,311 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.4.bert.pt, number of examples: 2001\n",
            "[2021-05-03 03:53:30,228 INFO] Loading test dataset from ../data/preprocessed_data/roberta_cnndm/tokenized.test.5.bert.pt, number of examples: 1485\n",
            "11490\n",
            "11490\n",
            "2021-05-03 03:56:57,904 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2021-05-03 03:56:57,904 INFO] Writing summaries.\n",
            "2021-05-03 03:56:57,908 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmp568siscp/system and model files to ../temp/tmp568siscp/model.\n",
            "[2021-05-03 03:56:57,908 INFO] Processing summaries. Saving system files to ../temp/tmp568siscp/system and model files to ../temp/tmp568siscp/model.\n",
            "2021-05-03 03:56:57,909 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-03-03-54-06/candidate/.\n",
            "[2021-05-03 03:56:57,909 INFO] Processing files in ../temp/rouge-tmp-2021-05-03-03-54-06/candidate/.\n",
            "2021-05-03 03:58:29,385 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp568siscp/system.\n",
            "[2021-05-03 03:58:29,385 INFO] Saved processed files to ../temp/tmp568siscp/system.\n",
            "2021-05-03 03:58:29,386 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2021-05-03-03-54-06/reference/.\n",
            "[2021-05-03 03:58:29,386 INFO] Processing files in ../temp/rouge-tmp-2021-05-03-03-54-06/reference/.\n",
            "2021-05-03 04:00:00,008 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp568siscp/model.\n",
            "[2021-05-03 04:00:00,008 INFO] Saved processed files to ../temp/tmp568siscp/model.\n",
            "2021-05-03 04:00:00,206 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmp58omupyx/rouge_conf.xml\n",
            "[2021-05-03 04:00:00,206 INFO] Written ROUGE configuration to ../temp/tmp58omupyx/rouge_conf.xml\n",
            "2021-05-03 04:00:00,206 [MainThread  ] [INFO ]  Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp58omupyx/rouge_conf.xml\n",
            "[2021-05-03 04:00:00,206 INFO] Running ROUGE with command /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /content/drive/.shortcut-targets-by-id/13NCxThpoCnV67kBccYli2itah05-zt7J/nn4nlp_project/files/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp58omupyx/rouge_conf.xml\n",
            "---------------------------------------------\n",
            "1 ROUGE-1 Average_R: 0.53267 (95%-conf.int. 0.52998 - 0.53527)\n",
            "1 ROUGE-1 Average_P: 0.38628 (95%-conf.int. 0.38360 - 0.38876)\n",
            "1 ROUGE-1 Average_F: 0.43256 (95%-conf.int. 0.43033 - 0.43465)\n",
            "---------------------------------------------\n",
            "1 ROUGE-2 Average_R: 0.25084 (95%-conf.int. 0.24813 - 0.25360)\n",
            "1 ROUGE-2 Average_P: 0.18280 (95%-conf.int. 0.18036 - 0.18509)\n",
            "1 ROUGE-2 Average_F: 0.20396 (95%-conf.int. 0.20157 - 0.20626)\n",
            "---------------------------------------------\n",
            "1 ROUGE-L Average_R: 0.48784 (95%-conf.int. 0.48526 - 0.49042)\n",
            "1 ROUGE-L Average_P: 0.35450 (95%-conf.int. 0.35192 - 0.35692)\n",
            "1 ROUGE-L Average_F: 0.39664 (95%-conf.int. 0.39447 - 0.39880)\n",
            "\n",
            "[2021-05-03 04:05:38,886 INFO] Rouges at step 48000 \n",
            ">> ROUGE-F(1/2/3/l): 43.26/20.40/39.66\n",
            "ROUGE-R(1/2/3/l): 53.27/25.08/48.78\n",
            "\n",
            "[2021-05-03 04:05:38,886 INFO] Validation xent: 5.13128 at step 48000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA9IfCqJ3aQX"
      },
      "source": [
        "#ls -1 | wc -l\n",
        "#!mv dm/*.story .\n",
        "#!find dm -name '*.story' -exec mv {} . \\;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2_V5HGKl9Vy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "72984ee1-66f7-466f-df8c-c5c0f1c46f1e"
      },
      "source": [
        "while True: pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-b16dc615ea65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}